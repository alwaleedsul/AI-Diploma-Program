{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. cuDF Import/Export and GPU Acceleration | Ø§Ø³ØªÙŠØ±Ø§Ø¯/ØªØµØ¯ÙŠØ± cuDF ÙˆØªØ³Ø±ÙŠØ¹ GPU\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Import and export data in different formats using cuDF functions\n",
    "- Use GPU acceleration from cuDF to process data faster\n",
    "- Compare cuDF performance with Pandas\n",
    "- Optimize data processing using GPU acceleration\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Examples 01â€“06 (data loading through EDA)\n",
    "- âœ… Understanding of Pandas basics\n",
    "- âœ… CUDA-capable GPU (optional, but recommended)\n",
    "\n",
    "**Leads to:** Example 08 (Feature extraction); Unit 3, Unit 4.\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 05, Unit 2**:\n",
    "- Import/Export using cuDF: Importing and exporting data in different formats using cuDF functions\n",
    "- Optimization using cuDF: Using GPU acceleration from cuDF to process data faster\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 2 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to cuDF\n",
    "\n",
    "**cuDF** is a GPU-accelerated DataFrame library that provides a pandas-like API for working with data on GPUs. It's part of the RAPIDS ecosystem and can significantly speed up data processing operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:19:14.714535Z",
     "iopub.status.busy": "2026-01-24T16:19:14.714463Z",
     "iopub.status.idle": "2026-01-24T16:19:14.718471Z",
     "shell.execute_reply": "2026-01-24T16:19:14.718298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’» Running on local machine\n",
      "   For Colab setup, see: DOCS/COLAB_SETUP.md\n"
     ]
    }
   ],
   "source": [
    "ðŸš€ Google Colab Setup (Run this first if using Colab)\n",
    "Ø¯Ù„ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯ Google Colab (Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Colab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:19:14.730459Z",
     "iopub.status.busy": "2026-01-24T16:19:14.730381Z",
     "iopub.status.idle": "2026-01-24T16:19:14.903236Z",
     "shell.execute_reply": "2026-01-24T16:19:14.903036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  cuDF not available. Install RAPIDS for GPU acceleration:\n",
      "   Note: Requires CUDA-capable GPU and RAPIDS installation\n",
      "   Continuing with Pandas examples...\n",
      "âœ… Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "# Try importing cuDF (requires CUDA and RAPIDS installation)\n",
    "try:\n",
    "    import cudf\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    CUDF_AVAILABLE = True\n",
    "    print(\"âœ… cuDF imported successfully!\")\n",
    "    print(f\"cuDF version: {cudf.__version__}\")\n",
    "except ImportError:\n",
    "    CUDF_AVAILABLE = False\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    print(\"âš ï¸  cuDF not available. Install RAPIDS for GPU acceleration:\")\n",
    "    print(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\")\n",
    "    print(\"   Continuing with Pandas examples...\")\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Import with cuDF\n",
    "\n",
    "cuDF supports importing data from CSV, Parquet, JSON, and other formats, similar to Pandas but with GPU acceleration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:19:14.904249Z",
     "iopub.status.busy": "2026-01-24T16:19:14.904172Z",
     "iopub.status.idle": "2026-01-24T16:19:14.921965Z",
     "shell.execute_reply": "2026-01-24T16:19:14.921758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample CSV file created\n",
      "\n",
      "============================================================\n",
      "Importing with Pandas (CPU):\n",
      "============================================================\n",
      "DataFrame shape: (10000, 4)\n",
      "\n",
      "First few rows:\n",
      "   id    value1  value2 category\n",
      "0   0 -0.310255      12        A\n",
      "1   1  0.283642      10        B\n",
      "2   2  0.549608      28        B\n",
      "3   3  0.368518      39        C\n",
      "4   4 -0.154028      32        A\n"
     ]
    }
   ],
   "source": [
    "# Generate sample data for demonstration\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': range(10000), 'value1': np.random.randn(10000),\n",
    "    'value2': np.random.randint(1, 100, 10000),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 10000)\n",
    "})\n",
    "\n",
    "# Save to CSV for demonstration\n",
    "sample_data.to_csv('sample_data_cudf.csv', index=False)\n",
    "print(\"âœ… Sample CSV file created\")\n",
    "\n",
    "if CUDF_AVAILABLE:\n",
    "    # Import with cuDF (GPU-accelerated)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Importing with cuDF (GPU-accelerated):\")\n",
    "    print(\"=\" * 60)\n",
    "    df_cudf = cudf.read_csv('sample_data_cudf.csv')\n",
    "    print(f\"DataFrame shape: {df_cudf.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df_cudf.head())\n",
    "    \n",
    "    # Import with Pandas (CPU)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Importing with Pandas (CPU):\")\n",
    "    print(\"=\" * 60)\n",
    "    df_pandas = pd.read_csv('sample_data_cudf.csv')\n",
    "    print(f\"DataFrame shape: {df_pandas.shape}\")\n",
    "else:\n",
    "    # Demonstrate with Pandas\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Importing with Pandas (CPU):\")\n",
    "    print(\"=\" * 60)\n",
    "    df_pandas = pd.read_csv('sample_data_cudf.csv')\n",
    "    print(f\"DataFrame shape: {df_pandas.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df_pandas.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Export with cuDF\n",
    "\n",
    "Exporting data to different formats (CSV, Parquet, JSON) using cuDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:19:14.922917Z",
     "iopub.status.busy": "2026-01-24T16:19:14.922868Z",
     "iopub.status.idle": "2026-01-24T16:19:14.931613Z",
     "shell.execute_reply": "2026-01-24T16:19:14.931438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Exporting with Pandas:\n",
      "============================================================\n",
      "âœ… Exported to CSV: output_pandas.csv\n",
      "\n",
      "Note: Install cuDF/RAPIDS for GPU-accelerated export and Parquet support\n"
     ]
    }
   ],
   "source": [
    "if CUDF_AVAILABLE:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Exporting with cuDF:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Export to CSV\n",
    "    df_cudf.to_csv('output_cudf.csv', index=False)\n",
    "    print(\"âœ… Exported to CSV: output_cudf.csv\")\n",
    "    \n",
    "    # Export to Parquet (efficient format, good for cuDF)\n",
    "    df_cudf.to_parquet('output_cudf.parquet')\n",
    "    print(\"âœ… Exported to Parquet: output_cudf.parquet\")\n",
    "    \n",
    "    # Note: cuDF also supports JSON, ORC, and other formats\n",
    "    print(\"\\nNote: cuDF supports CSV, Parquet, JSON, ORC, and other formats\")\n",
    "    print(\"Parquet format is often preferred for large datasets due to compression and speed\")\n",
    "else:\n",
    "    # Demonstrate with Pandas\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Exporting with Pandas:\")\n",
    "    print(\"=\" * 60)\n",
    "    df_pandas.to_csv('output_pandas.csv', index=False)\n",
    "    print(\"âœ… Exported to CSV: output_pandas.csv\")\n",
    "    print(\"\\nNote: Install cuDF/RAPIDS for GPU-accelerated export and Parquet support\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: GPU Acceleration Performance Comparison\n",
    "\n",
    "Let's compare cuDF (GPU) vs Pandas (CPU) performance for common operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:19:14.932500Z",
     "iopub.status.busy": "2026-01-24T16:19:14.932438Z",
     "iopub.status.idle": "2026-01-24T16:19:14.937904Z",
     "shell.execute_reply": "2026-01-24T16:19:14.937735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU Acceleration Benefits:\n",
      "============================================================\n",
      "\n",
      "    cuDF (GPU-accelerated) provides:\n",
      "    - 10-100x faster data processing for large datasets\n",
      "    - Efficient memory usage on GPU\n",
      "    - Seamless integration with other RAPIDS libraries\n",
      "    - pandas-like API for easy migration\n",
      "    \n",
      "    Use cases:\n",
      "    - Large-scale data cleaning and transformation\n",
      "    - Real-time data processing pipelines\n",
      "    - Accelerated exploratory data analysis\n",
      "    \n",
      "    Requirements:\n",
      "    - CUDA-capable NVIDIA GPU\n",
      "    - RAPIDS installation\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Create larger dataset for performance comparison\n",
    "large_data = pd.DataFrame({\n",
    "    'id': range(100000), 'value1': np.random.randn(100000),\n",
    "    'value2': np.random.randint(1, 1000, 100000),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], 100000)\n",
    "})\n",
    "\n",
    "if CUDF_AVAILABLE:\n",
    "    # Convert to cuDF\n",
    "    large_cudf = cudf.from_pandas(large_data)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Performance Comparison: cuDF (GPU) vs Pandas (CPU)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Operation 1: Filtering\n",
    "    print(\"\\n1. Filtering operations:\")\n",
    "    start = time.time()\n",
    "    filtered_cudf = large_cudf[large_cudf['value2'] > 500]\n",
    "    cudf_time = time.time() - start\n",
    "    print(f\"   cuDF (GPU): {cudf_time:.4f} seconds\")\n",
    "    \n",
    "    start = time.time()\n",
    "    filtered_pandas = large_data[large_data['value2'] > 500]\n",
    "    pandas_time = time.time() - start\n",
    "    print(f\"   Pandas (CPU): {pandas_time:.4f} seconds\")\n",
    "    print(f\"   Speedup: {pandas_time/cudf_time:.2f}x faster with cuDF\")\n",
    "    \n",
    "    # Operation 2: Groupby\n",
    "    print(\"\\n2. Groupby operations:\")\n",
    "    start = time.time()\n",
    "    grouped_cudf = large_cudf.groupby('category').mean()\n",
    "    cudf_time = time.time() - start\n",
    "    print(f\"   cuDF (GPU): {cudf_time:.4f} seconds\")\n",
    "    \n",
    "    start = time.time()\n",
    "    grouped_pandas = large_data.groupby('category').mean()\n",
    "    pandas_time = time.time() - start\n",
    "    print(f\"   Pandas (CPU): {pandas_time:.4f} seconds\")\n",
    "    print(f\"   Speedup: {pandas_time/cudf_time:.2f}x faster with cuDF\")\n",
    "    \n",
    "    print(\"\\nâœ… GPU acceleration provides significant speedup for large datasets!\")\n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GPU Acceleration Benefits:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\"\"\n",
    "    cuDF (GPU-accelerated) provides:\n",
    "    - 10-100x faster data processing for large datasets\n",
    "    - Efficient memory usage on GPU\n",
    "    - Seamless integration with other RAPIDS libraries\n",
    "    - pandas-like API for easy migration\n",
    "    \n",
    "    Use cases:\n",
    "    - Large-scale data cleaning and transformation\n",
    "    - Real-time data processing pipelines\n",
    "    - Accelerated exploratory data analysis\n",
    "    \n",
    "    Requirements:\n",
    "    - CUDA-capable NVIDIA GPU\n",
    "    - RAPIDS installation\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **cuDF**: GPU-accelerated DataFrame library with pandas-like API\n",
    "2. **Import/Export**: Supports CSV, Parquet, JSON, ORC formats\n",
    "3. **GPU Acceleration**: 10-100x faster for large datasets\n",
    "4. **Use Cases**: Large-scale data processing, real-time pipelines, accelerated EDA\n",
    "\n",
    "### Benefits:\n",
    "- Significant performance improvements for large datasets\n",
    "- Seamless pandas API compatibility\n",
    "- Integration with RAPIDS ecosystem\n",
    "- Efficient GPU memory utilization\n",
    "\n",
    "**Reference:** Course 05, Unit 2: \"Import/Export using cuDF\" and \"Optimization using cuDF: Using GPU acceleration\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}