{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Feature Transformation: Scaling and Encoding | ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª: Ø§Ù„Ù‚ÙŠØ§Ø³ ÙˆØ§Ù„ØªØ´ÙÙŠØ±\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Transform features using scaling techniques\n",
    "- Encode categorical variables for machine learning\n",
    "- Scale numerical features (StandardScaler, MinMaxScaler)\n",
    "- Encode categorical features (Label, One-Hot encoding)\n",
    "- Prepare data for ML models\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Example 1: Data Loading (need to load data first)\n",
    "- âœ… Example 2: Missing Values & Duplicates (clean data first)\n",
    "- âœ… Understanding of pandas DataFrames\n",
    "- âœ… Basic scikit-learn knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 05, Unit 2**:\n",
    "- Feature Transformation: Transforming data (e.g., scaling, encoding) to prepare it for analysis\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 2 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 1: Data Loading** - You need data loaded first!\n",
    "- âœ… **Example 2: Missing Values** - Data should be cleaned!\n",
    "- âœ… **Understanding of data types**: Numerical vs categorical features\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding when to scale vs encode\n",
    "- Knowing which transformation to use\n",
    "- Understanding why transformations are needed\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is part of Unit 2: Data Cleaning and Preparation**\n",
    "\n",
    "**Why feature transformation?**\n",
    "- **Before** building ML models, features need to be in the right format\n",
    "- **After** cleaning data, we transform it for analysis\n",
    "- **Scaling**: Makes numerical features comparable (age: 0-100, income: 0-100000)\n",
    "- **Encoding**: Converts categories to numbers (red/blue/green â†’ 0/1/2)\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Example 2: Missing Values (clean data first)\n",
    "- ğŸ““ Data cleaning techniques\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Example 5: EDA Visualizations (explore distributions and relationships)\n",
    "- ğŸ““ Example 6: Statistical EDA (summaries, correlations)\n",
    "- ğŸ““ Unit 4: Machine Learning (transformed data is ready for models!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Transformation prepares data for ML (essential step)\n",
    "2. Scaling ensures features are comparable\n",
    "3. Encoding converts categories to numbers (ML needs numbers)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Preparing Ingredients for Cooking | Ø§Ù„Ù‚ØµØ©: ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù„Ù„Ø·Ø¨Ø®\n",
    "\n",
    "Imagine you're cooking. **Before** you can cook, you need to prepare ingredients - cut vegetables to same size (scaling), convert different units to same measure (encoding). **After** preparing properly, all ingredients are ready to cook together!\n",
    "\n",
    "Same with data: **Before** machine learning, we transform features - scale numbers to same range, encode categories to numbers. **After** transforming, all features are ready for models!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Feature Transformation Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
    "\n",
    "Feature transformation is essential because:\n",
    "- **Scaling**: Makes features comparable (prevents one feature from dominating)\n",
    "- **Encoding**: Converts categories to numbers (ML algorithms need numbers)\n",
    "- **Performance**: Properly transformed data improves model performance\n",
    "- **Accuracy**: Scaling helps distance-based algorithms (KNN, SVM)\n",
    "\n",
    "**Common Student Questions:**\n",
    "- **Q: When do I scale vs encode?**\n",
    "  - Answer: Scale numerical features, encode categorical features\n",
    "  - Example: Age (numerical) â†’ scale, Color (categorical) â†’ encode\n",
    "  - Rule: Numbers â†’ scale, Categories â†’ encode\n",
    "  \n",
    "- **Q: Which scaler should I use?**\n",
    "  - Answer: StandardScaler for normal distributions, MinMaxScaler for bounded ranges\n",
    "  - Example: StandardScaler: mean=0, std=1; MinMaxScaler: range [0,1]\n",
    "  - Tip: Try both and see which works better for your data\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Feature transformation** prepares data for analysis by scaling numerical features and encoding categorical variables. This is essential for machine learning, as models require features in specific formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Inputs & ğŸ“¤ Outputs | Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª\n",
    "\n",
    "**Inputs:** What we use in this notebook\n",
    "\n",
    "- Raw features\n- pandas, sklearn (scaling, encoding)\n",
    "\n",
    "**Outputs:** What you'll see when you run the cells\n",
    "\n",
    "- Scaled/encoded features\n- Printed results\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PART 1: SCALING NUMERICAL FEATURES | Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n# ============================================================================\nprint(\"\\nğŸ“Š PART 1: Scaling Numerical Features | Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\")\nprint(\"-\" * 70)\n\n# Create sample data with different scales\nprint(\"\\nâœ… Example: Data with Different Scales\")\nprint(\"-\" * 70)\n\ndata = pd.DataFrame({\n    'age': [25, 30, 35, 40, 45],  # Range: 20-50\n    'income': [30000, 50000, 70000, 90000, 110000],  # Range: 30000-110000\n    'score': [0.1, 0.3, 0.5, 0.7, 0.9]  # Range: 0-1\n})\n\nprint(\"Original data (different scales):\")\nprint(data)\nprint(\"\\nProblem: Age (0-50) vs Income (0-110000) - different scales!\")\nprint(\"Solution: Scale all features to same range\")\n\n# StandardScaler (mean=0, std=1)\nprint(\"\\nâœ… Method 1: StandardScaler (mean=0, std=1)\")\nprint(\"-\" * 70)\nscaler_standard = StandardScaler()\ndata_scaled_standard = pd.DataFrame(\n    scaler_standard.fit_transform(data[['age', 'income', 'score']]),\n    columns=['age', 'income', 'score']\n)\nprint(\"Scaled data (StandardScaler):\")\nprint(data_scaled_standard)\nprint(f\"\\nMean: {data_scaled_standard.mean().values}\")\nprint(f\"Std: {data_scaled_standard.std().values}\")\n\n# MinMaxScaler (range [0, 1])\nprint(\"\\nâœ… Method 2: MinMaxScaler (range [0, 1])\")\nprint(\"-\" * 70)\nscaler_minmax = MinMaxScaler()\ndata_scaled_minmax = pd.DataFrame(\n    scaler_minmax.fit_transform(data[['age', 'income', 'score']]),\n    columns=['age', 'income', 'score']\n)\nprint(\"Scaled data (MinMaxScaler):\")\nprint(data_scaled_minmax)\nprint(f\"\\nMin: {data_scaled_minmax.min().values}\")\nprint(f\"Max: {data_scaled_minmax.max().values}\")\n\n# ============================================================================\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PART 2: ENCODING CATEGORICAL FEATURES | ØªØ´ÙÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"PART 2: Encoding Categorical Features | ØªØ´ÙÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\")\nprint(\"=\" * 70)\n\n# Create sample categorical data\nprint(\"\\nâœ… Example: Categorical Data\")\nprint(\"-\" * 70)\n\ncat_data = pd.DataFrame({\n    'color': ['red', 'blue', 'green', 'red', 'blue'],\n    'size': ['small', 'medium', 'large', 'small', 'large'],\n    'category': ['A', 'B', 'A', 'C', 'B']\n})\n\nprint(\"Original categorical data:\")\nprint(cat_data)\nprint(\"\\nProblem: ML algorithms need numbers, not text!\")\nprint(\"Solution: Encode categories to numbers\")\n\n# Label Encoding (for ordinal data)\nprint(\"\\nâœ… Method 1: Label Encoding (ordinal categories)\")\nprint(\"-\" * 70)\nlabel_encoder = LabelEncoder()\ncat_data['size_encoded'] = label_encoder.fit_transform(cat_data['size'])\nprint(\"Label encoded 'size' (small=0, medium=1, large=2):\")\nprint(cat_data[['size', 'size_encoded']])\nprint(\"\\nğŸ’¡ Use for: Ordinal categories (small < medium < large)\")\n\n# One-Hot Encoding (for nominal data)\nprint(\"\\nâœ… Method 2: One-Hot Encoding (nominal categories)\")\nprint(\"-\" * 70)\nonehot_encoded = pd.get_dummies(cat_data[['color']], prefix='color')\nprint(\"One-Hot encoded 'color':\")\nprint(onehot_encoded)\nprint(\"\\nğŸ’¡ Use for: Nominal categories (red â‰  blue â‰  green, no order)\")\n\n# ============================================================================\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PART 3: REAL-WORLD EXAMPLE | Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÙŠ\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"PART 3: Real-World Example | Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÙŠ\")\nprint(\"=\" * 70)\n\n# Create realistic dataset\nprint(\"\\nğŸ“Š Example: Prepare Data for ML Model\")\nprint(\"-\" * 70)\n\nml_data = pd.DataFrame({\n    'age': [25, 30, 35, 40, 45, 50],\n    'salary': [30000, 50000, 70000, 90000, 110000, 130000],\n    'city': ['Riyadh', 'Jeddah', 'Riyadh', 'Dammam', 'Jeddah', 'Riyadh'],\n    'experience_years': [2, 5, 8, 12, 15, 20]\n})\n\nprint(\"Original data:\")\nprint(ml_data)\n\n# Scale numerical features\nnumerical_cols = ['age', 'salary', 'experience_years']\nscaler = StandardScaler()\nml_data[numerical_cols] = scaler.fit_transform(ml_data[numerical_cols])\n\n# Encode categorical features\nml_data = pd.get_dummies(ml_data, columns=['city'], prefix='city')\n\nprint(\"\\nTransformed data (ready for ML):\")\nprint(ml_data)\nprint(\"\\nâœ… All features are now: scaled numerical + encoded categorical\")\n\n# ============================================================================\n# SUMMARY | Ø§Ù„Ù…Ù„Ø®Øµ\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Summary | Ø§Ù„Ù…Ù„Ø®Øµ\")\nprint(\"=\" * 70)\nprint(\"\"\"\nâœ… What you learned:\n   1. Scaling: StandardScaler (mean=0, std=1), MinMaxScaler (range [0,1])\n   2. Encoding: Label Encoding (ordinal), One-Hot Encoding (nominal)\n   3. When to use: Scale numerical, encode categorical\n   4. Real-world: Prepare data for ML models\n\nğŸ¯ Key Takeaways:\n   - Scaling: Makes numerical features comparable\n   - Encoding: Converts categories to numbers\n   - StandardScaler: For normal distributions\n   - MinMaxScaler: For bounded ranges\n   - Label Encoding: Ordinal categories (has order)\n   - One-Hot Encoding: Nominal categories (no order)\n\nğŸ“š Next Steps:\n   - Example 5: EDA Visualizations (explore your transformed data!)\n   - Example 6: Statistical EDA (summaries, correlations)\n   - Unit 4: Machine Learning (use transformed data for models)\n\"\"\")\nprint(\"âœ… Feature transformation concepts understood!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}