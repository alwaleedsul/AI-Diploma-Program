{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Statistical Exploratory Data Analysis | Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Perform comprehensive statistical EDA\n",
    "- Identify data distributions and patterns\n",
    "- Detect correlations and relationships\n",
    "- Generate statistical summaries and insights\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Unit 2: Data Cleaning examples\n",
    "- âœ… Understanding of pandas DataFrames\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 2** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Statistical Exploratory Data Analysis | Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ\n",
    "\n",
    "**All concepts are explained in the code comments below - you can learn everything from this notebook alone!**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— Building on Data Cleaning | Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**After cleaning data, what's next?**\n",
    "- We've cleaned missing values and duplicates\n",
    "- But we don't understand the data yet!\n",
    "- We need to explore and discover patterns\n",
    "\n",
    "**This notebook teaches EDA!**\n",
    "- We'll learn **statistical summaries** - understand data distributions\n",
    "- We'll learn **correlation analysis** - find relationships\n",
    "- We'll learn **pattern detection** - discover insights\n",
    "- We'll learn **data profiling** - comprehensive understanding\n",
    "\n",
    "**This is how you understand your data before modeling!**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Generate statistical summaries (mean, median, std, quartiles)\n",
    "2. Analyze correlations between variables\n",
    "3. Identify data distributions and patterns\n",
    "4. Create comprehensive data profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"\\nðŸ“š This notebook covers:\")\n",
    "print(\"   - Statistical summaries\")\n",
    "print(\"   - Correlation analysis\")\n",
    "print(\"   - Distribution analysis\")\n",
    "print(\"   - Data profiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create sample dataset\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "df = pd.DataFrame({\n",
    "    'age': np.random.normal(35, 10, n),\n",
    "    'income': np.random.normal(50000, 15000, n),\n",
    "    'education_years': np.random.normal(14, 3, n),\n",
    "    'satisfaction': np.random.uniform(1, 10, n)\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Statistical Summary\n",
    "print(\"=\" * 70)\n",
    "print(\"1. Statistical Summary | Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\\nKey Statistics:\")\n",
    "for col in df.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "    print(f\"  Median: {df[col].median():.2f}\")\n",
    "    print(f\"  Std: {df[col].std():.2f}\")\n",
    "    print(f\"  Min: {df[col].min():.2f}\")\n",
    "    print(f\"  Max: {df[col].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Correlation Analysis\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2. Correlation Analysis | ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "print(\"\\n\\nStrong Correlations (|r| > 0.5):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr) > 0.5:\n",
    "            col1 = correlation_matrix.columns[i]\n",
    "            col2 = correlation_matrix.columns[j]\n",
    "            print(f\"  {col1} â†” {col2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Distribution Analysis\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3. Distribution Analysis | ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nSkewness (measure of asymmetry):\")\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    skew = df[col].skew()\n",
    "    print(f\"  {col}: {skew:.3f}\")\n",
    "    if abs(skew) > 1:\n",
    "        print(f\"    â†’ Highly skewed!\")\n",
    "\n",
    "print(\"\\n\\nKurtosis (measure of tail heaviness):\")\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    kurt = df[col].kurtosis()\n",
    "    print(f\"  {col}: {kurt:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}