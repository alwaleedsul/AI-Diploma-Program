{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Feature Transformation: Scaling and Encoding | ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª: Ø§Ù„Ù‚ÙŠØ§Ø³ ÙˆØ§Ù„ØªØ´ÙÙŠØ±\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Transform features using scaling techniques\n",
    "- Encode categorical variables for machine learning\n",
    "- Scale numerical features (StandardScaler, MinMaxScaler)\n",
    "- Encode categorical features (Label, One-Hot encoding)\n",
    "- Prepare data for ML models\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Example 4: Data Loading (need to load data first)\n",
    "- âœ… Example 5: Missing Values & Duplicates (clean data first)\n",
    "- âœ… Understanding of pandas DataFrames\n",
    "- âœ… Basic scikit-learn knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 05, Unit 2**:\n",
    "- Feature Transformation: Transforming data (e.g., scaling, encoding) to prepare it for analysis\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 2 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 4: Data Loading** - You need data loaded first!\n",
    "- âœ… **Example 5: Missing Values** - Data should be cleaned!\n",
    "- âœ… **Understanding of data types**: Numerical vs categorical features\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding when to scale vs encode\n",
    "- Knowing which transformation to use\n",
    "- Understanding why transformations are needed\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is part of Unit 2: Data Cleaning and Preparation**\n",
    "\n",
    "**Why feature transformation?**\n",
    "- **Before** building ML models, features need to be in the right format\n",
    "- **After** cleaning data, we transform it for analysis\n",
    "- **Scaling**: Makes numerical features comparable (age: 0-100, income: 0-100000)\n",
    "- **Encoding**: Converts categories to numbers (red/blue/green â†’ 0/1/2)\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Example 5: Missing Values (clean data first)\n",
    "- ğŸ““ Data cleaning techniques\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Unit 4: Machine Learning (transformed data is ready for models!)\n",
    "- ğŸ““ Model training (models need scaled/encoded features)\n",
    "\n",
    "**Why this order?**\n",
    "1. Transformation prepares data for ML (essential step)\n",
    "2. Scaling ensures features are comparable\n",
    "3. Encoding converts categories to numbers (ML needs numbers)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Preparing Ingredients for Cooking | Ø§Ù„Ù‚ØµØ©: ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù„Ù„Ø·Ø¨Ø®\n",
    "\n",
    "Imagine you're cooking. **Before** you can cook, you need to prepare ingredients - cut vegetables to same size (scaling), convert different units to same measure (encoding). **After** preparing properly, all ingredients are ready to cook together!\n",
    "\n",
    "Same with data: **Before** machine learning, we transform features - scale numbers to same range, encode categories to numbers. **After** transforming, all features are ready for models!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Feature Transformation Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
    "\n",
    "Feature transformation is essential because:\n",
    "- **Scaling**: Makes features comparable (prevents one feature from dominating)\n",
    "- **Encoding**: Converts categories to numbers (ML algorithms need numbers)\n",
    "- **Performance**: Properly transformed data improves model performance\n",
    "- **Accuracy**: Scaling helps distance-based algorithms (KNN, SVM)\n",
    "\n",
    "**Common Student Questions:**\n",
    "- **Q: When do I scale vs encode?**\n",
    "  - Answer: Scale numerical features, encode categorical features\n",
    "  - Example: Age (numerical) â†’ scale, Color (categorical) â†’ encode\n",
    "  - Rule: Numbers â†’ scale, Categories â†’ encode\n",
    "  \n",
    "- **Q: Which scaler should I use?**\n",
    "  - Answer: StandardScaler for normal distributions, MinMaxScaler for bounded ranges\n",
    "  - Example: StandardScaler: mean=0, std=1; MinMaxScaler: range [0,1]\n",
    "  - Tip: Try both and see which works better for your data\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Feature transformation** prepares data for analysis by scaling numerical features and encoding categorical variables. This is essential for machine learning, as models require features in specific formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:45:39.825160Z",
     "iopub.status.busy": "2026-01-24T00:45:39.825110Z",
     "iopub.status.idle": "2026-01-24T00:45:40.432362Z",
     "shell.execute_reply": "2026-01-24T00:45:40.432037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported!\n",
      "\n",
      "======================================================================\n",
      "Feature Transformation: Scaling and Encoding | ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š PART 1: Scaling Numerical Features | Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âœ… Example: Data with Different Scales\n",
      "----------------------------------------------------------------------\n",
      "Original data (different scales):\n",
      "   age  income  score\n",
      "0   25   30000    0.1\n",
      "1   30   50000    0.3\n",
      "2   35   70000    0.5\n",
      "3   40   90000    0.7\n",
      "4   45  110000    0.9\n",
      "\n",
      "Problem: Age (0-50) vs Income (0-110000) - different scales!\n",
      "Solution: Scale all features to same range\n",
      "\n",
      "âœ… Method 1: StandardScaler (mean=0, std=1)\n",
      "----------------------------------------------------------------------\n",
      "Scaled data (StandardScaler):\n",
      "        age    income     score\n",
      "0 -1.414214 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107 -0.707107\n",
      "2  0.000000  0.000000  0.000000\n",
      "3  0.707107  0.707107  0.707107\n",
      "4  1.414214  1.414214  1.414214\n",
      "\n",
      "Mean: [ 0.0000000e+00 -4.4408921e-17 -4.4408921e-17]\n",
      "Std: [1.11803399 1.11803399 1.11803399]\n",
      "\n",
      "âœ… Method 2: MinMaxScaler (range [0, 1])\n",
      "----------------------------------------------------------------------\n",
      "Scaled data (MinMaxScaler):\n",
      "    age  income  score\n",
      "0  0.00    0.00   0.00\n",
      "1  0.25    0.25   0.25\n",
      "2  0.50    0.50   0.50\n",
      "3  0.75    0.75   0.75\n",
      "4  1.00    1.00   1.00\n",
      "\n",
      "Min: [0. 0. 0.]\n",
      "Max: [1. 1. 1.]\n",
      "\n",
      "======================================================================\n",
      "PART 2: Encoding Categorical Features | ØªØ´ÙÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\n",
      "======================================================================\n",
      "\n",
      "âœ… Example: Categorical Data\n",
      "----------------------------------------------------------------------\n",
      "Original categorical data:\n",
      "   color    size category\n",
      "0    red   small        A\n",
      "1   blue  medium        B\n",
      "2  green   large        A\n",
      "3    red   small        C\n",
      "4   blue   large        B\n",
      "\n",
      "Problem: ML algorithms need numbers, not text!\n",
      "Solution: Encode categories to numbers\n",
      "\n",
      "âœ… Method 1: Label Encoding (ordinal categories)\n",
      "----------------------------------------------------------------------\n",
      "Label encoded 'size' (small=0, medium=1, large=2):\n",
      "     size  size_encoded\n",
      "0   small             2\n",
      "1  medium             1\n",
      "2   large             0\n",
      "3   small             2\n",
      "4   large             0\n",
      "\n",
      "ğŸ’¡ Use for: Ordinal categories (small < medium < large)\n",
      "\n",
      "âœ… Method 2: One-Hot Encoding (nominal categories)\n",
      "----------------------------------------------------------------------\n",
      "One-Hot encoded 'color':\n",
      "   color_blue  color_green  color_red\n",
      "0       False        False       True\n",
      "1        True        False      False\n",
      "2       False         True      False\n",
      "3       False        False       True\n",
      "4        True        False      False\n",
      "\n",
      "ğŸ’¡ Use for: Nominal categories (red â‰  blue â‰  green, no order)\n",
      "\n",
      "======================================================================\n",
      "PART 3: Real-World Example | Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÙŠ\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Example: Prepare Data for ML Model\n",
      "----------------------------------------------------------------------\n",
      "Original data:\n",
      "   age  salary    city  experience_years\n",
      "0   25   30000  Riyadh                 2\n",
      "1   30   50000  Jeddah                 5\n",
      "2   35   70000  Riyadh                 8\n",
      "3   40   90000  Dammam                12\n",
      "4   45  110000  Jeddah                15\n",
      "5   50  130000  Riyadh                20\n",
      "\n",
      "Transformed data (ready for ML):\n",
      "       age   salary  experience_years  city_Dammam  city_Jeddah  city_Riyadh\n",
      "0 -1.46385 -1.46385         -1.372053        False        False         True\n",
      "1 -0.87831 -0.87831         -0.878114        False         True        False\n",
      "2 -0.29277 -0.29277         -0.384175        False        False         True\n",
      "3  0.29277  0.29277          0.274411         True        False        False\n",
      "4  0.87831  0.87831          0.768350        False         True        False\n",
      "5  1.46385  1.46385          1.591582        False        False         True\n",
      "\n",
      "âœ… All features are now: scaled numerical + encoded categorical\n",
      "\n",
      "======================================================================\n",
      "Summary | Ø§Ù„Ù…Ù„Ø®Øµ\n",
      "======================================================================\n",
      "\n",
      "âœ… What you learned:\n",
      "   1. Scaling: StandardScaler (mean=0, std=1), MinMaxScaler (range [0,1])\n",
      "   2. Encoding: Label Encoding (ordinal), One-Hot Encoding (nominal)\n",
      "   3. When to use: Scale numerical, encode categorical\n",
      "   4. Real-world: Prepare data for ML models\n",
      "\n",
      "ğŸ¯ Key Takeaways:\n",
      "   - Scaling: Makes numerical features comparable\n",
      "   - Encoding: Converts categories to numbers\n",
      "   - StandardScaler: For normal distributions\n",
      "   - MinMaxScaler: For bounded ranges\n",
      "   - Label Encoding: Ordinal categories (has order)\n",
      "   - One-Hot Encoding: Nominal categories (no order)\n",
      "\n",
      "ğŸ“š Next Steps:\n",
      "   - Unit 4: Machine Learning (use transformed data!)\n",
      "   - Model training requires scaled/encoded features\n",
      "   - Try different scalers and see which works best\n",
      "\n",
      "âœ… Feature transformation concepts understood!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Feature Transformation: Scaling and Encoding | ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: SCALING NUMERICAL FEATURES | Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š PART 1: Scaling Numerical Features | Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create sample data with different scales\n",
    "print(\"\\nâœ… Example: Data with Different Scales\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, 30, 35, 40, 45],  # Range: 20-50\n",
    "    'income': [30000, 50000, 70000, 90000, 110000],  # Range: 30000-110000\n",
    "    'score': [0.1, 0.3, 0.5, 0.7, 0.9]  # Range: 0-1\n",
    "})\n",
    "\n",
    "print(\"Original data (different scales):\")\n",
    "print(data)\n",
    "print(\"\\nProblem: Age (0-50) vs Income (0-110000) - different scales!\")\n",
    "print(\"Solution: Scale all features to same range\")\n",
    "\n",
    "# StandardScaler (mean=0, std=1)\n",
    "print(\"\\nâœ… Method 1: StandardScaler (mean=0, std=1)\")\n",
    "print(\"-\" * 70)\n",
    "scaler_standard = StandardScaler()\n",
    "data_scaled_standard = pd.DataFrame(\n",
    "    scaler_standard.fit_transform(data[['age', 'income', 'score']]),\n",
    "    columns=['age', 'income', 'score']\n",
    ")\n",
    "print(\"Scaled data (StandardScaler):\")\n",
    "print(data_scaled_standard)\n",
    "print(f\"\\nMean: {data_scaled_standard.mean().values}\")\n",
    "print(f\"Std: {data_scaled_standard.std().values}\")\n",
    "\n",
    "# MinMaxScaler (range [0, 1])\n",
    "print(\"\\nâœ… Method 2: MinMaxScaler (range [0, 1])\")\n",
    "print(\"-\" * 70)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_scaled_minmax = pd.DataFrame(\n",
    "    scaler_minmax.fit_transform(data[['age', 'income', 'score']]),\n",
    "    columns=['age', 'income', 'score']\n",
    ")\n",
    "print(\"Scaled data (MinMaxScaler):\")\n",
    "print(data_scaled_minmax)\n",
    "print(f\"\\nMin: {data_scaled_minmax.min().values}\")\n",
    "print(f\"Max: {data_scaled_minmax.max().values}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: ENCODING CATEGORICAL FEATURES | ØªØ´ÙÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 2: Encoding Categorical Features | ØªØ´ÙÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create sample categorical data\n",
    "print(\"\\nâœ… Example: Categorical Data\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "cat_data = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'red', 'blue'],\n",
    "    'size': ['small', 'medium', 'large', 'small', 'large'],\n",
    "    'category': ['A', 'B', 'A', 'C', 'B']\n",
    "})\n",
    "\n",
    "print(\"Original categorical data:\")\n",
    "print(cat_data)\n",
    "print(\"\\nProblem: ML algorithms need numbers, not text!\")\n",
    "print(\"Solution: Encode categories to numbers\")\n",
    "\n",
    "# Label Encoding (for ordinal data)\n",
    "print(\"\\nâœ… Method 1: Label Encoding (ordinal categories)\")\n",
    "print(\"-\" * 70)\n",
    "label_encoder = LabelEncoder()\n",
    "cat_data['size_encoded'] = label_encoder.fit_transform(cat_data['size'])\n",
    "print(\"Label encoded 'size' (small=0, medium=1, large=2):\")\n",
    "print(cat_data[['size', 'size_encoded']])\n",
    "print(\"\\nğŸ’¡ Use for: Ordinal categories (small < medium < large)\")\n",
    "\n",
    "# One-Hot Encoding (for nominal data)\n",
    "print(\"\\nâœ… Method 2: One-Hot Encoding (nominal categories)\")\n",
    "print(\"-\" * 70)\n",
    "onehot_encoded = pd.get_dummies(cat_data[['color']], prefix='color')\n",
    "print(\"One-Hot encoded 'color':\")\n",
    "print(onehot_encoded)\n",
    "print(\"\\nğŸ’¡ Use for: Nominal categories (red â‰  blue â‰  green, no order)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: REAL-WORLD EXAMPLE | Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÙŠ\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 3: Real-World Example | Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÙŠ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create realistic dataset\n",
    "print(\"\\nğŸ“Š Example: Prepare Data for ML Model\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "ml_data = pd.DataFrame({\n",
    "    'age': [25, 30, 35, 40, 45, 50],\n",
    "    'salary': [30000, 50000, 70000, 90000, 110000, 130000],\n",
    "    'city': ['Riyadh', 'Jeddah', 'Riyadh', 'Dammam', 'Jeddah', 'Riyadh'],\n",
    "    'experience_years': [2, 5, 8, 12, 15, 20]\n",
    "})\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(ml_data)\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_cols = ['age', 'salary', 'experience_years']\n",
    "scaler = StandardScaler()\n",
    "ml_data[numerical_cols] = scaler.fit_transform(ml_data[numerical_cols])\n",
    "\n",
    "# Encode categorical features\n",
    "ml_data = pd.get_dummies(ml_data, columns=['city'], prefix='city')\n",
    "\n",
    "print(\"\\nTransformed data (ready for ML):\")\n",
    "print(ml_data)\n",
    "print(\"\\nâœ… All features are now: scaled numerical + encoded categorical\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY | Ø§Ù„Ù…Ù„Ø®Øµ\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary | Ø§Ù„Ù…Ù„Ø®Øµ\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "âœ… What you learned:\n",
    "   1. Scaling: StandardScaler (mean=0, std=1), MinMaxScaler (range [0,1])\n",
    "   2. Encoding: Label Encoding (ordinal), One-Hot Encoding (nominal)\n",
    "   3. When to use: Scale numerical, encode categorical\n",
    "   4. Real-world: Prepare data for ML models\n",
    "\n",
    "ğŸ¯ Key Takeaways:\n",
    "   - Scaling: Makes numerical features comparable\n",
    "   - Encoding: Converts categories to numbers\n",
    "   - StandardScaler: For normal distributions\n",
    "   - MinMaxScaler: For bounded ranges\n",
    "   - Label Encoding: Ordinal categories (has order)\n",
    "   - One-Hot Encoding: Nominal categories (no order)\n",
    "\n",
    "ğŸ“š Next Steps:\n",
    "   - Unit 4: Machine Learning (use transformed data!)\n",
    "   - Model training requires scaled/encoded features\n",
    "   - Try different scalers and see which works best\n",
    "\"\"\")\n",
    "print(\"âœ… Feature transformation concepts understood!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
