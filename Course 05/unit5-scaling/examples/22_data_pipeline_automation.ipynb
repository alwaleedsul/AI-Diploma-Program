{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22. Data Pipeline Automation | Ø£ØªÙ…ØªØ© Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Build automated data processing pipelines\n",
    "- Schedule and orchestrate data workflows\n",
    "- Handle errors and retries in pipelines\n",
    "- Monitor pipeline execution and performance\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Unit 5: Production pipelines examples\n",
    "- âœ… Understanding of data processing workflows\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 5** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22. Data Pipeline Automation | Ø£ØªÙ…ØªØ© Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**All concepts are explained in the code comments below - you can learn everything from this notebook alone!**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Automating Data Workflows | Ø£ØªÙ…ØªØ© Ø³ÙŠØ± Ø¹Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**Manual data processing is slow and error-prone!**\n",
    "- Processing data manually takes too much time\n",
    "- Errors happen when steps are forgotten\n",
    "- We need automated, reliable pipelines\n",
    "\n",
    "**This notebook teaches pipeline automation!**\n",
    "- We'll learn **pipeline design** - structure data workflows\n",
    "- We'll learn **scheduling** - run pipelines automatically\n",
    "- We'll learn **error handling** - make pipelines robust\n",
    "- We'll learn **monitoring** - track pipeline health\n",
    "\n",
    "**This enables production-ready data pipelines!**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Design automated data processing pipelines\n",
    "2. Implement error handling and retries\n",
    "3. Schedule pipeline execution\n",
    "4. Monitor pipeline performance and health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"\\nğŸ“š This notebook covers:\")\n",
    "print(\"   - Pipeline design\")\n",
    "print(\"   - Error handling\")\n",
    "print(\"   - Pipeline monitoring\")\n",
    "print(\"   - Automation strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define Pipeline Steps\n",
    "print(\"=\" * 70)\n",
    "print(\"1. Pipeline Design | ØªØµÙ…ÙŠÙ… Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def step1_extract():\n",
    "    \"\"\"Extract data from source\"\"\"\n",
    "    print(\"  â†’ Step 1: Extracting data...\")\n",
    "    # Simulate data extraction\n",
    "    data = pd.DataFrame({\n",
    "        'id': range(1, 101),\n",
    "        'value': np.random.rand(100) * 100\n",
    "    })\n",
    "    time.sleep(0.1)  # Simulate processing time\n",
    "    print(f\"     âœ“ Extracted {len(data)} rows\")\n",
    "    return data\n",
    "\n",
    "def step2_transform(data):\n",
    "    \"\"\"Transform data\"\"\"\n",
    "    print(\"  â†’ Step 2: Transforming data...\")\n",
    "    data['value_normalized'] = (data['value'] - data['value'].mean()) / data['value'].std()\n",
    "    time.sleep(0.1)\n",
    "    print(f\"     âœ“ Transformed {len(data)} rows\")\n",
    "    return data\n",
    "\n",
    "def step3_load(data):\n",
    "    \"\"\"Load data to destination\"\"\"\n",
    "    print(\"  â†’ Step 3: Loading data...\")\n",
    "    # Simulate saving\n",
    "    time.sleep(0.1)\n",
    "    print(f\"     âœ“ Loaded {len(data)} rows\")\n",
    "    return True\n",
    "\n",
    "print(\"\\nâœ… Pipeline steps defined!\")\n",
    "print(\"   - Extract: Get data from source\")\n",
    "print(\"   - Transform: Process and clean data\")\n",
    "print(\"   - Load: Save processed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Execute Pipeline\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2. Pipeline Execution | ØªÙ†ÙÙŠØ° Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def run_pipeline():\n",
    "    \"\"\"Execute complete pipeline with error handling\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    print(f\"\\nğŸš€ Starting pipeline at {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract\n",
    "        data = step1_extract()\n",
    "        \n",
    "        # Transform\n",
    "        data = step2_transform(data)\n",
    "        \n",
    "        # Load\n",
    "        success = step3_load(data)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"\\nâœ… Pipeline completed successfully!\")\n",
    "        print(f\"   Duration: {duration:.2f} seconds\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Pipeline failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run pipeline\n",
    "success = run_pipeline()\n",
    "\n",
    "print(\"\\nğŸ’¡ Tip: Schedule this pipeline to run automatically (e.g., daily, hourly)!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}