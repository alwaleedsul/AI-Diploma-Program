{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21. Model Monitoring and Performance Tracking | Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Monitor deployed models in production\n",
    "- Track model performance metrics over time\n",
    "- Detect model drift and degradation\n",
    "- Implement alerting systems for model issues\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Unit 5: Deployment examples\n",
    "- âœ… Understanding of model evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 5** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21. Model Monitoring and Performance Tracking | Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡\n",
    "\n",
    "**All concepts are explained in the code comments below - you can learn everything from this notebook alone!**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— After Deployment | Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø´Ø±\n",
    "\n",
    "**Models don't stay perfect forever!**\n",
    "- Models degrade over time (data drift, concept drift)\n",
    "- Performance can drop without warning\n",
    "- We need to monitor and track performance\n",
    "\n",
    "**This notebook teaches monitoring!**\n",
    "- We'll learn **performance tracking** - monitor metrics over time\n",
    "- We'll learn **drift detection** - detect when models degrade\n",
    "- We'll learn **alerting** - get notified of issues\n",
    "- We'll learn **logging** - track predictions and errors\n",
    "\n",
    "**This ensures models stay reliable in production!**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Track model performance metrics over time\n",
    "2. Detect data drift and concept drift\n",
    "3. Implement alerting for model issues\n",
    "4. Log predictions and monitor model health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"\\nğŸ“š This notebook covers:\")\n",
    "print(\"   - Performance tracking\")\n",
    "print(\"   - Drift detection\")\n",
    "print(\"   - Alerting systems\")\n",
    "print(\"   - Model health monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Simulate performance metrics over time\n",
    "dates = pd.date_range(start='2024-01-01', periods=30, freq='D')\n",
    "\n",
    "# Simulate accuracy degrading over time (model drift)\n",
    "baseline_accuracy = 0.92\n",
    "drift = np.linspace(0, 0.15, 30)  # Gradual degradation\n",
    "noise = np.random.normal(0, 0.02, 30)\n",
    "accuracy = baseline_accuracy - drift + noise\n",
    "accuracy = np.clip(accuracy, 0, 1)  # Keep in [0, 1] range\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'accuracy': accuracy,\n",
    "    'predictions_count': np.random.randint(1000, 5000, 30)\n",
    "})\n",
    "\n",
    "print(\"Performance Metrics Over Time:\")\n",
    "print(metrics_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize Performance Trend\n",
    "print(\"=\" * 70)\n",
    "print(\"1. Performance Tracking | ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(metrics_df['date'], metrics_df['accuracy'], marker='o', linewidth=2)\n",
    "plt.axhline(y=0.85, color='r', linestyle='--', label='Alert Threshold (85%)')\n",
    "plt.title('Model Accuracy Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Performance trend visualized!\")\n",
    "print(f\"Current accuracy: {metrics_df['accuracy'].iloc[-1]:.3f}\")\n",
    "print(f\"Baseline accuracy: {baseline_accuracy:.3f}\")\n",
    "print(f\"Degradation: {(baseline_accuracy - metrics_df['accuracy'].iloc[-1])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drift Detection\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2. Drift Detection | Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "threshold = 0.85\n",
    "below_threshold = metrics_df[metrics_df['accuracy'] < threshold]\n",
    "\n",
    "if len(below_threshold) > 0:\n",
    "    print(f\"âš ï¸  ALERT: Model accuracy below threshold on {len(below_threshold)} days!\")\n",
    "    print(\"\\nDates with low accuracy:\")\n",
    "    for idx, row in below_threshold.iterrows():\n",
    "        print(f\"  {row['date'].strftime('%Y-%m-%d')}: {row['accuracy']:.3f}\")\n",
    "else:\n",
    "    print(\"âœ… No drift detected - model performance is stable\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Tip: Set up automated alerts when metrics drop below thresholds!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}