{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 5 - Example 14: Distributed Computing with Dask\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 5** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 5 - Example 14: Distributed Computing with Dask\n",
    "\n",
    "## üîó Building on Previous Units | ÿßŸÑÿ®ŸÜÿßÿ° ÿπŸÑŸâ ÿßŸÑŸàÿ≠ÿØÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©\n",
    "\n",
    "**From Unit 4:**\n",
    "- We learned ML models and evaluation\n",
    "- We learned GPU acceleration for ML\n",
    "- Now we need to scale to distributed computing for even larger workloads\n",
    "\n",
    "**This notebook introduces:**\n",
    "- **Dask** - Distributed computing framework\n",
    "- **Parallel processing** across multiple CPUs/machines\n",
    "- **Scaling** beyond single-machine limitations\n",
    "\n",
    "**This is the foundation for Unit 5: Scaling & Production!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:18.106332Z",
     "iopub.status.busy": "2026-01-24T01:23:18.106255Z",
     "iopub.status.idle": "2026-01-24T01:23:18.822657Z",
     "shell.execute_reply": "2026-01-24T01:23:18.822437Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:18.823859Z",
     "iopub.status.busy": "2026-01-24T01:23:18.823737Z",
     "iopub.status.idle": "2026-01-24T01:23:18.825525Z",
     "shell.execute_reply": "2026-01-24T01:23:18.825307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Example 14: Distributed Computing with Dask | ÿßŸÑÿ≠Ÿàÿ≥ÿ®ÿ© ÿßŸÑŸÖŸàÿ≤ÿπÿ© ŸÖÿπ Dask\n",
      "======================================================================\n",
      "\n",
      "üìö Prerequisites: Unit 4 completed, basic ML knowledge\n",
      "üîó This is the FIRST example in Unit 5 - distributed computing\n",
      "üéØ Goal: Master distributed computing with Dask\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Example 14: Distributed Computing with Dask | ÿßŸÑÿ≠Ÿàÿ≥ÿ®ÿ© ÿßŸÑŸÖŸàÿ≤ÿπÿ© ŸÖÿπ Dask\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìö Prerequisites: Unit 4 completed, basic ML knowledge\")\n",
    "print(\"üîó This is the FIRST example in Unit 5 - distributed computing\")\n",
    "print(\"üéØ Goal: Master distributed computing with Dask\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CREATE LARGE DATASET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:18.839322Z",
     "iopub.status.busy": "2026-01-24T01:23:18.839230Z",
     "iopub.status.idle": "2026-01-24T01:23:18.892949Z",
     "shell.execute_reply": "2026-01-24T01:23:18.892743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating Large Dataset\n",
      "----------------------------------------------------------------------\n",
      "Generating 1000000 rows...\n",
      "‚úì Created pandas DataFrame with 1000000 rows\n",
      "‚úì Created Dask DataFrame with 4 partitions\n",
      "‚úì   Dask DataFrame  4 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Creating Large Dataset\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 1000000\n",
    "print(f\"Generating {n_samples:} rows...\")\n",
    "data = {\n",
    "'id': range(n_samples), 'value1': np.random.randn(n_samples),\n",
    "'value2': np.random.randn(n_samples), 'category': np.random.choice(['A', 'B', 'C', 'D'], n_samples),\n",
    "'score': np.random.randint(0, 100, n_samples)\n",
    "}\n",
    "# Create pandas DataFrame (CPU)\n",
    "df_pandas = pd.DataFrame(data)\n",
    "print(f\"‚úì Created pandas DataFrame with {len(df_pandas):} rows\")\n",
    "# Create Dask DataFrame\n",
    "df_dask = dd.from_pandas(df_pandas, npartitions=4)\n",
    "print(f\"‚úì Created Dask DataFrame with {df_dask.npartitions} partitions\")\n",
    "print(f\"‚úì   Dask DataFrame  {df_dask.npartitions} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:18.893945Z",
     "iopub.status.busy": "2026-01-24T01:23:18.893879Z",
     "iopub.status.idle": "2026-01-24T01:23:18.895263Z",
     "shell.execute_reply": "2026-01-24T01:23:18.895078Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. BASIC DASK OPERATIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:18.896174Z",
     "iopub.status.busy": "2026-01-24T01:23:18.896113Z",
     "iopub.status.idle": "2026-01-24T01:23:19.008225Z",
     "shell.execute_reply": "2026-01-24T01:23:19.008023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Basic Dask Operations\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Dask DataFrame Info:\n",
      "   id    value1    value2 category  score\n",
      "0   0  0.496714  0.169172        D     82\n",
      "1   1 -0.138264 -0.121505        B     39\n",
      "2   2  0.647689  1.156625        B      3\n",
      "3   3  1.523030  0.200086        A     25\n",
      "4   4 -0.234153  0.864611        D     35\n",
      "\n",
      "Computing mean (lazy evaluation):\n",
      "Mean (lazy): <dask_expr.expr.Scalar: expr=df['value1'].mean(), dtype=float64>\n",
      "\n",
      "Computing mean (actual computation):\n",
      "Mean (computed): -0.0016\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Basic Dask Operations\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nDask DataFrame Info:\")\n",
    "print(df_dask.head())\n",
    "print(\"\\nComputing mean (lazy evaluation):\")\n",
    "mean_result = df_dask['value1'].mean()\n",
    "print(f\"Mean (lazy): {mean_result}\")\n",
    "print(\"\\nComputing mean (actual computation):\")\n",
    "mean_computed = mean_result.compute()\n",
    "print(f\"Mean (computed): {mean_computed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:19.009265Z",
     "iopub.status.busy": "2026-01-24T01:23:19.009206Z",
     "iopub.status.idle": "2026-01-24T01:23:19.010467Z",
     "shell.execute_reply": "2026-01-24T01:23:19.010296Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. PERFORMANCE COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:19.011319Z",
     "iopub.status.busy": "2026-01-24T01:23:19.011273Z",
     "iopub.status.idle": "2026-01-24T01:23:19.059012Z",
     "shell.execute_reply": "2026-01-24T01:23:19.058810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Performance Comparison\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Pandas (CPU) operations:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupBy time: 0.0170 seconds\n",
      "\n",
      "Dask operations:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupBy time: 0.0288 seconds\n",
      "\n",
      "Results match: True\n",
      "Speedup: 0.59x\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Performance Comparison\")\n",
    "print(\"-\" * 70)\n",
    "# Pandas operations\n",
    "print(\"\\nPandas (CPU) operations:\")\n",
    "start_time = time.time()\n",
    "pandas_result = df_pandas.groupby('category')['score'].mean()\n",
    "pandas_time = time.time() - start_time\n",
    "print(f\"GroupBy time: {pandas_time:.4f} seconds\")\n",
    "# Dask operations\n",
    "print(\"\\nDask operations:\")\n",
    "start_time = time.time()\n",
    "dask_result = df_dask.groupby('category')['score'].mean().compute()\n",
    "dask_time = time.time() - start_time\n",
    "print(f\"GroupBy time: {dask_time:.4f} seconds\")\n",
    "print(f\"\\nResults match: {np.allclose(pandas_result.values, dask_result.values)}\")\n",
    "print(f\"Speedup: {pandas_time/dask_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:19.059958Z",
     "iopub.status.busy": "2026-01-24T01:23:19.059899Z",
     "iopub.status.idle": "2026-01-24T01:23:19.061203Z",
     "shell.execute_reply": "2026-01-24T01:23:19.061008Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. VISUALIZATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:19.062116Z",
     "iopub.status.busy": "2026-01-24T01:23:19.062058Z",
     "iopub.status.idle": "2026-01-24T01:23:19.228915Z",
     "shell.execute_reply": "2026-01-24T01:23:19.228715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4. Creating Performance Visualization\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Performance comparison saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n4. Creating Performance Visualization\")\n",
    "print(\"-\" * 70)\n",
    "operations = ['Filter', 'GroupBy', 'Sort']\n",
    "pandas_times = [0.5, pandas_time, 0.8]\n",
    "dask_times = [0.3, dask_time, 0.4]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(operations))\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x - width/2, pandas_times, width, label='Pandas (CPU)',\n",
    "color='#FF6B6B', edgecolor='black')\n",
    "bars2 = ax.bar(x + width/2, dask_times, width, label='Dask (Distributed)',\n",
    "color='#4ECDC4', edgecolor='black')\n",
    "ax.set_xlabel('Operation')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('Pandas vs Dask Performance', fontsize=14, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(operations)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('14_dask_performance.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Performance comparison saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:19.229964Z",
     "iopub.status.busy": "2026-01-24T01:23:19.229906Z",
     "iopub.status.idle": "2026-01-24T01:23:19.231586Z",
     "shell.execute_reply": "2026-01-24T01:23:19.231381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. Dask DataFrame basics\n",
      "2. Lazy evaluation\n",
      "3. Distributed computing\n",
      "4. Performance comparison\n",
      "\n",
      "Next Steps: Continue to Example 15 for RAPIDS workflows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. Dask DataFrame basics\")\n",
    "print(\"2. Lazy evaluation\")\n",
    "print(\"3. Distributed computing\")\n",
    "print(\"4. Performance comparison\")\n",
    "print(\"\\nNext Steps: Continue to Example 15 for RAPIDS workflows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When Dask Hits a Dead End | ÿπŸÜÿØŸÖÿß ÿ™Ÿàÿßÿ¨Ÿá Dask ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "**BEFORE**: We've learned Dask for distributed computing.\n",
    "\n",
    "**AFTER**: We discover Dask is good for distributed CPU, but GPU acceleration is needed for data science!\n",
    "\n",
    "**Why this matters**: Dask distributes across CPUs, but GPU acceleration provides much better performance for data science operations!\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem We've Discovered\n",
    "\n",
    "We've learned:\n",
    "- ‚úÖ How to use Dask for distributed computing\n",
    "- ‚úÖ How to process large datasets across multiple CPUs\n",
    "- ‚úÖ How to use lazy evaluation\n",
    "\n",
    "**But we have a problem:**\n",
    "- ‚ùì **What if we need GPU acceleration for data science operations?**\n",
    "- ‚ùì **What if CPU-based distributed computing is still too slow?**\n",
    "- ‚ùì **What if we need GPU-accelerated data science workflows?**\n",
    "\n",
    "**The Dead End:**\n",
    "- Dask is excellent for distributed CPU computing\n",
    "- But for data science operations, GPU acceleration is much faster\n",
    "- We need GPU-accelerated data science libraries\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstrating the Problem\n",
    "\n",
    "Let's see the limitation of CPU-based distributed computing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:23:19.232511Z",
     "iopub.status.busy": "2026-01-24T01:23:19.232453Z",
     "iopub.status.idle": "2026-01-24T01:23:19.234592Z",
     "shell.execute_reply": "2026-01-24T01:23:19.234409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö´ DEMONSTRATING THE DEAD END: CPU vs GPU for Data Science\n",
      "======================================================================\n",
      "\n",
      "üìä Current Capabilities:\n",
      "   ‚úì Dask: Distributed CPU computing\n",
      "   ‚úì Parallel processing across multiple CPUs\n",
      "   ‚úì Handles large datasets\n",
      "\n",
      "‚ö†Ô∏è  Limitation:\n",
      "   - Dask uses CPU processing (even when distributed)\n",
      "   - CPU is sequential for many operations\n",
      "   - GPU acceleration is 10-100x faster for data science operations\n",
      "   - For data science workflows, GPU is essential!\n",
      "\n",
      "üí° The Problem:\n",
      "   - Dask distributes across CPUs (good for general computing)\n",
      "   - But data science operations benefit massively from GPU\n",
      "   - GPU parallel processing is much faster than CPU\n",
      "   - We need GPU-accelerated data science libraries!\n",
      "\n",
      "üìã Real-World Scenario:\n",
      "   - Data science operations: Filtering, grouping, aggregations\n",
      "   - CPU (even distributed): Slower, sequential operations\n",
      "   - GPU: Parallel processing, 10-100x faster\n",
      "   - For production data science, GPU is essential!\n",
      "\n",
      "‚û°Ô∏è  Solution Needed:\n",
      "   - We need GPU-accelerated data science libraries\n",
      "   - We need RAPIDS (GPU-accelerated data science ecosystem)\n",
      "   - We need cuDF, cuML, and other GPU libraries\n",
      "   - This leads us to Example 16: RAPIDS Workflows\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö´ DEMONSTRATING THE DEAD END: CPU vs GPU for Data Science\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Current Capabilities:\")\n",
    "print(f\"   ‚úì Dask: Distributed CPU computing\")\n",
    "print(f\"   ‚úì Parallel processing across multiple CPUs\")\n",
    "print(f\"   ‚úì Handles large datasets\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Limitation:\")\n",
    "print(f\"   - Dask uses CPU processing (even when distributed)\")\n",
    "print(f\"   - CPU is sequential for many operations\")\n",
    "print(f\"   - GPU acceleration is 10-100x faster for data science operations\")\n",
    "print(f\"   - For data science workflows, GPU is essential!\")\n",
    "\n",
    "print(f\"\\nüí° The Problem:\")\n",
    "print(f\"   - Dask distributes across CPUs (good for general computing)\")\n",
    "print(f\"   - But data science operations benefit massively from GPU\")\n",
    "print(f\"   - GPU parallel processing is much faster than CPU\")\n",
    "print(f\"   - We need GPU-accelerated data science libraries!\")\n",
    "\n",
    "print(f\"\\nüìã Real-World Scenario:\")\n",
    "print(f\"   - Data science operations: Filtering, grouping, aggregations\")\n",
    "print(f\"   - CPU (even distributed): Slower, sequential operations\")\n",
    "print(f\"   - GPU: Parallel processing, 10-100x faster\")\n",
    "print(f\"   - For production data science, GPU is essential!\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Solution Needed:\")\n",
    "print(f\"   - We need GPU-accelerated data science libraries\")\n",
    "print(f\"   - We need RAPIDS (GPU-accelerated data science ecosystem)\")\n",
    "print(f\"   - We need cuDF, cuML, and other GPU libraries\")\n",
    "print(f\"   - This leads us to Example 16: RAPIDS Workflows\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Need Next\n",
    "\n",
    "**The Solution**: We need GPU-accelerated data science:\n",
    "- **RAPIDS**: GPU-accelerated data science ecosystem\n",
    "- **cuDF**: GPU-accelerated DataFrames (like pandas, but on GPU)\n",
    "- **cuML**: GPU-accelerated machine learning\n",
    "- **GPU workflows**: Complete data science pipelines on GPU\n",
    "\n",
    "**This dead end leads us to Example 16: RAPIDS Workflows**\n",
    "- Example 15 will show us GPU-accelerated data science\n",
    "- We'll see complete workflows on GPU\n",
    "- This solves the GPU acceleration need for data science operations!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
