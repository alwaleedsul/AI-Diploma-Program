{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 10: Linear Regression\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 10: Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:25.230048Z",
     "iopub.status.busy": "2026-01-24T01:28:25.229997Z",
     "iopub.status.idle": "2026-01-24T01:28:26.102449Z",
     "shell.execute_reply": "2026-01-24T01:28:26.102231Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:26.103658Z",
     "iopub.status.busy": "2026-01-24T01:28:26.103558Z",
     "iopub.status.idle": "2026-01-24T01:28:26.105531Z",
     "shell.execute_reply": "2026-01-24T01:28:26.105359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Example 10: Linear Regression\n",
      " 10:  \n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4 - Example 10: Linear Regression\n",
    "\"\"\"\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 10: Linear Regression\")\n",
    "print(\" 10:  \")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:26.118463Z",
     "iopub.status.busy": "2026-01-24T01:28:26.118384Z",
     "iopub.status.idle": "2026-01-24T01:28:26.119704Z",
     "shell.execute_reply": "2026-01-24T01:28:26.119539Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. SIMPLE LINEAR REGRESSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:26.120617Z",
     "iopub.status.busy": "2026-01-24T01:28:26.120568Z",
     "iopub.status.idle": "2026-01-24T01:28:26.382491Z",
     "shell.execute_reply": "2026-01-24T01:28:26.382298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Simple Linear Regression\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Sample Data:\n",
      "          size          price\n",
      "0  1000.000000  164901.424590\n",
      "1  1030.303030  147367.222480\n",
      "2  1060.606061  172460.959173\n",
      "3  1090.909091  200236.350238\n",
      "4  1121.212121  149036.004819\n",
      "\n",
      "Model Parameters:\n",
      "Intercept: 93385.15\n",
      "Coefficient: 51.2084\n",
      "\n",
      "Training R¬≤: 0.7209\n",
      "Test R¬≤: 0.7837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Plot saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Simple Linear Regression\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "house_size = np.linspace(1000, 4000, 100)\n",
    "house_price = 50 * house_size + 100000 + np.random.normal(0, 30000, 100)\n",
    "df_simple = pd.DataFrame({'size': house_size, 'price': house_price})\n",
    "print(\"\\nSample Data:\")\n",
    "print(df_simple.head())\n",
    "X = df_simple[['size']]\n",
    "y = df_simple['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X_train, y_train)\n",
    "y_train_pred = model_simple.predict(X_train)\n",
    "y_test_pred = model_simple.predict(X_test)\n",
    "print(\"\\nModel Parameters:\")\n",
    "print(f\"Intercept: {model_simple.intercept_:.2f}\")\n",
    "print(f\"Coefficient: {model_simple.coef_[0]:.4f}\")\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"\\nTraining R¬≤: {train_r2:.4f}\")\n",
    "print(f\"Test R¬≤: {test_r2:.4f}\")\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].scatter(X_train, y_train, alpha=0.6, label='Training Data')\n",
    "axes[0].plot(X_train, y_train_pred, 'r-', linewidth=2, label='Regression Line')\n",
    "axes[0].set_xlabel('House Size (sq ft)')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].set_title('Simple Linear Regression Training')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[1].scatter(X_test, y_test, alpha=0.6, color='green', label='Test Data')\n",
    "axes[1].plot(X_test, y_test_pred, 'r-', linewidth=2, label='Regression Line')\n",
    "axes[1].set_xlabel('House Size (sq ft)')\n",
    "axes[1].set_ylabel('Price ($)')\n",
    "axes[1].set_title('Simple Linear Regression Test')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('10_linear_regression.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úì Plot saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:26.383400Z",
     "iopub.status.busy": "2026-01-24T01:28:26.383346Z",
     "iopub.status.idle": "2026-01-24T01:28:26.384624Z",
     "shell.execute_reply": "2026-01-24T01:28:26.384460Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. MULTIPLE LINEAR REGRESSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:26.385489Z",
     "iopub.status.busy": "2026-01-24T01:28:26.385438Z",
     "iopub.status.idle": "2026-01-24T01:28:26.529681Z",
     "shell.execute_reply": "2026-01-24T01:28:26.529470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Multiple Linear Regression\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Coefficients\n",
      "  size: 44.4460\n",
      "  bedrooms: 29230.2999\n",
      "  age: -4661.6167\n",
      "  location_score: 13817.9991\n",
      "\n",
      "Test R¬≤ Score: 0.8521\n",
      "‚úì Multiple regression plot saved\n",
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Next Steps: Continue to Example 11 for Classification\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Multiple Linear Regression\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "data_multiple = {\n",
    "'size': np.random.uniform(1000, 4000, n_samples),\n",
    "'bedrooms': np.random.randint(2, 6, n_samples),\n",
    "'age': np.random.uniform(0, 30, n_samples),\n",
    "'location_score': np.random.uniform(1, 10, n_samples)\n",
    "}\n",
    "df_multiple = pd.DataFrame(data_multiple)\n",
    "price = (50 * df_multiple['size'] + 30000 * df_multiple['bedrooms'] -\n",
    "5000 * df_multiple['age'] + 15000 * df_multiple['location_score'] +\n",
    "50000 + np.random.normal(0, 40000, n_samples))\n",
    "df_multiple['price'] = price\n",
    "X_multiple = df_multiple[['size', 'bedrooms', 'age', 'location_score']]\n",
    "y_multiple = df_multiple['price']\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "X_multiple, y_multiple, test_size=0.2, random_state=42)\n",
    "model_multiple = LinearRegression()\n",
    "model_multiple.fit(X_train_m, y_train_m)\n",
    "y_train_pred_m = model_multiple.predict(X_train_m)\n",
    "y_test_pred_m = model_multiple.predict(X_test_m)\n",
    "print(\"\\nCoefficients\")\n",
    "for feature, coef in zip(X_multiple.columns, model_multiple.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")\n",
    "test_r2_m = r2_score(y_test_m, y_test_pred_m)\n",
    "print(f\"\\nTest R¬≤ Score: {test_r2_m:.4f}\")\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(y_test_m, y_test_pred_m, alpha=0.6, color='green')\n",
    "ax.plot([y_test_m.min(), y_test_m.max()], [y_test_m.min(), y_test_m.max()], 'r--', linewidth=2)\n",
    "ax.set_xlabel('Actual Price ($)')\n",
    "ax.set_ylabel('Predicted Price ($)')\n",
    "ax.set_title(f'Multiple Regression: Predicted vs Actual (R¬≤ = {test_r2_m:.4f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('10_multiple_regression.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Multiple regression plot saved\")\n",
    "plt.close()\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNext Steps: Continue to Example 11 for Classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When Linear Regression Hits a Dead End | ÿπŸÜÿØŸÖÿß ÿ™Ÿàÿßÿ¨Ÿá ÿßŸÑÿßŸÜÿ≠ÿØÿßÿ± ÿßŸÑÿÆÿ∑Ÿä ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "**BEFORE**: We've learned linear regression for predicting continuous values.\n",
    "\n",
    "**AFTER**: We discover we need to predict categories/classes, not continuous values!\n",
    "\n",
    "**Why this matters**: Linear regression works for continuous predictions, but many problems require categorical predictions!\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem We've Discovered\n",
    "\n",
    "We've learned:\n",
    "- ‚úÖ How to use linear regression for continuous value prediction\n",
    "- ‚úÖ How to build simple and multiple linear regression models\n",
    "- ‚úÖ How to evaluate regression models\n",
    "\n",
    "**But we have a problem:**\n",
    "- ‚ùì **What if we need to predict categories (e.g., spam/not spam, yes/no)?**\n",
    "- ‚ùì **What if the target variable is discrete, not continuous?**\n",
    "- ‚ùì **What if we need classification, not regression?**\n",
    "\n",
    "**The Dead End:**\n",
    "- Linear regression predicts continuous values (prices, temperatures, etc.)\n",
    "- But many problems require categorical predictions (classes, categories, labels)\n",
    "- Linear regression doesn't work well for classification problems\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstrating the Problem\n",
    "\n",
    "Let's see what happens when we try to use linear regression for a classification problem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:26.530725Z",
     "iopub.status.busy": "2026-01-24T01:28:26.530661Z",
     "iopub.status.idle": "2026-01-24T01:28:26.533730Z",
     "shell.execute_reply": "2026-01-24T01:28:26.533566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö´ DEMONSTRATING THE DEAD END: Linear Regression for Classification\n",
      "======================================================================\n",
      "\n",
      "üìä Classification Problem Created:\n",
      "   - Features: 2 numerical features\n",
      "   - Target: Binary classification (0 or 1)\n",
      "   - Goal: Predict which class each sample belongs to\n",
      "\n",
      "‚ö†Ô∏è  Attempting Linear Regression for Classification:\n",
      "   - Linear Regression Accuracy: 97.00%\n",
      "\n",
      "üí° The Problem:\n",
      "   - Linear regression outputs continuous values (e.g., 0.3, 0.7, 1.2)\n",
      "   - Classification needs discrete classes (0 or 1)\n",
      "   - We have to threshold the output, which is not ideal\n",
      "   - Linear regression doesn't model probabilities well\n",
      "   - For classification problems, we need classification algorithms!\n",
      "\n",
      "üìã Real-World Classification Problems:\n",
      "   1. Email: Spam (1) or Not Spam (0)\n",
      "   2. Medical: Disease (1) or Healthy (0)\n",
      "   3. Customer: Will Buy (1) or Won't Buy (0)\n",
      "   4. Image: Cat (1) or Dog (0)\n",
      "   - All require predicting categories, not continuous values!\n",
      "\n",
      "‚û°Ô∏è  Solution Needed:\n",
      "   - We need classification algorithms (Logistic Regression, Decision Trees, etc.)\n",
      "   - We need algorithms designed for categorical predictions\n",
      "   - We need proper classification metrics (accuracy, precision, recall)\n",
      "   - This leads us to Example 11: Classification Algorithms\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö´ DEMONSTRATING THE DEAD END: Linear Regression for Classification\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a classification problem (binary: 0 or 1)\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "X_class = np.random.randn(n_samples, 2)\n",
    "# Create binary classification: class 0 or 1 based on a decision boundary\n",
    "y_class = ((X_class[:, 0] + X_class[:, 1]) > 0).astype(int)\n",
    "\n",
    "print(f\"\\nüìä Classification Problem Created:\")\n",
    "print(f\"   - Features: 2 numerical features\")\n",
    "print(f\"   - Target: Binary classification (0 or 1)\")\n",
    "print(f\"   - Goal: Predict which class each sample belongs to\")\n",
    "\n",
    "# Try to use linear regression for classification\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Attempting Linear Regression for Classification:\")\n",
    "lr_class = LinearRegression()\n",
    "lr_class.fit(X_class, y_class)\n",
    "y_pred_lr = lr_class.predict(X_class)\n",
    "\n",
    "# Convert predictions to binary (threshold at 0.5)\n",
    "y_pred_binary = (y_pred_lr > 0.5).astype(int)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_class, y_pred_binary)\n",
    "print(f\"   - Linear Regression Accuracy: {accuracy_lr:.2%}\")\n",
    "\n",
    "print(f\"\\nüí° The Problem:\")\n",
    "print(f\"   - Linear regression outputs continuous values (e.g., 0.3, 0.7, 1.2)\")\n",
    "print(f\"   - Classification needs discrete classes (0 or 1)\")\n",
    "print(f\"   - We have to threshold the output, which is not ideal\")\n",
    "print(f\"   - Linear regression doesn't model probabilities well\")\n",
    "print(f\"   - For classification problems, we need classification algorithms!\")\n",
    "\n",
    "print(f\"\\nüìã Real-World Classification Problems:\")\n",
    "print(f\"   1. Email: Spam (1) or Not Spam (0)\")\n",
    "print(f\"   2. Medical: Disease (1) or Healthy (0)\")\n",
    "print(f\"   3. Customer: Will Buy (1) or Won't Buy (0)\")\n",
    "print(f\"   4. Image: Cat (1) or Dog (0)\")\n",
    "print(f\"   - All require predicting categories, not continuous values!\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Solution Needed:\")\n",
    "print(f\"   - We need classification algorithms (Logistic Regression, Decision Trees, etc.)\")\n",
    "print(f\"   - We need algorithms designed for categorical predictions\")\n",
    "print(f\"   - We need proper classification metrics (accuracy, precision, recall)\")\n",
    "print(f\"   - This leads us to Example 11: Classification Algorithms\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Need Next\n",
    "\n",
    "**The Solution**: We need classification algorithms:\n",
    "- **Logistic Regression**: For binary and multi-class classification\n",
    "- **Decision Trees**: For non-linear classification boundaries\n",
    "- **Other classifiers**: SVM, Random Forest, etc.\n",
    "- **Classification metrics**: Accuracy, precision, recall, F1-score\n",
    "\n",
    "**This dead end leads us to Example 11: Classification Algorithms**\n",
    "- Example 11 will teach us classification algorithms\n",
    "- We'll learn how to predict categories instead of continuous values\n",
    "- This solves the classification problem that linear regression can't handle!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
