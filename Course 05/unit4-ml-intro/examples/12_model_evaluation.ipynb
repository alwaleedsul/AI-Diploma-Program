{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 12: Model Evaluation\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 12: Model Evaluation\n",
    "\n",
    "## üîó Solving the Problem from Example 11 | ÿ≠ŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÖŸÜ ÿßŸÑŸÖÿ´ÿßŸÑ 11\n",
    "\n",
    "**Remember the dead end from Example 11?**\n",
    "- We learned to build classification models\n",
    "- But we discovered accuracy alone can be misleading\n",
    "- We need comprehensive evaluation beyond just accuracy\n",
    "\n",
    "**This notebook solves that problem!**\n",
    "- We'll learn **comprehensive evaluation metrics** (precision, recall, F1, AUC)\n",
    "- We'll learn **cross-validation** for robust performance estimation\n",
    "- We'll learn **learning curves** to understand model behavior\n",
    "\n",
    "**This solves the evaluation problem from Example 11!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:33.339953Z",
     "iopub.status.busy": "2026-01-24T01:28:33.339895Z",
     "iopub.status.idle": "2026-01-24T01:28:34.250452Z",
     "shell.execute_reply": "2026-01-24T01:28:34.250260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Example 12: Model Evaluation | ÿ™ŸÇŸäŸäŸÖ ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨\n",
      "======================================================================\n",
      "\n",
      "üìö Prerequisites: Examples 10-11 completed, ML model knowledge\n",
      "üîó This is the THIRD example in Unit 4 - model evaluation\n",
      "üéØ Goal: Master model evaluation with cross-validation and metrics\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "                                     KFold, learning_curve)\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 12: Model Evaluation | ÿ™ŸÇŸäŸäŸÖ ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìö Prerequisites: Examples 10-11 completed, ML model knowledge\")\n",
    "print(\"üîó This is the THIRD example in Unit 4 - model evaluation\")\n",
    "print(\"üéØ Goal: Master model evaluation with cross-validation and metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:34.263629Z",
     "iopub.status.busy": "2026-01-24T01:28:34.263499Z",
     "iopub.status.idle": "2026-01-24T01:28:34.264931Z",
     "shell.execute_reply": "2026-01-24T01:28:34.264751Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. CROSS-VALIDATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:34.265835Z",
     "iopub.status.busy": "2026-01-24T01:28:34.265772Z",
     "iopub.status.idle": "2026-01-24T01:28:34.271275Z",
     "shell.execute_reply": "2026-01-24T01:28:34.271106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Cross Validation\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "5-Fold Cross-Validation R¬≤ Scores:\n",
      " R¬≤    :\n",
      "  Fold 1: 0.9978\n",
      "  Fold 2: 0.9980\n",
      "  Fold 3: 0.9976\n",
      "  Fold 4: 0.9987\n",
      "  Fold 5: 0.9985\n",
      "\n",
      "Mean CV Score: 0.9981 (+/- 0.0008)\n",
      "  CV: 0.9981\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Cross Validation\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "X = np.random.randn(n_samples, 4)\n",
    "y = X[:, 0] * 2 + X[:, 1] * 1.5 - X[:, 2] * 0.5 + np.random.randn(n_samples) * 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# K-Fold Cross-Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='r2')\n",
    "print(f\"\\n5-Fold Cross-Validation R¬≤ Scores:\")\n",
    "print(f\" R¬≤    :\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(f\"\\nMean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"  CV: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:34.272223Z",
     "iopub.status.busy": "2026-01-24T01:28:34.272168Z",
     "iopub.status.idle": "2026-01-24T01:28:34.273513Z",
     "shell.execute_reply": "2026-01-24T01:28:34.273340Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. LEARNING CURVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:34.274400Z",
     "iopub.status.busy": "2026-01-24T01:28:34.274343Z",
     "iopub.status.idle": "2026-01-24T01:28:36.318035Z",
     "shell.execute_reply": "2026-01-24T01:28:36.317827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Learning Curves\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Learning curves saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Learning Curves\")\n",
    "print(\"-\" * 70)\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "model, X_train, y_train, cv=5, n_jobs=-1,\n",
    "train_sizes=np.linspace(0.1, 1.0, 10), scoring='r2')\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='#FF6B6B', label='Training Score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='#FF6B6B')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='#4ECDC4', label='Validation Score')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='#4ECDC4')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('R¬≤ Score', fontsize=12)\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('12_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Learning curves saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:36.319094Z",
     "iopub.status.busy": "2026-01-24T01:28:36.319031Z",
     "iopub.status.idle": "2026-01-24T01:28:36.320445Z",
     "shell.execute_reply": "2026-01-24T01:28:36.320249Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. MULTIPLE METRICS EVALUATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:36.321323Z",
     "iopub.status.busy": "2026-01-24T01:28:36.321258Z",
     "iopub.status.idle": "2026-01-24T01:28:36.390593Z",
     "shell.execute_reply": "2026-01-24T01:28:36.365432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Multiple Metrics Evaluation\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Classification Metrics:\n",
      "  Accuracy:  0.9500\n",
      "  Precision: 0.9412\n",
      "  Recall:    0.9412\n",
      "  F1 Score:  0.9412\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Multiple Metrics Evaluation\")\n",
    "print(\"-\" * 70)\n",
    "# Classification metrics\n",
    "np.random.seed(42)\n",
    "X_clf = np.random.randn(200, 3)\n",
    "y_clf = (X_clf[:, 0] + X_clf[:, 1] > 0).astype(int)\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf)\n",
    "scaler = StandardScaler()\n",
    "X_train_clf_scaled = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler.transform(X_test_clf)\n",
    "clf_model = LogisticRegression(random_state=42)\n",
    "clf_model.fit(X_train_clf_scaled, y_train_clf)\n",
    "y_pred_clf = clf_model.predict(X_test_clf_scaled)\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "precision = precision_score(y_test_clf, y_pred_clf)\n",
    "recall = recall_score(y_test_clf, y_pred_clf)\n",
    "f1 = f1_score(y_test_clf, y_pred_clf)\n",
    "print(\"\\nClassification Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MODEL COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:36.417971Z",
     "iopub.status.busy": "2026-01-24T01:28:36.417685Z",
     "iopub.status.idle": "2026-01-24T01:28:36.627740Z",
     "shell.execute_reply": "2026-01-24T01:28:36.627406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4. Model Comparison\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Model Comparison:\n",
      "               Accuracy  Precision  Recall      F1\n",
      "Decision Tree       0.9     0.8421  0.9412  0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model comparison saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n4. Model Comparison\")\n",
    "print(\"-\" * 70)\n",
    "models = {\n",
    "'Logistic Regression': LogisticRegression(random_state=42), 'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth = 5)\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_clf_scaled, y_train_clf)\n",
    "y_pred = model.predict(X_test_clf_scaled)\n",
    "results[name] = {\n",
    "'Accuracy': accuracy_score(y_test_clf, y_pred),\n",
    "'Precision': precision_score(y_test_clf, y_pred),\n",
    "'Recall': recall_score(y_test_clf, y_pred),\n",
    "'F1': f1_score(y_test_clf, y_pred)\n",
    "}\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df.round(4))\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "comparison_df.plot(kind='bar', ax=ax, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])\n",
    "ax.set_title('Model Comparison', fontsize=14, weight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xlabel('Model')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('12_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Model comparison saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:36.629433Z",
     "iopub.status.busy": "2026-01-24T01:28:36.629294Z",
     "iopub.status.idle": "2026-01-24T01:28:36.631645Z",
     "shell.execute_reply": "2026-01-24T01:28:36.631377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. Cross-validation techniques\n",
      "2. Learning curves\n",
      "3. Multiple evaluation metrics\n",
      "4. Model comparison\n",
      "\n",
      "Next Steps: Continue to Example 13 for CPU vs GPU ML\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. Cross-validation techniques\")\n",
    "print(\"2. Learning curves\")\n",
    "print(\"3. Multiple evaluation metrics\")\n",
    "print(\"4. Model comparison\")\n",
    "print(\"\\nNext Steps: Continue to Example 13 for CPU vs GPU ML\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When Model Evaluation Hits a Dead End | ÿπŸÜÿØŸÖÿß ŸäŸàÿßÿ¨Ÿá ÿ™ŸÇŸäŸäŸÖ ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "**BEFORE**: We've learned comprehensive model evaluation techniques.\n",
    "\n",
    "**AFTER**: We discover evaluation on CPU is too slow for large datasets!\n",
    "\n",
    "**Why this matters**: CPU-based evaluation works, but large datasets require GPU acceleration!\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem We've Discovered\n",
    "\n",
    "We've learned:\n",
    "- ‚úÖ How to evaluate models comprehensively (cross-validation, metrics)\n",
    "- ‚úÖ How to compare models and understand performance\n",
    "- ‚úÖ How to create learning curves\n",
    "\n",
    "**But we have a problem:**\n",
    "- ‚ùì **What if we have large datasets (millions of samples)?**\n",
    "- ‚ùì **What if cross-validation takes hours on CPU?**\n",
    "- ‚ùì **What if we need faster training and evaluation?**\n",
    "\n",
    "**The Dead End:**\n",
    "- CPU-based evaluation works for small/medium datasets\n",
    "- But for large datasets, CPU processing is too slow\n",
    "- We need GPU acceleration for large-scale ML\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstrating the Problem\n",
    "\n",
    "Let's see what happens with large datasets on CPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T01:28:36.633009Z",
     "iopub.status.busy": "2026-01-24T01:28:36.632886Z",
     "iopub.status.idle": "2026-01-24T01:28:36.903085Z",
     "shell.execute_reply": "2026-01-24T01:28:36.902115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö´ DEMONSTRATING THE DEAD END: CPU Performance on Large Datasets\n",
      "======================================================================\n",
      "\n",
      "üìä Testing CPU Performance on Large Dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Dataset size: 100,000 samples √ó 10 features\n",
      "   - Task: Training and evaluating model\n",
      "\n",
      "‚è±Ô∏è  Testing CPU Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ CPU completed in 0.23 seconds\n",
      "   - Training + 5-fold cross-validation\n",
      "   - Mean CV score: 0.9995\n",
      "\n",
      "‚ö†Ô∏è  Performance Issue:\n",
      "   - 0.23 seconds for 100k samples\n",
      "   - For 1 million samples, this would take ~2.3 seconds (0.0 minutes)\n",
      "   - Real-world datasets can be 10-100x larger!\n",
      "\n",
      "üí° The Problem:\n",
      "   - CPU processing is sequential (one operation at a time)\n",
      "   - Large datasets require more time and computation\n",
      "   - Cross-validation multiplies the time (5-fold = 5x training time)\n",
      "   - For large-scale ML, we need GPU acceleration!\n",
      "\n",
      "‚û°Ô∏è  Solution Needed:\n",
      "   - We need GPU acceleration for ML training and evaluation\n",
      "   - We need parallel processing for faster computation\n",
      "   - We need GPU-accelerated ML libraries\n",
      "   - This leads us to Example 13: CPU vs GPU for ML\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö´ DEMONSTRATING THE DEAD END: CPU Performance on Large Datasets\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import time\n",
    "\n",
    "# Simulate large dataset\n",
    "print(f\"\\nüìä Testing CPU Performance on Large Dataset:\")\n",
    "large_n = 100_000  # 100k samples (real-world can be millions)\n",
    "\n",
    "# Create large dataset\n",
    "X_large = np.random.randn(large_n, 10)\n",
    "y_large = (X_large[:, 0] + X_large[:, 1] > 0).astype(int)\n",
    "\n",
    "print(f\"   - Dataset size: {large_n:,} samples √ó 10 features\")\n",
    "print(f\"   - Task: Training and evaluating model\")\n",
    "\n",
    "# Time CPU-based training and evaluation\n",
    "print(f\"\\n‚è±Ô∏è  Testing CPU Performance:\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "clf_large = LogisticRegression(random_state=42, max_iter = 1000)\n",
    "clf_large.fit(X_large, y_large)\n",
    "\n",
    "# Evaluate with cross-validation (5-fold)\n",
    "cv_scores_large = cross_val_score(clf_large, X_large, y_large, cv=5, n_jobs = -1)\n",
    "\n",
    "cpu_time = time.time() - start_time\n",
    "\n",
    "print(f\"   ‚úÖ CPU completed in {cpu_time:.2f} seconds\")\n",
    "print(f\"   - Training + 5-fold cross-validation\")\n",
    "print(f\"   - Mean CV score: {cv_scores_large.mean():.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Performance Issue:\")\n",
    "print(f\"   - {cpu_time:.2f} seconds for 100k samples\")\n",
    "print(f\"   - For 1 million samples, this would take ~{cpu_time * 10:.1f} seconds ({cpu_time * 10 / 60:.1f} minutes)\")\n",
    "print(f\"   - Real-world datasets can be 10-100x larger!\")\n",
    "\n",
    "print(f\"\\nüí° The Problem:\")\n",
    "print(f\"   - CPU processing is sequential (one operation at a time)\")\n",
    "print(f\"   - Large datasets require more time and computation\")\n",
    "print(f\"   - Cross-validation multiplies the time (5-fold = 5x training time)\")\n",
    "print(f\"   - For large-scale ML, we need GPU acceleration!\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Solution Needed:\")\n",
    "print(f\"   - We need GPU acceleration for ML training and evaluation\")\n",
    "print(f\"   - We need parallel processing for faster computation\")\n",
    "print(f\"   - We need GPU-accelerated ML libraries\")\n",
    "print(f\"   - This leads us to Example 13: CPU vs GPU for ML\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Need Next\n",
    "\n",
    "**The Solution**: We need GPU acceleration for ML:\n",
    "- **GPU-accelerated ML**: Libraries like cuML, XGBoost GPU\n",
    "- **Parallel processing**: GPU processes many operations simultaneously\n",
    "- **Faster training**: 10-100x speedup for large datasets\n",
    "- **Faster evaluation**: Cross-validation runs much faster on GPU\n",
    "\n",
    "**This dead end leads us to Example 13: CPU vs GPU for ML**\n",
    "- Example 13 will show us GPU acceleration for ML\n",
    "- We'll see dramatic speedup for training and evaluation\n",
    "- This solves the performance problem for large-scale machine learning!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
