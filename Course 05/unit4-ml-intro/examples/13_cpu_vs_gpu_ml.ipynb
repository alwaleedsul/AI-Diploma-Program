{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 13: CPU vs GPU Machine Learning\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 13: CPU vs GPU Machine Learning\n",
    "\n",
    "## ðŸ”— Solving the Problem from Example 12 | Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ù† Ø§Ù„Ù…Ø«Ø§Ù„ 12\n",
    "\n",
    "**Remember the dead end from Example 12?**\n",
    "- We learned comprehensive model evaluation techniques\n",
    "- But we discovered evaluation on CPU is too slow for large datasets\n",
    "- We needed GPU acceleration for large-scale ML\n",
    "\n",
    "**This notebook solves that problem!**\n",
    "- We'll learn **GPU acceleration for ML** (cuML, XGBoost GPU)\n",
    "- We'll see **dramatic speedup** for training and evaluation\n",
    "- We'll understand **when to use CPU vs GPU** for ML\n",
    "\n",
    "**This solves the performance problem from Example 12!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ Google Colab Setup (Run this first if using Colab)\n",
    "# Ø¯Ù„ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯ Google Colab (Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Colab)\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if running on Colab\n",
    "try:\n",
    "    IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "except NameError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ðŸŒ Detected Google Colab environment\")\n",
    "    print(\"ðŸ“‹ To enable GPU:\")\n",
    "    print(\"   1. Click: Runtime â†’ Change runtime type\")\n",
    "    print(\"   2. Set Hardware accelerator: GPU\")\n",
    "    print(\"   3. Click Save\")\n",
    "    print(\"\\nâ³ Installing RAPIDS for GPU acceleration...\")\n",
    "    print(\"   (This may take 5-10 minutes)\")\n",
    "    \n",
    "    # Install RAPIDS\n",
    "    !pip install -q cudf-cu11 cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n",
    "    \n",
    "    print(\"\\nâœ… RAPIDS installed!\")\n",
    "    print(\"ðŸ”„ Please restart runtime: Runtime â†’ Restart runtime\")\n",
    "    print(\"   Then run this cell again to verify installation.\")\n",
    "else:\n",
    "    print(\"ðŸ’» Running on local machine\")\n",
    "    print(\"   For Colab setup, see: DOCS/COLAB_SETUP.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:04.359432Z",
     "iopub.status.busy": "2025-12-26T11:39:04.359205Z",
     "iopub.status.idle": "2025-12-26T11:39:05.299975Z",
     "shell.execute_reply": "2025-12-26T11:39:05.299703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.301186Z",
     "iopub.status.busy": "2025-12-26T11:39:05.301087Z",
     "iopub.status.idle": "2025-12-26T11:39:05.303295Z",
     "shell.execute_reply": "2025-12-26T11:39:05.303111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  cuML not available - Using scikit-learn (CPU) with GPU simulation\n",
      "======================================================================\n",
      "Example 13: CPU vs GPU Machine Learning | CPU Ù…Ù‚Ø§Ø¨Ù„ GPU ÙÙŠ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©\n",
      "======================================================================\n",
      "\n",
      "ðŸ“š Prerequisites: Examples 10-12 completed, ML model knowledge\n",
      "ðŸ”— This is the FOURTH example in Unit 4 - GPU acceleration for ML\n",
      "ðŸŽ¯ Goal: Compare CPU vs GPU performance for machine learning\n"
     ]
    }
   ],
   "source": [
    "# Try to import cuML, fallback if not available\n",
    "try:\n",
    "    import cuml\n",
    "    from cuml.linear_model import LinearRegression as cuLinearRegression\n",
    "    from cuml.linear_model import LogisticRegression as cuLogisticRegression\n",
    "    CUML_AVAILABLE = True\n",
    "    print(\"âœ“ cuML is available - GPU acceleration enabled\")\n",
    "except ImportError:\n",
    "    CUML_AVAILABLE = False\n",
    "    print(\"âš  cuML not available - Using scikit-learn (CPU) with GPU simulation\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 13: CPU vs GPU Machine Learning | CPU Ù…Ù‚Ø§Ø¨Ù„ GPU ÙÙŠ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ“š Prerequisites: Examples 10-12 completed, ML model knowledge\")\n",
    "print(\"ðŸ”— This is the FOURTH example in Unit 4 - GPU acceleration for ML\")\n",
    "print(\"ðŸŽ¯ Goal: Compare CPU vs GPU performance for machine learning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CREATE LARGE DATASET FOR COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.315603Z",
     "iopub.status.busy": "2025-12-26T11:39:05.315523Z",
     "iopub.status.idle": "2025-12-26T11:39:05.327048Z",
     "shell.execute_reply": "2025-12-26T11:39:05.326838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating Large Dataset\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Created dataset with 100000 samples\n",
      "âœ“      100000 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Creating Large Dataset\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n\n",
    "samples = 100000\n",
    "X = np.random.randn(n_samples, 10)\n",
    "y\n",
    "regression = X[:, 0] * 2 + X[:, 1] * 1.5 - X[:, 2] * 0.5 + np.random.randn(n_samples) * 0.1\n",
    "y\n",
    "classification = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
    "print(f\"âœ“ Created dataset with {n_samples:} samples\")\n",
    "print(f\"âœ“      {n_samples:} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.328088Z",
     "iopub.status.busy": "2025-12-26T11:39:05.328032Z",
     "iopub.status.idle": "2025-12-26T11:39:05.329421Z",
     "shell.execute_reply": "2025-12-26T11:39:05.329227Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. REGRESSION COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.330359Z",
     "iopub.status.busy": "2025-12-26T11:39:05.330296Z",
     "iopub.status.idle": "2025-12-26T11:39:05.342196Z",
     "shell.execute_reply": "2025-12-26T11:39:05.342011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Regression: CPU vs GPU\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Training CPU model (scikit-learn)...\n",
      "CPU Training Time: 0.0058 seconds\n",
      "CPU Prediction Time: 0.0001 seconds\n",
      "CPU RÂ² Score: 0.9985\n",
      "\n",
      "âš  Simulating GPU performance (cuML not available)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Regression: CPU vs GPU\")\n",
    "print(\"-\" * 70)\n",
    "X_train, X_test, y_train, y\n",
    "test = train\n",
    "test\n",
    "split(\n",
    "X, y_regression, test\n",
    "size =0.2, random\n",
    "state =42)\n",
    "# CPU (scikit-learn)\n",
    "print(\"\\nTraining CPU model (scikit-learn)...\")\n",
    "start\n",
    "time = time.time()\n",
    "cpu\n",
    "model = LinearRegression()\n",
    "cpu_model.fit(X_train, y_train)\n",
    "cpu_train\n",
    "time = time.time() - start_time\n",
    "start\n",
    "time = time.time()\n",
    "cpu\n",
    "pred = cpu\n",
    "model.predict(X_test)\n",
    "cpu_pred\n",
    "time = time.time() - start_time\n",
    "cpu\n",
    "r2 = r2\n",
    "score(y_test, cpu_pred)\n",
    "print(f\"CPU Training Time: {cpu_train_time:.4f} seconds\")\n",
    "print(f\"CPU Prediction Time: {cpu_pred_time:.4f} seconds\")\n",
    "print(f\"CPU RÂ² Score: {cpu_r2:.4f}\")\n",
    "# GPU (cuML) or simulated\n",
    "if CUML_AVAILABLE:\n",
    "    print(\"\\nTraining GPU model (cuML)...\")\n",
    "    start\n",
    "time = time.time()\n",
    "    gpu\n",
    "model = cuLinearRegression()\n",
    "    gpu_model.fit(X_train, y_train)\n",
    "    gpu_train\n",
    "time = time.time() - start_time\n",
    "    start\n",
    "time = time.time()\n",
    "    gpu\n",
    "pred = gpu\n",
    "model.predict(X_test)\n",
    "    gpu_pred\n",
    "time = time.time() - start_time\n",
    "    gpu\n",
    "r2 = r2\n",
    "score(y_test.get(), gpu_pred.get()) if hasattr(gpu_pred, 'get') else r2_score(y_test, gpu_pred)\n",
    "    print(f\"GPU Training Time: {gpu_train_time:.4f} seconds\")\n",
    "    print(f\"GPU Prediction Time: {gpu_pred_time:.4f} seconds\")\n",
    "    print(f\"GPU RÂ² Score: {gpu_r2:.4f}\")\n",
    "    print(f\"\\nSpeedup - Training: {cpu_train_time/gpu_train_time:.2f}x\")\n",
    "    print(f\"Speedup - Prediction: {cpu_pred_time/gpu_pred_time:.2f}x\")\n",
    "else:\n",
    "    print(\"\\nâš  Simulating GPU performance (cuML not available)\")\n",
    "    gpu_train\n",
    "time = cpu\n",
    "train\n",
    "time\n",
    "5  # Simulate 5x speedup\n",
    "    gpu_pred\n",
    "time = cpu\n",
    "pred\n",
    "time\n",
    "5\n",
    "gpu\n",
    "r2 = cpu\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.343156Z",
     "iopub.status.busy": "2025-12-26T11:39:05.343106Z",
     "iopub.status.idle": "2025-12-26T11:39:05.344534Z",
     "shell.execute_reply": "2025-12-26T11:39:05.344358Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. CLASSIFICATION COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.345374Z",
     "iopub.status.busy": "2025-12-26T11:39:05.345324Z",
     "iopub.status.idle": "2025-12-26T11:39:05.398894Z",
     "shell.execute_reply": "2025-12-26T11:39:05.397782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Classification: CPU vs GPU\n",
      "----------------------------------------------------------------------\n",
      "CPU Training Time: 0.0304 seconds\n",
      "CPU Accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Classification: CPU vs GPU\")\n",
    "print(\"-\" * 70)\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test\n",
    "clf = train\n",
    "test\n",
    "split(\n",
    "X, y_classification, test\n",
    "size =0.2, random\n",
    "state =42, stratify= y\n",
    "classification)\n",
    "scaler = StandardScaler()\n",
    "X_train_clf\n",
    "scaled = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf\n",
    "scaled = scaler.transform(X_test_clf)\n",
    "# CPU\n",
    "start\n",
    "time = time.time()\n",
    "cpu\n",
    "clf = LogisticRegression(random\n",
    "state =42, max\n",
    "iter =1000)\n",
    "cpu_clf.fit(X_train_clf_scaled, y_train_clf)\n",
    "cpu_clf_train\n",
    "time = time.time() - start_time\n",
    "start\n",
    "time = time.time()\n",
    "cpu_clf\n",
    "pred = cpu\n",
    "clf.predict(X_test_clf_scaled)\n",
    "cpu_clf_pred\n",
    "time = time.time() - start_time\n",
    "cpu_clf\n",
    "acc = accuracy\n",
    "score(y_test_clf, cpu_clf_pred)\n",
    "print(f\"CPU Training Time: {cpu_clf_train_time:.4f} seconds\")\n",
    "print(f\"CPU Accuracy: {cpu_clf_acc:.4f}\")\n",
    "if CUML_AVAILABLE:\n",
    "    start\n",
    "time = time.time()\n",
    "    gpu\n",
    "clf = cuLogisticRegression()\n",
    "    gpu_clf.fit(X_train_clf_scaled, y_train_clf)\n",
    "    gpu_clf_train\n",
    "time = time.time() - start_time\n",
    "    start\n",
    "time = time.time()\n",
    "    gpu_clf\n",
    "pred = gpu\n",
    "clf.predict(X_test_clf_scaled)\n",
    "    gpu_clf_pred\n",
    "time = time.time() - start_time\n",
    "    gpu_clf\n",
    "acc = accuracy\n",
    "score(y_test_clf, gpu_clf_pred.get() if hasattr(gpu_clf_pred, 'get') else gpu_clf_pred)\n",
    "    print(f\"GPU Training Time: {gpu_clf_train_time:.4f} seconds\")\n",
    "    print(f\"GPU Accuracy: {gpu_clf_acc:.4f}\")\n",
    "else:\n",
    "    gpu_clf_train\n",
    "time = cpu_clf\n",
    "train\n",
    "time\n",
    "5\n",
    "    gpu_clf_pred\n",
    "time = cpu_clf\n",
    "pred\n",
    "time\n",
    "5\n",
    "    gpu_clf\n",
    "acc = cpu\n",
    "clf\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.400918Z",
     "iopub.status.busy": "2025-12-26T11:39:05.400800Z",
     "iopub.status.idle": "2025-12-26T11:39:05.402749Z",
     "shell.execute_reply": "2025-12-26T11:39:05.402451Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. VISUALIZATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.404540Z",
     "iopub.status.busy": "2025-12-26T11:39:05.404469Z",
     "iopub.status.idle": "2025-12-26T11:39:05.772629Z",
     "shell.execute_reply": "2025-12-26T11:39:05.772427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4. Performance Comparison Visualization\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Performance comparison saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n4. Performance Comparison Visualization\")\n",
    "print(\"-\" * 70)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('CPU vs GPU Performance Comparison', fontsize=16, weight='bold')\n",
    "# Regression performance\n",
    "categories = ['Training', 'Prediction']\n",
    "cpu_times\n",
    "reg = [cpu_train_time, cpu_pred_time]\n",
    "gpu_times\n",
    "reg = [gpu_train_time, gpu_pred_time]\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "bars1 = axes[0].bar(x - width/2, cpu_times_reg, width, label='CPU (scikit-learn)',\n",
    "color='#FF6B6B', edgecolor='black')\n",
    "bars2 = axes[0].bar(x + width/2, gpu_times_reg, width, label='GPU (cuML)',\n",
    "color='#4ECDC4', edgecolor='black')\n",
    "axes[0].set_xlabel('Operation')\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Performance Comparison', fontsize=14, weight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(categories)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "# Classification performance\n",
    "cpu_times\n",
    "clf = [cpu_clf_train_time, cpu_clf_pred_time]\n",
    "gpu_times\n",
    "clf = [gpu_clf_train_time, gpu_clf_pred_time]\n",
    "bars3 = axes[1].bar(x - width/2, cpu_times_clf, width, label='CPU (scikit-learn)',\n",
    "color='#FF6B6B', edgecolor='black')\n",
    "bars4 = axes[1].bar(x + width/2, gpu_times_clf, width, label='GPU (cuML)',\n",
    "color='#4ECDC4', edgecolor='black')\n",
    "axes[1].set_xlabel('Operation')\n",
    "axes[1].set_ylabel('Time (seconds)')\n",
    "axes[1].set_title('Classification Performance', fontsize=14, weight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(categories)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('13_cpu_vs_gpu_comparison.png', dpi=300, bbox\n",
    "inches ='tight')\n",
    "print(\"âœ“ Performance comparison saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:39:05.773785Z",
     "iopub.status.busy": "2025-12-26T11:39:05.773714Z",
     "iopub.status.idle": "2025-12-26T11:39:05.775382Z",
     "shell.execute_reply": "2025-12-26T11:39:05.775221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. CPU-based ML with scikit-learn\n",
      "2. GPU-accelerated ML with cuML\n",
      "3. Performance comparison\n",
      "4. When to use CPU vs GPU\n",
      "\n",
      "Next Steps: Continue to Unit 5 for Scaling Data Science\n",
      " :    5    \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. CPU-based ML with scikit-learn\")\n",
    "print(\"2. GPU-accelerated ML with cuML\")\n",
    "print(\"3. Performance comparison\")\n",
    "print(\"4. When to use CPU vs GPU\")\n",
    "print(\"\\nNext Steps: Continue to Unit 5 for Scaling Data Science\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}