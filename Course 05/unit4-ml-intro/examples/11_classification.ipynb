{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 11: Classification Basics\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 11: Classification Basics\n",
    "\n",
    "## üîó Solving the Problem from Example 10 | ÿ≠ŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÖŸÜ ÿßŸÑŸÖÿ´ÿßŸÑ 10\n",
    "\n",
    "**Remember the dead end from Example 10?**\n",
    "- We learned linear regression for predicting continuous values\n",
    "- But we discovered we need to predict categories/classes, not continuous values\n",
    "- Linear regression doesn't work well for classification problems\n",
    "\n",
    "**This notebook solves that problem!**\n",
    "- We'll learn **classification algorithms** (Logistic Regression, Decision Trees, etc.)\n",
    "- We'll learn how to **predict categories** instead of continuous values\n",
    "- We'll learn **classification metrics** (accuracy, precision, recall, F1-score)\n",
    "\n",
    "**This solves the classification problem from Example 10!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:35.817055Z",
     "iopub.status.busy": "2026-01-24T00:46:35.816995Z",
     "iopub.status.idle": "2026-01-24T00:46:36.720636Z",
     "shell.execute_reply": "2026-01-24T00:46:36.720440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Example 11: Classification Basics | ÿ£ÿ≥ÿßÿ≥Ÿäÿßÿ™ ÿßŸÑÿ™ÿµŸÜŸäŸÅ\n",
      "======================================================================\n",
      "\n",
      "üìö Prerequisites: Example 10 completed, linear regression knowledge\n",
      "üîó This is the SECOND example in Unit 4 - classification algorithms\n",
      "üéØ Goal: Master classification with logistic regression and decision trees\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, roc_curve, roc_auc_score)\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 11: Classification Basics | ÿ£ÿ≥ÿßÿ≥Ÿäÿßÿ™ ÿßŸÑÿ™ÿµŸÜŸäŸÅ\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìö Prerequisites: Example 10 completed, linear regression knowledge\")\n",
    "print(\"üîó This is the SECOND example in Unit 4 - classification algorithms\")\n",
    "print(\"üéØ Goal: Master classification with logistic regression and decision trees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.733712Z",
     "iopub.status.busy": "2026-01-24T00:46:36.733586Z",
     "iopub.status.idle": "2026-01-24T00:46:36.734950Z",
     "shell.execute_reply": "2026-01-24T00:46:36.734784Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. CREATE CLASSIFICATION DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.735858Z",
     "iopub.status.busy": "2026-01-24T00:46:36.735784Z",
     "iopub.status.idle": "2026-01-24T00:46:36.738551Z",
     "shell.execute_reply": "2026-01-24T00:46:36.738391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating Classification Data\n",
      "----------------------------------------------------------------------\n",
      "Data shape: (500, 3)\n",
      "Target distribution:\n",
      "target\n",
      "1    323\n",
      "0    177\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Creating Classification Data\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "X1 = np.random.normal(2, 1.5, n_samples)\n",
    "X2 = np.random.normal(3, 1.5, n_samples)\n",
    "X = np.column_stack([X1, X2])\n",
    "y = ((X1 - 2)**2 + (X2 - 3)**2 < 4).astype(int) + np.random.binomial(1, 0.1, n_samples)\n",
    "y = np.clip(y, 0, 1)\n",
    "df = pd.DataFrame(X, columns=['feature_1', 'feature_2'])\n",
    "df['target'] = y\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Target distribution:\\n{df['target'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.739415Z",
     "iopub.status.busy": "2026-01-24T00:46:36.739364Z",
     "iopub.status.idle": "2026-01-24T00:46:36.740601Z",
     "shell.execute_reply": "2026-01-24T00:46:36.740433Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.741409Z",
     "iopub.status.busy": "2026-01-24T00:46:36.741359Z",
     "iopub.status.idle": "2026-01-24T00:46:36.747757Z",
     "shell.execute_reply": "2026-01-24T00:46:36.747589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Logistic Regression\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Logistic Regression\")\n",
    "print(\"-\" * 70)\n",
    "X_data = df[['feature_1', 'feature_2']]\n",
    "y_data = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "y_test_pred_lr = logistic_model.predict(X_test_scaled)\n",
    "y_test_proba_lr = logistic_model.predict_proba(X_test_scaled)[:, 1]\n",
    "accuracy_lr = accuracy_score(y_test, y_test_pred_lr)\n",
    "print(f\"\\nLogistic Regression Accuracy: {accuracy_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.748695Z",
     "iopub.status.busy": "2026-01-24T00:46:36.748642Z",
     "iopub.status.idle": "2026-01-24T00:46:36.749984Z",
     "shell.execute_reply": "2026-01-24T00:46:36.749810Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. DECISION TREE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.750926Z",
     "iopub.status.busy": "2026-01-24T00:46:36.750875Z",
     "iopub.status.idle": "2026-01-24T00:46:36.754011Z",
     "shell.execute_reply": "2026-01-24T00:46:36.753838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Decision Tree\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Decision Tree Accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Decision Tree\")\n",
    "print(\"-\" * 70)\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_test_pred_dt = tree_model.predict(X_test)\n",
    "y_test_proba_dt = tree_model.predict_proba(X_test)[:, 1]\n",
    "accuracy_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "print(f\"\\nDecision Tree Accuracy: {accuracy_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.754940Z",
     "iopub.status.busy": "2026-01-24T00:46:36.754888Z",
     "iopub.status.idle": "2026-01-24T00:46:36.756297Z",
     "shell.execute_reply": "2026-01-24T00:46:36.756112Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. CONFUSION MATRICES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.757240Z",
     "iopub.status.busy": "2026-01-24T00:46:36.757183Z",
     "iopub.status.idle": "2026-01-24T00:46:36.990956Z",
     "shell.execute_reply": "2026-01-24T00:46:36.990768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4. Confusion Matrices\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Confusion matrices saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n4. Confusion Matrices\")\n",
    "print(\"-\" * 70)\n",
    "cm_lr = confusion_matrix(y_test, y_test_pred_lr)\n",
    "cm_dt = confusion_matrix(y_test, y_test_pred_dt)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Confusion Matrices')\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "axes[0].set_title('Logistic Regression')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "axes[1].set_title('Decision Tree')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('11_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Confusion matrices saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.992114Z",
     "iopub.status.busy": "2026-01-24T00:46:36.991992Z",
     "iopub.status.idle": "2026-01-24T00:46:36.993555Z",
     "shell.execute_reply": "2026-01-24T00:46:36.993372Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5. ROC CURVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:36.994566Z",
     "iopub.status.busy": "2026-01-24T00:46:36.994512Z",
     "iopub.status.idle": "2026-01-24T00:46:37.176267Z",
     "shell.execute_reply": "2026-01-24T00:46:37.176082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5. ROC Curves\n",
      "----------------------------------------------------------------------\n",
      "‚úì ROC curves saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n5. ROC Curves\")\n",
    "print(\"-\" * 70)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_test_proba_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_test_proba_lr)\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_test_proba_dt)\n",
    "auc_dt = roc_auc_score(y_test, y_test_proba_dt)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, linewidth=2, label=f'Logistic Regression (AUC = {auc_lr:.4f})')\n",
    "plt.plot(fpr_dt, tpr_dt, linewidth=2, label=f'Decision Tree (AUC = {auc_dt:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('11_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì ROC curves saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:37.177233Z",
     "iopub.status.busy": "2026-01-24T00:46:37.177169Z",
     "iopub.status.idle": "2026-01-24T00:46:37.178594Z",
     "shell.execute_reply": "2026-01-24T00:46:37.178427Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6. SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:37.179481Z",
     "iopub.status.busy": "2026-01-24T00:46:37.179426Z",
     "iopub.status.idle": "2026-01-24T00:46:37.180880Z",
     "shell.execute_reply": "2026-01-24T00:46:37.180698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. Logistic Regression for classification\n",
      "2. Decision Tree classifier\n",
      "3. Confusion matrix analysis\n",
      "4. ROC curves and AUC\n",
      "\n",
      "Next Steps: Continue to Example 12 for Model Evaluation\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. Logistic Regression for classification\")\n",
    "print(\"2. Decision Tree classifier\")\n",
    "print(\"3. Confusion matrix analysis\")\n",
    "print(\"4. ROC curves and AUC\")\n",
    "print(\"\\nNext Steps: Continue to Example 12 for Model Evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When Classification Hits a Dead End | ÿπŸÜÿØŸÖÿß ÿ™Ÿàÿßÿ¨Ÿá ÿßŸÑÿ™ÿµŸÜŸäŸÅ ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "**BEFORE**: We've learned to build classification models.\n",
    "\n",
    "**AFTER**: We discover we need proper evaluation beyond just accuracy!\n",
    "\n",
    "**Why this matters**: Accuracy alone can be misleading - we need comprehensive evaluation metrics!\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem We've Discovered\n",
    "\n",
    "We've learned:\n",
    "- ‚úÖ How to build classification models (Logistic Regression, Decision Trees)\n",
    "- ‚úÖ How to calculate accuracy\n",
    "- ‚úÖ How to create confusion matrices and ROC curves\n",
    "\n",
    "**But we have a problem:**\n",
    "- ‚ùì **What if accuracy is misleading (imbalanced classes)?**\n",
    "- ‚ùì **What if we need to understand model performance in detail?**\n",
    "- ‚ùì **What if we need to compare multiple models properly?**\n",
    "\n",
    "**The Dead End:**\n",
    "- We can build models and calculate accuracy\n",
    "- But accuracy alone doesn't tell the full story\n",
    "- We need comprehensive evaluation metrics and techniques\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstrating the Problem\n",
    "\n",
    "Let's see why accuracy alone can be misleading:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T00:46:37.181775Z",
     "iopub.status.busy": "2026-01-24T00:46:37.181709Z",
     "iopub.status.idle": "2026-01-24T00:46:37.184742Z",
     "shell.execute_reply": "2026-01-24T00:46:37.184589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö´ DEMONSTRATING THE DEAD END: Accuracy Can Be Misleading\n",
      "======================================================================\n",
      "\n",
      "üìä Imbalanced Dataset Example:\n",
      "   - Total samples: 1000\n",
      "   - Class 0 (majority): 900 (90.0%)\n",
      "   - Class 1 (minority): 100 (10.0%)\n",
      "\n",
      "‚ö†Ô∏è  Dummy Classifier (Always Predicts Class 0):\n",
      "   - Accuracy: 90.00%\n",
      "   - This looks good! But the model is useless!\n",
      "   - It never predicts class 1 (the important class)\n",
      "\n",
      "üí° The Problem:\n",
      "   - Accuracy alone can be misleading with imbalanced data\n",
      "   - We need precision, recall, F1-score to understand true performance\n",
      "   - We need to understand trade-offs (precision vs recall)\n",
      "   - We need proper evaluation techniques (cross-validation, learning curves)\n",
      "\n",
      "üìã What We Need for Proper Evaluation:\n",
      "   1. Multiple metrics (precision, recall, F1, AUC)\n",
      "   2. Cross-validation (robust performance estimation)\n",
      "   3. Learning curves (understand model behavior)\n",
      "   4. Model comparison (which model is actually better?)\n",
      "\n",
      "‚û°Ô∏è  Solution Needed:\n",
      "   - We need comprehensive model evaluation techniques\n",
      "   - We need to understand metrics beyond accuracy\n",
      "   - We need proper validation methods\n",
      "   - This leads us to Example 12: Model Evaluation\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö´ DEMONSTRATING THE DEAD END: Accuracy Can Be Misleading\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create imbalanced dataset to show the problem\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "# Imbalanced: 90% class 0, 10% class 1\n",
    "y_imbalanced = np.random.choice([0, 1], size=n_samples, p=[0.9, 0.1])\n",
    "X_imbalanced = np.random.randn(n_samples, 5)\n",
    "\n",
    "# Dummy classifier that always predicts class 0 (majority class)\n",
    "y_pred_dummy = np.zeros(n_samples)\n",
    "\n",
    "accuracy_dummy = accuracy_score(y_imbalanced, y_pred_dummy)\n",
    "print(f\"\\nüìä Imbalanced Dataset Example:\")\n",
    "print(f\"   - Total samples: {n_samples}\")\n",
    "print(f\"   - Class 0 (majority): {(y_imbalanced == 0).sum()} ({(y_imbalanced == 0).sum()/n_samples*100:.1f}%)\")\n",
    "print(f\"   - Class 1 (minority): {(y_imbalanced == 1).sum()} ({(y_imbalanced == 1).sum()/n_samples*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Dummy Classifier (Always Predicts Class 0):\")\n",
    "print(f\"   - Accuracy: {accuracy_dummy:.2%}\")\n",
    "print(f\"   - This looks good! But the model is useless!\")\n",
    "print(f\"   - It never predicts class 1 (the important class)\")\n",
    "\n",
    "print(f\"\\nüí° The Problem:\")\n",
    "print(f\"   - Accuracy alone can be misleading with imbalanced data\")\n",
    "print(f\"   - We need precision, recall, F1-score to understand true performance\")\n",
    "print(f\"   - We need to understand trade-offs (precision vs recall)\")\n",
    "print(f\"   - We need proper evaluation techniques (cross-validation, learning curves)\")\n",
    "\n",
    "print(f\"\\nüìã What We Need for Proper Evaluation:\")\n",
    "print(f\"   1. Multiple metrics (precision, recall, F1, AUC)\")\n",
    "print(f\"   2. Cross-validation (robust performance estimation)\")\n",
    "print(f\"   3. Learning curves (understand model behavior)\")\n",
    "print(f\"   4. Model comparison (which model is actually better?)\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Solution Needed:\")\n",
    "print(f\"   - We need comprehensive model evaluation techniques\")\n",
    "print(f\"   - We need to understand metrics beyond accuracy\")\n",
    "print(f\"   - We need proper validation methods\")\n",
    "print(f\"   - This leads us to Example 12: Model Evaluation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Need Next\n",
    "\n",
    "**The Solution**: We need comprehensive model evaluation:\n",
    "- **Multiple metrics**: Precision, recall, F1-score, AUC (not just accuracy)\n",
    "- **Cross-validation**: Robust performance estimation\n",
    "- **Learning curves**: Understand model behavior and overfitting\n",
    "- **Model comparison**: Proper techniques to compare models\n",
    "\n",
    "**This dead end leads us to Example 12: Model Evaluation**\n",
    "- Example 12 will teach us comprehensive evaluation techniques\n",
    "- We'll learn metrics beyond accuracy\n",
    "- We'll learn validation methods to properly assess models!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
