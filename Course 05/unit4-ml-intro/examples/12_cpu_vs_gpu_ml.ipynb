{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. CPU vs GPU Machine Learning | ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ø¹Ù„Ù‰ CPU Ù…Ù‚Ø§Ø¨Ù„ GPU\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand CPU vs GPU for machine learning\n",
    "- Compare performance between CPU and GPU\n",
    "- Use GPU-accelerated ML libraries (cuML)\n",
    "- Know when to use CPU vs GPU for ML tasks\n",
    "- Optimize ML workflows with GPU acceleration\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Example 3: Implementing ML Models (need ML knowledge)\n",
    "- âœ… Example 7: Model Evaluation (understand ML workflow)\n",
    "- âœ… Understanding of ML training process\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 3: Implementing ML Models** - You need ML knowledge!\n",
    "- âœ… **Example 7: Model Evaluation** - Understand ML workflow!\n",
    "- âœ… **Understanding of training**: What is model training? How long does it take?\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why GPU acceleration matters\n",
    "- Knowing when to use GPU\n",
    "- Understanding performance differences\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is part of Unit 4: Introduction to Machine Learning**\n",
    "\n",
    "**Why CPU vs GPU?**\n",
    "- **After** learning ML basics, we optimize performance\n",
    "- **GPU acceleration** speeds up training dramatically\n",
    "- **Understanding** when to use each is essential\n",
    "\n",
    "**Builds on**: \n",
    "- ðŸ““ Example 3: Implementing ML Models (ML knowledge)\n",
    "- ðŸ““ Example 7: Model Evaluation (ML workflow)\n",
    "\n",
    "**Leads to**: \n",
    "- ðŸ““ Unit 5: Extending the Scope of Data Science (GPU is part of scaling)\n",
    "- ðŸ““ Production ML (performance matters in production)\n",
    "\n",
    "**Why this order?**\n",
    "1. Performance optimization comes after learning basics\n",
    "2. GPU acceleration is powerful for large-scale ML\n",
    "3. Understanding trade-offs helps make decisions\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Turbo vs Regular Engine | Ø§Ù„Ù‚ØµØ©: Ù…Ø­Ø±Ùƒ ØªÙˆØ±Ø¨Ùˆ Ù…Ù‚Ø§Ø¨Ù„ Ø¹Ø§Ø¯ÙŠ\n",
    "\n",
    "Imagine you're driving. **Regular engine** (CPU) works fine for normal driving. **Turbo engine** (GPU) is much faster for racing (large datasets). **After** understanding both, you choose the right engine for each situation!\n",
    "\n",
    "Same with ML: **CPU** works fine for small datasets. **GPU** is much faster for large datasets. **After** understanding both, you choose the right one for each task!\n",
    "\n",
    "---\n",
    "\n",
    "## Why CPU vs GPU Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… CPU Ù…Ù‚Ø§Ø¨Ù„ GPU\n",
    "\n",
    "Understanding CPU vs GPU is essential because:\n",
    "- **Performance**: GPU can be 10-100x faster for large datasets\n",
    "- **Cost**: GPU costs more but saves time\n",
    "- **Scalability**: GPU enables large-scale ML\n",
    "- **Decision Making**: Know when to use each\n",
    "\n",
    "**Common Student Questions:**\n",
    "- **Q: When should I use GPU?**\n",
    "  - Answer: For large datasets, complex models, when speed matters\n",
    "  - Example: Training on 1M+ samples, deep learning models\n",
    "  - Rule: Small data â†’ CPU, Large data â†’ GPU\n",
    "  \n",
    "- **Q: Do I need GPU to learn ML?**\n",
    "  - Answer: No! CPU works fine for learning and small datasets\n",
    "  - Example: Most learning can be done on CPU\n",
    "  - Tip: Use GPU when you have large datasets or need speed\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**CPU vs GPU for ML** explores when to use each for machine learning tasks. GPU acceleration provides dramatic speedup for large-scale ML, while CPU is sufficient for smaller tasks and learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 - Example 12: CPU vs GPU Machine Learning\n",
    "\n",
    "## ðŸ”— Solving the Problem from Example 7 | Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ù† Ø§Ù„Ù…Ø«Ø§Ù„ 7\n",
    "\n",
    "**Remember the dead end from Example 7?**\n",
    "- We learned comprehensive model evaluation techniques\n",
    "- But we discovered evaluation on CPU is too slow for large datasets\n",
    "- We needed GPU acceleration for large-scale ML\n",
    "\n",
    "**This notebook solves that problem!**\n",
    "- We'll learn **GPU acceleration for ML** (cuML, XGBoost GPU)\n",
    "- We'll see **dramatic speedup** for training and evaluation\n",
    "- We'll understand **when to use CPU vs GPU** for ML\n",
    "\n",
    "**This solves the performance problem from Example 7!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:12.357862Z",
     "iopub.status.busy": "2026-01-24T16:20:12.357808Z",
     "iopub.status.idle": "2026-01-24T16:20:12.362076Z",
     "shell.execute_reply": "2026-01-24T16:20:12.361909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’» Running on local machine\n",
      "   For Colab setup, see: DOCS/COLAB_SETUP.md\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Google Colab Setup (Run this first if using Colab)\n",
    "# Ø¯Ù„ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯ Google Colab (Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Colab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:12.374382Z",
     "iopub.status.busy": "2026-01-24T16:20:12.374302Z",
     "iopub.status.idle": "2026-01-24T16:20:13.188356Z",
     "shell.execute_reply": "2026-01-24T16:20:13.188096Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.189509Z",
     "iopub.status.busy": "2026-01-24T16:20:13.189414Z",
     "iopub.status.idle": "2026-01-24T16:20:13.191531Z",
     "shell.execute_reply": "2026-01-24T16:20:13.191349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  cuML not available - Using scikit-learn (CPU) with GPU simulation\n",
      "======================================================================\n",
      "Example 12: CPU vs GPU Machine Learning | CPU Ù…Ù‚Ø§Ø¨Ù„ GPU ÙÙŠ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©\n",
      "======================================================================\n",
      "\n",
      "ðŸ“š Prerequisites: Examples 03â€“07 completed, ML model knowledge\n",
      "ðŸ”— This is the FOURTH example in Unit 4 - GPU acceleration for ML\n",
      "ðŸŽ¯ Goal: Compare CPU vs GPU performance for machine learning\n"
     ]
    }
   ],
   "source": [
    "# Try to import cuML, fallback if not available\n",
    "try:\n",
    "    import cuml\n",
    "    from cuml.linear_model import LinearRegression as cuLinearRegression\n",
    "    from cuml.linear_model import LogisticRegression as cuLogisticRegression\n",
    "    CUML_AVAILABLE = True\n",
    "    print(\"âœ“ cuML is available - GPU acceleration enabled\")\n",
    "except ImportError:\n",
    "    CUML_AVAILABLE = False\n",
    "    print(\"âš  cuML not available - Using scikit-learn (CPU) with GPU simulation\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 12: CPU vs GPU Machine Learning | CPU Ù…Ù‚Ø§Ø¨Ù„ GPU ÙÙŠ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ“š Prerequisites: Examples 03â€“07 completed, ML model knowledge\")\n",
    "print(\"ðŸ”— This is the FOURTH example in Unit 4 - GPU acceleration for ML\")\n",
    "print(\"ðŸŽ¯ Goal: Compare CPU vs GPU performance for machine learning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CREATE LARGE DATASET FOR COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.192514Z",
     "iopub.status.busy": "2026-01-24T16:20:13.192459Z",
     "iopub.status.idle": "2026-01-24T16:20:13.204511Z",
     "shell.execute_reply": "2026-01-24T16:20:13.204344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating Large Dataset\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Created dataset with 100000 samples\n",
      "âœ“      100000 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Creating Large Dataset\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 100000\n",
    "X = np.random.randn(n_samples, 10)\n",
    "y_regression = X[:, 0] * 2 + X[:, 1] * 1.5 - X[:, 2] * 0.5 + np.random.randn(n_samples) * 0.1\n",
    "y_classification = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
    "print(f\"âœ“ Created dataset with {n_samples:} samples\")\n",
    "print(f\"âœ“      {n_samples:} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.205499Z",
     "iopub.status.busy": "2026-01-24T16:20:13.205450Z",
     "iopub.status.idle": "2026-01-24T16:20:13.206763Z",
     "shell.execute_reply": "2026-01-24T16:20:13.206569Z"
    }
   },
   "outputs": [],
   "source": [
    "2. REGRESSION COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.207629Z",
     "iopub.status.busy": "2026-01-24T16:20:13.207584Z",
     "iopub.status.idle": "2026-01-24T16:20:13.224622Z",
     "shell.execute_reply": "2026-01-24T16:20:13.224424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Regression: CPU vs GPU\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Training CPU model (scikit-learn)...\n",
      "CPU Training Time: 0.0062 seconds\n",
      "CPU Prediction Time: 0.0052 seconds\n",
      "CPU RÂ² Score: 0.9985\n",
      "\n",
      "âš  Simulating GPU performance (cuML not available)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Regression: CPU vs GPU\")\n",
    "print(\"-\" * 70)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42)\n",
    "# CPU (scikit-learn)\n",
    "print(\"\\nTraining CPU model (scikit-learn)...\")\n",
    "start_time = time.time()\n",
    "cpu_model = LinearRegression()\n",
    "cpu_model.fit(X_train, y_train)\n",
    "cpu_train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "cpu_pred = cpu_model.predict(X_test)\n",
    "cpu_pred_time = time.time() - start_time\n",
    "cpu_r2 = r2_score(y_test, cpu_pred)\n",
    "print(f\"CPU Training Time: {cpu_train_time:.4f} seconds\")\n",
    "print(f\"CPU Prediction Time: {cpu_pred_time:.4f} seconds\")\n",
    "print(f\"CPU RÂ² Score: {cpu_r2:.4f}\")\n",
    "# GPU (cuML) or simulated\n",
    "if CUML_AVAILABLE:\n",
    "    print(\"\\nTraining GPU model (cuML)...\")\n",
    "    start_time = time.time()\n",
    "    gpu_model = cuLinearRegression()\n",
    "    gpu_model.fit(X_train, y_train)\n",
    "    gpu_train_time = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    gpu_pred = gpu_model.predict(X_test)\n",
    "    gpu_pred_time = time.time() - start_time\n",
    "    gpu_r2 = r2_score(y_test.get(), gpu_pred.get()) if hasattr(gpu_pred, 'get') else r2_score(y_test, gpu_pred)\n",
    "    print(f\"GPU Training Time: {gpu_train_time:.4f} seconds\")\n",
    "    print(f\"GPU Prediction Time: {gpu_pred_time:.4f} seconds\")\n",
    "    print(f\"GPU RÂ² Score: {gpu_r2:.4f}\")\n",
    "    print(f\"\\nSpeedup - Training: {cpu_train_time/gpu_train_time:.2f}x\")\n",
    "    print(f\"Speedup - Prediction: {cpu_pred_time/gpu_pred_time:.2f}x\")\n",
    "else:\n",
    "    print(\"\\nâš  Simulating GPU performance (cuML not available)\")\n",
    "    gpu_train_time = cpu_train_time / 5  # Simulate 5x speedup\n",
    "    gpu_pred_time = cpu_pred_time / 5\n",
    "    gpu_r2 = cpu_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.225713Z",
     "iopub.status.busy": "2026-01-24T16:20:13.225658Z",
     "iopub.status.idle": "2026-01-24T16:20:13.227101Z",
     "shell.execute_reply": "2026-01-24T16:20:13.226940Z"
    }
   },
   "outputs": [],
   "source": [
    "3. CLASSIFICATION COMPARISON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.228075Z",
     "iopub.status.busy": "2026-01-24T16:20:13.228028Z",
     "iopub.status.idle": "2026-01-24T16:20:13.329943Z",
     "shell.execute_reply": "2026-01-24T16:20:13.309793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Classification: CPU vs GPU\n",
      "----------------------------------------------------------------------\n",
      "CPU Training Time: 0.0408 seconds\n",
      "CPU Accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Classification: CPU vs GPU\")\n",
    "print(\"-\" * 70)\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_classification, test_size=0.2, random_state=42, stratify=y_classification)\n",
    "scaler = StandardScaler()\n",
    "X_train_clf_scaled = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler.transform(X_test_clf)\n",
    "# CPU\n",
    "start_time = time.time()\n",
    "cpu_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "cpu_clf.fit(X_train_clf_scaled, y_train_clf)\n",
    "cpu_clf_train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "cpu_clf_pred = cpu_clf.predict(X_test_clf_scaled)\n",
    "cpu_clf_pred_time = time.time() - start_time\n",
    "cpu_clf_acc = accuracy_score(y_test_clf, cpu_clf_pred)\n",
    "print(f\"CPU Training Time: {cpu_clf_train_time:.4f} seconds\")\n",
    "print(f\"CPU Accuracy: {cpu_clf_acc:.4f}\")\n",
    "if CUML_AVAILABLE:\n",
    "    start_time = time.time()\n",
    "    gpu_clf = cuLogisticRegression()\n",
    "    gpu_clf.fit(X_train_clf_scaled, y_train_clf)\n",
    "    gpu_clf_train_time = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    gpu_clf_pred = gpu_clf.predict(X_test_clf_scaled)\n",
    "    gpu_clf_pred_time = time.time() - start_time\n",
    "    gpu_clf_acc = accuracy_score(y_test_clf, gpu_clf_pred.get() if hasattr(gpu_clf_pred, 'get') else gpu_clf_pred)\n",
    "    print(f\"GPU Training Time: {gpu_clf_train_time:.4f} seconds\")\n",
    "    print(f\"GPU Accuracy: {gpu_clf_acc:.4f}\")\n",
    "else:\n",
    "    gpu_clf_train_time = cpu_clf_train_time / 5\n",
    "    gpu_clf_pred_time = cpu_clf_pred_time / 5\n",
    "    gpu_clf_acc = cpu_clf_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.363832Z",
     "iopub.status.busy": "2026-01-24T16:20:13.357883Z",
     "iopub.status.idle": "2026-01-24T16:20:13.377909Z",
     "shell.execute_reply": "2026-01-24T16:20:13.376392Z"
    }
   },
   "outputs": [],
   "source": [
    "4. VISUALIZATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.379738Z",
     "iopub.status.busy": "2026-01-24T16:20:13.379579Z",
     "iopub.status.idle": "2026-01-24T16:20:13.696313Z",
     "shell.execute_reply": "2026-01-24T16:20:13.696101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4. Performance Comparison Visualization\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Performance comparison saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n4. Performance Comparison Visualization\")\n",
    "print(\"-\" * 70)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('CPU vs GPU Performance Comparison', fontsize=16, weight='bold')\n",
    "# Regression performance\n",
    "categories = ['Training', 'Prediction']\n",
    "cpu_times_reg = [cpu_train_time, cpu_pred_time]\n",
    "gpu_times_reg = [gpu_train_time, gpu_pred_time]\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "bars1 = axes[0].bar(x - width/2, cpu_times_reg, width, label='CPU (scikit-learn)',\n",
    "color='#FF6B6B', edgecolor='black')\n",
    "bars2 = axes[0].bar(x + width/2, gpu_times_reg, width, label='GPU (cuML)',\n",
    "color='#4ECDC4', edgecolor='black')\n",
    "axes[0].set_xlabel('Operation')\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Performance Comparison', fontsize=14, weight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(categories)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "# Classification performance\n",
    "cpu_times_clf = [cpu_clf_train_time, cpu_clf_pred_time]\n",
    "gpu_times_clf = [gpu_clf_train_time, gpu_clf_pred_time]\n",
    "bars3 = axes[1].bar(x - width/2, cpu_times_clf, width, label='CPU (scikit-learn)',\n",
    "color='#FF6B6B', edgecolor='black')\n",
    "bars4 = axes[1].bar(x + width/2, gpu_times_clf, width, label='GPU (cuML)',\n",
    "color='#4ECDC4', edgecolor='black')\n",
    "axes[1].set_xlabel('Operation')\n",
    "axes[1].set_ylabel('Time (seconds)')\n",
    "axes[1].set_title('Classification Performance', fontsize=14, weight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(categories)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('13_cpu_vs_gpu_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Performance comparison saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T16:20:13.697444Z",
     "iopub.status.busy": "2026-01-24T16:20:13.697376Z",
     "iopub.status.idle": "2026-01-24T16:20:13.699089Z",
     "shell.execute_reply": "2026-01-24T16:20:13.698897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. CPU-based ML with scikit-learn\n",
      "2. GPU-accelerated ML with cuML\n",
      "3. Performance comparison\n",
      "4. When to use CPU vs GPU\n",
      "\n",
      "Next Steps: Continue to Unit 5 for Extending the Scope of Data Science\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. CPU-based ML with scikit-learn\")\n",
    "print(\"2. GPU-accelerated ML with cuML\")\n",
    "print(\"3. Performance comparison\")\n",
    "print(\"4. When to use CPU vs GPU\")\n",
    "print(\"\\nNext Steps: Continue to Unit 5 for Extending the Scope of Data Science\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}