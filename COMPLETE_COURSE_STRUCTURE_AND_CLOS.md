# AI Diploma - Complete Course Structure & CLOs
# دبلوم مشارك الذكاء الاصطناعي - هيكل الدورات ونواتج التعلم

**Source:** دبلوم مشارك الذكاء الاصطناعي (اكاديمية طويق للتدريب) نهائي.pdf  
**Program:** Associate Diploma in Artificial Intelligence  
**Duration:** 2 Semesters (16 weeks each)  
**Total Hours:** 944 training hours  
**Level:** Level 4 (Saudi National Qualifications Framework)

---

## Program Overview / نظرة عامة

### General Objective / الهدف العام

The program aims to prepare qualified personnel to work in the field of artificial intelligence, achieving Level 4 of the National Professional Qualifications System.

يهدف هذا البرنامج إلى إعداد الكوادر المؤهلة للعمل في مجالات الذكاء الاصطناعي، ويحصل على المستوى الرابع من نظام المؤهلات المهنية الوطنية.

### Detailed Program Objectives / الأهداف التفصيلية للبرنامج

By the end of this program, trainees will be able to:

1. Master Python programming, data structures, and Object-Oriented Programming (OOP) for developing AI applications efficiently
2. Design, develop, and optimize machine learning models
3. Apply deep learning concepts including Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN)
4. Develop AI solutions for Computer Vision and Natural Language Processing (NLP) tasks
5. Apply Reinforcement Learning and Generative AI techniques
6. Execute practical projects in AI through collaborative applications
7. Acquire necessary professional skills including effective communication, teamwork, and AI ethics

---

## Course Structure / هيكل الدورات

The diploma consists of **12 core courses** plus a **graduation project**, distributed across 2 semesters:

| # | Course Code | Course Name (English) | Course Name (Arabic) | Page |
|---|-------------|----------------------|---------------------|------|
| **Semester 1 الفصل الدراسي الأول** |
| 1 | AIAT 111 | Introduction to Artificial Intelligence and Applications | مقدمة في الذكاء الاصطناعي والتطبيقات | 10 |
| 2 | AIAT 112 | Python for Artificial Intelligence | بايثون للذكاء الاصطناعي | 18 |
| 3 | AIAT 113 | Mathematics and Probability for Machine Learning | الرياضيات والاحتمالات لتعلم الآلة | 26 |
| 4 | AIAT 114 | Machine Learning Algorithms and Applications | خوارزميات التعلم الآلي والتطبيقات | 33 |
| 5 | AIAT 115 | Scalable Data Science | علم البيانات القابل للتوسع | 41 |
| 6 | AIAT 116 | Artificial Intelligence Ethics | أخلاقيات الذكاء الاصطناعي | 49 |
| **Semester 2 الفصل الدراسي الثاني** |
| 7 | AIAT 121 | Natural Language Processing | معالجة اللغة الطبيعية | 59 |
| 8 | AIAT 122 | Deep Learning | التعلم العميق | 65 |
| 9 | AIAT 123 | Reinforcement Learning | التعلم التعزيزي | 69 |
| 10 | AIAT 124 | Generative Artificial Intelligence | الذكاء الاصطناعي التوليدي | 76 |
| 11 | AIAT 125 | Deploying AI Models | تطبيق نماذج الذكاء الاصطناعي | 84 |
| 12 | AIAT 126 | Graduation Project | مشروع التخرج | 92 |

---

## Detailed Course Learning Outcomes (CLOs)

### Course 1: AIAT 111 - Introduction to Artificial Intelligence and Applications
**مقدمة في الذكاء الاصطناعي والتطبيقات**

**Credit Hours:** 3 | **Theory:** 2 | **Practical:** 2 | **Contact Hours:** 4

#### Course Learning Outcomes:

**CLO1:** Differentiate between traditional AI (rule-based) and modern AI (data-driven), including major historical milestones and philosophical discussions (like Turing's objections).

**CLO2:** Apply basic AI techniques such as search algorithms (uninformed, heuristic, competitive) and understand agent design in the PEAS framework (rational agents).

**CLO3:** Demonstrate knowledge in cognitive systems, including knowledge representation, ontology, and cognitive agent engineering.

**CLO4:** Use Bayesian probabilities and other probabilistic models to handle uncertainty in AI problems, distinguishing between rule-based and data-driven systems.

**CLO5:** Implement supervised and unsupervised machine learning pipelines, understanding data processing, encoding, hypothesis space, and loss/optimization, with understanding of basic forward neural network mathematics for classification or regression tasks.

**CLO6:** Build and train basic feedforward neural networks for classification or regression tasks, understanding the mathematics of individual neurons, weights, and activation functions.

**CLO7:** Compare different deep learning architectures (CNN, RNN, LSTM), evaluate overfitting vs. underfitting, and apply techniques to improve model generalization.

**CLO8:** Explore concepts and frameworks of generative AI, discussing ethical implications and creative applications of models like GANs, Transformers, and Large Language Models.

#### Unit Structure:

**Unit 1: Introduction to AI and Applications** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Introduction to Artificial Intelligence (What is AI?, Weak vs Strong AI, history)
- Intelligent Agents and Rationality
- Philosophy of AI (Turing Test, objections)
- Search Algorithms in AI (uninformed, heuristic, adversarial)
- Adversarial Search (MiniMax, Alpha-Beta pruning)
- Knowledge Representation and Reasoning
- Python for AI Development basics
- Introduction to Generative AI

**Practical Content:**
- Lectures on AI history and evolution
- Discussions on Weak vs Strong AI and real-world implications
- Case studies on intelligent agents and rational decision-making
- Implementing search algorithms (uninformed, heuristic, greedy)
- Developing simple intelligent agents using MiniMax and Alpha-Beta pruning
- Applied workshops on Python basics for AI
- Working with NumPy for data processing in AI applications
- Introduction to generative AI frameworks with simple applications

**Unit 2: AI Concepts, Terminology, and Application Domains** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Python Basics Review
- Expert Systems (rule-based vs ML-based)
- Knowledge Representation (ontology, knowledge graphs, RDF, SPARQL)
- Probabilistic Reasoning and Uncertainty (Bayes' rule, Bayesian statistics)
- Introduction to Machine Learning (supervised, unsupervised, reinforcement learning)

**Practical Content:**
- Applied review of Python basics (lists, dictionaries, file handling)
- Implementing a simple expert system using Python
- Working with RDF and SPARQL for knowledge graph queries
- Applying Bayes' theorem to real-world problems using Python
- Encoding categorical features for ML models
- Developing simple supervised and unsupervised learning models

**Unit 3: AI Concepts, Terminology, and Application Domains Part 2** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Regression vs Classification
- Prediction vs Explanation in ML (interpretability methods: SHAP, LIME)
- Hypothesis Space and Parameters
- The Learner and Loss Functions (MSE, Cross-Entropy)
- Optimization in ML (gradient descent, overfitting)
- Introduction to Deep Learning
- The Neuron and Perceptron
- XOR Problem in Neural Networks

**Practical Content:**
- Implementing regression and classification models using Python
- Building a perceptron and testing activation functions
- Solving the XOR problem using a neural network in Keras

**Unit 4: Neural Networks Fundamentals** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- The Neuron and Activation Functions (Sigmoid, ReLU, Tanh, Softmax)
- Multi-class Classification and Multi-layer Networks
- Multi-Layer Perceptrons (MLP)
- Deep Neural Networks (DNNs)
- Introduction to CNNs
- Advanced Deep Learning Architectures (RNNs, LSTM, GRU)
- Trends in Deep Learning Training
- Overfitting and Underfitting in Deep Learning

**Practical Content:**
- Implementing a single neuron with different activation functions using Python
- Building a multi-class classification model with Keras
- Training a multi-layer perceptron (MLP) for classification tasks
- Implementing a CNN for image classification using TensorFlow/Keras
- Experimenting with RNN, LSTM, GRU for sequential data
- Applying early stopping and regularization to prevent overfitting

**Unit 5: Introduction to Generative AI and Course Summary** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Understanding Binary Classification Problems
- Diabetes Classification using Feedforward Neural Networks (FFNN)
- Building and Training FFNN for Diabetes Classification
- Exploratory Data Analysis (EDA) and Data Preprocessing
- Introduction to Generative Models (GANs, Transformers, LLMs)
- Ethical Implications and Future Trends of Generative AI

**Practical Content:**
- EDA and data preprocessing for medical datasets
- Building and training an FFNN for diabetes classification using Python
- Implementing feature scaling, encoding, and handling missing data in a medical dataset
- Experimenting with a simple GAN model or Transformer model for generative AI applications

---

### Course 2: AIAT 112 - Python for Artificial Intelligence
**بايثون للذكاء الاصطناعي**

**Credit Hours:** 4 | **Theory:** 2 | **Practical:** 4 | **Contact Hours:** 6

#### Course Learning Outcomes:

**CLO1:** Demonstrate and implement the functionality of at least three major algorithms in AI (e.g., k-Neighbors, Decision Trees) using Python.

**CLO2:** Complete a practical project that applies machine learning techniques to a real problem, demonstrating their ability to integrate AI concepts in practical application.

**CLO3:** Evaluate AI model performance using appropriate metrics (such as accuracy, precision, recall, F1 score), and be able to discuss the implications of these metrics in the context of their projects.

**CLO4:** Analyze case studies of AI applications, identifying the algorithms used and evaluating their effectiveness in solving specified problems.

**CLO5:** Design and implement a prototype of an intelligent system that includes at least two different AI techniques (such as natural language processing and machine learning), demonstrating creativity and technical competence.

#### Unit Structure:

**Unit 1: Course Introduction and Search Algorithms** (6 theory + 12 practical = 18 hours)

**Theoretical Content:**
- Introduction to AI Applications
- Fundamental Algorithms in AI (DFS, BFS, GBFS, A*)
- Adversarial Search and Game AI (Minimax, Alpha-Beta pruning)
- AI Learning Methodology and Course Structure
- AI Model Performance Analysis

**Practical Content:**
- Real-world AI applications
- Implementing AI algorithms
- Implementing search algorithms
- Implementing adversarial search
- AI learning methods and research
- Evaluating AI models

**Unit 2: Knowledge Representation** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Introduction to Propositional Logic
- Truth Tables and Logical Operators (AND, OR, NOT, IMPLIES, BICONDITIONAL)
- Applications of Propositional Logic
- Logical Reasoning and Inference Rules (Modus Ponens, Modus Tollens, Disjunctive Syllogism)
- Building Logical Arguments
- Introduction to Model Checking
- Temporal Logic and Model Checking Systems
- Inference in Propositional Logic
- Introduction to First-Order Logic (FOL)

**Practical Content:**
- Building truth tables for logical propositions using Python
- Implementing logical operators (AND, OR, NOT, IMPLIES, BICONDITIONAL)
- Applying inference rules (Modus Ponens, Modus Tollens, Disjunctive Syllogism) to solve logical problems
- Building logical arguments and validating them programmatically
- Implementing model checking algorithms for temporal logic
- Working with First-Order Logic (FOL) syntax and semantics
- Applying logical reasoning to solve AI problems (like knowledge-based systems)
- Writing code to parse and evaluate FOL formulas

**Unit 3: Learning Under Uncertainty** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Introduction to Bayesian Networks
- Inference in Bayesian Networks
- Hidden Markov Models (HMMs) - Forward-backward algorithm, Viterbi algorithm
- Applications of HMMs (speech recognition, POS tagging)
- Introduction to Reinforcement Learning (MDPs, policies, value functions)

**Practical Content:**
- Building Bayesian networks using Python libraries (pgmpy)
- Implementing inference algorithms for Bayesian networks
- Working with Hidden Markov Models (HMMs) for sequence prediction
- Implementing Viterbi algorithm for sequence decoding
- Applying HMMs to practical problems (speech recognition, POS tagging)
- Introduction to reinforcement learning: setting up environments and agents
- Implementing simple MDPs and value iteration algorithms

**Unit 4: Optimization Techniques** (7 theory + 13 practical = 20 hours)

**Theoretical Content:**
- Gradient Descent Optimization (batch, stochastic, mini-batch)
- Advanced Optimization Algorithms (Momentum, Adam, RMSprop)
- Regularization Techniques (L1, L2, Dropout, Early stopping)
- Hyperparameter Tuning (Grid search, Random search, Bayesian optimization)

**Practical Content:**
- Implementing gradient descent algorithms (batch, stochastic, mini-batch)
- Applying advanced optimizers (Adam, RMSprop) in neural networks
- Implementing regularization techniques (L1, L2, Dropout, Early Stopping)
- Performing hyperparameter tuning using grid search and random search
- Using cross-validation to select optimal hyperparameters
- Comparing different optimization algorithms on real datasets
- Implementing Bayesian optimization for hyperparameter search

**Unit 5: AI-Based Learning Models** (7 theory + 13 practical = 20 hours)

**Theoretical Content:**
- Neural Network Architectures (feedforward, CNN, RNN)
- Transfer Learning (pre-trained models, fine-tuning, domain adaptation)
- Model Evaluation and Selection (metrics, cross-validation, comparison)
- Deploying AI Models (serialization, API development, production)

**Practical Content:**
- Implementing different neural network architectures (feedforward, CNN, RNN)
- Applying transfer learning with pre-trained models (VGG, ResNet, BERT)
- Fine-tuning pre-trained models for domain-specific tasks
- Performing model evaluation and comparison using cross-validation
- Implementing model selection techniques
- Serializing and saving models for deployment
- Building simple APIs for model serving (Flask, FastAPI)
- Working on end-to-end projects integrating multiple AI techniques

---

### Course 3: AIAT 113 - Mathematics and Probability for Machine Learning
**الرياضيات والاحتمالات لتعلم الآلة**

**Credit Hours:** 4 | **Theory:** 2 | **Practical:** 4 | **Contact Hours:** 6

#### Course Learning Outcomes:

**CLO1:** Demonstrate comprehensive understanding of fundamental mathematical concepts, including linear algebra and probability, and their applications in AI and machine learning for solving complex problems.

**CLO2:** Apply mathematical techniques such as matrix operations, eigenvalue analysis, and multivariable calculus to solve complex machine learning problems.

**CLO3:** Evaluate and interpret data using statistical methods, including hypothesis testing and confidence intervals, to make informed decisions.

**CLO4:** Use dimensionality reduction techniques such as PCA, SVD, and t-SNE effectively for analyzing and visualizing high-dimensional datasets.

**CLO5:** Formulate, implement, and optimize machine learning models using gradient descent and other optimization techniques.

**CLO6:** Implement mathematical and statistical algorithms related to machine learning, including regression, dot products, and projections using Python libraries.

#### Unit Structure:

**Unit 1: Linear Algebra for Machine Learning and Data Transformations** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Machine Learning and Linear Algebra Fundamentals
- Vector Operations and Linear Algebra Fundamentals
- Matrix Operations and Transformations
- Matrices as Factors and Basis Transformations
- Eigenvectors and Eigenvalues

**Practical Content:**
- Performing vector and matrix operations using Python/NumPy
- Implementing substitution/elimination techniques for solving linear equations
- Computing determinants and inverse matrices computationally
- Writing code to apply transformation matrices and compute orthogonal basis sets
- Solving eigenvalue problems programmatically and applying eigenvalue analysis on large-dimensional matrices
- Experimenting with changes in ML model parameters and observing changes in model fit

**Unit 2: Calculus and Multivariate Calculus for Machine Learning** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Calculus Fundamentals (differentiation, chain rule)
- Multivariate Calculus (partial derivatives, Jacobian matrix)
- Calculus in Neural Networks (backpropagation)
- Power Series and Function Approximations

**Practical Content:**
- Applying differentiation to simple functions using Python
- Implementing multivariate chain rule calculations
- Using multivariate calculus to link network parameters to outputs
- Implementing backpropagation in a simple neural network
- Applying calculus concepts to optimize ML model parameters

**Unit 3: Optimization and Statistical Foundations for Machine Learning** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Gradient Descent and Model Optimization
- Regression and Model Fitting
- Statistical Analysis and Data Transformations
- Inner Product and Distance Measures
- Orthogonal Projections and Dimensionality Reduction

**Practical Content:**
- Implementing gradient descent for optimization problems
- Applying regression techniques and model fitting
- Performing statistical analysis on datasets
- Computing inner products and distance measures
- Implementing orthogonal projections and dimensionality reduction techniques

**Unit 4: Dimensionality Reduction and Data Representation Techniques** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Principal Component Analysis (PCA)
- Singular Value Decomposition (SVD)
- t-SNE (t-distributed Stochastic Neighbor Embedding)

**Practical Content:**
- Implementing PCA for dimensionality reduction using Python
- Applying SVD for data compression and feature extraction
- Using t-SNE for visualization of high-dimensional data
- Comparing different dimensionality reduction techniques
- Applying dimensionality reduction to real-world datasets

**Unit 5: Probability, Sampling, and Statistical Inference** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Probability and Distributions (Gaussian, Bernoulli, Poisson)
- Sampling and Estimation (MLE, confidence intervals)
- Bayesian Inference (Bayes' theorem, MCMC)
- Hypothesis Testing (p-values, significance testing)

**Practical Content:**
- Implementing probability distributions in Python (Gaussian, Bernoulli, Poisson)
- Applying Central Limit Theorem with simulations
- Performing sampling and point estimation
- Implementing Maximum Likelihood Estimation (MLE) for different distributions
- Applying Bayesian inference using Python (PyMC3, Stan)
- Implementing hypothesis testing procedures
- Computing p-values and confidence intervals
- Connecting probability theory to ML model implementations

---

### Course 4: AIAT 114 - Machine Learning Algorithms and Applications
**خوارزميات التعلم الآلي والتطبيقات**

**Credit Hours:** 4 | **Theory:** 2 | **Practical:** 4 | **Contact Hours:** 6

#### Course Learning Outcomes:

**CLO1:** Apply data preprocessing methodologies (handling missing data, categorical variables, feature scaling) effectively, understanding basic assumptions.

**CLO2:** Demonstrate competence in linear and multiple linear regression models, including interpreting model coefficients and understanding basic assumptions.

**CLO3:** Evaluate advanced regression algorithms (like Ridge, Lasso, SVR) and select appropriate models based on use cases.

**CLO4:** Build and evaluate classification models (such as Logistic Regression, Decision Trees, SVM, Random Forests) using various performance metrics.

**CLO5:** Implement clustering techniques (like K-means, hierarchical clustering) and dimensionality reduction (PCA, LDA) for exploratory data analysis.

**CLO6:** Deploy model selection strategies (like cross-validation, grid search) and boosting techniques (like XGBoost, AdaBoost) to improve model performance.

**CLO7:** Analyze and interpret machine learning results, providing recommendations effectively in business or research contexts.

#### Unit Structure:

**Unit 1: Regression Algorithms** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Introduction to Regression (simple, multiple, polynomial)
- Regularization in Regression (Ridge, Lasso, Elastic Net)
- Advanced Regression Techniques (SVR, Decision tree regression, Random forest regression)

**Practical Content:**
- Implementing simple and multiple linear regression using scikit-learn
- Applying polynomial regression for non-linear relationships
- Implementing Ridge and Lasso regression with regularization
- Building SVR models with different kernels
- Implementing decision tree and random forest regression
- Comparing regression algorithms on real datasets
- Visualizing regression results and residuals

**Unit 2: Regression and Model Evaluation** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Model Evaluation Metrics (MSE, RMSE, MAE, R²)
- Cross-Validation (k-fold, leave-one-out, stratified)
- Bias-Variance Tradeoff (overfitting, underfitting, model complexity)

**Practical Content:**
- Computing regression evaluation metrics (MSE, RMSE, MAE, R²)
- Implementing k-fold cross-validation for regression models
- Performing leave-one-out and stratified cross-validation
- Analyzing bias-variance tradeoff through learning curves
- Identifying and handling overfitting/underfitting
- Selecting optimal model complexity using validation sets
- Comparing model performance across different algorithms

**Unit 3: Classification Algorithms** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Logistic Regression (sigmoid function, OvR strategies)
- Decision Trees and Random Forests (splitting criteria, bagging)
- Support Vector Machines (SVM) for Classification (kernels, hyperparameters)
- Naive Bayes Classifier (types, applications)
- Model Evaluation Metrics (confusion matrix, ROC, AUC, F1-score)
- Ensemble Learning (Bagging, Boosting, Stacking)

**Practical Content:**
- Building logistic regression models for binary and multi-class classification
- Implementing decision trees and random forests
- Training SVM classifiers with different kernels
- Applying Naive Bayes classifier to classification problems
- Computing evaluation metrics (confusion matrix, ROC curves, AUC, F1-score)
- Implementing ensemble methods (Bagging, Boosting, Stacking)
- Comparing classification algorithms on real datasets

**Unit 4: Clustering and Dimensionality Reduction** (7 theory + 13 practical = 20 hours)

**Theoretical Content:**
- Clustering Techniques (K-Means, Hierarchical, DBSCAN)
- Dimensionality Reduction (PCA, LDA)
- Visualization and Model Evaluation

**Practical Content:**
- Implementing K-Means clustering algorithm
- Applying hierarchical clustering and DBSCAN
- Implementing PCA and LDA for dimensionality reduction
- Visualizing clustering results and reduced dimensions
- Evaluating clustering performance using metrics like silhouette score
- Comparing different clustering algorithms

**Unit 5: Model Selection and Boosting** (7 theory + 13 practical = 20 hours)

**Theoretical Content:**
- Model Selection and Hyperparameter Tuning
- Boosting Techniques (AdaBoost, Gradient Boosting, XGBoost)
- Comprehensive Model Evaluation
- Final Project and Course Summary

**Practical Content:**
- Implementing cross-validation and hyperparameter tuning using Python
- Using Grid Search and Random Search in scikit-learn to optimize parameters
- Building and training boosting models using libraries like XGBoost and LightGBM
- Comparing performance with traditional methods
- Evaluating models on real datasets using performance metrics
- Applying confusion matrices, plotting ROC curves for classification models
- Tuning models for optimal performance and documenting improvements
- Implementing final project: applying learned techniques on real dataset, evaluating results, presenting key insights

---

### Course 5: AIAT 115 - Scalable Data Science
**علم البيانات القابل للتوسع**

**Credit Hours:** 4 | **Theory:** 2 | **Practical:** 4 | **Contact Hours:** 6

#### Course Description:

This comprehensive course aims to equip learners with the necessary skills to analyze and interpret complex datasets effectively using Python. The course starts with fundamental concepts in data science and progresses to scalable techniques for handling large datasets. By the end of the course, participants will be equipped to build powerful, effective, and scalable data-driven solutions and confidently handle real-world data challenges.

#### Course Learning Outcomes:

**Portfolio Capability:** Demonstrate the ability to confidently analyze and visualize data using Python in diverse contexts.

**CLO1:** Demonstrate the ability to analyze and visualize data using Python with confidence in diverse contexts.

**CLO2:** Identify and implement strategies for scaling data processing tasks effectively.

**CLO3:** Clean and prepare raw datasets to make them suitable for analysis and modeling, handling missing data, outliers, and data transformation requirements.

**CLO4:** Build, evaluate, and deploy machine learning models using Python in a scalable environment, utilizing appropriate frameworks and tools.

**CLO5:** Complete a comprehensive data science project involving large-scale models and datasets, demonstrating end-to-end project management skills from data acquisition to model deployment.

#### Unit Structure:

**Unit 1: Introduction to Data Science** (6 theory + 12 practical = 18 hours)

**Theoretical Content:**
- Overview of Data Science and Applications (What is data science?, components: collection, cleaning, analysis, visualization)
- Applications across industries (healthcare, finance, e-commerce)
- Python fundamentals for Data Science
- Jupyter Notebooks introduction
- Python libraries: NumPy, Pandas, cuDF, Numba

**Practical Content:**
- Setting up Python environment and Jupyter Notebooks
- Working with NumPy for numerical computing
- Introduction to Pandas for data manipulation
- Exploring cuDF for GPU-accelerated dataframes
- Basic data operations using Python libraries
- Creating simple data analysis notebooks

**Unit 2: Data Cleaning and Preparation** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Data Import and Export (CSV, Parquet, databases using cuDF)
- Data cleaning techniques
- Handling missing data
- Data normalization and standardization
- Dealing with duplicates and inconsistent data

**Practical Content:**
- Importing data from CSV, Parquet, and other file formats using cuDF
- Exporting processed data to different file formats for later analysis
- Performing data cleaning operations (removing duplicates, handling inconsistencies)
- Handling missing data (imputation, deletion strategies)
- Normalizing and standardizing data for analysis
- Validating data quality and completeness

**Unit 3: Data Visualization** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Using Matplotlib and Seaborn (creating static, animated, interactive visualizations)
- Creating effective charts and graphs
- Interactive visualizations
- Communicating insights through visualizations

**Practical Content:**
- Creating charts using Matplotlib (line plots, bar charts, scatter plots)
- Creating advanced statistical charts using Seaborn
- Building interactive visualizations
- Designing effective data visualizations to communicate insights
- Customizing charts for different audiences

**Unit 4: Introduction to Machine Learning** (7 theory + 13 practical = 20 hours)

**Theoretical Content:**
- Overview of Machine Learning Concepts (definition, types, workflow)
- Machine Learning basics
- Supervised vs. Unsupervised learning
- Building and evaluating ML models
- Model deployment considerations

**Practical Content:**
- Preparing data for machine learning (feature engineering, train/test splits)
- Building simple supervised learning models (linear regression, classification)
- Evaluating model performance using appropriate metrics
- Implementing unsupervised learning algorithms (clustering, dimensionality reduction)
- Comparing different ML models and selecting the best performing one

**Unit 5: Extending the Scope of Data Science** (7 theory + 13 practical = 20 hours)

**Theoretical Content:**
- Introduction to Big Data Concepts (Volume, Variety, Velocity, Veracity)
- Big data frameworks and distributed computing
- Scalable data processing
- GPU acceleration with cuDF
- Performance optimization with Numba
- Production deployment and workflow optimization
- Future trends in data science

**Practical Content:**
- Working with large datasets using cuDF for GPU acceleration
- Optimizing data processing performance with Numba
- Implementing scalable data processing pipelines
- Deploying data science workflows to production environments
- Building end-to-end data science projects with scalable architectures

---

### Course 6: AIAT 116 - Artificial Intelligence Ethics
**أخلاقيات الذكاء الاصطناعي**

**Credit Hours:** 3 | **Theory:** 2 | **Practical:** 2 | **Contact Hours:** 4

#### Course Description:

This course explores the ethical implications, societal impacts, and responsible development of AI and data-driven technologies. Students will engage with ethical frameworks, regulatory guidelines, and case studies to analyze bias, privacy concerns, accountability, and fairness in AI systems critically. Through discussions and practical activities, learners will develop ethical decision-making skills and understand how to align AI applications with human values, legal requirements, and industry best practices.

#### Course Learning Outcomes:

**CLO1:** Explain ethical frameworks (e.g., utilitarianism, deontology, virtue ethics) and their relevance to AI development; analyze case studies of AI ethics violations.

**CLO2:** Identify and analyze bias, fairness, and discrimination in AI systems; apply bias detection and mitigation techniques and fairness metrics.

**CLO3:** Assess privacy, security, and data protection risks in AI applications; apply relevant regulations (e.g., GDPR, CCPA) and privacy-preserving techniques.

**CLO4:** Evaluate transparency, interpretability, and accountability in AI systems; apply XAI techniques (e.g., LIME, SHAP) and accountability frameworks.

**CLO5:** Analyze AI governance, regulations, and future challenges; formulate ethics policies and comply with legal frameworks.

#### Unit Structure:

**Unit 1: Foundations of AI Ethics** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Introduction to Ethics in AI (definition, importance in AI and data science)
- Ethical vs legal considerations in AI development
- Ethical frameworks and theories (Utilitarianism, Deontology, Virtue Ethics)
- The role of ethics in responsible AI development
- Ethical challenges in AI systems
- Unintended consequences of AI systems
- Ethical dilemmas in autonomous decision-making
- Case studies: ethical violations in AI

**Practical Content:**
- Analyzing ethical frameworks and applying them to AI case studies
- Discussing real-world ethical dilemmas in AI applications
- Evaluating case studies of ethical violations (bias in hiring algorithms, discriminatory AI systems)
- Participating in ethical decision-making exercises and debates
- Writing ethical analyses of AI systems

**Unit 2: Bias, Fairness, and Discrimination in AI** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Understanding Bias in AI (data bias, algorithmic bias, human bias)
- Sources of bias in AI models (data collection, feature selection, model training)
- Fairness in AI decision-making
- Fairness criteria (demographic parity, equalized odds, equalized probabilities)
- Discriminatory outcomes in AI applications (hiring, lending, healthcare, policing)
- Legal and ethical frameworks to prevent discrimination
- Bias detection and mitigation techniques (pre-processing, in-processing, post-processing)
- Fair learning and adversarial debiasing
- Explainable AI (XAI) for fairness

**Practical Content:**
- Implementing techniques for detecting and mitigating bias in AI models
- Evaluating fairness metrics in machine learning models
- Applying bias mitigation techniques (pre-processing, in-processing, post-processing)
- Using fairness assessment tools and libraries
- Analyzing real-world cases of bias in AI systems
- Building fair AI models with reduced bias

**Unit 3: Privacy, Security, and Data Protection** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Introduction to Privacy and Security in Data Science (definition, importance)
- Basic principles of data protection: confidentiality, integrity, availability
- Ethical concerns in data collection
- General Data Protection Regulation (GDPR) and user consent
- Privacy risks in AI applications
- Data security and encryption
- Privacy-preserving techniques (differential privacy, federated learning)
- Anonymization and de-identification
- Surveillance and facial recognition ethics
- Case studies: Cambridge Analytica scandal, privacy violations

**Practical Content:**
- Implementing privacy-preserving techniques (differential privacy, federated learning)
- Applying anonymization and de-identification methods to datasets
- Evaluating privacy risks in AI applications
- Analyzing case studies of privacy violations (Cambridge Analytica, data breaches)
- Implementing data security measures and encryption
- Designing privacy-friendly data collection and processing workflows

**Unit 4: Interpretability, Transparency, and Accountability** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Introduction to Interpretability in AI (importance, challenges, difference from understandability)
- Explainable AI (XAI) Techniques (LIME, SHAP, counterfactual analysis)
- Black-box models vs interpretable models
- Transparency in AI systems
- Accountability in AI development (who is responsible for AI decisions?)
- Designing ethical AI systems
- Documentation and audit trails for AI systems

**Practical Content:**
- Implementing XAI Techniques: Applying techniques like LIME and SHAP to interpret black-box models
- Evaluating Model Transparency: Evaluating and interpreting AI model transparency using different tools
- Case Studies Analysis: Analyzing success and failure in transparency and accountability in real-world AI
- Building Accountable AI Systems: Designing AI models with clear accountability frameworks and auditing mechanisms
- Ethical Review and Compliance: Conducting ethical review of AI models to ensure transparency and compliance with legal standards

**Unit 5: AI Governance, Regulations, and Future Challenges** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Introduction to AI Governance (definition, importance, stakeholders)
- Regulations and Legal Frameworks for AI (AI Act in EU, GDPR, industry-specific regulations)
- Legal and Ethical Considerations in AI (human rights, responsibility, accountability)
- Transparency and Accountability in AI
- Emerging Challenges in AI Governance
- Future Trends and Opportunities in AI Governance
- Case Studies in AI Regulation and Governance

**Practical Content:**
- AI Governance Frameworks: Analyzing and comparing different AI governance models
- Regulatory Compliance Auditing: Evaluating AI systems to ensure compliance with global regulations (GDPR, AI Act in EU)
- Transparency and Interpretability Tools: Implementing and testing interpretability techniques like LIME and SHAP
- Case Studies Evaluation: Evaluating regulatory challenges and AI in real world
- Accountability Practices in AI: Developing and simulating monitoring systems for AI decisions
- Predictive Analysis for Future Challenges: Identifying and predicting upcoming challenges in AI regulation

---

### Course 7: AIAT 121 - Natural Language Processing
**معالجة اللغة الطبيعية**

**Credit Hours:** 3 | **Theory:** 2 | **Practical:** 2 | **Contact Hours:** 4

#### Course Learning Outcomes:

**CLO1:** Understand the fundamentals of Natural Language Processing and its importance in real-world applications.

**CLO2:** Apply text processing techniques such as Tokenization, Stemming, Lemmatization, and Vectorization to convert to numerical representations.

**CLO3:** Implement traditional machine learning models for NLP tasks like classification, Named Entity Recognition, and topic modeling.

**CLO4:** Use deep learning techniques such as Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), and Transformers for advanced NLP applications.

**CLO5:** Work with popular NLP frameworks like NLTK, spaCy, and Hugging Face Transformers.

**CLO6:** Develop and evaluate NLP applications such as sentiment analysis, text summarization, and chatbots.

**CLO7:** Analyze ethical considerations and challenges in NLP, including bias and fairness in AI models.

**CLO8:** Fine-tune and optimize pre-trained language models for specialized NLP tasks.

**CLO9:** Implement NLP solutions for multilingual processing and cross-lingual understanding.

**CLO10:** Design and implement end-to-end NLP pipelines for real-world applications.

#### Unit Structure:

**Unit 1: Introduction to Natural Language Processing** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- NLP Fundamentals (definition, history, challenges)
- NLP Applications (chatbots, machine translation, sentiment analysis, speech recognition)
- NLP Tools and Libraries (NLTK, spaCy, Hugging Face Transformers)
- Basic Text Processing (tokenization, stop words, stemming, lemmatization, regex)

**Practical Content:**
- Implementing basic text processing techniques using NLTK and spaCy
- Performing tokenization, stemming, and lemmatization on sample datasets
- Writing a simple text conversion script using Python
- Exploring and analyzing real datasets like movie reviews or news articles

**Unit 2: Text Representation and Feature Engineering** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Word-Based Text Representations (One-Hot Encoding, BoW, TF-IDF)
- Word Embeddings (Word2Vec, GloVe, FastText)
- Contextual Embeddings (ELMo, BERT, GPT)
- Dimensionality Reduction Techniques (PCA, t-SNE, UMAP)

**Practical Content:**
- Converting text to numerical representations using TF-IDF and Word2Vec
- Training and representing word embeddings using Word2Vec from Gensim
- Implementing BERT embeddings using Hugging Face Transformers
- Applying dimensionality reduction on high-dimensional vectors and visualizing results

**Unit 3: Machine Learning for NLP** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Text Classification (sentiment analysis, spam detection)
- Named Entity Recognition (NER) and Part-of-Speech (POS) Tagging
- Topic Modeling (LDA, NMF)
- Model Evaluation Metrics (precision, recall, F1, ROC, AUC)

**Practical Content:**
- Training a spam detection model using Naive Bayes and Scikit-learn
- Building a sentiment analysis model for customer reviews using logistic regression
- Implementing NER and POS tagging using spaCy
- Applying topic modeling (LDA, NMF) on news article datasets

**Unit 4: Deep Learning for NLP** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Neural Networks for NLP
- Recurrent Neural Networks (RNNs)
- Long Short-Term Memory (LSTM) Networks
- Gated Recurrent Units (GRUs)
- Transformer Models and Attention Mechanism
- BERT, GPT, and T5 models
- Sequence-to-Sequence Models and Encoder-Decoder Architectures
- Transfer Learning in NLP

**Practical Content:**
- Building an LSTM-based text classifier using TensorFlow/Keras
- Fine-tuning BERT model for text classification using Hugging Face Transformers
- Implementing machine translation model using seq2seq with attention mechanisms
- Experimenting with GPT-3/GPT-4 for text generation using OpenAI API

**Unit 5: NLP Applications and Ethics Standards** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Text Summarization (extractive vs generative)
- Building Conversational AI and Chatbots
- Ethical Considerations in NLP (bias, fake news, privacy)
- Future Trends in NLP and AI

**Practical Content:**
- Implementing text summarization (extractive and generative approaches)
- Building a simple chatbot using rule-based or AI-powered approaches
- Analyzing bias in language models and implementing fairness checks
- Working on end-to-end NLP projects combining multiple techniques

---

### Course 8: AIAT 122 - Deep Learning
**التعلم العميق**

**Credit Hours:** 3 | **Theory:** 2 | **Practical:** 2 | **Contact Hours:** 4

#### Course Learning Outcomes:

**CLO1:** Explain fundamental concepts of deep learning, including neural network architecture and performance, backpropagation algorithm, and gradient descent.

**CLO2:** Develop and implement deep learning architectures such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformers using frameworks based on TensorFlow and PyTorch.

**CLO3:** Build and deploy deep learning models to solve real-world problems, including tasks such as image recognition (classification, object detection), Natural Language Processing (sentiment analysis, machine translation), and reinforcement learning (like Q-learning).

**CLO4:** Optimize deep learning models by applying techniques like hyperparameter tuning (grid search, random search), regularization (dropout, L2 regularization), and transfer learning (retraining pre-trained models).

**CLO5:** Evaluate critically ethical issues related to deep learning, including biases in datasets, fairness in model predictions, and interpretability of complex models, discussing potential solutions.

#### Unit Structure:

**Unit 1: Introduction to Deep Learning and Neural Networks** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Deep Learning Fundamentals (difference from ML, applications)
- Artificial Neural Networks (ANNs) - perceptrons, MLPs
- Activation Functions (ReLU, Sigmoid, Tanh, Softmax)
- Training Neural Networks (forward/backward propagation, gradient descent)
- Optimization Algorithms (SGD, Adam, RMSprop)
- Deep Learning Frameworks (TensorFlow, PyTorch, Google Colab)

**Practical Content:**
- Deep learning fundamentals compared to traditional ML
- Neural network structure and operation
- Activation functions and optimization algorithms
- Forward and backward propagation
- Setting up TensorFlow and PyTorch
- Implementing basic perceptron and MLP
- Training a neural network on simple dataset (e.g., MNIST handwritten digits)

**Unit 2: Convolutional Neural Networks (CNNs) for Computer Vision** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Image Processing Fundamentals (pixels, RGB, transformations)
- CNN Architecture (convolution, pooling, fully connected layers)
- Famous CNN Architectures (LeNet, AlexNet, VGG, ResNet, Inception)
- Advanced CNN Applications (object detection: YOLO, SSD, Faster R-CNN; segmentation: U-Net, Mask R-CNN)

**Practical Content:**
- Image processing fundamentals and feature extraction
- CNN architecture: convolutional layers, pooling layers, fully connected layers
- Introduction to pre-trained CNN architectures (ResNet, VGG, Inception)
- Implementing a CNN from scratch using TensorFlow/PyTorch
- Training a CNN on image datasets (e.g., CIFAR-10, ImageNet)
- Transfer learning using a pre-trained model for object detection

**Unit 3: Recurrent Neural Networks (RNNs) and Transformers for Sequential Data** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Understanding Sequential Data (temporal, audio, textual)
- Recurrent Neural Networks (RNNs) - vanishing/exploding gradients
- LSTM and GRU Networks
- Attention Mechanism and Transformers
- BERT and GPT applications in NLP

**Practical Content:**
- Understanding sequential data and time series prediction
- RNN structure and challenges (vanishing gradients problem)
- Advanced architectures: LSTM, GRU, Transformers, attention mechanism
- Applications in NLP
- Implementing RNN, LSTM, and GRU for text generation
- Using Transformer models like BERT and GPT for NLP tasks
- Performing sentiment analysis, machine translation, and speech recognition

**Unit 4: Advanced Deep Learning Techniques** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Generative Adversarial Networks (GANs) - image generation, Deepfakes
- Autoencoders and Variational Autoencoders (VAEs)
- Reinforcement Learning Fundamentals (DQN, policy gradients)
- Transfer Learning (pre-trained models, fine-tuning)
- Ethical Considerations (bias, fairness, interpretability)

**Practical Content:**
- GANs and Autoencoders (VAEs)
- Reinforcement learning fundamentals (Deep Q-Networks, policy gradients)
- Transfer learning and fine-tuning models
- Ethical concerns in AI (bias, fairness, interpretability)
- Building and training GANs for image generation
- Implementing a VAE (Variational Autoencoder) for anomaly detection
- Fine-tuning a pre-trained model (e.g., using BERT for text classification)
- Exploring reinforcement learning using OpenAI Gym

**Unit 5: Model Optimization and Deployment** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Regularization and Hyperparameter Tuning (Dropout, Batch Norm, L1/L2)
- Model Compression (pruning, quantization)
- Deploying Deep Learning Models (SavedModel, ONNX, Flask/FastAPI, TensorFlow Serving)
- Cloud Deployment (Google Cloud, AWS, Azure)
- Mobile Deployment (TensorFlow Lite, ONNX)

**Practical Content:**
- Regularization and hyperparameter tuning
- Regularization techniques (Dropout, Batch Normalization)
- Model compression for edge devices
- Cloud deployment of deep learning models
- Optimizing deep learning models using regularization
- Exporting models in different formats (SavedModel, ONNX)
- Deploying models using Flask/FastAPI or TensorFlow Serving
- Deploying models on cloud platforms (AWS, GCP, Azure)

---

### Course 9: AIAT 123 - Reinforcement Learning
**التعلم التعزيزي**

**Credit Hours:** 3 | **Theory:** 2 | **Practical:** 2 | **Contact Hours:** 4

#### Course Learning Outcomes:

**CLO1:** Explain basic principles of reinforcement learning, including key concepts such as agents, reward signals, policies, and Markov Decision Processes (MDPs).

**CLO2:** Apply reinforcement learning algorithms such as Q-learning, policy gradient methods, and Actor-Critic approaches to solve decision-making problems.

**CLO3:** Implement deep reinforcement learning techniques using neural networks and explore their relationship with deep learning.

**CLO4:** Evaluate and optimize reinforcement learning models by applying strategies to improve training efficiency and performance.

**CLO5:** Develop solutions based on reinforcement learning for real-world applications such as autonomous navigation, game playing, and optimization tasks.

**CLO6:** Analyze critically challenges and ethical considerations in reinforcement learning, including exploration vs. exploitation tradeoffs, reward shaping, and fairness in AI systems.

#### Unit Structure:

**Unit 1: Introduction to Reinforcement Learning** (6 theory + 12 practical = 18 hours)

**Theoretical Content:**
- Introduction to Reinforcement Learning (difference from supervised/unsupervised)
- Basic Concepts (agent, environment, reward, action, state, policy, value function)
- Markov Decision Processes (MDPs) - Bellman equation, value iteration
- Exploration vs Exploitation (Epsilon-Greedy, UCB, Thompson Sampling)
- Applications (robotics, healthcare, gaming, finance)
- Setting Up RL Problems (state/action spaces, reward functions)

**Practical Content:**
- Setting up RL environment: installing OpenAI Gym and using Python-based frameworks for RL
- Implementing MDPs: solving simple MDPs using Value Iteration and Policy Iteration algorithms
- Exploration strategies: programming Epsilon-Greedy strategy and visualizing its impact
- Solving RL problems: defining states, actions, and rewards, running RL simulations
- Mini projects: applying RL in games like CartPole and FrozenLake, implementing Q-learning and DQN

**Unit 2: Prediction and Control without a Model** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Dynamic Programming (DP) - Bellman equations, value/policy iteration
- Monte Carlo Methods (prediction, control, first-visit vs every-visit)
- Temporal Difference (TD) Learning - TD(0), n-step TD
- Q-Learning (Q-table, off-policy learning, convergence)
- SARSA (on-policy approach, difference from Q-learning)
- Policy Iteration and Value Iteration

**Practical Content:**
- Implementing Monte Carlo methods for estimating value functions
- Applying Q-learning and SARSA in OpenAI Gym (CartPole, FrozenLake)
- Using Python to update Q-tables and display agent learning progress
- Comparing TD learning with Monte Carlo methods
- Implementing policy iteration and value iteration algorithms

**Unit 3: Deep Reinforcement Learning** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Introduction to Deep RL (what is DRL, why DRL)
- Deep Q-Learning (DQN) - experience replay, target networks
- Policy Gradient Methods - REINFORCE algorithm
- Actor-Critic Methods - A2C, PPO
- DDPG (Deep Deterministic Policy Gradient)
- Deep RL Applications (games, robotics, self-driving cars, healthcare)
- Challenges in Deep RL (exploration vs exploitation, sample efficiency, stability)

**Practical Content:**
- Implementing Deep RL: starting with simple algorithms like DQN and progressing to advanced algorithms like Actor-Critic, DDPG in environments like OpenAI Gym
- Training and evaluation: monitoring learning curves, rewards, and stability to evaluate model performance
- Optimization: experimenting with techniques like experience replay, reward shaping, and hyperparameter tuning to improve learning efficiency
- Applications: applying Deep RL in games, robotics, and optimization tasks in simulation environments
- Handling challenges: working on exploration vs exploitation problems, stability, and experimenting with techniques like intrinsic motivation and curriculum learning

**Unit 4: Exploration and Exploitation Strategies** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Introduction to Exploration and Exploitation
- Exploration Strategies (Epsilon-Greedy, Boltzmann Exploration, Thompson Sampling, Intrinsic Motivation)
- Exploitation Strategies (greedy action selection, deterministic policies)
- Balancing Exploration and Exploitation (trade-off strategies, epsilon decay)
- Adaptive Exploration Strategies (UCB, Bayesian Optimization)

**Practical Content:**
- Implementing various exploration strategies
- Comparing performance of different exploration methods
- Tuning exploration parameters

**Unit 5: Advanced Topics and Applications** (7 theory + 3 practical = 10 hours)

**Theoretical Content:**
- Multi-Agent RL (cooperative and competitive settings)
- Hierarchical RL (options framework, goal-conditioned RL)
- Model-Based RL (learning world models, planning with learned models)
- Real-World Applications (robotics, game playing, resource optimization)

**Practical Content:**
- Implementing multi-agent RL environments and training cooperative/competitive agents
- Experimenting with hierarchical RL using options framework
- Building model-based RL systems with learned world models
- Applying RL in practical scenarios: robotics simulations, game playing, resource optimization
- Comparing model-based vs model-free approaches
- Implementing goal-conditioned RL for complex tasks

---

### Course 10: AIAT 124 - Generative Artificial Intelligence
**الذكاء الاصطناعي التوليدي**

**Credit Hours:** 3 | **Theory:** 2 | **Practical:** 2 | **Contact Hours:** 4

#### Course Learning Outcomes:

**CLO1:** Explain basic principles of generative AI, including probabilistic modeling and neural network architectures, latent space, sampling, and data generation.

**CLO2:** Apply generative modeling techniques such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Transformer-based models (like GPT and BERT) to generate synthetic data across different domains.

**CLO3:** Implement and optimize generative models using frameworks like TensorFlow and PyTorch for tasks such as text generation, image synthesis, and audio creation.

**CLO4:** Evaluate generative model performance using quantitative metrics (like FID, BLEU, and perplexity) and qualitative assessments, addressing challenges like mode collapse and overfitting.

**CLO5:** Design and develop solutions based on generative AI for practical applications, including automated content creation, data augmentation, and AI-supported creativity in industries like healthcare, entertainment, and design.

**CLO6:** Analyze ethical, legal, and social implications of generative AI, including issues related to bias, misinformation, intellectual property rights, and responsible deployment of AI.

**CLO7:** Explore emerging trends and future developments in generative AI, such as multimodal generation, diffusion models, and their potential impacts on industry and society.

#### Unit Structure:

**Unit 1: Foundations of Generative AI** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Introduction to Generative Models (discriminative vs generative)
- Deep Learning Foundations for Generative AI
- Variational Autoencoders (VAEs) - autoencoder architecture, latent space
- Generative Adversarial Networks (GANs) - generator/discriminator, variants (DCGAN, StyleGAN, WGAN)
- Training and Evaluation of Generative Models (metrics: perplexity, BLEU, FID)

**Practical Content:**
- Building and training a simple GAN using TensorFlow/PyTorch
- Implementing a VAE (Variational Autoencoder) for image generation
- Comparing different generative model architectures (GANs vs VAEs)
- Experimenting with training techniques like gradient penalties and spectral normalization
- Evaluating generative models using metrics like FID and BLEU scores
- Generating samples from trained generative models
- Exploring latent spaces and interpolation in VAEs

**Unit 2: Text and Language Generation** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Language Models for Text Generation (N-gram, neural language models, RNNs)
- Transformer-based Generation (GPT architecture, autoregressive generation, beam search)
- Advanced Language Models (GPT-2/3/4, BERT, T5)
- Prompt Engineering (effective prompting, few-shot/zero-shot learning)
- Applications of Text Generation (conversational AI, content creation, code generation)

**Practical Content:**
- Implementing text generation using GPT models
- Fine-tuning language models for specific tasks
- Practicing prompt engineering with OpenAI API or Hugging Face Transformers
- Building a text-to-text generation system using Transformers
- Generating creative text (stories, poems) using language models
- Implementing conversational AI or chatbot using generative models
- Evaluating text generation quality using metrics like BLEU and perplexity

**Unit 3: Image and Visual Generation** (6 theory + 6 practical = 12 hours)

**Theoretical Content:**
- Image Generation Techniques (GANs for image synthesis, StyleGAN variants)
- Diffusion Models (denoising diffusion probabilistic models, DALL-E, Stable Diffusion)
- Image-to-Image Translation (Pix2Pix, CycleGAN, style transfer)

**Practical Content:**
- Generating AI-created images using StyleGAN, DALL-E, or Stable Diffusion
- Experimenting with Deepfake techniques
- Audio and voice synthesis using AI tools like WaveNet or Jukebox
- Creating AI-generated music and human voice synthesis
- Applying models like OpenAI Codex or GitHub Copilot for code generation
- Automating code generation and software development tasks
- Developing comprehensive projects integrating generative AI in real-world applications like marketing, healthcare, or gaming
- Reviewing AI-generated outputs for accuracy, fairness, and potential biases

**Unit 4: Ethical and Regulatory Considerations** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Bias and Fairness in Generative AI (sources of bias, mitigation techniques)
- Deepfakes and Misinformation (impact, detection, mitigation)
- Intellectual Property Rights (ownership of AI-generated content, copyright)
- Regulatory Frameworks (GDPR, AI Act, compliance)
- Responsible AI Development and Governance
- Future Ethical and Regulatory Challenges

**Practical Content:**
- Implementing techniques for detecting and mitigating bias in generative models
- Experimenting with deepfake creation and using tools to detect AI-generated content
- Discussing real-world cases related to AI-generated content and intellectual property rights
- Applying AI regulatory guidelines (like GDPR) to ensure compliance in model development
- Building ethical AI models with principles like fairness and transparency
- Participating in discussions on ethical issues in AI development and use

**Unit 5: Future Trends and Research in Generative AI** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- New Developments in Generative Models (GANs advances, VAEs, Diffusion models)
- Multimodal Generative AI (CLIP, text-to-image models, multi-input systems)
- Applications in Creative Industries (digital art, music, video, game design)
- Legal and Ethical Challenges (copyright, deepfakes, bias)
- Research and Future Trends (stability, efficiency, computational challenges)

**Practical Content:**
- Experimenting with advanced generative models (StyleGAN, Stable Diffusion, DALL-E)
- Building multimodal applications that generate content from multiple inputs
- Generating creative content (images, text, audio) for artistic projects
- Implementing scientific applications using generative AI (e.g., data augmentation for research)
- Evaluating model quality and ethics: testing for bias, fairness, and accuracy in generated content
- Building a comprehensive project integrating generative AI in real-world applications (marketing, healthcare, or gaming)
- Reviewing AI-generated outputs for accuracy, fairness, and potential biases

---

### Course 11: AIAT 125 - Deploying AI Models
**تطبيق نماذج الذكاء الاصطناعي**

**Credit Hours:** 4 | **Theory:** 2 | **Practical:** 4 | **Contact Hours:** 6

#### Course Learning Outcomes:

**CLO1:** Explain key concepts for deploying AI models and the comprehensive deployment process.

**CLO2:** Apply deployment techniques to package AI models for deployment in different environments.

**CLO3:** Implement and manage Application Programming Interfaces (APIs) for serving AI models and creating inference pipelines.

**CLO4:** Use containerization techniques (Docker) and orchestration tools (Kubernetes) to deploy scalable models.

**CLO5:** Set up Continuous Integration/Continuous Delivery (CI/CD) pipelines to deploy AI models with minimal downtime.

**CLO6:** Monitor deployed AI models in terms of performance and solve common problems related to model degradation or bias.

#### Unit Structure:

**Unit 1: Introduction to AI Model Deployment** (6 theory + 12 practical = 18 hours)

**Theoretical Content:**
- AI Model Deployment Lifecycle (development, testing, deployment, monitoring)
- Deployment Environments (cloud vs local, AWS/GCP/Azure benefits)
- Key Challenges in Model Deployment (performance, scalability, ethics, security)
- Model Packaging (serialization formats: Pickle, ONNX, PMML, SavedModel)
- Deployment Tools and Frameworks (Flask, FastAPI, TensorFlow Serving, Docker, Kubernetes)

**Practical Content:**
- Preparing AI model for deployment: training and saving a model using TensorFlow or PyTorch
- Building API interface for AI models: implementing a simple API using Flask or FastAPI to serve predictions
- Containerizing AI model: using Docker to package a trained model for scalable deployment
- Deploying model on cloud: hosting a model on AWS, Google Cloud, or Azure
- Model validation and testing: running unit tests and performance evaluations before deployment
- Monitoring and updating deployed models: implementing logs, feedback loops, and retraining strategies

**Unit 2: Model Packaging and Serving** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Model Packaging and Data Serialization (Pickle, ONNX, PMML, SavedModel)
- Containerized Packaging Using Containers (Docker images, dependencies)
- Building APIs for Model Serving (REST, gRPC, Flask, FastAPI)
- Model Serving Frameworks (TensorFlow Serving, TorchServe, MLflow)
- Batch vs Real-time Inference (streaming with Kafka/RabbitMQ)
- Scaling and Managing Model Serving (load balancing, auto-scaling, Kubernetes)

**Practical Content:**
- Model serialization: saving and loading models in different formats (Pickle, ONNX, SavedModel)
- Creating Docker images for AI models with proper dependencies
- Building REST and gRPC APIs using Flask and FastAPI
- Deploying models using TensorFlow Serving or TorchServe
- Implementing batch and real-time inference pipelines
- Setting up load balancing and auto-scaling for model serving

**Unit 3: Cloud Deployment and Infrastructure** (6 theory + 13 practical = 19 hours)

**Theoretical Content:**
- Introduction to Cloud Computing for AI Deployment (IaaS, PaaS, SaaS)
- Major Cloud Platforms (AWS SageMaker, GCP Vertex AI, Azure ML)
- Containers and Orchestration (Docker, Kubernetes)
- Model Deployment Strategies on Cloud (batch vs real-time, REST APIs)
- Performance Optimization, Compliance, and Security

**Practical Content:**
- Deploying models on cloud platforms (AWS SageMaker, GCP Vertex AI, Azure ML)
- Building REST APIs for model serving on cloud infrastructure
- Using Kubernetes for orchestrating containerized AI models
- Optimizing model performance and resource usage on cloud
- Implementing security and compliance measures for deployed models

**Unit 4: Containers and Orchestration** (7 theory + 7 practical = 14 hours)

**Theoretical Content:**
- Introduction to Containers (Docker basics: images, containers, Dockerfile)
- Working with Docker for AI Model Deployment
- Introduction to Kubernetes (pods, nodes, clusters, scaling)
- CI/CD for AI Model Deployment (GitHub Actions, Jenkins, versioning)

**Practical Content:**
- Building Docker containers for AI models
- Creating Dockerfiles for reproducible model deployments
- Deploying models using Kubernetes
- Setting up CI/CD pipelines for automated model deployment
- Managing containerized model versions and updates

**Unit 5: Monitoring, Maintenance, and MLOps** (7 theory + 3 practical = 10 hours)

**Theoretical Content:**
- Model Monitoring (performance tracking, drift detection, alerting)
- MLOps Best Practices (experiment tracking, model versioning, reproducibility)
- Model Maintenance (retraining strategies, A/B testing, canary deployments)

**Practical Content:**
- Setting up model monitoring and performance tracking systems
- Implementing drift detection algorithms
- Using experiment tracking tools (MLflow, Weights & Biases)
- Implementing model versioning and reproducibility practices
- Setting up retraining pipelines
- Performing A/B testing for model comparison
- Implementing canary deployment strategies

---

### Course 12: AIAT 126 - Graduation Project
**مشروع التخرج**

**Credit Hours:** 5 | **Theory:** 1 | **Practical:** 8 | **Contact Hours:** 10

#### Course Learning Outcomes:

**CLO1:** Design and develop a comprehensive solution based on AI to address a specific real-world problem.

**CLO2:** Integrate knowledge from different AI subdisciplines into a coherent and practical system.

**CLO3:** Conduct critical evaluation of the implemented solution's performance using relevant metrics.

**CLO4:** Communicate effectively the project objectives, processes, results, and implications through technical documentation.

**CLO5:** Identify and analyze ethical, legal, and social considerations related to the AI solution.

#### Unit Structure:

**Unit 1: Project Planning and Proposal** (3 theory + 11 practical = 14 hours)

**Theoretical Content:**
- Identifying Project Scope and Objectives (goals, feasibility, stakeholder analysis)
- Literature Review and Background Research (research papers, state-of-the-art, gap analysis)
- Writing Project Proposal (structure, methodology, timeline, risk assessment)
- Defining Success Metrics (evaluation metrics, success criteria, baseline targets)

**Practical Content:**
- Selecting and defining a graduation project topic
- Conducting literature review and compiling relevant research papers
- Writing a comprehensive project proposal document
- Creating project timeline and resource allocation plan
- Defining success metrics and evaluation criteria for the project
- Presenting project proposal to advisors/peers for feedback

**Unit 2: Data Collection and Preparation** (3 theory + 18 practical = 21 hours)

**Theoretical Content:**
- Data Sourcing Strategies (public datasets, APIs, web scraping, legal considerations)
- Data Cleaning and Preprocessing (missing data, outliers, normalization)
- Feature Engineering (feature selection/extraction, transformation, domain-specific techniques)
- Data Validation (quality assessment, train/validation/test splits, bias detection)

**Practical Content:**
- Collecting and acquiring datasets for the graduation project
- Performing data cleaning and preprocessing using Python libraries (Pandas, NumPy)
- Implementing feature engineering techniques
- Validating data quality and preparing train/validation/test splits
- Documenting data collection and preprocessing procedures
- Creating data exploration notebooks with visualizations

**Unit 3: Model Development and Training** (3 theory + 25 practical = 28 hours)

**Theoretical Content:**
- Model Selection and Architecture Design (algorithm selection, NN architectures, transfer learning)
- Training and Validation (training pipelines, validation strategies, monitoring)
- Hyperparameter Optimization (understanding hyperparameters, Grid/Random/Bayesian search)
- Performance Evaluation (evaluation metrics, pipelines, failure analysis)

**Practical Content:**
- Implementing model architecture and training pipeline
- Training models with different hyperparameter configurations
- Performing hyperparameter optimization using grid search or automated tools
- Evaluating model performance using appropriate metrics
- Analyzing model outputs and identifying areas for improvement
- Iteratively refining the model based on validation results
- Documenting training procedures and results

**Unit 4: Evaluation and Optimization** (3 theory + 25 practical = 28 hours)

**Theoretical Content:**
- Understanding Evaluation Metrics for Different AI Tasks
- Techniques for Model Optimization and Fine-tuning
- Addressing Overfitting and Underfitting
- Comparative Analysis with Baseline Models

**Practical Content:**
- Conducting experiments and collecting performance metrics
- Comparing results with baseline or standard models
- Analyzing failure cases and identifying weaknesses in the model
- Visualizing results using graphs, confusion matrices, or heat maps
- Iteratively improving model parameters or retraining with improved data

**Unit 5: Project Documentation and Final Presentation** (4 theory + 17 practical = 21 hours)

**Theoretical Content:**
- Technical Writing Standards and Report Structure
- Effective Data Visualization and Storytelling with AI Results
- Public Speaking Principles and Presentation Design

**Practical Content:**
- Writing final project report (including summary, methodology, results, discussion)
- Designing slide decks or posters for presentation
- Preparing recorded video or live demonstration of project
- Practicing oral presentation or defense of project
- Compiling source code, documents, and final submission package

---

## Unit Structure for Each Course

Each course is divided into **5 units**, with the following typical structure:

- **Unit 1:** Introduction and fundamental concepts
- **Unit 2:** Core techniques and methodologies
- **Unit 3:** Advanced topics and applications
- **Unit 4:** Integration and optimization
- **Unit 5:** Projects, ethics, and future trends

**Total per course:**
- **Theory hours:** 32
- **Practical hours:** 32
- **Total:** 64 hours

---

## Assessment Methods

Each course includes multiple assessment methods:

1. **Formative Assessments:** Quizzes, assignments, practical exercises
2. **Projects:** Hands-on projects demonstrating practical skills
3. **Case Studies:** Analysis of real-world AI applications
4. **Final Examination:** Comprehensive assessment of theoretical and practical knowledge
5. **Graduation Project:** Capstone project demonstrating mastery of AI concepts

---

## Key Technologies and Tools

Students will gain hands-on experience with:

- **Programming Languages:** Python
- **ML/DL Frameworks:** TensorFlow, PyTorch, Keras
- **NLP Libraries:** NLTK, spaCy, Hugging Face Transformers
- **Data Science Tools:** NumPy, Pandas, Scikit-learn
- **Visualization:** Matplotlib, Seaborn
- **Deployment:** Docker, Kubernetes, Flask/FastAPI
- **Version Control:** Git
- **Cloud Platforms:** (for scalable deployment)

---

## Prerequisites

- Bachelor's degree in Computer Science or equivalent
- Advanced computer skills test covering:
  - Programming
  - Data structures and algorithms
  - Systems analysis
  - Deep Python proficiency
- Personal interview assessing motivation and readiness
- Minimum age: 21 years at graduation

---

## Graduation Requirements

- Complete all 12 courses successfully
- Complete graduation project
- Demonstrate competency in all CLOs
- Meet ethical and professional standards

---

**Document Generated:** January 7, 2025  
**Source Document:** دبلوم مشارك الذكاء الاصطناعي (اكاديمية طويق للتدريب) نهائي.pdf (101 pages)  
**Extraction Method:** Automated text extraction using pdfplumber + manual verification

---

## Notes

1. Some course CLOs (particularly for Course 5: Scalable Data Science and Course 6: AI Ethics) were not fully detailed in the extracted sections and may require additional verification from the original PDF.

2. The program follows the Saudi National Qualifications Framework at Level 4.

3. Total program duration: 2 semesters × 16 weeks = 32 weeks of intensive training.

4. The diploma emphasizes both theoretical foundations and practical applications with a 50/50 split between theory and hands-on practice.

5. All courses integrate ethical considerations and real-world applications throughout the curriculum.

