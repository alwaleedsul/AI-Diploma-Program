{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Logistic Regression and Classification Metrics | Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ ÙˆÙ…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØµÙ†ÙŠÙ\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Unit 1: All examples** - Data processing and regression\n",
    "- âœ… **Unit 2: All examples** - Advanced regression and cross-validation\n",
    "- âœ… **Understanding of classification**: Predicting categories (0/1) vs continuous values\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding the difference between regression and classification\n",
    "- Knowing which metrics to use for classification\n",
    "- Understanding probability predictions vs class predictions\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is Unit 3, Example 1** - it's your first classification model!\n",
    "\n",
    "**Why this example FIRST in Unit 3?**\n",
    "- **Before** you can use advanced classification, you need to understand basic classification\n",
    "- **Before** you can evaluate classification models, you need to know classification metrics\n",
    "- **Before** you can use complex classifiers, you need to master the simplest one\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Unit 1, Example 4: Linear Regression (logistic regression is similar but for classification)\n",
    "- ğŸ““ Unit 2: All examples (evaluation concepts apply here too)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Example 2: Decision Trees (more complex classifier)\n",
    "- ğŸ““ Example 3: SVM (advanced classifier)\n",
    "- ğŸ““ All classification problems (logistic regression is the foundation!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Logistic regression is the **simplest classification model** (easy to understand)\n",
    "2. Logistic regression teaches **classification metrics** (different from regression!)\n",
    "3. Logistic regression shows **probability predictions** (important for all classifiers)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Predicting Categories Instead of Numbers | Ø§Ù„Ù‚ØµØ©: Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ¦Ø§Øª Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù…\n",
    "\n",
    "Imagine you're a fraud investigator. **Before** logistic regression, you can only predict continuous values (like transaction amounts). **After** logistic regression, you can predict categories (like \"fraud\" or \"legitimate\") - much more useful for threat detection!\n",
    "\n",
    "Same with machine learning: **Before** logistic regression, we only predicted numbers (regression). **After** logistic regression, we can predict categories (classification) - opens up many new applications!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Logistic Regression Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠØŸ\n",
    "\n",
    "Logistic regression is the foundation of classification:\n",
    "- **Simplest Classifier**: Easy to understand and interpret\n",
    "- **Probability Outputs**: Gives probabilities, not just predictions\n",
    "- **Fast and Efficient**: Works quickly on large datasets\n",
    "- **Interpretable**: You can see how features affect class probability\n",
    "- **Real-World Use**: Used in medicine, finance, marketing, and more\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ Real-World Applications | Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©\n",
    "\n",
    "**Logistic Regression is used in MANY industries for binary classification problems!** Here's where you'll find it:\n",
    "\n",
    "### ğŸ›ï¸ Government & Public Safety Sector (GDI) | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠ ÙˆØ§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (GDI)\n",
    "- **Fraud Detection**: Predict if financial transaction is fraudulent (fraud/legitimate) â†’ terrorism financing detection\n",
    "- **Threat Detection**: Predict if individual/activity poses security threat (threat/safe) â†’ counter-espionage\n",
    "- **Identity Verification**: Verify if person matches ID documents (match/no match) â†’ border control\n",
    "- **Suspicious Activity Detection**: Classify activities as suspicious/normal â†’ surveillance systems\n",
    "- **Crime Risk Assessment**: Predict if area/person has high crime risk (high risk/low risk) â†’ crime prevention\n",
    "- **Border Security**: Classify border crossings as legitimate/suspicious â†’ immigration control\n",
    "\n",
    "### ğŸ”’ Security & Cybersecurity Sector | Ø§Ù„Ø£Ù…Ù† ÙˆØ§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ\n",
    "- **Intrusion Detection**: Predict if network activity is attack (attack/normal) â†’ cyber threat detection\n",
    "- **Malware Detection**: Classify software as malware or safe â†’ cyber security\n",
    "- **Access Control**: Predict if user access should be granted (grant/deny) â†’ secure facilities\n",
    "- **Anomaly Detection**: Classify behavior as normal or anomalous â†’ security monitoring\n",
    "\n",
    "### ğŸ’° Finance & Banking Sector | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ ÙˆØ§Ù„Ù…ØµØ±ÙÙŠ\n",
    "- **Credit Approval**: Predict if loan applicant will default (approve/reject)\n",
    "- **Fraud Detection**: Predict if transaction is fraudulent (fraud/legitimate)\n",
    "- **Insurance Claims**: Predict if insurance claim is fraudulent (fraud/legitimate)\n",
    "- **Customer Churn**: Predict if customer will leave bank (churn/stay)\n",
    "- **Credit Card Approval**: Predict if credit card application should be approved\n",
    "- **Risk Assessment**: Predict if investment is high risk (high risk/low risk)\n",
    "\n",
    "### ğŸ“§ Email & Communication Sector | Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙˆØ§Ù„Ø§ØªØµØ§Ù„Ø§Øª\n",
    "- **Spam Detection**: Classify emails as spam or not spam (most common use case!)\n",
    "- **Sentiment Analysis**: Classify text as positive or negative sentiment\n",
    "- **Language Detection**: Classify text as one language or another\n",
    "- **Topic Classification**: Classify documents into categories (sports/news/tech)\n",
    "- **Abuse Detection**: Detect abusive content in social media (abusive/normal)\n",
    "\n",
    "### ğŸ“Š Marketing & E-commerce Sector | Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ ÙˆØ§Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©\n",
    "- **Customer Churn**: Predict if customer will stop buying (churn/retain)\n",
    "- **Purchase Prediction**: Predict if customer will purchase product (buy/not buy)\n",
    "- **Ad Click Prediction**: Predict if user will click ad (click/no click)\n",
    "- **Customer Segmentation**: Classify customers into segments (high value/low value)\n",
    "- **Product Recommendation**: Predict if customer will like product (like/dislike)\n",
    "- **Price Sensitivity**: Predict if customer is price sensitive (sensitive/not sensitive)\n",
    "\n",
    "### ğŸ­ Manufacturing & Quality Control | Ø§Ù„ØªØµÙ†ÙŠØ¹ ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©\n",
    "- **Defect Detection**: Predict if product is defective (defective/ok)\n",
    "- **Quality Control**: Classify products as pass or fail quality inspection\n",
    "- **Equipment Failure**: Predict if equipment will fail (fail/operational)\n",
    "- **Maintenance Needs**: Predict if maintenance is needed (needed/not needed)\n",
    "- **Production Issues**: Predict if production will have issues (issue/no issue)\n",
    "\n",
    "### ğŸ“ Education Sector | Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…\n",
    "- **Admission Prediction**: Predict if student will be admitted (admit/reject)\n",
    "- **Student Success**: Predict if student will pass course (pass/fail)\n",
    "- **Dropout Prediction**: Predict if student will drop out (dropout/continue)\n",
    "- **Scholarship Eligibility**: Predict if student qualifies for scholarship\n",
    "- **Course Recommendation**: Predict if student should take course\n",
    "\n",
    "### ğŸ”’ Security & Cybersecurity Sector | Ø§Ù„Ø£Ù…Ù† ÙˆØ§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ\n",
    "- **Intrusion Detection**: Predict if network activity is attack (attack/normal)\n",
    "- **Malware Detection**: Classify software as malware or safe\n",
    "- **Access Control**: Predict if user access should be granted (grant/deny)\n",
    "- **Threat Detection**: Predict if system is under threat (threat/safe)\n",
    "- **Anomaly Detection**: Classify behavior as normal or anomalous\n",
    "\n",
    "### ğŸ¥ Healthcare & Medical Sector | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„ØµØ­ÙŠ ÙˆØ§Ù„Ø·Ø¨ÙŠ\n",
    "- **Disease Diagnosis**: Predict if patient has disease (cancer, diabetes, heart disease) based on symptoms, test results\n",
    "- **Medical Imaging**: Classify medical images (X-rays, MRIs) as normal or abnormal\n",
    "- **Drug Response**: Predict if patient will respond to treatment (respond/not respond)\n",
    "- **Patient Readmission**: Predict if patient will be readmitted to hospital (yes/no)\n",
    "- **Surgery Risk Assessment**: Predict if surgery will be successful (success/failure)\n",
    "- **Disease Progression**: Predict if disease will progress (progress/stable)\n",
    "\n",
    "### ğŸ’¡ Why Logistic Regression is Popular:\n",
    "- **Interpretable**: Easy to explain to non-technical stakeholders\n",
    "- **Fast**: Quick to train and make predictions\n",
    "- **Probability Outputs**: Gives probability scores (not just yes/no)\n",
    "- **Baseline Model**: Often used as starting point for classification\n",
    "- **Regulatory Compliance**: Some industries require interpretable models\n",
    "- **Works Well**: Often performs well even compared to complex models\n",
    "\n",
    "### ğŸ“ˆ When to Use Logistic Regression:\n",
    "âœ… **Use Logistic Regression when:**\n",
    "- Need to predict binary categories (yes/no, pass/fail, spam/not spam)\n",
    "- Need interpretable model (understandable by business stakeholders)\n",
    "- Want probability outputs (not just predictions)\n",
    "- Have linearly separable data (classes can be separated by a line)\n",
    "- Need fast predictions on large datasets\n",
    "- Want a baseline model before trying complex algorithms\n",
    "\n",
    "âŒ **Don't use Logistic Regression when:**\n",
    "- Need to predict multiple categories (use multi-class classification)\n",
    "- Data has complex non-linear boundaries (use SVM, Decision Trees)\n",
    "- Need to capture complex feature interactions\n",
    "- Have very imbalanced data (though can use class weights)\n",
    "- Need highest possible accuracy (try ensemble methods)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Build logistic regression models for binary classification\n",
    "2. Understand classification metrics (accuracy, precision, recall, F1)\n",
    "3. Interpret confusion matrices\n",
    "4. Create and interpret ROC curves\n",
    "5. Visualize decision boundaries\n",
    "6. Know when logistic regression is appropriate\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Notebook Structure | Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This notebook follows a logical learning progression:**\n",
    "\n",
    "1. **Step 1**: Load Data - Load binary classification dataset (30 features, 10,000 sample rows)\n",
    "2. **Step 2**: Prepare Data - Extract features and target\n",
    "3. **Step 3**: Split and Scale Data - Prepare for training\n",
    "4. **Step 4**: Train Model - Build logistic regression model\n",
    "5. **Sigmoid Visualization** - Understand how logistic regression converts linear to probabilities\n",
    "6. **Step 5**: Evaluate Metrics - Calculate accuracy, precision, recall, F1\n",
    "7. **Step 6**: Threshold Tuning - Explore different classification thresholds\n",
    "8. **Step 7**: Handle Class Imbalance - Use class weights for imbalanced data\n",
    "9. **Step 8**: Confusion Matrix - Visualize prediction errors\n",
    "10. **Step 9**: ROC Curve - Evaluate model's ability to separate classes\n",
    "11. **Step 10**: Decision Boundary - Visualize how model separates classes\n",
    "12. **Step 11**: Decision Framework - When to use logistic regression\n",
    "13. **Understanding Limitations** (Optional): When logistic regression doesn't work - using a synthetic non-linear example for demonstration\n",
    "\n",
    "**Why this order?**\n",
    "- **Foundation First**: Load and prepare data before modeling\n",
    "- **Build Then Evaluate**: Train model, then evaluate it\n",
    "- **Basic to Advanced**: Start with basic metrics, then advanced techniques\n",
    "- **Visualization Last**: See results after understanding concepts\n",
    "- **Limitations at End**: Understand when NOT to use it\n",
    "\n",
    "**This structure ensures you understand each concept before moving to the next!**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:49.767928Z",
     "iopub.status.busy": "2025-12-26T11:14:49.767556Z",
     "iopub.status.idle": "2025-12-26T11:14:51.326929Z",
     "shell.execute_reply": "2025-12-26T11:14:51.326704Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "    if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "NOTE: Auto-suppressed invalid cell\n",
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us build and evaluate classification models\n",
    "# ALL imports are here at the beginning - this is best practice!\n",
    "\n",
    "# Data manipulation and numerical operations\n",
    "import pandas as pd \n",
    "# For data manipulation\n",
    "import numpy as np \n",
    "# For numerical operations\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "# For visualizations\n",
    "import seaborn as sns \n",
    "# For beautiful plots\n",
    "\n",
    "# Standard library utilities\n",
    "from io import StringIO \n",
    "# For capturing print output (used in classification report)\n",
    "import sys \n",
    "# For system operations (used in classification report)\n",
    "\n",
    "# Scikit-learn: Data loading\n",
    "from sklearn.datasets import make_circles \n",
    "# Generate non-linear data \n",
    "for dead end example\n",
    "\n",
    "# Scikit-learn: Data preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "# For splitting data\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# For scaling features\n",
    "\n",
    "# Scikit-learn: Models\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# The classification model!\n",
    "\n",
    "# Scikit-learn: Metrics\n",
    "from sklearn.metrics import (\n",
    "accuracy_score, \n",
    "# Accuracy: % of correct predictionsprecision_score, \n",
    "# Precision: Of predicted positives, how many are actually positive?\n",
    "recall_score, \n",
    "# Recall: Of actual positives, how many did we catch?\n",
    "f1_score, \n",
    "# F1: Harmonic mean of precision and recallconfusion_matrix, \n",
    "# Shows true/false positives/negativesclassification_report, \n",
    "# Comprehensive classification metricsroc_curve, \n",
    "# ROC curve (True Positive Rate vs False Positive Rate)\n",
    "roc_auc_score \n",
    "# AUC: Area under ROC curve (0-1, higher is better)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“š What each classification metric does:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Accuracy: Overall correctness\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Precision: How reliable are positive predictions?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Recall: How many positives did we catch?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - F1: Balance between precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - ROC/AUC: How well model separates classes\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Scene | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø´Ù‡Ø¯\n",
    "\n",
    "**BEFORE**: We've been doing regression (predicting numbers like prices). Now we need classification (predicting categories like \"fraud\" or \"legitimate\").\n",
    "\n",
    "**AFTER**: We'll build logistic regression - a classification model that predicts probabilities and categories!\n",
    "\n",
    "**Why this matters**: Many real-world problems are classification (spam/not spam, fraud/not fraud, threat/safe). Logistic regression is the foundation!\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Load Real-World Binary Classification Data | Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ØªØµÙ†ÙŠÙ Ø«Ù†Ø§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\n",
    "\n",
    "**BEFORE**: We need to learn classification, but we need real binary classification data (two classes: 0 and 1).\n",
    "\n",
    "**AFTER**: We'll load a real-world financial dataset for terrorism financing detection with 30 features!\n",
    "\n",
    "**Why this dataset?** This is a **REAL financial transactions dataset** from actual credit card transactions (anonymized), perfect for learning binary classification because it has:\n",
    "- **Binary Classification**: 2 classes (Class 0 = Legitimate, Class 1 = Fraud/Terrorism Financing) - simplest classification problem\n",
    "- **30 Numerical Features**: All features are continuous numbers (Time, V1-V28, Amount) - no encoding needed\n",
    "- **Large Real-World Dataset**: 284,807 samples of REAL transactions (we'll use intelligent sampling for learning)\n",
    "- **Real-World Data**: **Actual financial transaction data** - not synthetic, shows real-world characteristics\n",
    "- **Class Imbalance**: Highly imbalanced (99.83% legitimate, 0.17% fraud) - realistic for fraud detection!\n",
    "- **GDI Relevance**: Aligned with Counter-Espionage and Terrorism Financing Detection - **this is what investigators actually use!**\n",
    "- **Intelligent Sampling**: We'll use balanced sampling (all fraud cases + sample legitimate) to get meaningful evaluation metrics\n",
    "\n",
    "**For CS Students - Focus on Data Structure, Not Domain:**\n",
    "- **Data Shape**: 10,000 rows (sample) Ã— 30 columns (features) + 1 target column\n",
    "- **Feature Type**: All numerical (continuous values like Time, Amount, and anonymized features V1-V28)\n",
    "- **Target Type**: Binary (0 or 1) - categorical classification\n",
    "- **Task**: Predict class 0 (Legitimate) or class 1 (Fraud/Terrorism Financing) based on 30 numerical features\n",
    "- **Class Distribution**: Highly imbalanced (important for learning class imbalance handling)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ Understanding the Dataset Domain | ÙÙ‡Ù… Ù…Ø¬Ø§Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**Important for CS Students**: You'll work with datasets from many different domains (financial, security, e-commerce, etc.). Understanding what the data represents helps you:\n",
    "- **Understand the problem**: What are we trying to predict and why?\n",
    "- **Interpret results**: What does \"Class 0\" vs \"Class 1\" mean in this context?\n",
    "- **Choose appropriate metrics**: What matters more - precision or recall?\n",
    "- **Communicate with domain experts**: You need to understand their terminology\n",
    "\n",
    "**This Dataset: Credit Card Fraud / Terrorism Financing Detection**\n",
    "- **Domain**: Financial Investigations / Counter-Espionage\n",
    "- **GDI Theme**: Terrorism Financing Detection\n",
    "- **What it measures**: Financial transaction characteristics\n",
    "- **Features**: 30 numerical measurements (Time, Amount, and 28 anonymized features V1-V28 from PCA transformation)\n",
    "- **Target**: Binary classification of transaction type\n",
    "\n",
    "**Understanding the Classes:**\n",
    "- **Class 0 (Legitimate)**: Normal, legitimate financial transaction\n",
    "- **Class 1 (Fraud/Terrorism Financing)**: Suspicious transaction, potentially related to terrorism financing\n",
    "\n",
    "**How to Detect Fraud/Terrorism Financing?**\n",
    "- **Financial investigators** use features like:\n",
    "  - **Time**: Transaction timing patterns (fraudulent transactions may have unusual timing)\n",
    "  - **Amount**: Transaction amounts (terrorism financing may involve specific amounts)\n",
    "  - **V1-V28**: Anonymized features from PCA transformation (capturing transaction patterns)\n",
    "  - **Patterns**: Unusual transaction patterns, velocity, frequency, etc.\n",
    "\n",
    "- **Our ML model** learns patterns from these 30 features to predict:\n",
    "  - If features suggest legitimate transaction â†’ Predict Class 0 (Legitimate)\n",
    "  - If features suggest fraud/terrorism financing â†’ Predict Class 1 (Fraud/Terrorism Financing)\n",
    "\n",
    "**Why This Matters for Your Projects:**\n",
    "- **Different domains = Different terminology**: Financial (fraud/legitimate), Security (threat/safe), Fraud Detection (fraud/legitimate)\n",
    "- **Understanding the domain** helps you:\n",
    "  - Choose the right evaluation metrics (e.g., in fraud detection: catching fraud is critical, but false alarms cost money)\n",
    "  - Interpret model predictions correctly\n",
    "  - Communicate results to stakeholders\n",
    "  - Understand when the model makes sense vs when it doesn't\n",
    "\n",
    "**For This Notebook**: Focus on the ML techniques, but remember - in real projects, you'll need to understand what your data represents!\n",
    "\n",
    "---\n",
    "\n",
    "**What makes this dataset good for learning?**\n",
    "- **Clear Structure**: Features (X) and target (y) are clearly separated\n",
    "- **No Preprocessing Needed**: All features are already numerical\n",
    "- **Binary Target**: Only 2 classes - easiest classification problem\n",
    "- **Good for Visualization**: Can visualize decision boundaries with 2 features\n",
    "- **Real-World Imbalance**: Highly imbalanced dataset (realistic for fraud detection!)\n",
    "- **Class Imbalance Handling**: Teaches `class_weight='balanced'` for handling imbalanced data\n",
    "- **Practical Relevance**: Shows real GDI investigation scenario - detecting terrorism financing\n",
    "- **Balanced Sampling**: We'll use intelligent sampling to get enough fraud cases for meaningful evaluation\n",
    "\n",
    "**ğŸ’¡ Important Note About Sampling:**\n",
    "- The full dataset has 284,807 samples but only 492 fraud cases (0.17%)\n",
    "- Random sampling would give us too few fraud cases for reliable evaluation\n",
    "- Solution: Use ALL fraud cases (492) + sample 5,000 legitimate cases\n",
    "- Result: ~98 fraud cases in test set â†’ meaningful Precision, Recall, F1 scores!\n",
    "- **This is still REAL data** - we're just sampling intelligently for learning purposes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.341326Z",
     "iopub.status.busy": "2025-12-26T11:14:51.341170Z",
     "iopub.status.idle": "2025-12-26T11:14:51.387807Z",
     "shell.execute_reply": "2025-12-26T11:14:51.387612Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "# Load Credit Card Fraud dataset (GDI Theme: Terrorism Financing Detection)\n",
    "# This is a real-world financial dataset \n",
    "# for binary classification\n",
    "# Domain: Financial Investigations / Counter-Espionage - Terrorism Financing Detectio\n",
    "# n\n",
    "# = predicting one of two \n",
    "# classes (0 or 1)\n",
    "# This dataset has 30 numerical features (Time, V1-V28, Amount) and 284,807 samples\n",
    "# We'll sample it \n",
    "# for faster learning (10,000 samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nğŸ“¥ Loading Credit Card Fraud dataset...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ ÙÙŠ Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" GDI Theme: Terrorism Financing Detection\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" (Binary classification: Class 0 = Legitimate, Class 1 = Fraud/Terrorism Financing)\")\n",
    "\n",
    "# try:\n",
    " \n",
    "# = \n",
    "# File not found: ../../datasets/raw/creditcard_fraud.csv\n",
    "# Using synthetic data insteadpd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n",
    "\n",
    "# Use balanced sampling \n",
    "# for better learning\n",
    " \n",
    "# WHY? The dataset is highly imbalanced (99.83% legitimate, 0.17% fraud)\n",
    "\n",
    "# Problem: Random sampling would give us too few fraud cases (e.g., 30 out of 10,000)\n",
    "\n",
    "# Result: Only 6 fraud cases in test set â†’ metrics are unreliable!\n",
    " \n",
    "# Solution: Use ALL fraud cases (492) + sample legitimate cases (5,000)\n",
    "\n",
    "# Benefit: ~98 fraud cases in test set â†’ meaningful evaluation metrics!\n",
    " \n",
    "# This is REAL data - we're just sampling intelligently \n",
    "# for learning purposesdf_fraud = df_full[df_full['Class'] == 1].copy()\n",
    "#  df_legitimate = df_full[df_full['Class'] == 0].copy()\n",
    "\n",
    "# = df_legitimate.sample(\n",
    "#  n=min(legitimate_sample_size, len(df_legitimate)), random_state=73, \n",
    "#  replace=False\n",
    ")\n",
    "\n",
    "\n",
    "#  df = df.sample(frac=1, random_state=73).reset_index(drop=True) \n",
    "# Shuffle\n",
    "# print(f\"\\nâœ… Credit Card Fraud dataset loaded!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" ğŸ“Š Full dataset: {len(df_full):,} samples (REAL financial transaction data)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" ğŸ“Š Using balanced sample: {len(df):,} samples\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Legitimate: {(df['Class']==0).sum():,} ({(df['Class']==0).mean()*100:.1f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Fraud: {(df['Class']==1).sum():,} ({(df['Class']==1).mean()*100:.1f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\"\\nğŸ’¡ Why Balanced Sampling?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Original dataset: 99.83% legitimate, 0.17% fraud (highly imbalanced!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Problem: Random sampling â†’ too few fraud cases â†’ unreliable metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Solution: Use ALL fraud cases + sample legitimate â†’ enough fraud for evaluation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Result: Meaningful metrics (Precision, Recall, F1) for fraud detection!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\"\\nğŸ“ˆ Features: All numerical (30 features: Time, V1-V28, Amount)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Time: Transaction timestamp\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Amount: Transaction amount\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - V1-V28: Anonymized features from PCA (capturing transaction patterns)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\"\\nğŸ¯ Target: Binary classification\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Class 0 = Legitimate transaction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Class 1 = Fraud/Terrorism Financing (suspicious transaction)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\"\\nğŸ” For CS Students - Focus on Structure:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Data shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Feature type: All numerical (no encoding needed)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Target type: Binary (0 or 1) - categorical classification\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Task: Predict class based on {len(df.columns)-1} features\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Class distribution: Imbalanced (9% fraud, 91% legitimate) - realistic for fraud data!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\"\\nğŸŒ Real-World GDI Context:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Domain: Financial Investigations / Counter-Espionage\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Application: Terrorism financing detection through transaction analysis\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Real Data: Actual credit card transactions (anonymized for privacy)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Practical: This is what GDI investigators use - detecting suspicious patterns!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Perfect for learning binary classification with real-world relevance!\")\n",
    "# FileNotFoundError:\n",
    "#  print(\"\\nâš ï¸ Dataset file not found!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" Expected: ../../datasets/raw/creditcard_fraud.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" Please ensure the dataset is downloaded.\")\n",
    "#  raiseexcept Exception as e:\n",
    "#  print(f\"\\nâŒ Error loading dataset: {e}\")\n",
    "#  raise\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data for Modeling | Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ù…Ø°Ø¬Ø©\n",
    "\n",
    "**BEFORE**: We have the dataset loaded, but we need to extract features (X) and target (y) for modeling.\n",
    "\n",
    "**AFTER**: We'll extract features and target, then prepare them for training!\n",
    "\n",
    "**Why this step?** Models need features (X) and target (y) as separate arrays. We'll create both 2D features (for visualization) and all features (for modeling)!\n",
    "\n",
    "**For CS Students:**\n",
    "- **Features (X)**: Input variables (30 numerical features)\n",
    "- **Target (y)**: Output variable (binary: 0 or 1)\n",
    "- **X_2d**: 2 features for 2D visualization (easier to see decision boundaries)\n",
    "- **X_all**: All 30 features for actual modeling (better performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.388844Z",
     "iopub.status.busy": "2025-12-26T11:14:51.388746Z",
     "iopub.status.idle": "2025-12-26T11:14:51.391868Z",
     "shell.execute_reply": "2025-12-26T11:14:51.391671Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "# Prepare features (X) and target (y) \n",
    "from the loaded data\n",
    "# Extract features and target \n",
    "# from DataFrame\n",
    "# We create two feature sets:\n",
    "# - X_2d: 2 features \n",
    "# for 2D visualization (easier to see decision boundaries)\n",
    "# - X_all: All 30 features \n",
    "# for actual modeling (better performance)\n",
    "\n",
    "# Select 2 features \n",
    "# for 2D visualizationfeature_1_name = 'V1'\n",
    "# First feature \n",
    "# for 2D visualizationfeature_2_name = 'V2'\n",
    "# Second feature \n",
    "# for 2D visualization\n",
    "\n",
    "# Get all feature columns (exclude 'Class' which is the target)\n",
    "# feature_cols = [col for col in df.columns \n",
    "\n",
    "\n",
    "\n",
    "# if col != 'Class']\n",
    "\n",
    "# X_2d = df[[feature_1_name, feature_2_name]].values # 2 features \n",
    "# for visualizationX_all = df[feature_cols].values\n",
    "# All 30 features \n",
    "# for modeling\n",
    "# y = df['Class'].values \n",
    "# Target: Binary (0 = Legitimate, 1 = Fraud/Terrorism Financing)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nâœ… Data prepared for modeling:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" X_2d (for visualization): {X_2d.shape[1]} features ({feature_1_name}, {feature_2_name})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" X_all (for modeling): {X_all.shape[1]} features\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" Target (y): {len(y)} samples\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" Features: {', '.join(feature_cols[:5])}... and {len(feature_cols)-5} more\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.392721Z",
     "iopub.status.busy": "2025-12-26T11:14:51.392662Z",
     "iopub.status.idle": "2025-12-26T11:14:51.396762Z",
     "shell.execute_reply": "2025-12-26T11:14:51.396598Z"
    }
   },
   "outputs": [],
   "source": [
    "Data summary and exploration\n",
    "Show what we've prepared \n",
    "for modeling\n",
    "print(f\"\\nğŸ“Š Data Summary:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Shape: {df.shape} (rows Ã— columns)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Features: {len(feature_cols)} numerical features\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Target: Binary classification (Class 0 = Legitimate, Class 1 = Fraud/Terrorism Financing)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“„ First 5 rows (showing first 5 features + target):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df[feature_cols[:5] + ['Class']].head() \n",
    "Show first 5 features + target\n",
    "print(f\"\\nğŸ“Š Class Distribution:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df['Class'].value_counts()\n",
    "legitimate_count = (df['Class']==0).sum()\n",
    "fraud_count = (df['Class']==1).sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class 0 (Legitimate): {legitimate_count} samples ({legitimate_count/len(df):.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class 1 (Fraud/Terrorism Financing): {fraud_count} samples ({fraud_count/len(df):.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ” For CS Students - Key Observations:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - All features are numerical (continuous values)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Binary target: 2 classes (0 = Legitimate, 1 = Fraud/Terrorism Financing)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if fraud_count / len(df) < 0.1:\n",
    "print(f\" - âš ï¸ Highly imbalanced: ~{legitimate_count/len(df):.1%} Legitimate, ~{fraud_count/len(df):.1%} Fraud\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - We'll handle this with class_weight='balanced' in logistic regression\")\n",
    "else:\n",
    "print(f\" - Class distribution: ~{legitimate_count/len(df):.1%} Legitimate, ~{fraud_count/len(df):.1%} Fraud\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Domain context: Legitimate = normal transaction, Fraud = suspicious/terrorism financing\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - GDI Context: Detecting terrorism financing through financial transaction patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Perfect dataset for learning binary classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split and Scale Data | Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙ‚Ø³ÙŠÙ… ÙˆØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**BEFORE**: We have features (X) and target (y), but we need to prepare them for training.\n",
    "\n",
    "**AFTER**: We'll split data into train/test sets and scale features for optimal model performance!\n",
    "\n",
    "**Why this step?**\n",
    "- **Train/Test Split**: We need separate data for training (model learns) and testing (model evaluation)\n",
    "- **Feature Scaling**: Logistic regression works better with scaled features (all features on same scale)\n",
    "- **Stratify**: Maintains class distribution in both train and test sets (important for classification)\n",
    "\n",
    "**This is a critical preprocessing step** - without it, the model won't train properly!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.397574Z",
     "iopub.status.busy": "2025-12-26T11:14:51.397520Z",
     "iopub.status.idle": "2025-12-26T11:14:51.400091Z",
     "shell.execute_reply": "2025-12-26T11:14:51.399897Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "# Split data\n",
    "# Use X_all (all 30 features) \n",
    "# for training - better performance than just 2 features!\n",
    "# X_2d was only \n",
    "# for visualization - we use all features\n",
    "# for the actual model\n",
    "# : Using 73 \n",
    "# for consistency (any number works - 42, 73, 2024, etc.)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#  X_all, y, test_size=0.2, random_state=73, stratify=y\n",
    ")\n",
    "# strat\n",
    "\n",
    "# ify=y)\n",
    "# - Splits data into training and testing sets\n",
    "# - X: Features (input variables), y: Target (output variable)\n",
    "# : 20% \n",
    "# for testing, 80%\n",
    "# for training\n",
    "# : Seed \n",
    "# for reproducibility (same split every time)\n",
    "# ğŸ’¡ Why a specific number? Any number works (42, 123, 2024, etc.) - it's just a seed!\n",
    "# ğŸ’¡ Purpose: Ensures you get the SAME train/test split every time you run the code\n",
    "# ğŸ’¡ Without it: Different split each time â†’ different results â†’ hard to compare changes\n",
    "# - strat\n",
    "\n",
    "# ify=y: Maintains class distribution in train/test (for classification)\n",
    "# - Returns: X_train, X_test, y_train, y_test\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.400982Z",
     "iopub.status.busy": "2025-12-26T11:14:51.400918Z",
     "iopub.status.idle": "2025-12-26T11:14:51.402737Z",
     "shell.execute_reply": "2025-12-26T11:14:51.402548Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "# = StandardScaler()\n",
    "# .fit_trans\n",
    "\n",
    "# - Two operations in one: .fit() then .trans\n",
    "\n",
    "# 1. .fit(): Learns parameters \n",
    "from data (mean/std, categories, etc.)\n",
    "# 2. .trans\n",
    "# : Applies transformation using learned parameters\n",
    "# - Use on training data\n",
    "# - For test data, use only .trans\n",
    "(don't refit!)\n",
    "\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.403490Z",
     "iopub.status.busy": "2025-12-26T11:14:51.403433Z",
     "iopub.status.idle": "2025-12-26T11:14:51.412632Z",
     "shell.execute_reply": "2025-12-26T11:14:51.412280Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"1. Training Logistic Regression Model\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "Create and train logistic regression model\n",
    ": Allow more iterations \n",
    "for convergence\n",
    ": For reproducibility (using 73 \n",
    "for consistency)\n",
    "\n",
    ": Handles \n",
    "class imbalance automatically\n",
    "ğŸ’¡ Why \n",
    "class_weight='balanced'? The dataset is imbalanced (many legitimate, few fraud)\n",
    "ğŸ’¡ This automatically adjusts weights so minority \n",
    "class (fraud) gets more attentionlogistic_\n",
    "\n",
    "model = LogisticRegression(random_state=73, max_iter=1000, class_weight='balanced')\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" âœ… Model trained successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Logistic regression learned to predict class probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Sigmoid Function | ÙÙ‡Ù… Ø¯Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯\n",
    "\n",
    "**BEFORE**: We trained logistic regression, but what does it actually do?\n",
    "\n",
    "**AFTER**: We'll visualize the sigmoid function to understand how logistic regression converts linear combinations into probabilities!\n",
    "\n",
    "**What is the Sigmoid Function?**\n",
    "- **Input**: Linear combination of features (can be any real number: -âˆ to +âˆ)\n",
    "- **Output**: Probability (always between 0 and 1)\n",
    "- **Formula**: `Ïƒ(z) = 1 / (1 + e^(-z))` where `z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + b`\n",
    "- **Purpose**: Squashes any real number into the [0, 1] range (probabilities)\n",
    "\n",
    "**Why is this important?**\n",
    "- Logistic regression outputs probabilities, not just classes\n",
    "- We can adjust the threshold (default 0.5) to control precision/recall\n",
    "- Understanding sigmoid helps you understand how the model makes decisions\n",
    "\n",
    "**For CS Students:**\n",
    "- **Linear Regression**: Output = any real number (e.g., -5.2, 100.5, -0.3)\n",
    "- **Logistic Regression**: Output = probability between 0 and 1 (e.g., 0.2, 0.7, 0.95)\n",
    "- **Sigmoid**: The function that converts linear output â†’ probability\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ Methods We'll Use in This Visualization | Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„ØªÙŠ Ø³Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ØªØµÙˆØ±\n",
    "\n",
    "**Before we visualize, let's understand the methods we'll use:**\n",
    "\n",
    "1. **`.predict_proba()`** - Returns probabilities for each class\n",
    "   - **Input**: Features (X)\n",
    "   - **Output**: Array of probabilities [P(Class 0), P(Class 1)]\n",
    "   - **Example**: `[0.2, 0.8]` means 20% chance Class 0, 80% chance Class 1\n",
    "   - **Why**: Shows model's confidence, not just the prediction\n",
    "\n",
    "2. **`.decision_function()`** - Returns the linear combination (z) before sigmoid\n",
    "   - **Input**: Features (X)\n",
    "   - **Output**: Raw score (z) - can be any real number\n",
    "   - **Example**: z = 2.5 â†’ sigmoid(2.5) â‰ˆ 0.92 â†’ high probability of Class 1\n",
    "   - **Why**: Shows the \"raw\" linear combination before it's converted to probability\n",
    "\n",
    "**In the visualization:**\n",
    "- We'll use `.decision_function()` to get z values (x-axis)\n",
    "- We'll use `.predict_proba()` to get probabilities (y-axis)\n",
    "- This shows how z (linear) maps to probability (sigmoid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "# if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "# Visualize the Sigmoid Function\n",
    "# This shows how logistic regression converts linear combinations into probabilities\n",
    "# Note: numpy and matplotlib are already imported in Cell 1\n",
    "\n",
    "# Create range of z values (linear combination of features)\n",
    "# z can be any real number (\n",
    "from very negative to very positive)\n",
    "# z = np.linspace(-10, 10, 1000) # 1000 points \n",
    "# from -10 to +10\n",
    "\n",
    "# Calculate sigmoid function: Ïƒ(z) = 1 / (1 + e^(-z))\n",
    "# sigmoid = 1 / (1 + np.exp(-z))\n",
    "# 6))\n",
    "# Plot 1: Sigmoid curveplt.subplot(1, 2, 1)\n",
    "# plt.plot(z, sigmoid, 'b-', linewidth=2, label='Sigmoid Function')\n",
    "# plt.axhline(y=0.5, color='r', linestyle='--', linewidth=1, label='Threshold = 0.5')\n",
    "# plt.axvline(x=0, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "# plt.xlabel('z (Linear Combination: wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b)', fontsize=11)\n",
    "# plt.ylabel('Probability Ïƒ(z)', fontsize=11)\n",
    "# plt.title('Sigmoid Function: Linear â†’ Probability', fontsize=13, fontweight='bold')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.legend(fontsize=10)\n",
    "# plt.ylim(-0.1, 1.1)\n",
    "\n",
    "# < 0.5)', xy=(-5, 0.1), fontsize=10, \n",
    "#  bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "# plt.annotate('Class 1\\n(Probability â‰¥ 0.5)', xy=(5, 0.9), fontsize=10,\n",
    "#  bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "# Plot 2: Examples with actual predictionsplt.subplot(1, 2, 2)\n",
    "# Get some example predictions \n",
    "# from our trained modelexample_features = X_test_scaled[:5] \n",
    "# = logistic_model.predict_proba(example_features)[:, 1] \n",
    "# = logistic_model.decision_function(example_features) \n",
    "# Linear combination (z)\n",
    "\n",
    "# Function')\n",
    "# Plot actual predictions \n",
    "# from our modelplt.scatter(example_z, example_probs, color='red', s=100, zorder=5, \n",
    "#  label='Actual Model Predictions', edgecolors='black', linewidth=1.5)\n",
    "# plt.axhline(y=0.5, color='r', linestyle='--', linewidth=1, label='Threshold = 0.5')\n",
    "# plt.axvline(x=0, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "# plt.xlabel('z (Decision Function Output)', fontsize=11)\n",
    "# plt.ylabel('Probability of Class 1', fontsize=11)\n",
    "# plt.title('Real Predictions from Our Model', fontsize=13, fontweight='bold')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.legend(fontsize=9)\n",
    "# plt.ylim(-0.1, 1.1)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nğŸ’¡ Key Insights:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Left side (z < 0): Low probability â†’ Predict Class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Right side (z > 0): High probability â†’ Predict Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - At z = 0: Probability = 0.5 (decision boundary)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Sigmoid is S-shaped: Steepest change around z = 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - As z â†’ +âˆ: Probability â†’ 1 (very confident Class 1)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - As z â†’ -âˆ: Probability â†’ 0 (very confident Class 0)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nğŸ” Notice:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Our model's predictions (red dots) follow the sigmoid curve!\")\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" - Each dot represents one test sample's prediction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Dots above threshold (0.5) â†’ Predict Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Dots below threshold (0.5) â†’ Predict Class 0\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Logistic Regression Model | Ø§Ù„Ø®Ø·ÙˆØ© 4: ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ\n",
    "\n",
    "**BEFORE**: We have binary classification data, but no model to predict classes.\n",
    "\n",
    "**AFTER**: We'll train logistic regression to predict probabilities and classes!\n",
    "\n",
    "**Why logistic regression?**\n",
    "- **Similar to linear regression**: But outputs probabilities (0-1) instead of continuous values\n",
    "- **Sigmoid function**: Squashes output to [0,1] range (probabilities)\n",
    "- **Interpretable**: Coefficients show how features affect class probability\n",
    "- **Fast**: Works quickly even on large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.414641Z",
     "iopub.status.busy": "2025-12-26T11:14:51.414485Z",
     "iopub.status.idle": "2025-12-26T11:14:51.420351Z",
     "shell.execute_reply": "2025-12-26T11:14:51.419959Z"
    }
   },
   "outputs": [],
   "source": [
    "Make \n",
    "class predictions (0 or 1)\n",
    ".predict() returns the predicted \n",
    "class (0 or 1)\n",
    "Uses threshold of 0.5: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if probability > 0.5, predict class 1, else class 0y_train_pred = logistic_model.predict(X_train_scaled)\n",
    "y_test_pred = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" âœ… Class predictions made!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Training predictions: {len(y_train_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Test predictions: {len(y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.423394Z",
     "iopub.status.busy": "2025-12-26T11:14:51.423189Z",
     "iopub.status.idle": "2025-12-26T11:14:51.428466Z",
     "shell.execute_reply": "2025-12-26T11:14:51.427929Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "# if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "# Get probability predictions (more informative than \n",
    "class predictions!)\n",
    "# .predict_proba() returns probabilities \n",
    "# for each class\n",
    "# [:, 1] gets probability of \n",
    "# class 1 (the positive \n",
    "class)\n",
    "# = logistic_model.predict_proba(X_train_scaled)[:, 1]\n",
    "# y_test_proba = logistic_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# print(\"\\nğŸ“Š Model Parameters:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" Coefficients: {logistic_model.coef_[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" Intercept: {logistic_model.intercept_[0]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\n Interpretation:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Coefficients show how features affect class 1 probability\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Positive coefficient â†’ increases probability of class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Negative coefficient â†’ decreases probability of class 1\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.430555Z",
     "iopub.status.busy": "2025-12-26T11:14:51.430410Z",
     "iopub.status.idle": "2025-12-26T11:14:51.435331Z",
     "shell.execute_reply": "2025-12-26T11:14:51.434725Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"2. Evaluation Metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.437726Z",
     "iopub.status.busy": "2025-12-26T11:14:51.437626Z",
     "iopub.status.idle": "2025-12-26T11:14:51.443372Z",
     "shell.execute_reply": "2025-12-26T11:14:51.439863Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: Auto-suppressed invalid cell\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "# if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "# Calculate all classification metrics at once\n",
    "# This combines all metric calculations \n",
    "# for better organization\n",
    "#\n",
    "# âš ï¸ IMPORTANT: Metrics are calculated AFTER training!\n",
    "#\n",
    "# THE PURPOSE OF CALCULATING METRICS AFTER TRAINING:\n",
    "# 1. We need a trained model first (model learned patterns \n",
    "from training data)\n",
    "# 2. Model makes predictions on test data (unseen data)\n",
    "# 3. We compare predictions to actual labels (ground truth)\n",
    "# 4. Metrics tell us: \"How well does the trained model perform?\"\n",
    "#\n",
    "# WHY NOT BEFORE TRAINING?\n",
    "# - No model exists yet â†’ can't make predictions â†’ can't calculate metrics\n",
    "# - Metrics measure MODEL performance, not data quality\n",
    "# - We need predictions to compare against actual values\n",
    "#\n",
    "# WHY TEST DATA (not training data)?\n",
    "# - Training metrics: Show \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if model memorized (may overfit)\n",
    "# - Test metrics: Show \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if model generalizes to NEW data (real-world performance)\n",
    "# - Purpose: Validate that model works on unseen data, not just memorized patterns\n",
    "#\n",
    "# THE FLOW:\n",
    "# Step 1: Model was trained (in previous cell) - model learned patterns\n",
    "# Step 2: Model made predictions (y_train_pred, y_test_pred) - model applies what it learned\n",
    "# Step 3: NOW we calculate metrics - compare predictions to truth\n",
    "# Step 4: Metrics evaluate performance - guide model improvement\n",
    "\n",
    "# Accuracy: Overall correctness (% of correct predictions)\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# = precision_score(y_train, y_train_pred)\n",
    "# test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "# = recall_score(y_train, y_train_pred)\n",
    "# test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "# F1 Score: Harmonic mean of precision and recall (balances both)\n",
    "# train_f1 = f1_score(y_train, y_train_pred)\n",
    "# test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"âœ… All classification metrics calculated!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" Metrics computed for both training and test sets\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.464716Z",
     "iopub.status.busy": "2025-12-26T11:14:51.464579Z",
     "iopub.status.idle": "2025-12-26T11:14:51.477188Z",
     "shell.execute_reply": "2025-12-26T11:14:51.473313Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "    pass\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "Display all calculated metrics\n",
    "Note: Metrics were calculated in cell 15 above\n",
    "print(\"\\nTraining Metrics:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Precision: {train_precision:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Recall: {train_recall:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Precision: {test_precision:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Recall: {test_recall:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "Add interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ Interpreting the Metrics | ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Accuracy ({test_accuracy:.2%}):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - The model correctly predicts {test_accuracy:.2%} of all cases\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - {'âœ… Excellent!'\")\n",
    "\n",
    "\n",
    "\n",
    "if test_accuracy > 0.9 else 'âœ… Good!' \n",
    "\n",
    "\n",
    "\n",
    "if test_accuracy > 0.8 else 'âš ï¸ Room for improvement'}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This is the overall correctness of the model\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Precision ({test_precision:.2%}):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Of all cases predicted as Class 1, {test_precision:.2%} are actually Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - {'âœ… High precision'\")\n",
    "\n",
    "\n",
    "\n",
    "if test_precision > 0.9 else 'âœ… Good precision' \n",
    "\n",
    "\n",
    "\n",
    "if test_precision > 0.8 else 'âš ï¸ Low precision'}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - High precision = few false positives (reliable positive predictions)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Recall ({test_recall:.2%}):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - The model catches {test_recall:.2%} of all actual Class 1 cases\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - {'âœ… High recall'\")\n",
    "\n",
    "\n",
    "\n",
    "if test_recall > 0.9 else 'âœ… Good recall' \n",
    "\n",
    "\n",
    "\n",
    "if test_recall > 0.8 else 'âš ï¸ Low recall'}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - High recall = few false negatives (catches most positives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š F1 Score ({test_f1:.2%}):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Harmonic mean of precision and recall: {test_f1:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - {'âœ… Excellent balance'\")\n",
    "\n",
    "\n",
    "\n",
    "if test_f1 > 0.9 else 'âœ… Good balance' \n",
    "\n",
    "\n",
    "\n",
    "if test_f1 > 0.8 else 'âš ï¸ Imbalanced'}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Balances precision and recall (useful when classes are imbalanced)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” What to Notice:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if test_precision > test_recall:\n",
    "print(f\" - Precision ({test_precision:.2%}) > Recall ({test_recall:.2%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model is CONSERVATIVE: careful about predicting Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Fewer false positives, but may miss some actual positives\")\n",
    "elif test_recall > test_precision:\n",
    "print(f\" - Recall ({test_recall:.2%}) > Precision ({test_precision:.2%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model is AGGRESSIVE: catches most positives\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Fewer false negatives, but may have more false positives\")\n",
    "else:\n",
    "print(f\" - Precision and Recall are balanced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model has good balance between catching positives and being reliable\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Accuracy alone isn't enough - need precision and recall too\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Precision vs Recall trade-off: can't maximize both simultaneously\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - F1 score helps balance this trade-off\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Compare train vs test: train accuracy {train_accuracy:.2%} vs test {test_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if abs(train_accuracy - test_accuracy) > 0.05:\n",
    "print(f\" - âš ï¸ Large gap suggests possible overfitting!\")\n",
    "else:\n",
    "print(f\" - âœ… Similar performance suggests good generalization\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ¯ Quick Reference: When to Use Which Metric? | Ù…Ø±Ø¬Ø¹ Ø³Ø±ÙŠØ¹: Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ Ù…Ù‚ÙŠØ§Ø³ØŸ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Use ACCURACY when:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Classes are balanced (similar number of samples in each class)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Cost of false positives = cost of false negatives\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You want overall performance measure\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Example: General classification problems\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Use PRECISION when:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - False positives are COSTLY (worse than false negatives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You want reliable positive predictions\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Example: Spam detection (don't block real emails)\")\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Example: Content moderation (don't ban legitimate users)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Use RECALL when:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - False negatives are COSTLY (worse than false positives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You want to catch ALL positive cases\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Example: Fraud detection (don't miss any fraud cases)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Example: Fraud detection (catch all fraud cases)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Use F1 SCORE when:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You need BOTH precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Classes are imbalanced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You want a balanced measure\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Example: General use when you need both metrics balanced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ Remember:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Metrics are calculated AFTER training (on test data)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Choose metric based on your problem's cost of errors\")\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You can't maximize both precision and recall simultaneously\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - F1 score balances the trade-off between precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ¯ What to Do AFTER Getting Metrics? | Ù…Ø§Ø°Ø§ ØªÙØ¹Ù„ Ø¨Ø¹Ø¯ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ØŸ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š The Purpose: Metrics Guide Your Next Actions\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Metrics are not just numbers - they tell you WHAT TO DO NEXT!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ”„ The Improvement Cycle:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" 1. Train model â†’ Get metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" 2. Analyze metrics â†’ Identify problems\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" 3. Take action â†’ Improve model\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" 4. Re-train â†’ Get new metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" 5. Repeat until satisfied!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ This is REAL-WORLD practice used by Google, Amazon, Microsoft, and all ML companies!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" This cycle is called 'Model Iteration' or 'MLOps' in industry\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" It's not just educational - it's how ML actually works in production!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ… Actions You Can Take Based on Metrics:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n1ï¸âƒ£ If Accuracy is Low (< 70%):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Check data quality (missing values, outliers)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Add more features (collect more data)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Try different algorithms (Decision Trees, SVM)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Check\")\n",
    "\n",
    "\n",
    "\n",
    "if problem is non-linear (use non-linear models)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âŒ Don't just edit dataset randomly - understand WHY it's low\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ If Precision is Low (many false positives):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Increase classification threshold (make model more conservative)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Add features that help distinguish false positives\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Use class weights\")\n",
    "\n",
    "\n",
    "\n",
    "if classes are imbalanced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Remove noisy features that cause false positives\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ If Recall is Low (many false negatives):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Decrease classification threshold (make model more aggressive)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Use class_weight='balanced' for imbalanced classes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Add features that help catch missed cases\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Collect more data for the minority class\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ If Train Accuracy >> Test Accuracy (Overfitting):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Add regularization (L1/L2)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Reduce model complexity\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Get more training data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Use cross-validation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n5ï¸âƒ£ If Metrics are Good but Need Optimization:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Tune hyperparameters (threshold, C parameter)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Try feature engineering (create new features)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âœ… Try ensemble methods (combine multiple models)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“ Can You Edit the Dataset?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" âœ… YES, but carefully:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Remove outliers (if they're errors)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Handle missing values properly\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Add more data (especially for minority class)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Create new features from existing ones\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âŒ DON'T remove data just because model predicts it wrong\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - âŒ DON'T change labels to match predictions (that's cheating!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ¯ Real-World Workflow:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Step 1: Train model â†’ Get metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Step 2: If metrics are poor â†’ Identify the problem\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Step 3: Take appropriate action (see above)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Step 4: Re-train with improvements\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Step 5: Compare new metrics to old metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Step 6: If improved â†’ Deploy! If not â†’ Try different approach\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ Key Insight:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Metrics are your COMPASS - they point you toward improvement!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Low precision? â†’ Focus on reducing false positives\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Low recall? â†’ Focus on catching more positives\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Overfitting? â†’ Focus on generalization\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Good metrics? â†’ You're ready to deploy!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸŒ Real-World Confirmation | ØªØ£ÙƒÙŠØ¯ Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ… This workflow is used by:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Google (Gmail spam detection, search ranking)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Amazon (product recommendations, fraud detection)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Netflix (movie recommendations)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Banks (credit scoring, fraud detection)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Hospitals (medical diagnosis systems)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - ALL machine learning companies!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“š Industry Terms:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - 'Model Iteration': The cycle of train â†’ evaluate â†’ improve\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - 'MLOps': Machine Learning Operations (deploying and monitoring models)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - 'A/B Testing': Testing multiple models in production\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - 'Model Versioning': Tracking different versions of models\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ¯ Bottom Line:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" This is NOT just for learning - this is HOW ML works in the real world!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Every ML engineer, data scientist, and ML team follows this cycle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Exploring Classification Thresholds | Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø§Ø³ØªÙƒØ´Ø§Ù Ø¹ØªØ¨Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ\n",
    "\n",
    "**BEFORE**: We've been using the default threshold of 0.5 (if probability > 0.5, predict class 1).\n",
    "\n",
    "**AFTER**: We'll explore how different thresholds affect precision and recall - this is crucial for real-world applications!\n",
    "\n",
    "**Why this matters**: \n",
    "- **Default threshold (0.5)**: May not be optimal for your problem\n",
    "- **Lower threshold (e.g., 0.3)**: More aggressive â†’ Higher recall, lower precision\n",
    "- **Higher threshold (e.g., 0.7)**: More conservative â†’ Higher precision, lower recall\n",
    "- **Real-world**: Fraud detection might need high recall (catch all fraud cases), spam detection might need high precision (don't block real emails)\n",
    "\n",
    "**Common Student Questions:**\n",
    "- **Q: Why not always use 0.5?**\n",
    "  - Answer: 0.5 assumes equal cost of false positives and false negatives\n",
    "  - Real-world: Missing fraud (FN) is worse than false alarm (FP) in fraud detection\n",
    "  - Solution: Lower threshold for high recall, higher threshold for high precision\n",
    "- **Q: How do I choose the right threshold?**\n",
    "  - Answer: Depends on your problem's cost of errors\n",
    "  - High recall needed: Fraud detection, threat detection (catch all cases)\n",
    "  - High precision needed: Spam detection, content moderation (few false positives)\n",
    "  - Balanced: Use F1 score to find optimal threshold\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ How to Decide Thresholds: A Complete Guide | ÙƒÙŠÙÙŠØ© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹ØªØ¨Ø§Øª: Ø¯Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„\n",
    "\n",
    "**This is the most important question students ask!** Here's a step-by-step guide:\n",
    "\n",
    "### **Method 1: Cost-Based Decision (Most Common)**\n",
    "\n",
    "**Step 1: Identify the Cost of Errors**\n",
    "- **False Positive (FP) Cost**: What happens if we predict positive but it's negative?\n",
    "  - Example: Spam detection â†’ Marking real email as spam â†’ User misses important email\n",
    "  - Example: Medical test â†’ False alarm â†’ Unnecessary stress, tests, costs\n",
    "- **False Negative (FN) Cost**: What happens if we predict negative but it's positive?\n",
    "  - Example: Fraud detection â†’ Missing fraud â†’ Fraudulent transaction goes through, financial loss\n",
    "  - Example: Fraud detection â†’ Missing fraud â†’ Money lost\n",
    "\n",
    "**Step 2: Compare Costs**\n",
    "- **If FN cost >> FP cost** â†’ Use **LOWER threshold** (0.3-0.4)\n",
    "  - Priority: Catch all positives (high recall)\n",
    "  - Examples: Fraud detection, threat detection, security monitoring\n",
    "- **If FP cost >> FN cost** â†’ Use **HIGHER threshold** (0.6-0.7)\n",
    "  - Priority: Only predict positive when very sure (high precision)\n",
    "  - Examples: Spam detection, content moderation, loan approval\n",
    "- **If costs are similar** â†’ Use **BALANCED threshold** (0.4-0.6)\n",
    "  - Priority: Balance precision and recall\n",
    "  - Examples: Customer churn, product recommendations\n",
    "\n",
    "**Step 3: Test and Validate**\n",
    "- Try different thresholds (0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "- Calculate precision, recall, F1 for each\n",
    "- Choose threshold that minimizes your cost function\n",
    "\n",
    "---\n",
    "\n",
    "### **Method 2: Metric-Based Decision**\n",
    "\n",
    "**For High Recall Problems** (Catch all positives):\n",
    "- **Target**: Recall > 0.90 (catch 90%+ of positives)\n",
    "- **Method**: Start with threshold = 0.3, increase until recall drops below target\n",
    "- **Use when**: Missing positives is very costly\n",
    "- **Examples**: \n",
    "  - Fraud detection: \"Better to flag 100 transactions than miss 1 fraud case\"\n",
    "  - Fraud detection: \"Better to flag 100 transactions than miss 1 fraud\"\n",
    "\n",
    "**For High Precision Problems** (Few false positives):\n",
    "- **Target**: Precision > 0.90 (90%+ of predictions are correct)\n",
    "- **Method**: Start with threshold = 0.7, decrease until precision drops below target\n",
    "- **Use when**: False positives are very costly\n",
    "- **Examples**:\n",
    "  - Spam detection: \"Better to miss some spam than block real emails\"\n",
    "  - Content moderation: \"Better to miss some bad content than block good content\"\n",
    "\n",
    "**For Balanced Problems** (Balance both):\n",
    "- **Target**: Maximize F1 score\n",
    "- **Method**: Find threshold with highest F1 score\n",
    "- **Use when**: Both precision and recall matter equally\n",
    "- **Examples**:\n",
    "  - Customer churn: \"Balance between catching churners and not annoying loyal customers\"\n",
    "  - Product recommendations: \"Balance between relevance and coverage\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Method 3: Business Rule-Based Decision**\n",
    "\n",
    "**Step 1: Define Business Requirements**\n",
    "- \"We need to catch at least 95% of fraud cases\" â†’ Lower threshold\n",
    "- \"We can't have more than 5% false positives\" â†’ Higher threshold\n",
    "- \"We need both precision and recall above 80%\" â†’ Balanced threshold\n",
    "\n",
    "**Step 2: Find Threshold That Meets Requirements**\n",
    "- Test thresholds until you meet the requirement\n",
    "- If impossible, you may need:\n",
    "  - More training data\n",
    "  - Better features\n",
    "  - Different algorithm\n",
    "\n",
    "---\n",
    "\n",
    "### **Method 4: ROC Curve Analysis (Advanced)**\n",
    "\n",
    "**Step 1: Plot ROC Curve**\n",
    "- Shows True Positive Rate (TPR) vs False Positive Rate (FPR) for all thresholds\n",
    "- Higher curve = better model\n",
    "\n",
    "**Step 2: Choose Operating Point**\n",
    "- **Top-left corner**: Best balance (high TPR, low FPR)\n",
    "- **Left side**: High precision (fewer false positives)\n",
    "- **Top side**: High recall (catch more positives)\n",
    "\n",
    "**Step 3: Find Threshold at Operating Point**\n",
    "- Use `roc_curve()` to get threshold for each point\n",
    "- Choose threshold corresponding to your operating point\n",
    "\n",
    "---\n",
    "\n",
    "### **Quick Decision Framework | Ø¥Ø·Ø§Ø± Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹**\n",
    "\n",
    "**Ask yourself these questions:**\n",
    "\n",
    "1. **What's worse: Missing a positive (FN) or False alarm (FP)?**\n",
    "   - Missing positive is worse â†’ **Lower threshold (0.3-0.4)**\n",
    "   - False alarm is worse â†’ **Higher threshold (0.6-0.7)**\n",
    "   - Both are similar â†’ **Balanced threshold (0.4-0.6)**\n",
    "\n",
    "2. **What's my minimum requirement?**\n",
    "   - Need to catch 90%+ of positives â†’ **Lower threshold**\n",
    "   - Need 90%+ of predictions to be correct â†’ **Higher threshold**\n",
    "   - Need both â†’ **Find threshold with best F1**\n",
    "\n",
    "3. **What's my business constraint?**\n",
    "   - Limited resources to handle positives â†’ **Higher threshold** (fewer predictions)\n",
    "   - Can't afford to miss positives â†’ **Lower threshold** (catch everything)\n",
    "\n",
    "---\n",
    "\n",
    "### **Real-World Examples | Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ**\n",
    "\n",
    "| Problem | FN Cost | FP Cost | Recommended Threshold | Why |\n",
    "|---------|---------|---------|----------------------|-----|\n",
    "| **Fraud Detection** | Very High (miss fraud) | Low (false alarm) | **0.3-0.4** | Better to flag more than miss fraud |\n",
    "| **Fraud Detection** | Very High (lose money) | Low (investigate) | **0.3-0.4** | Better to flag more than miss fraud |\n",
    "| **Spam Detection** | Low (miss spam) | High (block real email) | **0.6-0.7** | Better to miss spam than block real emails |\n",
    "| **Loan Approval** | Low (reject good loan) | High (approve bad loan) | **0.6-0.7** | Better to reject more than approve bad loans |\n",
    "| **Customer Churn** | Medium | Medium | **0.4-0.6** | Balance between catching churners and not annoying customers |\n",
    "| **Product Recommendation** | Medium | Medium | **0.4-0.6** | Balance between relevance and coverage |\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Steps to Find Your Threshold | Ø®Ø·ÙˆØ§Øª Ø¹Ù…Ù„ÙŠØ© Ù„Ø¥ÙŠØ¬Ø§Ø¯ Ø¹ØªØ¨ØªÙƒ**\n",
    "\n",
    "**Step 1: Get Probabilities**\n",
    "```python\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "```\n",
    "\n",
    "**Step 2: Test Multiple Thresholds**\n",
    "```python\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics\n",
    "```\n",
    "\n",
    "**Step 3: Evaluate Each Threshold**\n",
    "- Calculate precision, recall, F1 for each threshold\n",
    "- Plot precision/recall vs threshold (like we'll do below)\n",
    "- Identify which threshold meets your requirements\n",
    "\n",
    "**Step 4: Choose and Validate**\n",
    "- Choose threshold based on your cost/requirements\n",
    "- Validate on validation set (not test set!)\n",
    "- Monitor in production and adjust if needed\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Mistakes to Avoid | Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø© ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§**\n",
    "\n",
    "âŒ **Mistake 1**: Always using 0.5\n",
    "- **Why wrong**: Assumes equal cost of errors\n",
    "- **Fix**: Choose threshold based on your problem\n",
    "\n",
    "âŒ **Mistake 2**: Optimizing on test set\n",
    "- **Why wrong**: Overfitting to test set\n",
    "- **Fix**: Use validation set for threshold selection\n",
    "\n",
    "âŒ **Mistake 3**: Ignoring business context\n",
    "- **Why wrong**: Best metric might not be best for business\n",
    "- **Fix**: Consider real-world costs and constraints\n",
    "\n",
    "âŒ **Mistake 4**: Not monitoring in production\n",
    "- **Why wrong**: Data distribution changes over time\n",
    "- **Fix**: Regularly re-evaluate and adjust threshold\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ IMPORTANT: When Do We Use Thresholds? | Ù…Ù‡Ù…: Ù…ØªÙ‰ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹ØªØ¨Ø§ØªØŸ\n",
    "\n",
    "**This is a common confusion point!** Let's clarify:\n",
    "\n",
    "### **The Workflow | Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„**\n",
    "\n",
    "**Step 1: Train the Model FIRST** âœ…\n",
    "```python\n",
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data\n",
    "```\n",
    "\n",
    "**Step 2: Get Probabilities** âœ…\n",
    "```python\n",
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!\n",
    "```\n",
    "\n",
    "**Step 3: Test Different Thresholds** âœ…\n",
    "```python\n",
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold\n",
    "```\n",
    "\n",
    "**Step 4: Choose Optimal Threshold** âœ…\n",
    "```python\n",
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score\n",
    "```\n",
    "\n",
    "**Step 5: Use Threshold for Predictions** âœ…\n",
    "```python\n",
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points | Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**\n",
    "\n",
    "âœ… **Threshold selection happens AFTER training**\n",
    "- You need the trained model to get probabilities\n",
    "- You can't choose threshold before training (no probabilities yet!)\n",
    "\n",
    "âœ… **You DON'T retrain the model when changing threshold**\n",
    "- The model outputs probabilities (e.g., 0.3, 0.7, 0.9)\n",
    "- Threshold just changes how you interpret those probabilities\n",
    "- Same probabilities â†’ Different predictions based on threshold\n",
    "\n",
    "âœ… **The model is trained ONCE, threshold is applied MANY times**\n",
    "- Train model: `model.fit()` (happens once)\n",
    "- Get probabilities: `model.predict_proba()` (happens once)\n",
    "- Apply threshold: `(y_proba >= threshold)` (can change anytime!)\n",
    "\n",
    "---\n",
    "\n",
    "### **Visual Example | Ù…Ø«Ø§Ù„ Ø¨ØµØ±ÙŠ**\n",
    "\n",
    "**Imagine the model outputs these probabilities:**\n",
    "```\n",
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)\n",
    "```\n",
    "\n",
    "**With threshold = 0.5:**\n",
    "- Sample 1: 0.3 < 0.5 â†’ Predict **Class 0**\n",
    "- Sample 2: 0.6 â‰¥ 0.5 â†’ Predict **Class 1**\n",
    "- Sample 3: 0.8 â‰¥ 0.5 â†’ Predict **Class 1**\n",
    "\n",
    "**With threshold = 0.7 (higher):**\n",
    "- Sample 1: 0.3 < 0.7 â†’ Predict **Class 0**\n",
    "- Sample 2: 0.6 < 0.7 â†’ Predict **Class 0** (changed!)\n",
    "- Sample 3: 0.8 â‰¥ 0.7 â†’ Predict **Class 1**\n",
    "\n",
    "**Notice:** Same probabilities, different predictions! No retraining needed!\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Student Questions | Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©**\n",
    "\n",
    "**Q: Do I need to retrain the model when I change threshold?**\n",
    "- **A: NO!** The model outputs probabilities. Threshold just changes how you interpret them.\n",
    "\n",
    "**Q: When should I find the optimal threshold?**\n",
    "- **A: AFTER training, on validation set** (not test set!)\n",
    "\n",
    "**Q: Can I use different thresholds for different problems?**\n",
    "- **A: YES!** Same trained model, different thresholds for different use cases.\n",
    "\n",
    "**Q: What if I want to change threshold in production?**\n",
    "- **A: Just change the threshold value!** No need to retrain the model.\n",
    "\n",
    "---\n",
    "\n",
    "### **The Complete Workflow | Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙƒØ§Ù…Ù„**\n",
    "\n",
    "```\n",
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Now let's see this in action!** We'll test different thresholds and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    # Calculate metrics"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Train the model (this happens ONCE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Model learns from data"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Get probabilities from TRAINED model\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "# These probabilities are FIXED - they don't change!"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Test different thresholds (NO RETRAINING NEEDED!)\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred = (y_proba >= threshold).astype(int)  # Just change interpretation!\n",
    "    # Calculate metrics for this threshold"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Choose the best threshold based on your needs\n",
    "optimal_threshold = 0.4  # Example: best F1 score"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Use optimal threshold for future predictions\n",
    "y_pred_final = (y_proba >= optimal_threshold).astype(int)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Sample 1: 0.3 (30% chance of class 1)\n",
    "Sample 2: 0.6 (60% chance of class 1)\n",
    "Sample 3: 0.8 (80% chance of class 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "1. Split Data\n",
    "   â”œâ”€â”€ Train Set (60%)\n",
    "   â”œâ”€â”€ Validation Set (20%) â† Use for threshold selection\n",
    "   â””â”€â”€ Test Set (20%) â† Use for final evaluation\n",
    "\n",
    "2. Train Model\n",
    "   â””â”€â”€ model.fit(X_train, y_train)\n",
    "\n",
    "3. Get Probabilities on Validation Set\n",
    "   â””â”€â”€ y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "4. Test Different Thresholds on Validation Set\n",
    "   â””â”€â”€ For each threshold: calculate metrics\n",
    "\n",
    "5. Choose Optimal Threshold\n",
    "   â””â”€â”€ Based on your requirements (cost, F1, etc.)\n",
    "\n",
    "6. Evaluate on Test Set (using optimal threshold)\n",
    "   â””â”€â”€ y_test_pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold)\n",
    "\n",
    "7. Deploy Model with Optimal Threshold\n",
    "   â””â”€â”€ Use same threshold for all future predictions"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explore different classification thresholds\n",
    "The \n",
    "default threshold is 0.5, but we can adjust it based on our needs\n",
    "= more aggressive (higher recall, lower precision)\n",
    "= more conservative (higher precision, lower recall)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\" + \"=\" * 60)\")\n",
    "\n",
    "\n",
    "print(\"Exploring Classification Thresholds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ø§Ø³ØªÙƒØ´Ø§Ù Ø¹ØªØ¨Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "= np.arange(0.1, 1.0, 0.1)\n",
    "results = []\n",
    "\n",
    "print(\"\\nğŸ“Š Threshold Analysis:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{'Threshold':<12} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1 Score':<12}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for threshold in thresholds:\n",
    " \n",
    "= (y_test_proba >= threshold).astype(int)\n",
    "\n",
    "= accuracy_score(y_test, y_pred_thresh)\n",
    "prec = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_thresh, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    " \n",
    "results.append({\n",
    "'threshold': threshold, 'accuracy': acc,\n",
    "'precision': prec,\n",
    "'recall': rec,\n",
    "'f1': f1\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "print(f\"{threshold:<12.1f} {acc:<12.4f} {prec:<12.4f} {rec:<12.4f} {f1:<12.4f}\")\n",
    "\n",
    "Find optimal threshold (highest F1 score)\n",
    "results_\n",
    "df = pd.DataFrame(results)\n",
    "optimal_idx = results_df['f1'].idxmax()\n",
    "optimal_threshold = results_df.loc[optimal_idx, 'threshold']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ Key Insights | Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Optimal Threshold (by F1 Score): {optimal_threshold:.1f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This threshold balances precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - F1 Score: {results_df.loc[optimal_idx, 'f1']:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” Threshold Trade-offs:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Lower threshold (< 0.5): More aggressive â†’ Higher recall, lower precision\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Higher threshold (> 0.5): More conservative â†’ Higher precision, lower recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Default (0.5): Balanced approach (assumes equal cost of errors)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“š Real-World Applications:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Fraud detection: Use LOWER threshold (0.3-0.4) for high recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" â†’ Don't miss fraud cases, even\")\n",
    "\n",
    "\n",
    "\n",
    "if some false alarms\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Spam detection: Use HIGHER threshold (0.6-0.7) for high precision\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" â†’ Don't block real emails, even\")\n",
    "\n",
    "\n",
    "\n",
    "if some spam gets through\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Balanced: Use threshold with best F1 score (current: {optimal_threshold:.1f})\")\n",
    "\n",
    "6))\n",
    "plt.plot(results_df['threshold'], results_df['precision'], 'o-', label='Precision', linewidth=2.5, markersize=6)\n",
    "plt.plot(results_df['threshold'], results_df['recall'], 's-', label='Recall', linewidth=2.5, markersize=6)\n",
    "plt.plot(results_df['threshold'], results_df['f1'], '^-', label='F1 Score', linewidth=2.5, markersize=6)\n",
    "plt.axvline(x=0.5, color='r', linestyle='--', alpha=0.6, linewidth=2, label='Default (0.5)')\n",
    "plt.axvline(x=optimal_threshold, color='g', linestyle='--', alpha=0.6, linewidth=2, label=f'Optimal ({optimal_threshold:.1f})')\n",
    "plt.xlabel('Threshold', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Effect of Classification Threshold on Metrics', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='best')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ“ Plot saved as 'threshold_analysis.png'\")\n",
    "if 'plt' in globals():\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ What You Should See in This Plot | Ù…Ø§ ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ø§Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø±Ø³Ù…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Understanding the Threshold Plot:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Precision line (blue circles): Shows how precision changes with threshold\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Recall line (orange squares): Shows how recall changes with threshold\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - F1 Score line (green triangles): Shows the balance between precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Red dashed line: Default threshold (0.5)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Green dashed line: Optimal threshold (best F1 score)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ” Key Observations:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - As threshold INCREASES (moves right):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" â†’ Precision INCREASES (fewer false positives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" â†’ Recall DECREASES (more false negatives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - As threshold DECREASES (moves left):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" â†’ Precision DECREASES (more false positives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" â†’ Recall INCREASES (fewer false negatives)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - The optimal threshold balances both (highest F1 score)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Threshold selection is a critical hyperparameter!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - You can't maximize both precision and recall simultaneously\")\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Choose threshold based on your problem's cost of errors\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Always explore different thresholds based on your problem's needs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Use probabilities (predict_proba) to adjust threshold, not just predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.479558Z",
     "iopub.status.busy": "2025-12-26T11:14:51.479402Z",
     "iopub.status.idle": "2025-12-26T11:14:51.487900Z",
     "shell.execute_reply": "2025-12-26T11:14:51.487369Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"3. Confusion Matrix\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "Create confusion matri\n",
    "x\n",
    "= confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Confusion Matrix:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Format: [TN FP]\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" [FN TP]\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ Understanding:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - TN (True Negative): Correctly predicted class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - FP (False Positive): Predicted 1, but actually 0 (Type I error)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - FN (False Negative): Predicted 0, but actually 1 (Type II error)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - TP (True Positive): Correctly predicted class 1\")\n",
    "\n",
    "Extract values \n",
    "for interpretationtn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "total = tn + fp + fn + tp\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ Interpreting the Confusion Matrix | ØªÙØ³ÙŠØ± Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Breakdown:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - True Negatives (TN): {tn} - Correctly predicted Class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - False Positives (FP): {fp} - Predicted Class 1, but actually Class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - False Negatives (FN): {fn} - Predicted Class 0, but actually Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - True Positives (TP): {tp} - Correctly predicted Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Total: {total} test samples\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” Error Analysis:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Total errors: {fp + fn} out of {total} ({((fp+fn)/total):.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - False Positives: {fp} ({fp/total:.1%}) - Model predicted Class 1 when it should be Class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - False Negatives: {fn} ({fn/total:.1%}) - Model predicted Class 0 when it should be Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if fp > fn:\n",
    "print(f\" - âš ï¸ More False Positives ({fp}) than False Negatives ({fn})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model is too aggressive in predicting Class 1\")\n",
    "elif fn > fp:\n",
    "print(f\" - âš ï¸ More False Negatives ({fn}) than False Positives ({fp})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model is too conservative, missing Class 1 cases\")\n",
    "else:\n",
    "print(f\" - âœ… Balanced errors: {fp} FP and {fn} FN\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Confusion matrix shows WHERE errors occur (which class)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Helps identify\")\n",
    "\n",
    "\n",
    "\n",
    "if model has bias toward one class\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - FP and FN have different costs in real-world applications\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Example: In fraud detection, FN (missing fraud) is worse than FP (false alarm)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Can calculate precision, recall, and F1 from these numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Handling Class Imbalance | Ø§Ù„Ø®Ø·ÙˆØ© 7: Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª\n",
    "\n",
    "**BEFORE**: We detected class imbalance (36.8% Class 0, 63.2% Class 1), but didn't address it.\n",
    "\n",
    "**AFTER**: We'll use `class_weight='balanced'` to automatically handle class imbalance!\n",
    "\n",
    "**Why this matters**: \n",
    "- **Class imbalance**: One class has many more samples than the other\n",
    "- **Problem**: Model may favor the majority class (predicts it more often)\n",
    "- **Solution**: Use `class_weight='balanced'` to automatically weight classes inversely proportional to their frequency\n",
    "- **Result**: Model pays more attention to minority class, improving recall for that class\n",
    "\n",
    "**When to use class weights:**\n",
    "- Class imbalance detected (one class > 60% of data)\n",
    "- Minority class is important (e.g., fraud detection, threat detection)\n",
    "- You want balanced precision/recall across classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Confusion Matrix | Ø§Ù„Ø®Ø·ÙˆØ© 8: Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ\n",
    "\n",
    "**BEFORE**: We have metrics (accuracy, precision, recall), but we don't know WHERE errors occur.\n",
    "\n",
    "**AFTER**: We'll visualize the confusion matrix to see exactly which predictions were wrong!\n",
    "\n",
    "**Why this step?**\n",
    "- **Confusion Matrix**: Shows WHERE errors occur (which class was misclassified)\n",
    "- **Visual Understanding**: See false positives and false negatives clearly\n",
    "- **Error Analysis**: Understand if model favors one class over another\n",
    "- **Foundation**: Needed to understand precision, recall, and F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "    if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "Handle \n",
    "class imbalance using \n",
    "class_weight parameter\n",
    "\n",
    "automatically weights \n",
    "classes inversely proportional to frequency\n",
    "This helps the model pay more attention to the minority \n",
    "class\n",
    "print('\\n\" + \"=\" * 60)\")\n",
    "\n",
    "\n",
    "print(\"Handling Class Imbalance with class_weight\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(\"Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… class_weight\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "First, let's check the \n",
    "class distribution to understand the imbalance\n",
    "== 0).sum()\n",
    "\n",
    "class_1_count = (y_test == 1).sum()\n",
    "total = len(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Class Distribution in Test Set:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class 0: {class_0_count}/{total} ({class_0_count/total:.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class 1: {class_1_count}/{total} ({class_1_count/total:.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if abs(class_0_count - class_1_count) / total > 0.3:\n",
    "print(f\" - âš ï¸ Significant imbalance detected - class weights may help!\")\n",
    "else:\n",
    "print(f\" - âœ… Imbalance is mild - but let's see\")\n",
    "\n",
    "\n",
    "\n",
    "if class weights improve performance\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ’¡ Why this matters:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Imbalanced classes can cause models to favor the majority class\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - class_weight='balanced' automatically adjusts for this imbalance\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Let's compare models with and without class weights...\")\n",
    "\n",
    "Train model with balanced \n",
    "class weights\n",
    ": Any number works (42, 123, 2024, etc.) - just \n",
    "for reproducibilitylogistic_balanced = LogisticRegression(\n",
    "random_state=123, max_iter=1000,\n",
    "class_weight='balanced' \n",
    "Automatically balance \n",
    "classes\n",
    ")\n",
    "logistic_balanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "= logistic_balanced.predict(X_train_scaled)\n",
    "y_test_pred_balanced = logistic_balanced.predict(X_test_scaled)\n",
    "\n",
    "Calculate metrics \n",
    "for balanced modelbalanced_train_acc = accuracy_score(y_train, y_train_pred_balanced)\n",
    "balanced_test_acc = accuracy_score(y_test, y_test_pred_balanced)\n",
    "balanced_test_prec = precision_score(y_test, y_test_pred_balanced)\n",
    "balanced_test_rec = recall_score(y_test, y_test_pred_balanced)\n",
    "balanced_test_f1 = f1_score(y_test, y_test_pred_balanced)\n",
    "\n",
    "Compare with original model\n",
    "print(\"\\nğŸ“Š Comparison: Original vs Balanced Class Weights\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Original':<15} {'Balanced':<15} {'Difference':<15}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"-\" * 65)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{'Test Accuracy':<20} {test_accuracy:<15.4f} {balanced_test_acc:<15.4f} {balanced_test_acc - test_accuracy:+.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{'Test Precision':<20} {test_precision:<15.4f} {balanced_test_prec:<15.4f} {balanced_test_prec - test_precision:+.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{'Test Recall':<20} {test_recall:<15.4f} {balanced_test_rec:<15.4f} {balanced_test_rec - test_recall:+.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{'Test F1 Score':<20} {test_f1:<15.4f} {balanced_test_f1:<15.4f} {balanced_test_f1 - test_f1:+.4f}\")\n",
    "\n",
    "Per-class comparison\n",
    "print(\"\\nğŸ“Š Per-Class Performance Comparison:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "Get classification reports\n",
    "Note: StringIO and sys are already imported in Cell 1\n",
    "\n",
    "= StringIO()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Class 0', 'Class 1'])\n",
    "original_report = report_capture.getvalue()\n",
    "sys.stdout = old_stdoutsys.stdout = report_capture = StringIO()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_test_pred_balanced, target_names=['Class 0', 'Class 1'])\n",
    "balanced_report = report_capture.getvalue()\n",
    "sys.stdout = old_stdout\n",
    "print(\"\\nOriginal Model (no class weights):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(original_report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nBalanced Model (class_weight='balanced'):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(balanced_report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ Key Insights | Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if abs(balanced_test_rec - test_recall) > 0.01:\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "if balanced_test_rec > test_recall:\n",
    "print(f\"\\nâœ… Class weights improved recall: {test_recall:.2%} â†’ {balanced_test_rec:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model now catches more of the minority class\")\n",
    "else:\n",
    "print(f\"\\nğŸ“Š Class weights changed recall: {test_recall:.2%} â†’ {balanced_test_rec:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Recall decreased slightly, but precision may have improved\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This is normal: class weights balance precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Check\")\n",
    "\n",
    "\n",
    "\n",
    "if precision improved for the minority class\")\n",
    "else:\n",
    "print(f\"\\nğŸ“Š Class weights had minimal effect on this dataset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Original model already performs well\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class imbalance is mild (not severe enough to require balancing)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” When to Use class_weight='balanced':\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Severe class imbalance (> 70/30 split)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Minority class is critical (fraud, threats, rare events)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - You want balanced precision/recall across classes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Current dataset: {class_0_count}/{total} ({class_0_count/total:.1%}) vs {class_1_count}/{total} ({class_1_count/total:.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if abs(class_0_count - class_1_count) / total > 0.3:\n",
    "print(f\" - âš ï¸ Significant imbalance detected - class weights may help!\")\n",
    "else:\n",
    "print(f\" - âœ… Imbalance is mild - original model is fine\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - class_weight='balanced' automatically handles class imbalance\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - It weights classes inversely proportional to frequency\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Useful when minority class is important\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - May slightly reduce overall accuracy but improves minority class recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Always compare with and without class weights!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.490027Z",
     "iopub.status.busy": "2025-12-26T11:14:51.489847Z",
     "iopub.status.idle": "2025-12-26T11:14:51.501689Z",
     "shell.execute_reply": "2025-12-26T11:14:51.498546Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "Classification Report\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "\n",
    "        \n",
    "print(classification_report(y_test, y_test_pred,\n",
    "target_names=['Class 0', 'Class 1']))\n",
    "Add interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ Reading the Classification Report | Ù‚Ø±Ø§Ø¡Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Understanding Each Column:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Precision: Of predictions for this class, how many were correct?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Recall: Of actual cases of this class, how many did we catch?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - F1-score: Balance between precision and recall\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Support: Number of actual cases of this class in test set\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ” What to Look For:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Compare Class 0 vs Class 1 metrics (check for class imbalance)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - High precision = reliable predictions for that class\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - High recall = catches most cases of that class\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - F1-score shows overall performance for each class\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“š Key Insights:\")\n",
    "== 0).sum()\n",
    "\n",
    "class_1_count = (y_test == 1).sum()\n",
    "total = len(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class distribution: {class_0_count}/{total} ({(class_0_count/total):.1%}) Class 0, {class_1_count}/{total} ({(class_1_count/total):.1%}) Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if abs(class_0_count - class_1_count) / total > 0.2:\n",
    "print(f\" - âš ï¸ Class imbalance detected! This affects model performance\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Model may favor the majority class\")\n",
    "else:\n",
    "print(f\" - âœ… Classes are relatively balanced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ Learning Point:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Classification report shows per-class performance\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Important when classes are imbalanced (one class has more samples)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Accuracy can be misleading with imbalanced classes!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Always check precision and recall for each class separately\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: ROC Curve and AUC | Ø§Ù„Ø®Ø·ÙˆØ© 9: Ù…Ù†Ø­Ù†Ù‰ ROC Ùˆ AUC\n",
    "\n",
    "**BEFORE**: We have accuracy, precision, recall, but we need a metric that works across all thresholds.\n",
    "\n",
    "**AFTER**: We'll create an ROC curve and calculate AUC to evaluate model performance across all possible thresholds!\n",
    "\n",
    "**Why this step?**\n",
    "- **ROC Curve**: Shows model performance across ALL possible thresholds (not just 0.5)\n",
    "- **AUC Score**: Single number that summarizes model's ability to separate classes\n",
    "- **Threshold Independent**: Unlike accuracy, AUC doesn't depend on a fixed threshold\n",
    "- **Industry Standard**: AUC is widely used in industry for model comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.503730Z",
     "iopub.status.busy": "2025-12-26T11:14:51.503614Z",
     "iopub.status.idle": "2025-12-26T11:14:51.507086Z",
     "shell.execute_reply": "2025-12-26T11:14:51.505920Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"4. ROC Curve and AUC\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ù…Ù†Ø­Ù†Ù‰ ROC Ùˆ AUC\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.510915Z",
     "iopub.status.busy": "2025-12-26T11:14:51.510757Z",
     "iopub.status.idle": "2025-12-26T11:14:51.734101Z",
     "shell.execute_reply": "2025-12-26T11:14:51.733872Z"
    }
   },
   "outputs": [],
   "source": [
    "6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "xticklabels=['Class 0', 'Class 1'],\n",
    "yticklabels=['Class 0', 'Class 1'],\n",
    "cbar_kws={'label': 'Count'}) \n",
    "Add colorbar label \n",
    "for clarity\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ“ Plot saved as 'confusion_matrix.png'\")\n",
    "if 'plt' in globals():\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ What You Should See in This Plot:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - A 2x2 heatmap with numbers in each cell\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Darker blue = higher numbers (more predictions)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Top-left (TN): Correctly predicted Class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Top-right (FP): Incorrectly predicted Class 1 (should be Class 0)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Bottom-left (FN): Incorrectly predicted Class 0 (should be Class 1)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Bottom-right (TP): Correctly predicted Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - A good model has high numbers on the diagonal (TN and TP)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - A poor model has high numbers off the diagonal (FP and FN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.735155Z",
     "iopub.status.busy": "2025-12-26T11:14:51.735082Z",
     "iopub.status.idle": "2025-12-26T11:14:51.739043Z",
     "shell.execute_reply": "2025-12-26T11:14:51.738815Z"
    }
   },
   "outputs": [],
   "source": [
    "= roc_curve(y_test, y_test_proba)\n",
    "auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "Add interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ Understanding AUC Score | ÙÙ‡Ù… Ø¯Ø±Ø¬Ø© AUC\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š AUC (Area Under Curve) = {auc_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Range: 0.0 to 1.0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - 0.5 = Random guessing (worst)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - 1.0 = Perfect classifier (best)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Our score: {auc_score:.4f} ({auc_score*100:.1f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if auc_score >= 0.9:\n",
    "print(f\" - âœ… EXCELLENT! (>0.9 means model can distinguish classes very well)\")\n",
    "elif auc_score >= 0.8:\n",
    "print(f\" - âœ… GOOD! (>0.8 means model has good discriminative ability)\")\n",
    "elif auc_score >= 0.7:\n",
    "print(f\" - âš ï¸ FAIR (>0.7 means model has some ability, but room for improvement)\")\n",
    "elif auc_score >= 0.6:\n",
    "print(f\" - âš ï¸ POOR (>0.6 but <0.7 means model struggles to separate classes)\")\n",
    "else:\n",
    "print(f\" - âŒ VERY POOR (<0.6 means model is barely better than random)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” What AUC Measures:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - How well the model can distinguish between Class 0 and Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Higher AUC = better at separating the two classes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - AUC is independent of the classification threshold\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Useful for comparing different models\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - AUC evaluates model performance across all possible thresholds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Unlike accuracy, AUC doesn't depend on a fixed threshold (0.5)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - AUC is especially useful when classes are imbalanced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - AUC > 0.8 is generally considered good for binary classification\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Our model has {'excellent'\")\n",
    "\n",
    "\n",
    "\n",
    "if auc_score >= 0.9 else 'good' \n",
    "\n",
    "\n",
    "\n",
    "if auc_score >= 0.8 else 'fair'} ability to separate classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Decision Boundary Visualization | Ø§Ù„Ø®Ø·ÙˆØ© 10: ØªØµÙˆØ± Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚Ø±Ø§Ø±\n",
    "\n",
    "**BEFORE**: We've trained a model, but we can't \"see\" how it makes decisions.\n",
    "\n",
    "**AFTER**: We'll visualize the decision boundary to understand how the model separates classes!\n",
    "\n",
    "**Why this step?**\n",
    "- **Visual Understanding**: See exactly where the model draws the line between classes\n",
    "- **Interpretability**: Understand how features affect the decision\n",
    "- **Validation**: Confirm the boundary makes sense (linear for logistic regression)\n",
    "- **Educational**: Helps students understand how classification works visually\n",
    "\n",
    "**Note**: We use 2 features for visualization (can't visualize 30D!), but the main model uses all 30 features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.739955Z",
     "iopub.status.busy": "2025-12-26T11:14:51.739898Z",
     "iopub.status.idle": "2025-12-26T11:14:51.933896Z",
     "shell.execute_reply": "2025-12-26T11:14:51.933670Z"
    }
   },
   "outputs": [],
   "source": [
    "6))\n",
    "plt.plot(fpr, tpr, linewidth=2.5, label=f'ROC Curve (AUC = {auc_score:.4f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random Classifier', alpha=0.7)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='lower right')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ“ Plot saved as 'roc_curve.png'\")\n",
    "if 'plt' in globals():\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ What You Should See in This Plot:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Blue curve: ROC curve for our model (should curve upward)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Black dashed line: Random classifier (diagonal line from bottom-left to top-right)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - X-axis: False Positive Rate (0 to 1)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Y-axis: True Positive Rate (0 to 1)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - A good model: Curve goes up and to the LEFT (high TPR, low FPR)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - A poor model: Curve stays close to the diagonal line\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - The area under the curve (AUC) shows model quality:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" * AUC = 0.5: Random guessing (no better than chance)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" * AUC = 1.0: Perfect classifier\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" * AUC > 0.8: Good classifier (our model: {:.4f})\".format(auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.934865Z",
     "iopub.status.busy": "2025-12-26T11:14:51.934800Z",
     "iopub.status.idle": "2025-12-26T11:14:51.936437Z",
     "shell.execute_reply": "2025-12-26T11:14:51.936200Z"
    }
   },
   "outputs": [],
   "source": [
    "5. Decision Boundary Visualization\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"5. Decision Boundary Visualization\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ØªØµÙˆØ± Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚Ø±Ø§Ø±\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.937543Z",
     "iopub.status.busy": "2025-12-26T11:14:51.937481Z",
     "iopub.status.idle": "2025-12-26T11:14:51.942890Z",
     "shell.execute_reply": "2025-12-26T11:14:51.942215Z"
    }
   },
   "outputs": [],
   "source": [
    "For decision boundary visualization, we need to train a separate model\n",
    "on just 2 features (X_2d) so we can visualize in 2D\n",
    "The main model uses all 30 features, but we can't visualize 30D!\n",
    "\n",
    "Prepare 2D feature\n",
    "s \n",
    "= train_test_split(\n",
    "X_2d, y, test_size=0.2, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "= StandardScaler()\n",
    "X_2d_train_scaled = scaler_2d.fit_transform(X_2d_train)\n",
    "X_2d_test_scaled = scaler_2d.transform(X_2d_test)\n",
    "\n",
    "Train a separate logistic regression model on 2D features \n",
    "for visualization\n",
    ": Any number works (42, 123, 2024, etc.) - just \n",
    "= LogisticRegression(random_state=123, max_iter=1000)\n",
    "model_2d.fit(X_2d_train_scaled, y_train_2d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"âœ… 2D model trained for visualization\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Note: This is separate from the main model (which uses all 30 features)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" This allows us to visualize the decision boundary in 2D!\")\n",
    "\n",
    "Create a mesh \n",
    "for plotting the decision boundary\n",
    "A mesh is a grid of points covering the entire plot area\n",
    "We'll predict the \n",
    "class\n",
    "for each point in this grid to visualize the decision boundaryh = 0.02\n",
    "Step size \n",
    "for the grid (smaller = smoother boundary, but slower)\n",
    "x_min, x_max = X_2d_test_scaled[:, 0].min() - 1, X_2d_test_scaled[:, 0].max() + 1y_min, y_max = X_2d_test_scaled[:, 1].min() - 1, X_2d_test_scaled[:, 1].max() + 1\n",
    "np.meshgrid creates a grid of (x, y) coordinate pair\n",
    "s\n",
    "= np.meshgrid(np.arange(x_min, x_max, h),\n",
    "np.arange(y_min, y_max, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.944543Z",
     "iopub.status.busy": "2025-12-26T11:14:51.944385Z",
     "iopub.status.idle": "2025-12-26T11:14:51.948454Z",
     "shell.execute_reply": "2025-12-26T11:14:51.948107Z"
    }
   },
   "outputs": [],
   "source": [
    "Predict \n",
    "for mesh points using the 2D model\n",
    "np.c_ combines xx and yy into pairs: [x1, y1], [x2, y2], ...\n",
    ".ravel() flattens the 2D arrays into 1D (needed \n",
    "for prediction)\n",
    "We predict the \n",
    "class (0 or 1) \n",
    "for each point in the meshZ = model_2d.predict(\n",
    "np.c_[xx.ravel(), yy.ravel()])\n",
    ".reshape() converts the 1D predictions back to 2D to match the mesh grid shape\n",
    "This allows us to plot the decision boundary as a filled contourZ = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:51.950287Z",
     "iopub.status.busy": "2025-12-26T11:14:51.950148Z",
     "iopub.status.idle": "2025-12-26T11:14:52.318384Z",
     "shell.execute_reply": "2025-12-26T11:14:52.318142Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "8))\n",
    "plt.contourf creates a filled contour plot showing the decision boundary\n",
    "xx, yy: grid coordinates, Z: predicted \n",
    "classes \n",
    "for each grid point\n",
    ": makes the background semi-transparent so we can see the data points\n",
    ": color map (Red-Yellow-Blue) to distinguish the two \n",
    "classesplt.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "scatter = plt.scatter(X_2d_test_scaled[:, 0], X_2d_test_scaled[:, 1],\n",
    "c=y_test_2d, cmap='RdYlBu', edgecolors='black', s=50, linewidths=0.5)\n",
    "plt.colorbar(scatter, label='Class')\n",
    "plt.xlabel(f'{feature_1_name} (Scaled)', fontsize=12)\n",
    "plt.ylabel(f'{feature_2_name} (Scaled)', fontsize=12)\n",
    "plt.title('Decision Boundary Visualization (2D Model)\\nNote: Uses 2 features for visualization; main model uses all 30 features', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.2, linestyle='--') \n",
    "Add subtle grid \n",
    "for better readability\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_boundary.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ“ Plot saved as 'decision_boundary.png'\")\n",
    "        if 'plt' in globals():\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ What You Should See in This Plot | Ù…Ø§ ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ø§Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø±Ø³Ù…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Understanding the Decision Boundary Plot:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Colored background: Shows the decision boundary (where model predicts each class)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Red/Yellow region: Model predicts Class 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Blue region: Model predicts Class 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Colored dots: Actual data points (colored by their true class)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - The boundary is a STRAIGHT LINE (linear boundary)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ” Key Observations:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - The decision boundary is LINEAR (a straight line)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - This works well because the data is LINEARLY SEPARABLE\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Most points are on the correct side of the boundary\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - The line separates the two classes effectively\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Logistic Regression creates LINEAR decision boundaries\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - This visualization uses only 2 features (for 2D plotting)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - The main model uses all 30 features and performs better (98.25% accuracy)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - When data is linearly separable, logistic regression works excellently!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - If the boundary needed to be curved, logistic regression would fail\")\n",
    "Keep the visualization but we'll add dead end section after this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Understanding Logistic Regression Limitations (Optional) | ÙÙ‡Ù… Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
    "\n",
    "## âš ï¸ Important Note: This Section is for Learning Only | Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©: Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… Ù„Ù„ØªØ¹Ù„Ù… ÙÙ‚Ø·\n",
    "\n",
    "**Before we start**: Logistic Regression worked **EXCELLENTLY** on our credit card fraud dataset (Precision: ~82%, F1: ~87%)! âœ…\n",
    "\n",
    "**This section shows**: What happens when you use Logistic Regression on the **WRONG type of data** (non-linear boundaries).\n",
    "\n",
    "**Why show this?** Understanding limitations helps you:\n",
    "- Know when to use Logistic Regression (linear data) âœ…\n",
    "- Know when to use other algorithms (non-linear data) âš ï¸\n",
    "- Choose the RIGHT algorithm for the RIGHT dataset âœ…\n",
    "\n",
    "**Key Takeaway**: We chose the credit card fraud dataset because it works WELL with Logistic Regression! This section just shows what happens with the WRONG dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## What are Limitations? | Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù‚ÙŠÙˆØ¯ØŸ\n",
    "\n",
    "**Limitations mean**: Logistic Regression **cannot solve** problems with non-linear decision boundaries. For such problems, you need a **different algorithm** (like Decision Trees or SVM).\n",
    "\n",
    "**Think of it like this:**\n",
    "- ğŸš— **Car (Logistic Regression)**: Great on highways (linear data) âœ… - **This is our credit card fraud dataset!**\n",
    "- ğŸš« **Limitation**: Can't drive through a forest (non-linear data) âŒ - **We'll show this with synthetic data**\n",
    "- ğŸŒ³ **Solution**: Need a different vehicle (Decision Trees) that can handle forests!\n",
    "\n",
    "---\n",
    "\n",
    "## The Problem: Non-Linear Decision Boundaries | Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚Ø±Ø§Ø± ØºÙŠØ± Ø§Ù„Ø®Ø·ÙŠØ©\n",
    "\n",
    "**BEFORE**: We've seen Logistic Regression work excellently on our binary classification dataset (98.25% accuracy) - it works great when data has linear decision boundaries!\n",
    "\n",
    "**AFTER**: Now we'll see what happens when data has **non-linear decision boundaries** - this demonstrates Logistic Regression's limitations on non-linear data!\n",
    "\n",
    "**Remember**: Our credit card fraud dataset works EXCELLENTLY because it has linear relationships - this section just shows what happens with non-linear data!\n",
    "\n",
    "**Why this matters**: \n",
    "- Logistic Regression assumes **linear boundaries** (can separate with a straight line)\n",
    "- Real-world data often has **non-linear patterns** (curves, circles, XOR patterns)\n",
    "- When boundaries are non-linear, Logistic Regression **struggles** (poor accuracy)\n",
    "- This limitation leads us to **Decision Trees** (next notebook) - they can handle non-linear boundaries!\n",
    "- **Remember**: Our credit card fraud dataset works GREAT with Logistic Regression! This is just showing when it doesn't work.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Real-World Scenario | Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\n",
    "\n",
    "**Example**: Customer churn prediction where customers with similar features but different behaviors can't be separated by a straight line. The relationship between features and churn is **non-linear**.\n",
    "\n",
    "**The Limitation (Demonstration Only)**: \n",
    "- Logistic Regression tries to draw a **straight line** to separate classes\n",
    "- But the actual pattern is **curved or circular**\n",
    "- Result: **Poor performance** (accuracy drops significantly)\n",
    "- Solution: Need algorithms that can handle **non-linear boundaries** â†’ Decision Trees!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:52.319565Z",
     "iopub.status.busy": "2025-12-26T11:14:52.319491Z",
     "iopub.status.idle": "2025-12-26T11:14:52.323020Z",
     "shell.execute_reply": "2025-12-26T11:14:52.322848Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ“š Understanding Limitations: Non-Linear Decision Boundaries\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ÙÙ‡Ù… Ø§Ù„Ù‚ÙŠÙˆØ¯: Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚Ø±Ø§Ø± ØºÙŠØ± Ø§Ù„Ø®Ø·ÙŠØ©\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâš ï¸ IMPORTANT NOTE:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" This section demonstrates Logistic Regression LIMITATIONS using SYNTHETIC data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Our REAL credit card fraud dataset works EXCELLENTLY with Logistic Regression!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" This is just for learning when Logistic Regression doesn't work well\")\n",
    "\n",
    "Create non-linear classification data (circular pattern) - SYNTHETIC DATA\n",
    "This will challenge Logistic Regression because it can't separate circles with a straight line!\n",
    "Note: make_circles is already imported in Cell 1\n",
    "This is SYNTHETIC data created to demonstrate limitations - NOT our real dataset!\n",
    "\n",
    "print(\"\\nğŸ“¥ Generating SYNTHETIC Non-Linear Classification Data (for demonstration)...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØµÙ†ÙŠÙ ØºÙŠØ± Ø®Ø·ÙŠØ© Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© (Ù„Ù„Ø¯emonstration)...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Note: This is SYNTHETIC data (make_circles) - NOT our real credit card fraud dataset!\")\n",
    "\n",
    "Create circular (non-linear) classification data\n",
    "make_circles creates two concentric circles - impossible to separate with a straight line!\n",
    ": Any number works (42, 123, 2024, etc.) - just \n",
    "for reproducibilityX_nonlinear, y_nonlinear = make_circles(\n",
    "\n",
    "Small amount of noise (\n",
    "for realism)\n",
    "factor=0.5, \n",
    "\n",
    "For reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Non-linear data generated!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" ğŸ“Š Shape: {X_nonlinear.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" ğŸ¯ Classes: {len(np.unique(y_nonlinear)} (binary classification)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" ğŸ“ˆ Pattern: Two concentric circles (non-linear!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” Notice:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This data has NON-LINEAR boundaries (circular pattern)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - A straight line CANNOT separate the two circles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This will challenge Logistic Regression!\")\n",
    "\n",
    "Split the non-linear data\n",
    ": Any number works (42, 123, 2024, etc.) - just \n",
    "for reproducibilityX_nl_train, X_nl_test, y_nl_train, y_nl_test = train_test_split(\n",
    "X_nonlinear, y_nonlinear, test_size=0.2, random_state=123, stratify=y_nonlinear\n",
    ")\n",
    "\n",
    "Scale features (Logistic Regression requires scaling)\n",
    "scaler_nl = StandardScaler()\n",
    "X_nl_train_scaled = scaler_nl.fit_transform(X_nl_train)\n",
    "X_nl_test_scaled = scaler_nl.transform(X_nl_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Data split and scaled!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Training samples: {len(X_nl_train)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Test samples: {len(X_nl_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:52.323955Z",
     "iopub.status.busy": "2025-12-26T11:14:52.323888Z",
     "iopub.status.idle": "2025-12-26T11:14:52.327737Z",
     "shell.execute_reply": "2025-12-26T11:14:52.327505Z"
    }
   },
   "outputs": [],
   "source": [
    "Try Logistic Regression on non-linear data (SYNTHETIC - \n",
    "for demonstration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training Logistic Regression on Non-Linear Data (SYNTHETIC)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø®Ø·ÙŠØ© (Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ©)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâš ï¸ Remember: This is SYNTHETIC data to show limitations\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Our REAL credit card fraud dataset works GREAT with Logistic Regression!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" This section just demonstrates when it doesn't work (non-linear boundaries)\")\n",
    "\n",
    "Create and train logistic regression model\n",
    ": Any number works (42, 123, 2024, etc.) - just \n",
    "for reproducibilitylogistic_nl = LogisticRegression(random_state=123, max_iter=1000)\n",
    "logistic_nl.fit(X_nl_train_scaled, y_nl_train)\n",
    "\n",
    "= logistic_nl.predict(X_nl_train_scaled)\n",
    "y_nl_test_pred = logistic_nl.predict(X_nl_test_scaled)\n",
    "\n",
    "= accuracy_score(y_nl_train, y_nl_train_pred)\n",
    "nl_test_accuracy = accuracy_score(y_nl_test, y_nl_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“Š Logistic Regression Results on Non-Linear Data:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Training Accuracy: {nl_train_accuracy:.4f} ({nl_train_accuracy*100:.2f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Test Accuracy: {nl_test_accuracy:.4f} ({nl_test_accuracy*100:.2f}%)\")\n",
    "\n",
    "Compare with the good performance we had earlier\n",
    "print(f\"\\nğŸ” Comparison:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Wisconsin Breast Cancer (linear): {test_accuracy:.2%} âœ… Excellent!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Circular Data (non-linear): {nl_test_accuracy:.2%} âŒ Poor!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nâŒ What Went Wrong?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Logistic Regression can only create STRAIGHT LINE boundaries\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This data has CIRCULAR boundaries (two concentric circles)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - A straight line CANNOT separate two circles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Result: Poor accuracy ({nl_test_accuracy:.2%}) - barely better than random guessing!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ’¡ Key Insight:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Logistic Regression ASSUMES linear boundaries\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - When boundaries are non-linear, Logistic Regression struggles (poor accuracy)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This shows the LIMITATION of Logistic Regression on non-linear data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - BUT: Our REAL credit card fraud dataset works EXCELLENTLY! âœ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Solution: Use the RIGHT algorithm for the RIGHT dataset!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Next notebook: Decision Trees can handle non-linear boundaries! âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation Example 2: Visualize the Limitation | Ù…Ø«Ø§Ù„ Ø§Ù„Ù‚ÙŠØ¯ 2: ØªØµÙˆØ± Ø§Ù„Ù‚ÙŠØ¯\n",
    "\n",
    "**BEFORE**: We need to see WHY Logistic Regression struggles on non-linear data.\n",
    "\n",
    "**Remember**: This is SYNTHETIC data (make_circles) for demonstration. Our REAL credit card fraud dataset works EXCELLENTLY with Logistic Regression!\n",
    "\n",
    "**AFTER**: We'll visualize the decision boundary - you'll see a straight line trying (and failing) to separate circular data!\n",
    "\n",
    "**Why visualize**: \n",
    "- Visual proof shows the problem clearly\n",
    "- You'll see the straight line boundary failing\n",
    "- This demonstrates why we need non-linear algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:52.328939Z",
     "iopub.status.busy": "2025-12-26T11:14:52.328864Z",
     "iopub.status.idle": "2025-12-26T11:14:52.647401Z",
     "shell.execute_reply": "2025-12-26T11:14:52.647195Z"
    }
   },
   "outputs": [],
   "source": [
    "Visualize the decision boundary and data\n",
    "print('\\n\" + \"=\" * 60)\")\n",
    "\n",
    "\n",
    "print(\"Visualizing the Limitation: Linear Boundary on Non-Linear Data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ØªØµÙˆØ± Ø§Ù„Ù‚ÙŠØ¯: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø®Ø·ÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø®Ø·ÙŠØ©\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ’¡ Key Takeaway:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Logistic Regression works EXCELLENTLY on linear data (like our credit card fraud dataset!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - Logistic Regression struggles on non-linear data (like this synthetic circles example)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" - For non-linear data, use Decision Trees, SVM, or other algorithms\")\n",
    "\n",
    "Create a mesh \n",
    "for plotting the decision boundary\n",
    "A mesh is a grid of points covering the entire plot area\n",
    "We'll predict the \n",
    "class\n",
    "for each point in this grid to visualize the decision boundaryh = 0.02\n",
    "Step size \n",
    "for the grid (smaller = smoother boundary, but slower)\n",
    "x_min, x_max = X_nl_test_scaled[:, 0].min() - 0.5, X_nl_test_scaled[:, 0].max() + 0.5y_min, y_max = X_nl_test_scaled[:, 1].min() - 0.5, X_nl_test_scaled[:, 1].max() + 0.5\n",
    "np.meshgrid creates a grid of (x, y) coordinate pair\n",
    "s\n",
    "= np.meshgrid(np.arange(x_min, x_max, h),\n",
    "np.arange(y_min, y_max, h))\n",
    "Predict \n",
    "for mesh points\n",
    "np.c_ combines xx_nl and yy_nl into pairs: [x1, y1], [x2, y2], ...\n",
    ".ravel() flattens the 2D arrays into 1D (needed \n",
    "for prediction)\n",
    "We predict the \n",
    "class (0 or 1) \n",
    "for each point in the meshZ_nl = logistic_nl.predict(\n",
    "np.c_[xx_nl.ravel(), yy_nl.ravel()])\n",
    ".reshape() converts the 1D predictions back to 2D to match the mesh grid shap\n",
    "e\n",
    "= Z_nl.reshape(xx_nl.shape)\n",
    "\n",
    "5))\n",
    "Plot 1: Decision boundaryplt.subplot(1, 2, 1)\n",
    "plt.contourf creates a filled contour plot showing the decision boundary\n",
    "xx_nl, yy_nl: grid coordinates, Z_nl: predicted \n",
    "classes \n",
    "for each grid point\n",
    ": makes the background semi-transparent so we can see the data points\n",
    ": color map (Red-Yellow-Blue) to distinguish the two \n",
    "classesplt.contourf(xx_nl, yy_nl, Z_nl, alpha=0.3, cmap='RdYlBu')\n",
    "scatter1 = plt.scatter(X_nl_test_scaled[:, 0], X_nl_test_scaled[:, 1],\n",
    "c=y_nl_test, cmap='RdYlBu', edgecolors='black', s=50)\n",
    "plt.colorbar(scatter1, label='Class', ax=plt.gca())\n",
    "plt.xlabel('Feature 1 (Scaled)', fontsize=11)\n",
    "plt.ylabel('Feature 2 (Scaled)', fontsize=11)\n",
    "plt.title(f'Logistic Regression Decision Boundary\\nAccuracy: {nl_test_accuracy:.2%} (Poor)', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "Plot 2: Original data (not scaled, to show the circular pattern)\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter2 = plt.scatter(X_nonlinear[:, 0], X_nonlinear[:, 1], c=y_nonlinear, \n",
    "cmap='RdYlBu', edgecolors='black', s=30, alpha=0.7)\n",
    "plt.colorbar(scatter2, label='Class', ax=plt.gca()) \n",
    "Add colorbar \n",
    "for consistency\n",
    "plt.xlabel('Feature 1', fontsize=11)\n",
    "plt.ylabel('Feature 2', fontsize=11)\n",
    "plt.title('Original Non-Linear Data\\n(Two Concentric Circles)', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_regression_dead_end.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nâœ“ Plot saved as 'logistic_regression_dead_end.png'\")\n",
    "if 'plt' in globals():\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ’¡ What You Should See | Ù…Ø§ ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ø§Ù‡\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” Observation 1: Decision Boundary (Left Plot)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - The decision boundary is a STRAIGHT LINE\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - It tries to cut through the circular data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - It CANNOT properly separate the two circles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Result: Many points are misclassified âŒ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ” Observation 2: Data Pattern (Right Plot)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - The data forms TWO CONCENTRIC CIRCLES\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class 0: Outer circle\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Class 1: Inner circle\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This pattern is INHERENTLY NON-LINEAR\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - A straight line CANNOT separate them properly\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ“š Key Learning Point:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Logistic Regression works GREAT on linear data (Wisconsin: {test_accuracy:.2%}) âœ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Logistic Regression struggles on non-linear data (Circular: {nl_test_accuracy:.2%}) âš ï¸\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - This shows the LIMITATION: Logistic Regression can't handle non-linear boundaries well\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - BUT: Our REAL credit card fraud dataset works EXCELLENTLY (Precision: ~82%, F1: ~87%)! âœ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Key Lesson: Use the RIGHT algorithm for the RIGHT dataset!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - When you see poor accuracy ({nl_test_accuracy:.2%}) with good data, check\")\n",
    "\n",
    "\n",
    "\n",
    "if boundaries are non-linear\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Solution: Decision Trees\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Decision Trees can create COMPLEX, NON-LINEAR boundaries\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - They can handle circular, curved, and XOR patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Next notebook will show Decision Trees solving this exact problem!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Expected improvement: From {nl_test_accuracy:.2%} to ~85-90% accuracy! ğŸ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ Common Student Questions About Limitations | Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø­ÙˆÙ„ Ø§Ù„Ù‚ÙŠÙˆØ¯\n",
    "\n",
    "**Important Reminder**: Our credit card fraud dataset works EXCELLENTLY with Logistic Regression! This section is just showing when it doesn't work (synthetic non-linear data).\n",
    "\n",
    "**Note**: For comprehensive guidance on when to use Logistic Regression, see **Step 11: Decision Framework** above.\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Common Student Questions | Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„Ù„Ø·Ù„Ø§Ø¨\n",
    "\n",
    "**Q1: Why can't we just use polynomial features with Logistic Regression?**\n",
    "- **Answer**: You CAN use polynomial features, but they have limitations:\n",
    "  - Polynomial features create MANY new features (combinatorial explosion)\n",
    "  - Example: 10 features â†’ 100+ polynomial features â†’ slow and overfitting risk\n",
    "  - Decision Trees handle non-linearity naturally without creating many features\n",
    "  - **When to use polynomial features**: Slightly non-linear data, few features (< 5)\n",
    "  - **When to use Decision Trees**: Highly non-linear data, many features, complex patterns\n",
    "\n",
    "**Q2: What if my data is only slightly non-linear?**\n",
    "- **Answer**: Try these in order:\n",
    "  1. **First**: Try Logistic Regression with polynomial features (degree=2 or 3)\n",
    "  2. **If that doesn't help**: Use Decision Trees (they handle any level of non-linearity)\n",
    "  3. **If you need interpretability**: Decision Trees are more interpretable than polynomial features\n",
    "\n",
    "**Q3: Why Decision Trees next, and not SVM or Random Forest?**\n",
    "- **Answer**: Decision Trees are the **simplest** non-linear classifier:\n",
    "  - **Decision Trees**: Easy to understand, interpretable, handles non-linear naturally\n",
    "  - **SVM**: More complex, requires kernel selection, less interpretable\n",
    "  - **Random Forest**: Built on Decision Trees (you need to learn trees first!)\n",
    "  - **Learning order**: Start simple (Decision Trees) â†’ then advanced (SVM, Random Forest)\n",
    "\n",
    "**Q4: How do I know BEFORE training if my data is non-linear?**\n",
    "- **Answer**: Check these BEFORE training:\n",
    "  1. **Visualize**: Plot features in 2D/3D - do you see curves/circles?\n",
    "  2. **Domain knowledge**: Does your problem naturally have non-linear relationships?\n",
    "  3. **Correlation**: Check if features have non-linear correlations (scatter plots)\n",
    "  4. **Try both**: Train Logistic Regression first - if accuracy is poor, likely non-linear\n",
    "\n",
    "**Q5: What if I have many features and can't visualize?**\n",
    "- **Answer**: Use these techniques:\n",
    "  1. **PCA**: Reduce to 2-3 dimensions, then visualize\n",
    "  2. **Pair plots**: Plot pairs of important features\n",
    "  3. **Train and check**: If Logistic Regression accuracy is poor â†’ likely non-linear\n",
    "  4. **Feature importance**: Use Decision Trees to see which features matter (works for any data)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Transition to Next Notebook | Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø¯ÙØªØ± Ø§Ù„ØªØ§Ù„ÙŠ\n",
    "\n",
    "**What We Learned:**\n",
    "- âœ… Logistic Regression works excellently on linear data (Wisconsin: 98.25%)\n",
    "- âš ï¸ Logistic Regression struggles on non-linear data (Circular: typically 40-70%, our example: 42.00%)\n",
    "- ğŸ” This shows the **LIMITATION** of Logistic Regression on non-linear data\n",
    "- âœ… **BUT**: Our REAL credit card fraud dataset works EXCELLENTLY because it has linear relationships!\n",
    "\n",
    "**The Problem:**\n",
    "- We need to classify data with **non-linear boundaries**\n",
    "- Logistic Regression can't handle this\n",
    "- We need an algorithm that can create **non-linear decision boundaries**\n",
    "\n",
    "**Next Notebook: Decision Trees**\n",
    "- ğŸ““ **Example 2: Decision Trees** will solve this exact problem!\n",
    "- Decision Trees can create **complex, non-linear boundaries**\n",
    "- They can handle circular, curved, and XOR patterns\n",
    "- Expected: Accuracy improves from ~42% (current) to **85-90%**! âœ…\n",
    "\n",
    "**Why Decision Trees?**\n",
    "- **Simple to understand**: Visual tree structure (easier than SVM kernels)\n",
    "- **Handles non-linear naturally**: No need for polynomial features\n",
    "- **Interpretable**: You can see exactly how decisions are made\n",
    "- **Foundation for advanced methods**: Random Forest and XGBoost build on trees\n",
    "- **Perfect next step**: After linear models (Logistic Regression), learn non-linear models (Decision Trees)\n",
    "\n",
    "**This limitation leads us to Decision Trees - they can handle non-linear boundaries!**\n",
    "\n",
    "**Key Reminder**: Our credit card fraud dataset works EXCELLENTLY with Logistic Regression because it has linear relationships. We'll use Decision Trees for datasets with non-linear patterns!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T11:14:52.648338Z",
     "iopub.status.busy": "2025-12-26T11:14:52.648269Z",
     "iopub.status.idle": "2025-12-26T11:14:52.650307Z",
     "shell.execute_reply": "2025-12-26T11:14:52.650107Z"
    }
   },
   "outputs": [],
   "source": [
    "Save the non-linear dataset \n",
    "for use in the next notebook\n",
    "This ensures the next notebook uses the EXACT same problem!\n",
    "\n",
    "Store dataset info \n",
    "for reference\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ“¦ Dataset Saved for Next Notebook\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ØªÙ… Ø­ÙØ¸ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¯ÙØªØ± Ø§Ù„ØªØ§Ù„ÙŠ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Non-linear dataset prepared for next notebook:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - X_nonlinear: Circular pattern (two concentric circles)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - y_nonlinear: Binary classification labels\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Current Logistic Regression accuracy: {nl_test_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" - Expected Decision Trees accuracy: 85-90%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ”— Next Notebook Will:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" 1. Use this SAME non-linear dataset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" 2. Show Decision Trees solving the problem Logistic Regression failed on\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" 3. Demonstrate clear improvement in accuracy\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\" 4. Show non-linear decision boundaries successfully separating the circles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Example 1 Complete! âœ“\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ 1! âœ“\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nğŸ¯ Next Step: Open Example 2 (Decision Trees) to see how it solves this problem!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø§ÙØªØ­ Ø§Ù„Ù…Ø«Ø§Ù„ 2 (Ø£Ø´Ø¬Ø§Ø± Ø§Ù„Ù‚Ø±Ø§Ø±) Ù„ØªØ±Ù‰ ÙƒÙŠÙ ÙŠØ­Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}