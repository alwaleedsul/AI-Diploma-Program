{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data Loading and Exploration | \u062a\u062d\u0645\u064a\u0644 \u0648\u0627\u0633\u062a\u0643\u0634\u0627\u0641 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\n",
    "\n",
    "## \ud83d\udcda Prerequisites (What You Need First) | \u0627\u0644\u0645\u062a\u0637\u0644\u0628\u0627\u062a \u0627\u0644\u0623\u0633\u0627\u0633\u064a\u0629\n",
    "\n",
    "**BEFORE starting this notebook**, you should have:\n",
    "- \u2705 **Python 3.8+ installed** and working\n",
    "- \u2705 **Basic Python knowledge**: Variables, data types, lists, dictionaries\n",
    "- \u2705 **Libraries installed**: pandas, numpy, matplotlib, seaborn (see `requirements.txt`)\n",
    "- \u2705 **Understanding of data**: What is a dataset? What are rows and columns?\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding DataFrame operations\n",
    "- Understanding data types and structures\n",
    "- Using pandas functions\n",
    "- Interpreting statistical summaries\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udd17 Where This Notebook Fits | \u0645\u0643\u0627\u0646 \u0647\u0630\u0627 \u0627\u0644\u062f\u0641\u062a\u0631\n",
    "\n",
    "**This is the FIRST example** - it's the foundation for all data science!\n",
    "\n",
    "**Why this example FIRST?**\n",
    "- **Before** you can build ML models, you need to understand your data\n",
    "- **Before** you can clean data, you need to load and explore it\n",
    "- **Before** you can make predictions, you need to know what you're working with\n",
    "\n",
    "**Builds on**: \n",
    "- Python basics (variables, data structures)\n",
    "- Basic understanding of data files (CSV format)\n",
    "\n",
    "**Leads to**: \n",
    "- \ud83d\udcd3 Example 2: Data Cleaning (needs data exploration skills)\n",
    "- \ud83d\udcd3 Example 3: Data Preprocessing (needs data understanding)\n",
    "- \ud83d\udcd3 Example 4: Linear Regression (needs clean, explored data)\n",
    "- \ud83d\udcd3 All other ML examples (all need data exploration first!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Data exploration teaches you **what you're working with** (needed for all ML)\n",
    "2. Data exploration shows you **data quality issues** (needed for cleaning)\n",
    "3. Data exploration helps you **understand relationships** (needed for modeling)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Getting to Know Your Data | \u0627\u0644\u0642\u0635\u0629: \u0627\u0644\u062a\u0639\u0631\u0641 \u0639\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a\u0643\n",
    "\n",
    "Imagine you're a detective investigating a case. **Before** you can solve it, you need to examine all the evidence - look at it, understand what it means, check if anything is missing, and see how pieces connect. **After** exploring the evidence thoroughly, you can start building your case!\n",
    "\n",
    "Same with machine learning: **Before** building models, we explore our data - load it, examine its structure, check for problems, understand relationships. **After** thorough exploration, we can build accurate models!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Data Exploration Matters | \u0644\u0645\u0627\u0630\u0627 \u064a\u0647\u0645 \u0627\u0633\u062a\u0643\u0634\u0627\u0641 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\u061f\n",
    "\n",
    "Data exploration is the foundation of data science:\n",
    "- **Find Problems Early**: Missing values, duplicates, outliers\n",
    "- **Understand Structure**: What columns mean, what data types we have\n",
    "- **Discover Patterns**: Relationships between variables\n",
    "- **Make Informed Decisions**: Know what preprocessing is needed\n",
    "- **Save Time Later**: Catch issues before they break your models\n",
    "\n",
    "## Learning Objectives | \u0623\u0647\u062f\u0627\u0641 \u0627\u0644\u062a\u0639\u0644\u0645\n",
    "1. Load data from CSV files using pandas\n",
    "2. Inspect data structure (shape, types, columns)\n",
    "3. Calculate basic statistics (mean, median, std)\n",
    "4. Identify missing values and duplicates\n",
    "5. Analyze categorical and numerical data\n",
    "6. Understand data quality before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us work with data and create visualizations\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis (DataFrames, reading CSV)\n",
    "import numpy as np   # For numerical operations (arrays, math functions)\n",
    "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
    "import seaborn as sns  # For statistical visualizations (beautiful plots)\n",
    "from sklearn.datasets import fetch_california_housing  # Real-world housing dataset\n",
    "\n",
    "print(\"\u2705 Libraries imported successfully!\")\n",
    "print(\"\\n\ud83d\udcda What each library does:\")\n",
    "print(\"   - pandas: Load, manipulate, and analyze data (our main tool!)\")\n",
    "print(\"   - numpy: Fast numerical computations (arrays, math)\")\n",
    "print(\"   - matplotlib: Create basic plots and charts\")\n",
    "print(\"   - seaborn: Create beautiful statistical visualizations\")\n",
    "print(\"   - sklearn.datasets: Access real-world datasets for learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Scene | \u0627\u0644\u062c\u0632\u0621 \u0627\u0644\u0623\u0648\u0644: \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0645\u0634\u0647\u062f\n",
    "\n",
    "**BEFORE**: We have raw data files (CSV) that we know nothing about.\n",
    "\n",
    "**AFTER**: We'll load the data, explore its structure, understand its quality, and be ready for the next steps (cleaning and modeling)!\n",
    "\n",
    "**Why this matters**: You can't build good models on bad data. Exploration helps us find and fix problems early!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Data Loading and Exploration\")\n",
    "print(\"\u0645\u062b\u0627\u0644 1: \u062a\u062d\u0645\u064a\u0644 \u0648\u0627\u0633\u062a\u0643\u0634\u0627\u0641 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading Data from CSV | \u0627\u0644\u062e\u0637\u0648\u0629 1: \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0646 \u0645\u0644\u0641 CSV\n",
    "\n",
    "**BEFORE**: We have a CSV file but can't use it in Python.\n",
    "\n",
    "**AFTER**: We'll load it into a pandas DataFrame (a table-like structure) that we can work with!\n",
    "\n",
    "**Why CSV?** CSV (Comma-Separated Values) is the most common data format. Almost every dataset comes as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real-world California Housing dataset\n",
    "# This is REAL data from the 1990 California census about housing prices\n",
    "# Source: sklearn.datasets.fetch_california_housing\n",
    "\n",
    "# fetch_california_housing()\n",
    "# - Fetches the California housing dataset (real-world data!)\n",
    "# - Returns a Bunch object with 'data' (features), 'target' (prices), and 'feature_names'\n",
    "# - This dataset has 20,640 samples of California housing districts\n",
    "# - Features: MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
    "# - Target: Median house value (in hundreds of thousands of dollars)\n",
    "\n",
    "print(\"\ud83d\udce5 Loading California Housing dataset...\")\n",
    "housing_data = fetch_california_housing()\n",
    "\n",
    "# Create DataFrame from the real data\n",
    "# pd.DataFrame(data, columns=feature_names)\n",
    "# - pd.DataFrame(): Creates a pandas DataFrame (2D table-like structure)\n",
    "# - data: The feature data (housing_data.data)\n",
    "# - columns: Column names (housing_data.feature_names)\n",
    "# - Returns DataFrame with real housing data\n",
    "\n",
    "df = pd.DataFrame(housing_data.data, columns=housing_data.feature_names)\n",
    "\n",
    "# Add the target (median house value) as a column\n",
    "# housing_data.target: Median house values (what we might want to predict later)\n",
    "df['MedHouseVal'] = housing_data.target\n",
    "\n",
    "print(\"\\n\u2705 Real-world California Housing data loaded!\")\n",
    "print(\"   \ud83d\udcca This is REAL data from the 1990 California census\")\n",
    "print(f\"   \ud83d\udcc8 Contains {len(df)} housing districts with {len(df.columns)} features\")\n",
    "print(f\"   \ud83c\udfe0 Features: {', '.join(housing_data.feature_names[:4])}... and more\")\n",
    "print(\"   \ud83d\udcb0 Target: MedHouseVal (median house value in $100,000s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for demonstration (optional - you can also work with the DataFrame directly)\n",
    "\n",
    "# df.to_csv('sample_housing_data.csv', index=False)\n",
    "# - df.to_csv(): Saves DataFrame to CSV file\n",
    "# - 'sample_housing_data.csv': File name/path to save\n",
    "# - index=False: Don't save row index to file (keeps CSV clean)\n",
    "#   - If index=True, first column would be row numbers (0, 1, 2, ...)\n",
    "# - CSV = Comma-Separated Values (standard data format)\n",
    "# Result: Creates CSV file with DataFrame data\n",
    "\n",
    "# In this example, we'll work directly with the DataFrame (df)\n",
    "# But saving to CSV is useful for sharing data or working with it later\n",
    "# df.to_csv('california_housing.csv', index=False)  # Uncomment to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In this example, we already have our data in df (loaded from sklearn)",
    "# But in real projects, you often load data from CSV files like this:",
    "",
    "# pd.read_csv('filename.csv')",
    "# - pd.read_csv(): Reads CSV file and creates DataFrame",
    "# - 'filename.csv': File path/name to read",
    "# - Automatically detects: column names from first row, data types, separator",
    "# - Returns DataFrame with data from CSV",
    "# - Common parameters: sep=',', header=0, index_col=None",
    "",
    "# pd.read_csv() is the most common way to load data",
    "# Why read_csv? CSV is the standard format for data science!",
    "",
    "# Example (if you saved the data earlier):",
    "# df = pd.read_csv('california_housing.csv')",
    "# - Automatically detects:",
    "#   - Column names from first row",
    "#   - Data types (int, float, string)",
    "#   - Separator (comma by default)",
    "",
    "# Let's inspect our current DataFrame (already loaded from sklearn)",
    "",
    "# len(df)",
    "# - Returns number of rows in DataFrame",
    "# - len(): Python built-in function, works on any sequence",
    "",
    "# len(df.columns)",
    "# - df.columns: Returns Index object with column names",
    "# - len(): Counts number of columns",
    "",
    "# ', '.join(df.columns)",
    "# - df.columns: Column names",
    "# - ', '.join(): Joins items with comma and space",
    "# - Converts column names list to readable string",
    "",
    "print(\"\\n\u2705 Data loaded successfully!\")",
    "print(\"\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0628\u0646\u062c\u0627\u062d!\")",
    "print(f\"\\n\ud83d\udccb Dataset Overview:\")",
    "print(f\"   - Source: California Housing (1990 Census) - REAL DATA\")",
    "print(f\"   - Rows: {len(df):,} housing districts\")",
    "print(f\"   - Columns: {len(df.columns)} features\")",
    "print(f\"   - Column names: {', '.join(df.columns[:5])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic Data Inspection | \u0627\u0644\u062e\u0637\u0648\u0629 2: \u0627\u0644\u0641\u062d\u0635 \u0627\u0644\u0623\u0633\u0627\u0633\u064a \u0644\u0644\u0628\u064a\u0627\u0646\u0627\u062a\n",
    "\n",
    "**BEFORE**: We loaded data but don't know what's inside.\n",
    "\n",
    "**AFTER**: We'll see the first/last rows, understand the structure, and know what we're working with!\n",
    "\n",
    "**Why inspect first?** You need to see your data before you can work with it. It's like opening a box before using what's inside!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows using .head()",
    "# Why .head()? It shows you a sample of your data without printing everything",
    "# Default shows 5 rows, but you can specify: .head(10) for 10 rows",
    "",
    "# df.head(7)",
    "# - df.head(n): Returns first n rows of DataFrame",
    "# - Default: .head() shows first 5 rows",
    "# - .head(7): Shows first 7 rows",
    "# - Returns DataFrame (not Series)",
    "# - Useful for quick data inspection without printing entire dataset",
    "# - Opposite: .tail() shows last rows",
    "print(\"\\n\ud83d\udcc4 First 5 rows / \u0627\u0644\u0635\u0641\u0648\u0641 \u0627\u0644\u062e\u0645\u0633\u0629 \u0627\u0644\u0623\u0648\u0644\u0649:\")",
    "print(\"   (This gives us a quick look at what the data looks like)\")",
    "print(df.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows",
    "",
    "# df.tail()",
    "# - df.tail(n): Returns last n rows of DataFrame",
    "# - Default: .tail() shows last 5 rows",
    "# - .tail(10): Shows last 10 rows",
    "# - Returns DataFrame",
    "# - Useful for checking end of dataset",
    "# - Opposite: .head() shows first rows",
    "print(\"\\nLast 5 rows / \u0627\u0644\u0635\u0641\u0648\u0641 \u0627\u0644\u062e\u0645\u0633\u0629 \u0627\u0644\u0623\u062e\u064a\u0631\u0629:\")",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape (rows, columns)",
    "# .shape tells us the dimensions: (number_of_rows, number_of_columns)",
    "# Why check shape? It tells us how much data we have - important for understanding dataset size!",
    "",
    "# df.shape",
    "# - Returns tuple: (number_of_rows, number_of_columns)",
    "# - shape[0]: Number of rows (first element)",
    "# - shape[1]: Number of columns (second element)",
    "# - Example: (10, 5) means 10 rows and 5 columns",
    "# - Useful for understanding dataset size before processing",
    "print(\"\\n\ud83d\udcd0 Data Shape / \u0634\u0643\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a (\u0635\u0641\u0648\u0641\u060c \u0623\u0639\u0645\u062f\u0629):\")",
    "print(f\"   Rows: {df.shape[0]} (number of houses)\")",
    "print(f\"   Columns: {df.shape[1]} (number of features)\")",
    "print(f\"   \u0627\u0644\u0635\u0641\u0648\u0641: {df.shape[0]}, \u0627\u0644\u0623\u0639\u0645\u062f\u0629: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical summary for all numerical columns",
    "# .describe() gives us: count, mean, std, min, 25%, 50% (median), 75%, max",
    "# Why .describe()? It's a quick way to see all important statistics at once!",
    "",
    "# df.describe()",
    "# - Returns DataFrame with statistical summary for numeric columns",
    "# - Statistics included:",
    "#   - count: Number of non-null values",
    "#   - mean: Average value",
    "#   - std: Standard deviation (spread of data)",
    "#   - min: Minimum value",
    "#   - 25%: 25th percentile (Q1)",
    "#   - 50%: 50th percentile (median)",
    "#   - 75%: 75th percentile (Q3)",
    "#   - max: Maximum value",
    "# - Only shows numeric columns (int64, float64)",
    "# - Skips text/object columns",
    "print(\"\\n\ud83d\udcca Statistical Summary / \u0627\u0644\u0645\u0644\u062e\u0635 \u0627\u0644\u0625\u062d\u0635\u0627\u0626\u064a:\")",
    "print(\"   (This shows mean, median, std, min, max for all numerical columns)\")",
    "print(df.describe())",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types for each column",
    "# .dtypes shows what type of data each column contains",
    "# Why check types? Different types need different handling:",
    "#   - int64/float64: Numbers (can do math)",
    "#   - object: Text/categories (need encoding for ML)",
    "",
    "# df.dtypes",
    "# - Returns Series showing data type of each column",
    "# - Common types:",
    "#   - int64: Integer numbers (whole numbers)",
    "#   - float64: Decimal numbers (floating point)",
    "#   - object: Text/strings (pandas uses 'object' for strings)",
    "#   - bool: Boolean (True/False)",
    "#   - datetime64: Date/time values",
    "# - Important: ML algorithms need numeric types, text needs encoding",
    "print(\"\\n\ud83d\udd22 Data Types / \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a:\")",
    "print(\"   (Understanding types helps us know how to process each column)\")",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values",
    "# .isnull() returns True for missing values, False otherwise",
    "# .sum() counts how many True values (missing values) in each column",
    "# Why check missing values? ML models can't work with missing data - we need to handle them!",
    "",
    "# df.isnull().sum()",
    "# - df.isnull(): Returns DataFrame with True/False",
    "#   - True = missing value (NaN/None)",
    "#   - False = value exists",
    "#   - Alternative: df.isna() does the same thing",
    "# - .sum(): Counts True values for each column",
    "#   - Sums True (1) and False (0) for each column",
    "#   - Returns Series with column names and count of missing values",
    "# - Result: Shows how many missing values in each column",
    "missing_values = df.isnull().sum()",
    "",
    "# missing_values.sum()",
    "# - .sum() on Series: Adds up all values",
    "# - Gives total missing values across all columns",
    "total_missing = missing_values.sum()",
    "",
    "print(\"\\n\ud83d\udd0d Missing Values Check / \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629:\")",
    "print(\"   (Shows how many missing values in each column)\")",
    "print(missing_values)",
    "",
    "if total_missing == 0:",
    "    print(\"\\n   \u2705 No missing values found! Data is complete.\")",
    "    print(\"   \u2705 \u0644\u0627 \u062a\u0648\u062c\u062f \u0642\u064a\u0645 \u0645\u0641\u0642\u0648\u062f\u0629! \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0643\u0627\u0645\u0644\u0629.\")",
    "else:",
    "    print(f\"\\n   \u26a0\ufe0f  Found {total_missing} missing value(s) total\")",
    "    print(f\"   \u26a0\ufe0f  \u062a\u0645 \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 {total_missing} \u0642\u064a\u0645\u0629 \u0645\u0641\u0642\u0648\u062f\u0629\")",
    "    print(\"   \ud83d\udca1 We'll learn how to handle these in Example 2: Data Cleaning\")",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data information",
    "# .info() gives us a summary: data types, non-null counts, memory usage",
    "# Why .info()? It's a quick health check - shows if we have missing values!",
    "",
    "# df.info()",
    "# - Prints comprehensive summary of DataFrame",
    "# - Shows:",
    "#   - Number of rows and columns",
    "#   - Column names and data types",
    "#   - Non-null counts (how many non-missing values per column)",
    "#   - Memory usage",
    "# - Useful for quick data quality check",
    "# - Returns None (prints to console, doesn't return DataFrame)",
    "print(\"\\n\u2139\ufe0f  Data Info / \u0645\u0639\u0644\u0648\u0645\u0627\u062a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a:\")",
    "print(\"   (This shows us data types AND if there are missing values)\")",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows",
    "# .duplicated() returns True for duplicate rows (rows that appear more than once)",
    "# .sum() counts how many duplicate rows we have",
    "# Why check duplicates? Duplicates can bias our models - same data counted twice!",
    "",
    "duplicate_count = df.duplicated().sum()",
    "",
    "print(\"\\n\ud83d\udd0d Duplicate Rows Check / \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0644\u0635\u0641\u0648\u0641 \u0627\u0644\u0645\u0643\u0631\u0631\u0629:\")",
    "print(f\"   Number of duplicate rows: {duplicate_count}\")",
    "",
    "if duplicate_count == 0:",
    "    print(\"\\n   \u2705 No duplicate rows found! Each row is unique.\")",
    "    print(\"   \u2705 \u0644\u0627 \u062a\u0648\u062c\u062f \u0635\u0641\u0648\u0641 \u0645\u0643\u0631\u0631\u0629! \u0643\u0644 \u0635\u0641 \u0641\u0631\u064a\u062f.\")",
    "else:",
    "    print(f\"\\n   \u26a0\ufe0f  Found {duplicate_count} duplicate row(s)\")",
    "    print(f\"   \u26a0\ufe0f  \u062a\u0645 \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 {duplicate_count} \u0635\u0641 \u0645\u0643\u0631\u0631\")",
    "    print(\"   \ud83d\udca1 We'll learn how to remove these in Example 2: Data Cleaning\")",
    "    ",
    "    # Show duplicate rows if they exist",
    "    print(\"\\n   Duplicate rows:\")",
    "    print(df[df.duplicated()])",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Statistical Summary | \u0627\u0644\u062e\u0637\u0648\u0629 3: \u0627\u0644\u0645\u0644\u062e\u0635 \u0627\u0644\u0625\u062d\u0635\u0627\u0626\u064a\n",
    "\n",
    "**BEFORE**: We see individual rows but don't understand the overall patterns.\n",
    "\n",
    "**AFTER**: We'll calculate statistics (mean, median, std) to understand the distribution of our data!\n",
    "\n",
    "**Why statistics?** They summarize your data in numbers:\n",
    "- **Mean**: Average value\n",
    "- **Median**: Middle value (less affected by outliers)\n",
    "- **Std**: How spread out the data is\n",
    "- **Min/Max**: Range of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check for Missing Values | \u0627\u0644\u062e\u0637\u0648\u0629 4: \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629\n",
    "\n",
    "**BEFORE**: We don't know if our data has gaps or missing information.\n",
    "\n",
    "**AFTER**: We'll identify any missing values that could cause problems in our models!\n",
    "\n",
    "**Why check for missing values?** \n",
    "- ML models can't work with missing data\n",
    "- Missing values indicate data quality issues\n",
    "- We need to handle them before modeling (fill, drop, or impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical data (location column)",
    "# .value_counts() counts how many times each category appears",
    "# Why analyze categorical data? Shows if categories are balanced or imbalanced!",
    "",
    "print(\"\\n\ud83d\udcca Categorical Data Analysis / \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0641\u0626\u0648\u064a\u0629:\")",
    "print(\"   Location distribution / \u062a\u0648\u0632\u064a\u0639 \u0627\u0644\u0645\u0648\u0642\u0639:\")",
    "",
    "location_counts = df['location'].value_counts()",
    "print(location_counts)",
    "",
    "print(\"\\n   Interpretation:\")",
    "print(f\"   - Total locations: {len(location_counts)}\")",
    "print(f\"   - Most common: {location_counts.index[0]} (appears {location_counts.iloc[0]} times)\")",
    "print(f\"   - Least common: {location_counts.index[-1]} (appears {location_counts.iloc[-1]} times)\")",
    "",
    "# Check if balanced",
    "if location_counts.max() - location_counts.min() <= 1:",
    "    print(\"\\n   \u2705 Categories are balanced (similar counts)\")",
    "    print(\"   \u2705 \u0627\u0644\u0641\u0626\u0627\u062a \u0645\u062a\u0648\u0627\u0632\u0646\u0629 (\u0623\u0639\u062f\u0627\u062f \u0645\u062a\u0634\u0627\u0628\u0647\u0629)\")",
    "else:",
    "    print(\"\\n   \u26a0\ufe0f  Categories are imbalanced (very different counts)\")",
    "    print(\"   \u26a0\ufe0f  \u0627\u0644\u0641\u0626\u0627\u062a \u063a\u064a\u0631 \u0645\u062a\u0648\u0627\u0632\u0646\u0629 (\u0623\u0639\u062f\u0627\u062f \u0645\u062e\u062a\u0644\u0641\u0629)\")",
    "    print(\"   \ud83d\udca1 Imbalanced categories might need special handling in ML models\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check for Duplicates | \u0627\u0644\u062e\u0637\u0648\u0629 5: \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0644\u062a\u0643\u0631\u0627\u0631\u0627\u062a\n",
    "\n",
    "**BEFORE**: We might have the same row appearing multiple times.\n",
    "\n",
    "**AFTER**: We'll identify duplicate rows that could skew our analysis!\n",
    "\n",
    "**Why check for duplicates?**\n",
    "- Duplicates can bias our models (same data counted twice)\n",
    "- They waste computational resources\n",
    "- They indicate data collection issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for a specific column (price)# Why focus on price? It's our target variable - we want to predict it!# Understanding its distribution helps us choose the right modelprint(\"\\n\" + \"=\" * 60)print(\"6. Column-specific Statistics\")print(\"\u0627\u0644\u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062e\u0627\u0635\u0629 \u0628\u0627\u0644\u0623\u0639\u0645\u062f\u0629\")print(\"=\" * 60)print(\"\\n\ud83d\udcb0 Price statistics / \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u0633\u0639\u0631:\")print(\"   (Understanding price distribution helps us build better models)\")print(f\"   Mean (Average): ${df['MedHouseVal'].mean():,.2f}\")print(f\"   Median (Middle): ${df['MedHouseVal'].median():,.2f}\")print(f\"   Standard Deviation (Spread): ${df['MedHouseVal'].std():,.2f}\")print(f\"   Min (Lowest): ${df['MedHouseVal'].min():,.2f}\")print(f\"   Max (Highest): ${df['MedHouseVal'].max():,.2f}\")# Why median vs mean? Median is less affected by outliers!if abs(df['MedHouseVal'].mean() - df['MedHouseVal'].median()) > df['MedHouseVal'].std():    print(\"\\n   \u26a0\ufe0f  Mean and median are very different - possible outliers!\")else:    print(\"\\n   \u2705 Mean and median are close - data looks balanced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Data Quality Assessment \u2192 Modeling Readiness | \u0627\u0644\u062e\u0637\u0648\u0629 8: \u062a\u0642\u064a\u064a\u0645 \u062c\u0648\u062f\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u2192 \u062c\u0627\u0647\u0632\u064a\u0629 \u0627\u0644\u0646\u0645\u0630\u062c\u0629\n",
    "\n",
    "**BEFORE**: We've explored the data and found issues, but don't know if it's ready for modeling.\n",
    "\n",
    "**AFTER**: You'll have a clear framework to assess data quality and determine if your data is ready for machine learning!\n",
    "\n",
    "**Why this matters**: Building models on poor-quality data leads to:\n",
    "- **Unreliable predictions** \u2192 Models learn from bad patterns\n",
    "- **Wasted time** \u2192 Models fail or perform poorly\n",
    "- **Wrong conclusions** \u2192 Decisions based on flawed data\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfaf Decision Framework: Is Your Data Ready for Modeling? | \u0625\u0637\u0627\u0631 \u0627\u0644\u0642\u0631\u0627\u0631: \u0647\u0644 \u0628\u064a\u0627\u0646\u0627\u062a\u0643 \u062c\u0627\u0647\u0632\u0629 \u0644\u0644\u0646\u0645\u0630\u062c\u0629\u061f\n",
    "\n",
    "**Key Question**: Can I build a machine learning model with this data, or do I need to clean/preprocess first?\n",
    "\n",
    "#### Decision Tree:\n",
    "\n",
    "```\n",
    "Have you completed data exploration?\n",
    "\u251c\u2500 NO \u2192 EXPLORE FIRST (this notebook!)\n",
    "\u2502   \u2514\u2500 Why? You can't assess quality without exploring\n",
    "\u2502\n",
    "\u2514\u2500 YES \u2192 Check data quality issues:\n",
    "    \u251c\u2500 Missing values > 10%? \u2192 NEEDS CLEANING (Example 2)\n",
    "    \u2502   \u2514\u2500 Why? Too much missing data breaks models\n",
    "    \u2502\n",
    "    \u251c\u2500 Duplicates > 5%? \u2192 NEEDS CLEANING (Example 2)\n",
    "    \u2502   \u2514\u2500 Why? Duplicates bias models (same data counted twice)\n",
    "    \u2502\n",
    "    \u251c\u2500 Outliers that are clearly errors? \u2192 NEEDS CLEANING (Example 2)\n",
    "    \u2502   \u2514\u2500 Why? Errors skew models (e.g., age = 200)\n",
    "    \u2502\n",
    "    \u251c\u2500 Wrong data types? \u2192 NEEDS CLEANING (Example 2)\n",
    "    \u2502   \u2514\u2500 Why? Can't calculate on text (e.g., \"25\" instead of 25)\n",
    "    \u2502\n",
    "    \u251c\u2500 Features on different scales? \u2192 NEEDS PREPROCESSING (Example 3)\n",
    "    \u2502   \u2514\u2500 Why? Algorithms biased toward larger numbers\n",
    "    \u2502\n",
    "    \u251c\u2500 Categorical features not encoded? \u2192 NEEDS PREPROCESSING (Example 3)\n",
    "    \u2502   \u2514\u2500 Why? ML algorithms need numbers, not text\n",
    "    \u2502\n",
    "    \u2514\u2500 All checks passed? \u2192 READY FOR MODELING! \u2705\n",
    "        \u2514\u2500 Why? Data is clean, preprocessed, and ready\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca Data Quality Checklist | \u0642\u0627\u0626\u0645\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u062c\u0648\u062f\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\n",
    "\n",
    "Use this checklist to assess your data:\n",
    "\n",
    "| Quality Aspect | Good | Warning | Critical | Action Needed |\n",
    "|----------------|------|---------|---------|---------------|\n",
    "| **Missing Values** | < 5% | 5-10% | > 10% | Clean (Example 2) |\n",
    "| **Duplicates** | < 1% | 1-5% | > 5% | Remove (Example 2) |\n",
    "| **Outliers (Errors)** | None | Few | Many | Remove (Example 2) |\n",
    "| **Data Types** | Correct | Some issues | Many issues | Fix (Example 2) |\n",
    "| **Feature Scaling** | Similar scales | Different scales | Very different | Preprocess (Example 3) |\n",
    "| **Categorical Encoding** | Encoded | Some encoded | Not encoded | Preprocess (Example 3) |\n",
    "| **Sample Size** | > 1000 | 100-1000 | < 100 | May need more data |\n",
    "\n",
    "**Decision Rule**: If ANY aspect is \"Critical\", data is **NOT ready** for modeling. Fix issues first!\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcc8 Modeling Readiness Levels | \u0645\u0633\u062a\u0648\u064a\u0627\u062a \u062c\u0627\u0647\u0632\u064a\u0629 \u0627\u0644\u0646\u0645\u0630\u062c\u0629\n",
    "\n",
    "#### Level 1: Raw Data (Not Ready) \u274c\n",
    "- **Characteristics**: Just loaded from file, no exploration\n",
    "- **Issues**: Unknown data quality, unknown structure\n",
    "- **Action**: Complete this notebook (exploration)\n",
    "\n",
    "#### Level 2: Explored Data (Partially Ready) \u26a0\ufe0f\n",
    "- **Characteristics**: Explored structure, found issues\n",
    "- **Issues**: Missing values, duplicates, outliers, wrong types\n",
    "- **Action**: Complete Example 2 (cleaning)\n",
    "\n",
    "#### Level 3: Clean Data (Mostly Ready) \u26a0\ufe0f\n",
    "- **Characteristics**: Clean, no missing values, correct types\n",
    "- **Issues**: Features not scaled, categories not encoded\n",
    "- **Action**: Complete Example 3 (preprocessing)\n",
    "\n",
    "#### Level 4: Preprocessed Data (Ready!) \u2705\n",
    "- **Characteristics**: Clean, scaled, encoded, split into train/test\n",
    "- **Issues**: None\n",
    "- **Action**: Ready for modeling (Example 4+)\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca Real-World Examples | \u0623\u0645\u062b\u0644\u0629 \u0645\u0646 \u0627\u0644\u0639\u0627\u0644\u0645 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\n",
    "\n",
    "#### Example 1: E-commerce Dataset\n",
    "- **Exploration Findings**: 15% missing prices, 3% duplicates, prices range $10-$10,000\n",
    "- **Quality Assessment**: \u274c NOT READY\n",
    "- **Issues**: Too many missing values, features need scaling\n",
    "- **Action Plan**: \n",
    "  1. Clean missing values (Example 2)\n",
    "  2. Scale prices (Example 3)\n",
    "  3. Then model (Example 4)\n",
    "\n",
    "#### Example 2: Medical Dataset\n",
    "- **Exploration Findings**: 2% missing ages, no duplicates, age range 0-100\n",
    "- **Quality Assessment**: \u26a0\ufe0f PARTIALLY READY\n",
    "- **Issues**: Small missing values (can remove), but need to check other features\n",
    "- **Action Plan**:\n",
    "  1. Remove missing values (Example 2)\n",
    "  2. Check if scaling needed (Example 3)\n",
    "  3. Then model (Example 4)\n",
    "\n",
    "#### Example 3: Customer Dataset\n",
    "- **Exploration Findings**: No missing values, no duplicates, all features scaled, categories encoded\n",
    "- **Quality Assessment**: \u2705 READY\n",
    "- **Issues**: None\n",
    "- **Action Plan**: Ready to build models (Example 4)\n",
    "\n",
    "---\n",
    "\n",
    "### \u2705 Key Takeaways | \u0627\u0644\u0646\u0642\u0627\u0637 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629\n",
    "\n",
    "1. **Always explore first** - You can't assess quality without exploration\n",
    "2. **Check all quality aspects** - Missing values, duplicates, outliers, types, scaling, encoding\n",
    "3. **Use the checklist** - Systematic assessment prevents missing issues\n",
    "4. **Fix critical issues first** - Don't model on bad data\n",
    "5. **Understand readiness levels** - Know where your data stands\n",
    "6. **Document findings** - Write down what you found and what needs fixing\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udf93 Practice Assessment | \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u0642\u064a\u064a\u0645\n",
    "\n",
    "**Scenario**: You've explored a dataset and found:\n",
    "- 8% missing values in \"income\" column\n",
    "- 2% duplicate rows\n",
    "- Age ranges from 18 to 65 (reasonable)\n",
    "- Salary ranges from $30,000 to $200,000\n",
    "- Department column has categories: \"IT\", \"HR\", \"Finance\"\n",
    "\n",
    "**Your task**: Assess data quality and determine modeling readiness!\n",
    "\n",
    "**Answer**:\n",
    "1. **Missing values (8%)**: \u26a0\ufe0f WARNING - Should clean (Example 2)\n",
    "2. **Duplicates (2%)**: \u2705 GOOD - Can remove (Example 2)\n",
    "3. **Age range**: \u2705 GOOD - Reasonable range\n",
    "4. **Salary range**: \u26a0\ufe0f WARNING - Different scale from age, needs scaling (Example 3)\n",
    "5. **Department**: \u26a0\ufe0f WARNING - Categorical, needs encoding (Example 3)\n",
    "6. **Overall Assessment**: \u26a0\ufe0f PARTIALLY READY\n",
    "7. **Action Plan**: \n",
    "   - Clean missing values and duplicates (Example 2)\n",
    "   - Scale salary and encode department (Example 3)\n",
    "   - Then ready for modeling (Example 4)\n",
    "\n",
    "---\n",
    "\n",
    "**Connection to Next Steps**: \n",
    "- \ud83d\udcd3 **Example 2: Data Cleaning** - Fixes the quality issues we found\n",
    "- \ud83d\udcd3 **Example 3: Data Preprocessing** - Prepares clean data for modeling\n",
    "- \ud83d\udcd3 **Example 4: Linear Regression** - Builds models on ready data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Categorical Data Analysis | \u0627\u0644\u062e\u0637\u0648\u0629 7: \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0641\u0626\u0648\u064a\u0629\n",
    "\n",
    "**BEFORE**: We see categorical values (like 'A', 'B', 'C' for location) but don't know their distribution.\n",
    "\n",
    "**AFTER**: We'll count how many times each category appears to understand the balance!\n",
    "\n",
    "**Why analyze categorical data?**\n",
    "- Shows if categories are balanced or imbalanced\n",
    "- Helps decide if we need encoding (one-hot, label encoding)\n",
    "- Reveals data quality issues (unexpected categories)\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfaf Summary: What We Learned | \u0627\u0644\u0645\u0644\u062e\u0635: \u0645\u0627 \u062a\u0639\u0644\u0645\u0646\u0627\u0647\n",
    "\n",
    "**BEFORE this notebook**: We had raw data files we couldn't use.\n",
    "\n",
    "**AFTER this notebook**: We can:\n",
    "- \u2705 Load data from CSV files\n",
    "- \u2705 Inspect data structure and types\n",
    "- \u2705 Calculate statistical summaries\n",
    "- \u2705 Identify data quality issues (missing values, duplicates)\n",
    "- \u2705 Analyze both numerical and categorical data\n",
    "\n",
    "**Next Steps**: \n",
    "- \ud83d\udcd3 Example 2: Data Cleaning (fix the issues we found)\n",
    "- \ud83d\udcd3 Example 3: Data Preprocessing (prepare data for modeling)\n",
    "- \ud83d\udcd3 Example 4: Linear Regression (build our first model!)\n",
    "\n",
    "---\n",
    "\n",
    "## \u2705 Example 1 Complete! | \u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 1!\n",
    "\n",
    "You've learned the foundation of data science: **exploration before modeling**!\n",
    "\n",
    "**Key Takeaway**: Always explore your data first. You can't build good models on bad data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}