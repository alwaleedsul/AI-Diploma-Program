{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Ridge and Lasso Regression | Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø±ÙŠØ¯Ø¬ ÙˆÙ„Ø§Ø³Ùˆ\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Unit 1: All examples** - Data processing, linear regression, polynomial regression\n",
    "- âœ… **Understanding of overfitting**: What happens when models are too complex\n",
    "- âœ… **Basic linear algebra**: Understanding coefficients and regularization\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why regularization is needed\n",
    "- Knowing when to use Ridge vs Lasso\n",
    "- Understanding how alpha (regularization strength) works\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is Unit 2, Example 1** - it solves the overfitting problem from polynomial regression!\n",
    "\n",
    "**Why this example FIRST in Unit 2?**\n",
    "- **Before** you can use advanced techniques, you need to solve overfitting\n",
    "- **Before** you can build robust models, you need regularization\n",
    "- **Before** you can handle multicollinearity, you need Ridge/Lasso\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Unit 1, Example 4: Linear Regression (we know basic regression)\n",
    "- ğŸ““ Unit 1, Example 5: Polynomial Regression (we saw overfitting!)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Example 2: Cross-Validation (evaluates models properly)\n",
    "- ğŸ““ Unit 3: Classification (same regularization concepts apply)\n",
    "- ğŸ““ All ML models (regularization is universal!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Ridge/Lasso solve **overfitting** (critical problem from Unit 1)\n",
    "2. Ridge/Lasso teach **regularization** (essential ML concept)\n",
    "3. Ridge/Lasso show **feature selection** (Lasso automatically selects features)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Preventing Overfitting | Ø§Ù„Ù‚ØµØ©: Ù…Ù†Ø¹ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªÙ„Ø§Ø¦Ù…\n",
    "\n",
    "Imagine you're learning to drive. **Before** regularization, you memorize every turn on the training route perfectly, but fail on new routes (overfitting). **After** regularization, you learn general driving principles that work everywhere!\n",
    "\n",
    "Same with machine learning: **Before** Ridge/Lasso, models memorize training data perfectly but fail on new data. **After** Ridge/Lasso, models learn general patterns that generalize well!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Ridge and Lasso Matter | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… Ø±ÙŠØ¯Ø¬ ÙˆÙ„Ø§Ø³ÙˆØŸ\n",
    "\n",
    "Regularization prevents overfitting:\n",
    "- **Ridge (L2)**: Shrinks coefficients toward zero (keeps all features)\n",
    "- **Lasso (L1)**: Shrinks some coefficients to exactly zero (feature selection!)\n",
    "- **Both**: Prevent overfitting by penalizing large coefficients\n",
    "- **Alpha**: Controls regularization strength (higher = more regularization)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ Real-World Applications | Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©\n",
    "\n",
    "**Ridge and Lasso Regression are used when you have MANY features or risk of overfitting!** Here's where you'll find them:\n",
    "\n",
    "### ğŸ’° Finance & Banking Sector | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ ÙˆØ§Ù„Ù…ØµØ±ÙÙŠ\n",
    "- **Credit Scoring**: Many features (income, age, credit history, employment, etc.) â†’ Ridge/Lasso prevents overfitting\n",
    "- **Stock Price Prediction**: Hundreds of market indicators â†’ Lasso selects most important features\n",
    "- **Risk Assessment**: Many risk factors â†’ Ridge handles multicollinearity (correlated features)\n",
    "- **Fraud Detection**: Many transaction features â†’ Lasso automatically selects relevant features\n",
    "- **Loan Default Prediction**: Multiple borrower characteristics â†’ Regularization improves generalization\n",
    "\n",
    "### ğŸ¥ Healthcare & Medical Sector | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„ØµØ­ÙŠ ÙˆØ§Ù„Ø·Ø¨ÙŠ\n",
    "- **Disease Diagnosis**: Many symptoms, test results, patient data â†’ Lasso selects key indicators\n",
    "- **Drug Discovery**: Thousands of molecular features â†’ Lasso identifies important compounds\n",
    "- **Medical Imaging**: Many pixel/voxel features â†’ Ridge prevents overfitting\n",
    "- **Genomics**: Thousands of genes â†’ Lasso selects relevant genes for disease prediction\n",
    "- **Patient Outcome Prediction**: Many clinical variables â†’ Ridge handles correlated features\n",
    "\n",
    "### ğŸ“Š Marketing & E-commerce Sector | Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ ÙˆØ§Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©\n",
    "- **Customer Segmentation**: Many customer attributes â†’ Lasso selects key segmentation features\n",
    "- **Churn Prediction**: Hundreds of customer behavior features â†’ Lasso identifies important predictors\n",
    "- **Recommendation Systems**: Many product/user features â†’ Ridge prevents overfitting\n",
    "- **Ad Click Prediction**: Many user, ad, context features â†’ Lasso selects most relevant\n",
    "- **Price Optimization**: Many market factors â†’ Ridge handles multicollinearity\n",
    "\n",
    "### ğŸ­ Manufacturing & Quality Control | Ø§Ù„ØªØµÙ†ÙŠØ¹ ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©\n",
    "- **Quality Prediction**: Many manufacturing parameters â†’ Lasso selects critical parameters\n",
    "- **Defect Detection**: Many sensor readings â†’ Ridge prevents overfitting\n",
    "- **Production Optimization**: Many process variables â†’ Lasso identifies key factors\n",
    "- **Supply Chain Forecasting**: Many demand factors â†’ Ridge handles correlated features\n",
    "- **Equipment Failure Prediction**: Many sensor features â†’ Lasso selects important sensors\n",
    "\n",
    "### ğŸ”¬ Scientific Research & Data Analysis | Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "- **Genomics Research**: Thousands of genes â†’ Lasso selects relevant genes\n",
    "- **Climate Modeling**: Many climate variables â†’ Ridge handles multicollinearity\n",
    "- **Material Science**: Many material properties â†’ Lasso identifies key properties\n",
    "- **Social Science Research**: Many survey variables â†’ Ridge prevents overfitting\n",
    "- **Epidemiology**: Many risk factors â†’ Lasso selects important risk factors\n",
    "\n",
    "### ğŸ›ï¸ Government & Public Safety Sector (Ministry of Interior) | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠ ÙˆØ§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©)\n",
    "- **Threat Assessment**: Many threat indicators â†’ Lasso selects key threat factors â†’ counter-terrorism\n",
    "- **Traffic Prediction**: Many traffic sensors â†’ Ridge handles correlated sensor data â†’ traffic management\n",
    "- **Crime Risk Models**: Many crime factors â†’ Lasso identifies critical risk factors â†’ crime prevention\n",
    "- **Emergency Response**: Many emergency variables â†’ Ridge handles multicollinearity â†’ emergency services\n",
    "- **Border Security Screening**: Many traveler features â†’ Lasso selects important indicators â†’ border control\n",
    "- **Surveillance Systems**: Many surveillance features â†’ Ridge prevents overfitting â†’ security monitoring\n",
    "- **Traffic Violation Detection**: Many violation factors â†’ Lasso identifies key factors â†’ traffic enforcement\n",
    "- **Personnel Security**: Many personnel features â†’ Ridge handles correlated features â†’ internal organization\n",
    "- **Access Control**: Many access factors â†’ Lasso selects critical factors â†’ government facilities\n",
    "- **Traffic Flow Analysis**: Many traffic variables â†’ Ridge handles multicollinearity â†’ smart traffic systems\n",
    "\n",
    "### ğŸ¯ When to Use Ridge vs Lasso:\n",
    "**Use RIDGE (L2) when:**\n",
    "- âœ… All features might be important (don't want to remove any)\n",
    "- âœ… Features are correlated (multicollinearity present)\n",
    "- âœ… Want to keep all features but shrink coefficients\n",
    "- âœ… Need stable, interpretable model\n",
    "- âœ… **Example**: Medical diagnosis with many correlated symptoms\n",
    "\n",
    "**Use LASSO (L1) when:**\n",
    "- âœ… Want automatic feature selection (remove irrelevant features)\n",
    "- âœ… Have many features, but only some are important\n",
    "- âœ… Need simpler model (fewer features)\n",
    "- âœ… Want to identify most important predictors\n",
    "- âœ… **Example**: Genomics with thousands of genes, only few matter\n",
    "\n",
    "**Use BOTH (Elastic Net) when:**\n",
    "- âœ… Want benefits of both (feature selection + handling multicollinearity)\n",
    "- âœ… Have many correlated features, but only some are important\n",
    "- âœ… Need balanced approach\n",
    "\n",
    "### ğŸ’¡ Why Regularization is Critical:\n",
    "- **Prevents Overfitting**: Models generalize better to new data\n",
    "- **Handles Many Features**: Works well with high-dimensional data\n",
    "- **Feature Selection (Lasso)**: Automatically identifies important features\n",
    "- **Stability**: More stable predictions than unregularized models\n",
    "- **Industry Standard**: Used in production ML systems worldwide\n",
    "\n",
    "### ğŸ“ˆ When to Use Ridge/Lasso:\n",
    "âœ… **Use Ridge/Lasso when:**\n",
    "- Have many features (more features than samples)\n",
    "- Risk of overfitting (complex model, small dataset)\n",
    "- Features are correlated (multicollinearity)\n",
    "- Need feature selection (use Lasso)\n",
    "- Want better generalization than linear regression\n",
    "\n",
    "âŒ **Don't use Ridge/Lasso when:**\n",
    "- Have very few features (regularization not needed)\n",
    "- Data is very large (overfitting less likely)\n",
    "- Need all features (use Ridge, not Lasso)\n",
    "- Simple linear relationship (regular linear regression sufficient)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Build Ridge regression models (L2 regularization)\n",
    "2. Build Lasso regression models (L1 regularization)\n",
    "3. Understand the difference between Ridge and Lasso\n",
    "4. Tune alpha hyperparameter\n",
    "5. Compare regularized models with linear regression\n",
    "6. Understand when to use each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:18:49.767466Z",
     "iopub.status.busy": "2025-12-25T19:18:49.767130Z",
     "iopub.status.idle": "2025-12-25T19:19:02.880919Z",
     "shell.execute_reply": "2025-12-25T19:19:02.880490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "\n",
      "ğŸ“š What each model does:\n",
      "   - LinearRegression: No regularization (baseline)\n",
      "   - Ridge: L2 regularization (keeps all features, shrinks coefficients)\n",
      "   - Lasso: L1 regularization (removes some features, shrinks others)\n",
      "   - StandardScaler: CRITICAL! Regularization requires scaled features!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us build regularized regression models\n",
    "\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np   # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,  # Baseline model (no regularization)\n",
    "    Ridge,             # L2 regularization (shrinks coefficients)\n",
    "    Lasso              # L1 regularization (shrinks + feature selection)\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler  # Important! Regularization needs scaled features\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # For evaluation\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"\\nğŸ“š What each model does:\")\n",
    "print(\"   - LinearRegression: No regularization (baseline)\")\n",
    "print(\"   - Ridge: L2 regularization (keeps all features, shrinks coefficients)\")\n",
    "print(\"   - Lasso: L1 regularization (removes some features, shrinks others)\")\n",
    "print(\"   - StandardScaler: CRITICAL! Regularization requires scaled features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Scene | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø´Ù‡Ø¯\n",
    "\n",
    "**BEFORE**: We saw overfitting in polynomial regression - models that fit training data too well but fail on new data.\n",
    "\n",
    "**AFTER**: We'll use Ridge and Lasso regularization to prevent overfitting by penalizing large coefficients!\n",
    "\n",
    "**Why this matters**: Overfitting is the #1 problem in ML. Regularization is the #1 solution!\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Load Real-World Data with Multicollinearity | Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ø¹ Ø§Ø±ØªØ¨Ø§Ø· Ù…ØªØ¹Ø¯Ø¯\n",
    "\n",
    "**BEFORE**: We need to learn regularization, but we need real data that has multicollinearity (correlated features).\n",
    "\n",
    "**AFTER**: We'll load the California Housing dataset - real data where features are naturally correlated (multicollinearity) - this is when regularization helps most!\n",
    "\n",
    "**Why California Housing?** This is REAL data from the 1990 census where features like AveRooms, AveBedrms, and Population are naturally correlated. When features are correlated, regular linear regression struggles. Ridge/Lasso handle this better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:02.903886Z",
     "iopub.status.busy": "2025-12-25T19:19:02.903705Z",
     "iopub.status.idle": "2025-12-25T19:19:04.089011Z",
     "shell.execute_reply": "2025-12-25T19:19:04.088655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¥ Loading California Housing dataset...\n",
      "ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù„ÙŠÙÙˆØ±Ù†ÙŠØ§ Ù„Ù„Ø¥Ø³ÙƒØ§Ù†...\n",
      "\n",
      "âœ… Real-world California Housing data loaded!\n",
      "   ğŸ“Š This is REAL data from the 1990 California census\n",
      "   ğŸ“ˆ Contains 20640 housing districts with 8 features\n",
      "\n",
      "ğŸ” Notice:\n",
      "   - Features like AveRooms, AveBedrms, Population are naturally correlated\n",
      "   - This multicollinearity makes regularization important!\n",
      "   - Ridge/Lasso will handle this better than regular linear regression\n"
     ]
    }
   ],
   "source": [
    "# Load real-world California Housing dataset\n",
    "# This dataset naturally has multicollinearity (correlated features)\n",
    "# Multicollinearity = features are correlated with each other\n",
    "# This is a common real-world problem that regularization solves!\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "print(\"\\nğŸ“¥ Loading California Housing dataset...\")\n",
    "print(\"ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù„ÙŠÙÙˆØ±Ù†ÙŠØ§ Ù„Ù„Ø¥Ø³ÙƒØ§Ù†...\")\n",
    "\n",
    "housing_data = fetch_california_housing()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(housing_data.data, columns=housing_data.feature_names)\n",
    "df['target'] = housing_data.target\n",
    "\n",
    "print(f\"\\nâœ… Real-world California Housing data loaded!\")\n",
    "print(f\"   ğŸ“Š This is REAL data from the 1990 California census\")\n",
    "print(f\"   ğŸ“ˆ Contains {len(df)} housing districts with {len(df.columns)-1} features\")\n",
    "print(f\"\\nğŸ” Notice:\")\n",
    "print(\"   - Features like AveRooms, AveBedrms, Population are naturally correlated\")\n",
    "print(\"   - This multicollinearity makes regularization important!\")\n",
    "print(\"   - Ridge/Lasso will handle this better than regular linear regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Understanding the Dataset | ÙÙ‡Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "### For CS Students - Focus on Data Structure, Not Domain | Ù„Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ - Ø±ÙƒØ² Ø¹Ù„Ù‰ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆÙ„ÙŠØ³ Ø§Ù„Ù…Ø¬Ø§Ù„\n",
    "\n",
    "**As computer science students, you'll work with many different types of datasets** (medical, financial, e-commerce, etc.). **What matters is the data structure, not the domain knowledge!**\n",
    "\n",
    "**Data Structure Focus**:\n",
    "- **Data Shape**: 20,640 rows Ã— 8 columns (samples Ã— features)\n",
    "- **Feature Types**: All numerical (float64) - continuous values\n",
    "- **Target Type**: Regression (predicting continuous value: house price)\n",
    "- **Task**: Predict median house value based on features\n",
    "- **Data Quality**: Real-world data with multicollinearity (correlated features)\n",
    "\n",
    "**Why This Structure Matters**:\n",
    "- **Multicollinearity present** â†’ Need regularization (Ridge/Lasso handle correlated features)\n",
    "- **Regression task** â†’ We'll use regression metrics (MSE, RMSE, RÂ²)\n",
    "- **Many features** â†’ Risk of overfitting (regularization prevents this)\n",
    "- **Real-world data** â†’ Shows why regularization is needed (correlated features common in real data)\n",
    "\n",
    "### Understanding the Dataset Domain (Brief) | ÙÙ‡Ù… Ù…Ø¬Ø§Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¨Ø§Ø®ØªØµØ§Ø±)\n",
    "\n",
    "**What is this data?** California housing prices from 1990 census.\n",
    "\n",
    "**Why does this matter?** \n",
    "- **For regularization**: Features are correlated (multicollinearity) â†’ Ridge/Lasso handle this better\n",
    "- **For model selection**: Many features â†’ risk of overfitting â†’ need regularization\n",
    "- **For evaluation**: Continuous target â†’ use regression metrics (MSE, RMSE, RÂ²)\n",
    "\n",
    "**Domain Context** (Brief):\n",
    "- **MedInc**: Median income (correlated with house prices)\n",
    "- **AveRooms, AveBedrms**: Average rooms/bedrooms (correlated with each other - multicollinearity!)\n",
    "- **Population**: Population density (affects prices)\n",
    "- **Multicollinearity**: AveRooms and AveBedrms are correlated (more rooms usually means more bedrooms)\n",
    "\n",
    "**ğŸ’¡ Key Point for CS Students**: You don't need to be a real estate expert! Focus on:\n",
    "- Understanding the **data structure** (rows, columns, types, correlations)\n",
    "- Recognizing **multicollinearity** (correlated features need regularization)\n",
    "- Choosing the right **regularization method** (Ridge vs Lasso) based on structure, not domain knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.090829Z",
     "iopub.status.busy": "2025-12-25T19:19:04.090631Z",
     "iopub.status.idle": "2025-12-25T19:19:04.095770Z",
     "shell.execute_reply": "2025-12-25T19:19:04.095506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Real Data Summary:\n",
      "   Shape: (20640, 9)\n",
      "   Features: MedInc, HouseAge, AveRooms, AveBedrms... and more\n",
      "   Target: Median House Value (in $100,000s)\n",
      "\n",
      "ğŸ“„ First 5 rows:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  target  \n",
      "0    -122.23   4.526  \n",
      "1    -122.22   3.585  \n",
      "2    -122.24   3.521  \n",
      "3    -122.25   3.413  \n",
      "4    -122.25   3.422  \n",
      "\n",
      "ğŸ” Notice:\n",
      "   - This is REAL data from 1990 California census\n",
      "   - Features are naturally correlated (multicollinearity)\n",
      "   - Regular regression may struggle; Ridge/Lasso will handle this better!\n"
     ]
    }
   ],
   "source": [
    "# Data summary comes first (showing what we loaded)\n",
    "# Then we'll check for multicollinearity\n",
    "\n",
    "print(f\"\\nğŸ“Š Real Data Summary:\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Features: {', '.join(housing_data.feature_names[:4])}... and more\")\n",
    "print(f\"   Target: Median House Value (in $100,000s)\")\n",
    "print(f\"\\nğŸ“„ First 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nğŸ” Notice:\")\n",
    "print(\"   - This is REAL data from 1990 California census\")\n",
    "print(\"   - Features are naturally correlated (multicollinearity)\")\n",
    "print(\"   - Regular regression may struggle; Ridge/Lasso will handle this better!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.096979Z",
     "iopub.status.busy": "2025-12-25T19:19:04.096884Z",
     "iopub.status.idle": "2025-12-25T19:19:04.104358Z",
     "shell.execute_reply": "2025-12-25T19:19:04.104128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Checking for multicollinearity in real data...\n",
      "   (Correlated features make regularization important)\n",
      "\n",
      "   âœ… Found 2 highly correlated feature pairs:\n",
      "      - AveRooms â†” AveBedrms: 0.848\n",
      "      - Latitude â†” Longitude: -0.925\n",
      "\n",
      "ğŸ’¡ What to Notice:\n",
      "   - Correlation values close to 1.0 (or -1.0) mean features are highly correlated\n",
      "   - Notice: AveRooms â†” AveBedrms correlation = 0.848 (very high! They move together)\n",
      "   - Notice: Latitude â†” Longitude correlation = -0.925 (very high! They're related)\n",
      "   - When features are correlated like this, regular Linear Regression can struggle\n",
      "   - This is why we need Ridge/Lasso - they handle multicollinearity better! âœ…\n"
     ]
    }
   ],
   "source": [
    "# Now check for multicollinearity in the loaded data\n",
    "print(\"\\nğŸ“Š Checking for multicollinearity in real data...\")\n",
    "print(\"   (Correlated features make regularization important)\")\n",
    "\n",
    "# Check correlation between features\n",
    "correlation_matrix = df[housing_data.feature_names].corr()\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:  # High correlation threshold\n",
    "            high_corr_pairs.append((\n",
    "                correlation_matrix.columns[i],\n",
    "                correlation_matrix.columns[j],\n",
    "                corr_val\n",
    "            ))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"\\n   âœ… Found {len(high_corr_pairs)} highly correlated feature pairs:\")\n",
    "    for feat1, feat2, corr in high_corr_pairs[:3]:  # Show first 3\n",
    "        print(f\"      - {feat1} â†” {feat2}: {corr:.3f}\")\n",
    "    print(\"\\nğŸ’¡ What to Notice:\")\n",
    "    print(\"   - Correlation values close to 1.0 (or -1.0) mean features are highly correlated\")\n",
    "    print(\"   - Notice: AveRooms â†” AveBedrms correlation = 0.848 (very high! They move together)\")\n",
    "    print(\"   - Notice: Latitude â†” Longitude correlation = -0.925 (very high! They're related)\")\n",
    "    print(\"   - When features are correlated like this, regular Linear Regression can struggle\")\n",
    "    print(\"   - This is why we need Ridge/Lasso - they handle multicollinearity better! âœ…\")\n",
    "else:\n",
    "    print(\"   - Features have moderate correlation (still benefits from regularization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data for Modeling | Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ù…Ø°Ø¬Ø©\n",
    "\n",
    "**BEFORE**: We've loaded and explored the data, and we found multicollinearity (correlated features). Now we need to prepare the data for modeling!\n",
    "\n",
    "**AFTER**: We'll split the data into training and test sets, and scale the features!\n",
    "\n",
    "**Why scaling matters**: Regularization is sensitive to feature scale! Features on different scales (e.g., age vs income) will be penalized differently. If we don't scale, features with larger values would be penalized more heavily by regularization, which is unfair! We MUST scale first!\n",
    "\n",
    "**What we'll do**:\n",
    "1. Split data: 80% training, 20% testing (to evaluate models properly)\n",
    "2. Scale features: Use StandardScaler (mean=0, std=1) so all features are on the same scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.105491Z",
     "iopub.status.busy": "2025-12-25T19:19:04.105408Z",
     "iopub.status.idle": "2025-12-25T19:19:04.111042Z",
     "shell.execute_reply": "2025-12-25T19:19:04.110827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Data prepared for modeling:\n",
      "   Features (X): 8 features\n",
      "   Target (y): 20640 samples\n",
      "   Feature names: MedInc, HouseAge, AveRooms, AveBedrms... and more\n",
      "   âœ… Data split and scaled!\n",
      "   Training set: 16512 samples\n",
      "   Test set: 4128 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (X) and target (y) from real data\n",
    "X_data = df[housing_data.feature_names]  # All 8 features\n",
    "y_data = df['target']  # Median House Value\n",
    "\n",
    "print(f\"\\nâœ… Data prepared for modeling:\")\n",
    "print(f\"   Features (X): {X_data.shape[1]} features\")\n",
    "print(f\"   Target (y): {y_data.shape[0]} samples\")\n",
    "print(f\"   Feature names: {', '.join(X_data.columns[:4])}... and more\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# train_test_split(X, y, test_size=0.2, random_state=123  # Any number works - just for reproducibility)\n",
    "# - Splits data into training and testing sets\n",
    "# - X: Features (input variables), y: Target (output variable)\n",
    "# - test_size=0.2: 20% for testing, 80% for training\n",
    "# - random_state=123  # Any number works - just for reproducibility: Seed for reproducibility (same split every time)\n",
    "# - Returns: X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=123  # Any number works - just for reproducibility\n",
    ")\n",
    "\n",
    "# Scale features (CRITICAL for regularization!)\n",
    "# Regularization is sensitive to feature scale, so we MUST scale first!\n",
    "# Without scaling, features with larger values would be penalized more\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"   âœ… Data split and scaled!\")\n",
    "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Alpha (Î±) - The Regularization Parameter | ÙÙ‡Ù… Alpha (Î±) - Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…\n",
    "\n",
    "**BEFORE**: You know Ridge and Lasso use regularization, but what is alpha exactly?\n",
    "\n",
    "**AFTER**: You'll understand that alpha controls how much regularization is applied!\n",
    "\n",
    "**Why this matters**: Choosing the wrong alpha can lead to:\n",
    "- **Overfitting** (alpha too small) â†’ Model memorizes training data\n",
    "- **Underfitting** (alpha too large) â†’ Model becomes too simple, can't learn patterns\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š What is Alpha (Î±)? | Ù…Ø§ Ù‡Ùˆ Alpha (Î±)ØŸ\n",
    "\n",
    "**Alpha (Î±)** is the **regularization strength parameter** that controls the trade-off between:\n",
    "1. **Fitting the training data well** (low error on training data)\n",
    "2. **Keeping the model simple** (small coefficients to prevent overfitting)\n",
    "\n",
    "### ğŸ”¢ How Alpha Works | ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ Alpha\n",
    "\n",
    "**The Math Behind It:**\n",
    "\n",
    "For **Ridge Regression (L2)**, the cost function becomes:\n",
    "```\n",
    "Cost = MSE + Î± Ã— (sum of squared coefficients)\n",
    "```\n",
    "\n",
    "For **Lasso Regression (L1)**, the cost function becomes:\n",
    "```\n",
    "Cost = MSE + Î± Ã— (sum of absolute coefficients)\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- **Î± = 0**: No regularization â†’ Same as Linear Regression\n",
    "- **Î± > 0**: Regularization is applied\n",
    "- **Higher Î±** â†’ More regularization â†’ Smaller coefficients\n",
    "- **Lower Î±** â†’ Less regularization â†’ Coefficients closer to Linear Regression\n",
    "\n",
    "### ğŸ“Š Alpha Values and Their Effects | Ù‚ÙŠÙ… Alpha ÙˆØªØ£Ø«ÙŠØ±Ø§ØªÙ‡Ø§\n",
    "\n",
    "| Alpha Value | Effect | Result |\n",
    "|-------------|--------|--------|\n",
    "| **Î± = 0** | No regularization | Same as Linear Regression |\n",
    "| **Î± = 0.01** | Very light regularization | Coefficients slightly shrunk |\n",
    "| **Î± = 0.1** | Light regularization | Noticeable coefficient shrinkage |\n",
    "| **Î± = 1.0** | Moderate regularization | Significant coefficient reduction |\n",
    "| **Î± = 10.0** | Heavy regularization | Very small coefficients |\n",
    "| **Î± = 100+** | Very heavy regularization | Most coefficients near zero (especially in Lasso) |\n",
    "\n",
    "### ğŸ¯ Alpha in Ridge vs Lasso | Alpha ÙÙŠ Ridge Ù…Ù‚Ø§Ø¨Ù„ Lasso\n",
    "\n",
    "**Ridge (L2) Regularization:**\n",
    "- **Shrinks coefficients smoothly** toward zero\n",
    "- **Never sets coefficients to exactly zero**\n",
    "- Keeps all features, just makes them smaller\n",
    "- **Best for**: When all features might be relevant\n",
    "\n",
    "**Lasso (L1) Regularization:**\n",
    "- **Can set coefficients to exactly zero** (feature selection!)\n",
    "- **More aggressive** shrinkage\n",
    "- **Best for**: When you want to remove irrelevant features\n",
    "\n",
    "### âš–ï¸ The Trade-off | Ø§Ù„Ù…Ù‚Ø§ÙŠØ¶Ø©\n",
    "\n",
    "```\n",
    "Alpha (Î±) = 0          Alpha (Î±) = small        Alpha (Î±) = large\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ No Regularizationâ”‚   â”‚ Light Regularization â”‚  â”‚ Heavy Regularizationâ”‚\n",
    "â”‚                 â”‚   â”‚                 â”‚      â”‚                 â”‚\n",
    "â”‚ - Fits training â”‚   â”‚ - Balanced      â”‚      â”‚ - Very simple   â”‚\n",
    "â”‚   data perfectlyâ”‚   â”‚ - Good          â”‚      â”‚ - May underfit  â”‚\n",
    "â”‚ - May overfit!  â”‚   â”‚   generalizationâ”‚      â”‚ - Small coefs   â”‚\n",
    "â”‚ - Large coefs   â”‚   â”‚ - Smaller coefs â”‚      â”‚ - Some = 0      â”‚\n",
    "â”‚                 â”‚   â”‚                 â”‚      â”‚   (Lasso only)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ğŸ’¡ How to Choose Alpha? | ÙƒÙŠÙ ØªØ®ØªØ§Ø± AlphaØŸ\n",
    "\n",
    "1. **Start with a range** (e.g., 0.01, 0.1, 1.0, 10.0, 100.0)\n",
    "2. **Train models** with different alpha values\n",
    "3. **Evaluate on validation/test set** (not training set!)\n",
    "4. **Choose the alpha** that gives the best test performance\n",
    "5. **Use cross-validation** for more reliable selection (coming in Example 2!)\n",
    "\n",
    "### ğŸ“ Important Notes | Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©\n",
    "\n",
    "- **Alpha must be â‰¥ 0** (can't be negative)\n",
    "- **Scaling matters!** Regularization requires scaled features (that's why we used StandardScaler)\n",
    "- **Different datasets** need different alpha values\n",
    "- **Ridge and Lasso** may have different optimal alpha values\n",
    "- **Tuning alpha is a hyperparameter** search problem (we'll learn Grid Search in Unit 5!)\n",
    "\n",
    "---\n",
    "\n",
    "**In this notebook**, we'll try different alpha values and see how they affect model performance! ğŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building and Comparing Models | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø¨Ù†Ø§Ø¡ ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
    "\n",
    "**BEFORE**: We understand what alpha is and our data is prepared. Now let's build models!\n",
    "\n",
    "**AFTER**: We'll build three models and compare them to see how regularization helps.\n",
    "\n",
    "**Approach**: \n",
    "1. **Linear Regression** (baseline - no regularization)\n",
    "2. **Ridge Regression** (L2 regularization - shrinks all coefficients)\n",
    "3. **Lasso Regression** (L1 regularization - can remove features)\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Linear Regression Baseline | Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ ÙƒØ®Ø· Ø£Ø³Ø§Ø³\n",
    "\n",
    "**Why start here?** We need a baseline to compare against! Linear Regression has no regularization (Î± = 0), so we can see the difference when we add regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.112142Z",
     "iopub.status.busy": "2025-12-25T19:19:04.112078Z",
     "iopub.status.idle": "2025-12-25T19:19:04.117049Z",
     "shell.execute_reply": "2025-12-25T19:19:04.116844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1. Linear Regression (Baseline)\n",
      "Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ (Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³)\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Linear Regression Results:\n",
      "   MSE: 0.5559 (lower is better)\n",
      "   RÂ² Score: 0.5758 (closer to 1 is better)\n",
      "\n",
      "   Coefficients (first 5): [ 0.85438303  0.12254624 -0.29441013  0.33925949 -0.00230772]\n",
      "   Notice: Some coefficients might be large or unstable\n",
      "\n",
      "ğŸ’¡ What we learned:\n",
      "   - Linear Regression baseline: MSE = 0.5559, RÂ² = 0.5758\n",
      "   - Now let's see if Ridge or Lasso can improve this!\n",
      "   - Regularization should help stabilize these coefficients and potentially improve performance!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"1. Linear Regression (Baseline)\")\n",
    "print(\"Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ (Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Try regular linear regression first (no regularization)\n",
    "# This is our baseline to compare against\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "lr_mse = mean_squared_error(y_test, lr_pred)\n",
    "lr_r2 = r2_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"\\nğŸ“Š Linear Regression Results:\")\n",
    "print(f\"   MSE: {lr_mse:.4f} (lower is better)\")\n",
    "print(f\"   RÂ² Score: {lr_r2:.4f} (closer to 1 is better)\")\n",
    "print(f\"\\n   Coefficients (first 5): {lr.coef_[:5]}\")\n",
    "print(f\"   Notice: Some coefficients might be large or unstable\")\n",
    "print(f\"\\nğŸ’¡ What we learned:\")\n",
    "print(f\"   - Linear Regression baseline: MSE = {lr_mse:.4f}, RÂ² = {lr_r2:.4f}\")\n",
    "print(f\"   - Now let's see if Ridge or Lasso can improve this!\")\n",
    "print(f\"   - Regularization should help stabilize these coefficients and potentially improve performance!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Ridge Regression (L2 Regularization) | Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø±ÙŠØ¯Ø¬ (Ø§Ù„ØªÙ†Ø¸ÙŠÙ… L2)\n",
    "\n",
    "**BEFORE**: We have our baseline. Now let's try Ridge regression with different alpha values.\n",
    "\n",
    "**AFTER**: We'll see how different alpha values affect Ridge's performance and coefficients.\n",
    "\n",
    "**What to expect**: \n",
    "- Ridge will try different alpha values (0.01, 0.1, 1.0, 10.0, 100.0)\n",
    "- Remember from the Alpha explanation: higher alpha = more regularization = smaller coefficients\n",
    "- Ridge keeps ALL features but shrinks them toward zero\n",
    "- We'll find the best alpha that minimizes test MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.118040Z",
     "iopub.status.busy": "2025-12-25T19:19:04.117979Z",
     "iopub.status.idle": "2025-12-25T19:19:04.124706Z",
     "shell.execute_reply": "2025-12-25T19:19:04.124519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. Ridge Regression (L2 Regularization)\n",
      "Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø±ÙŠØ¯Ø¬ (Ø§Ù„ØªÙ†Ø¸ÙŠÙ… L2)\n",
      "============================================================\n",
      "\n",
      "   Trying different alpha values...\n",
      "   Alpha   0.01: MSE = 0.5559, RÂ² = 0.5758\n",
      "   Alpha   0.10: MSE = 0.5559, RÂ² = 0.5758\n",
      "   Alpha   1.00: MSE = 0.5559, RÂ² = 0.5758\n",
      "   Alpha  10.00: MSE = 0.5555, RÂ² = 0.5761\n",
      "   Alpha 100.00: MSE = 0.5533, RÂ² = 0.5778\n",
      "\n",
      "ğŸ’¡ What to Notice:\n",
      "   - Look at how MSE and RÂ² change as alpha increases\n",
      "   - Notice: Very low alpha (0.01) gives similar results to Linear Regression (MSE = 0.5559)\n",
      "   - Notice: The changes are SMALL (0.5559 â†’ 0.5533) - but regularization still helps!\n",
      "   - Why small changes? The original model wasn't heavily overfitting, so regularization's benefit is modest\n",
      "   - Even small improvements (0.0026 lower MSE) can be meaningful - regularization stabilizes the model!\n",
      "   - Best alpha: 100.0 gives MSE = 0.5533 (lowest error, best performance)\n",
      "   - This teaches us: Regularization doesn't always dramatically improve performance, but it makes models more stable!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. Ridge Regression (L2 Regularization)\")\n",
    "print(\"Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø±ÙŠØ¯Ø¬ (Ø§Ù„ØªÙ†Ø¸ÙŠÙ… L2)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ridge regression with different alpha values\n",
    "# Alpha (Î±) = regularization strength parameter (see Alpha explanation section above!)\n",
    "# - Higher alpha = more regularization = smaller coefficients\n",
    "# - Lower alpha = less regularization = closer to Linear Regression\n",
    "# Why try different alphas? We need to find the best balance between fitting the data and preventing overfitting!\n",
    "# We'll evaluate each alpha on the test set and pick the one with lowest MSE\n",
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "ridge_results = []\n",
    "\n",
    "print(\"\\n   Trying different alpha values...\")\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)  # Create Ridge model with this alpha\n",
    "    ridge.fit(X_train_scaled, y_train)  # Train on scaled data\n",
    "    ridge_pred = ridge.predict(X_test_scaled)  # Predict on test data\n",
    "    \n",
    "    mse = mean_squared_error(y_test, ridge_pred)\n",
    "    r2 = r2_score(y_test, ridge_pred)\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'alpha': alpha,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'model': ridge\n",
    "    })\n",
    "    print(f\"   Alpha {alpha:6.2f}: MSE = {mse:.4f}, RÂ² = {r2:.4f}\")\n",
    "\n",
    "# Add interpretation after showing all results\n",
    "print(\"\\nğŸ’¡ What to Notice:\")\n",
    "print(\"   - Look at how MSE and RÂ² change as alpha increases\")\n",
    "print(\"   - Notice: Very low alpha (0.01) gives similar results to Linear Regression (MSE = 0.5559)\")\n",
    "print(\"   - Notice: The changes are SMALL (0.5559 â†’ 0.5533) - but regularization still helps!\")\n",
    "print(\"   - Why small changes? The original model wasn't heavily overfitting, so regularization's benefit is modest\")\n",
    "print(\"   - Even small improvements (0.0026 lower MSE) can be meaningful - regularization stabilizes the model!\")\n",
    "print(\"   - Best alpha: 100.0 gives MSE = 0.5533 (lowest error, best performance)\")\n",
    "print(\"   - This teaches us: Regularization doesn't always dramatically improve performance, but it makes models more stable!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Lasso Regression (L1 Regularization) | Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ù„Ø§Ø³Ùˆ (Ø§Ù„ØªÙ†Ø¸ÙŠÙ… L1)\n",
    "\n",
    "**BEFORE**: We've seen how Ridge works. Now let's try Lasso!\n",
    "\n",
    "**AFTER**: We'll see how Lasso differs from Ridge - it can actually remove features!\n",
    "\n",
    "**Key difference from Ridge**:\n",
    "- **Ridge**: Shrinks all coefficients toward zero (keeps all features)\n",
    "- **Lasso**: Can set coefficients to EXACTLY zero (removes features automatically!)\n",
    "- This is Lasso's special power: **automatic feature selection**\n",
    "- We'll count how many features Lasso keeps vs removes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.125649Z",
     "iopub.status.busy": "2025-12-25T19:19:04.125593Z",
     "iopub.status.idle": "2025-12-25T19:19:04.136547Z",
     "shell.execute_reply": "2025-12-25T19:19:04.136206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. Lasso Regression (L1 Regularization)\n",
      "Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ù„Ø§Ø³Ùˆ (Ø§Ù„ØªÙ†Ø¸ÙŠÙ… L1)\n",
      "============================================================\n",
      "\n",
      "   Trying different alpha values...\n",
      "   Alpha   0.01: MSE = 0.5483, RÂ² = 0.5816, Features = 7/8\n",
      "   Alpha   0.10: MSE = 0.6796, RÂ² = 0.4814, Features = 3/8\n",
      "   Alpha   1.00: MSE = 1.3107, RÂ² = -0.0002, Features = 0/8\n",
      "   Alpha  10.00: MSE = 1.3107, RÂ² = -0.0002, Features = 0/8\n",
      "   Alpha 100.00: MSE = 1.3107, RÂ² = -0.0002, Features = 0/8\n",
      "\n",
      "ğŸ’¡ What to Notice:\n",
      "   - Look at the 'Features' column: This shows how many features Lasso KEPT (non-zero coefficients)\n",
      "   - Notice: As alpha increases, fewer features are used (Lasso removes more features!)\n",
      "   - Notice: High alpha (1.0+) removes ALL features (Features = 0/8) - this is too much regularization!\n",
      "   - âš ï¸ CRITICAL: When alpha â‰¥ 1.0, RÂ² becomes NEGATIVE (RÂ² = -0.0002)!\n",
      "     â†’ Negative RÂ² means the model is WORSE than just predicting the mean!\n",
      "     â†’ This happens because Lasso removed ALL features (no model left!)\n",
      "     â†’ This is what OVER-REGULARIZATION looks like - alpha is too high!\n",
      "   - Notice: Low alpha (0.01) keeps most features (Features = 7/8) - good balance\n",
      "   - Compare with Ridge: Ridge always uses ALL 8 features, Lasso can remove some!\n",
      "   - Which alpha performed best? Look for the lowest MSE value above! ğŸ‘†\n",
      "   - Best alpha = 0.01 (lowest MSE = 0.5483, highest RÂ² = 0.5816, keeps 7/8 features)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. Lasso Regression (L1 Regularization)\")\n",
    "print(\"Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ù„Ø§Ø³Ùˆ (Ø§Ù„ØªÙ†Ø¸ÙŠÙ… L1)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lasso regression with different alpha values\n",
    "# Lasso does feature selection - sets some coefficients to zero!\n",
    "lasso_results = []\n",
    "\n",
    "print(\"\\n   Trying different alpha values...\")\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)  # Create Lasso model\n",
    "    lasso.fit(X_train_scaled, y_train)  # Train on scaled data\n",
    "    lasso_pred = lasso.predict(X_test_scaled)  # Predict\n",
    "    \n",
    "    mse = mean_squared_error(y_test, lasso_pred)\n",
    "    r2 = r2_score(y_test, lasso_pred)\n",
    "    \n",
    "    # Count non-zero coefficients (features that Lasso kept)\n",
    "    # Why check this? Lasso removes features by setting coefficients to zero!\n",
    "    n_features = np.sum(np.abs(lasso.coef_) > 0.01)\n",
    "    \n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'n_features': n_features,  # How many features Lasso kept\n",
    "        'model': lasso\n",
    "    })\n",
    "    print(f\"   Alpha {alpha:6.2f}: MSE = {mse:.4f}, RÂ² = {r2:.4f}, Features = {n_features}/{len(X_data.columns)}\")\n",
    "\n",
    "# Add interpretation after showing all results\n",
    "print(\"\\nğŸ’¡ What to Notice:\")\n",
    "print(\"   - Look at the 'Features' column: This shows how many features Lasso KEPT (non-zero coefficients)\")\n",
    "print(\"   - Notice: As alpha increases, fewer features are used (Lasso removes more features!)\")\n",
    "print(\"   - Notice: High alpha (1.0+) removes ALL features (Features = 0/8) - this is too much regularization!\")\n",
    "print(\"   - âš ï¸ CRITICAL: When alpha â‰¥ 1.0, RÂ² becomes NEGATIVE (RÂ² = -0.0002)!\")\n",
    "print(\"     â†’ Negative RÂ² means the model is WORSE than just predicting the mean!\")\n",
    "print(\"     â†’ This happens because Lasso removed ALL features (no model left!)\")\n",
    "print(\"     â†’ This is what OVER-REGULARIZATION looks like - alpha is too high!\")\n",
    "print(\"   - Notice: Low alpha (0.01) keeps most features (Features = 7/8) - good balance\")\n",
    "print(\"   - Compare with Ridge: Ridge always uses ALL 8 features, Lasso can remove some!\")\n",
    "print(\"   - Which alpha performed best? Look for the lowest MSE value above! ğŸ‘†\")\n",
    "print(\"   - Best alpha = 0.01 (lowest MSE = 0.5483, highest RÂ² = 0.5816, keeps 7/8 features)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.138455Z",
     "iopub.status.busy": "2025-12-25T19:19:04.138344Z",
     "iopub.status.idle": "2025-12-25T19:19:04.142334Z",
     "shell.execute_reply": "2025-12-25T19:19:04.141286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ” Finding Best Ridge Alpha\n",
      "Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ù‚ÙŠÙ…Ø© Alpha Ù„Ø±ÙŠØ¬\n",
      "============================================================\n",
      "\n",
      "âœ… Best Ridge Model:\n",
      "   Alpha (Î±): 100.0\n",
      "   Test MSE: 0.5533 (lowest error)\n",
      "   Test RÂ²: 0.5778 (higher is better)\n",
      "\n",
      "ğŸ’¡ Insight: Ridge with Î±=100.0 gives the best performance!\n"
     ]
    }
   ],
   "source": [
    "# Find best Ridge alpha (the one with lowest test MSE)\n",
    "# We tried different alpha values above, now let's pick the best one\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ” Finding Best Ridge Alpha\")\n",
    "print(\"Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ù‚ÙŠÙ…Ø© Alpha Ù„Ø±ÙŠØ¬\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_ridge = min(ridge_results, key=lambda x: x['mse'])\n",
    "print(f\"\\nâœ… Best Ridge Model:\")\n",
    "print(f\"   Alpha (Î±): {best_ridge['alpha']}\")\n",
    "print(f\"   Test MSE: {best_ridge['mse']:.4f} (lowest error)\")\n",
    "print(f\"   Test RÂ²: {best_ridge['r2']:.4f} (higher is better)\")\n",
    "print(f\"\\nğŸ’¡ Insight: Ridge with Î±={best_ridge['alpha']} gives the best performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.144666Z",
     "iopub.status.busy": "2025-12-25T19:19:04.144514Z",
     "iopub.status.idle": "2025-12-25T19:19:04.147383Z",
     "shell.execute_reply": "2025-12-25T19:19:04.146808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ” Finding Best Lasso Alpha\n",
      "Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ù‚ÙŠÙ…Ø© Alpha Ù„Ù„Ø§Ø³Ùˆ\n",
      "============================================================\n",
      "\n",
      "âœ… Best Lasso Model:\n",
      "   Alpha (Î±): 0.01\n",
      "   Test MSE: 0.5483 (lowest error)\n",
      "   Test RÂ²: 0.5816 (higher is better)\n",
      "   Features used: 7/8\n",
      "\n",
      "ğŸ’¡ Insight: Lasso with Î±=0.01 gives the best performance!\n",
      "   Plus: Lasso automatically removed 1 features (feature selection!)\n"
     ]
    }
   ],
   "source": [
    "# Find best Lasso alpha (the one with lowest test MSE)\n",
    "# We tried different alpha values above, now let's pick the best one\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ” Finding Best Lasso Alpha\")\n",
    "print(\"Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ù‚ÙŠÙ…Ø© Alpha Ù„Ù„Ø§Ø³Ùˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_lasso = min(lasso_results, key=lambda x: x['mse'])\n",
    "print(f\"\\nâœ… Best Lasso Model:\")\n",
    "print(f\"   Alpha (Î±): {best_lasso['alpha']}\")\n",
    "print(f\"   Test MSE: {best_lasso['mse']:.4f} (lowest error)\")\n",
    "print(f\"   Test RÂ²: {best_lasso['r2']:.4f} (higher is better)\")\n",
    "print(f\"   Features used: {best_lasso['n_features']}/{len(X_data.columns)}\")\n",
    "print(f\"\\nğŸ’¡ Insight: Lasso with Î±={best_lasso['alpha']} gives the best performance!\")\n",
    "if best_lasso['n_features'] < len(X_data.columns):\n",
    "    print(f\"   Plus: Lasso automatically removed {len(X_data.columns) - best_lasso['n_features']} features (feature selection!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model Comparison | Ø§Ù„Ø®Ø·ÙˆØ© 4: Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
    "\n",
    "**BEFORE**: We've built three models (Linear, Ridge, Lasso) and found the best alpha for Ridge and Lasso. \n",
    "\n",
    "**AFTER**: Now let's compare all three models side-by-side to see which performs best!\n",
    "\n",
    "**What we'll compare**:\n",
    "- **Linear Regression**: Our baseline (no regularization, Î± = 0)\n",
    "- **Best Ridge Model**: Best performing Ridge with optimal alpha\n",
    "- **Best Lasso Model**: Best performing Lasso with optimal alpha\n",
    "\n",
    "**Why compare?** This helps us understand:\n",
    "- Does regularization actually help? (Ridge/Lasso vs Linear)\n",
    "- Which regularization works better? (Ridge vs Lasso)\n",
    "- What are the trade-offs? (performance vs simplicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.150759Z",
     "iopub.status.busy": "2025-12-25T19:19:04.150507Z",
     "iopub.status.idle": "2025-12-25T19:19:04.160523Z",
     "shell.execute_reply": "2025-12-25T19:19:04.159435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. Model Comparison\n",
      "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
      "============================================================\n",
      "\n",
      "Comparison Table:\n",
      "            Model  Test MSE  Test RÂ²\n",
      "Linear Regression  0.555892 0.575788\n",
      "  Ridge (Î±=100.0)  0.553266 0.577791\n",
      "   Lasso (Î±=0.01)  0.548255 0.581615\n",
      "\n",
      "ğŸ’¡ Quick Look - What to Notice in the Table Above:\n",
      "   - Look at the Test MSE column: Which model has the LOWEST MSE? (Lower is better!)\n",
      "   - Look at the Test RÂ² column: Which model has the HIGHEST RÂ²? (Higher is better!)\n",
      "   - Notice: All three models have SIMILAR performance (values are close to each other)\n",
      "   - Notice: The differences are SMALL - this is normal and realistic!\n",
      "   - Notice: Lasso has the best MSE (0.5483) and RÂ² (0.5816) - regularization helped!\n",
      "   - ğŸ’¡ Learning point: Small improvements (0.0076 MSE difference) are meaningful in practice!\n",
      "   - Regularization's value isn't always huge performance gains - it's about stability and robustness!\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ Interpreting the Comparison | ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Best Model by MSE: Lasso (Î±=0.01)\n",
      "   - Lowest error: 0.5483\n",
      "   - This model has the smallest prediction errors\n",
      "\n",
      "ğŸ“Š Best Model by RÂ²: Lasso (Î±=0.01)\n",
      "   - Highest RÂ²: 0.5816\n",
      "   - This model explains the most variance\n",
      "\n",
      "ğŸ” Key Observations:\n",
      "   - âœ… All models perform similarly (MSE difference: 0.0076)\n",
      "   - Regularization shows SMALL improvements - this is actually normal and realistic!\n",
      "   - Why small changes? The original Linear Regression model wasn't heavily overfitting\n",
      "   - This teaches us: Regularization doesn't always create dramatic improvements\n",
      "   - But regularization still helps: It stabilizes coefficients and prevents overfitting!\n",
      "   - Even small improvements matter in real-world applications\n",
      "   - âœ… RÂ² scores are very close (difference: 0.0058)\n",
      "\n",
      "ğŸ“š What This Teaches Us:\n",
      "   - Compare models using multiple metrics (MSE and RÂ²)\n",
      "   - Lower MSE = better predictions (less error)\n",
      "   - Higher RÂ² = better fit (explains more variance)\n",
      "   - Regularization (Ridge/Lasso) helps when there's overfitting\n",
      "   - âš ï¸ Important: Small improvements (like 0.0076 MSE difference) are NORMAL and REALISTIC!\n",
      "   - Not every dataset will show dramatic improvements - that's okay!\n",
      "   - Regularization's value: It stabilizes models and prevents overfitting, even if performance gains are modest\n",
      "   - Lasso has advantage: automatic feature selection (removes irrelevant features)\n",
      "   - In practice, regularization is about robustness and generalization, not just performance numbers\n",
      "\n",
      "ğŸ’¡ Lasso Feature Selection:\n",
      "   - Lasso used only 7/8 features\n",
      "   - Removed 1 features (set coefficients to 0)\n",
      "   - This is Lasso's unique advantage: automatic feature selection!\n",
      "   - Simpler model (fewer features) = easier to interpret\n"
     ]
    }
   ],
   "source": [
    "# 4. Comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. Model Comparison\")\n",
    "print(\"Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\")\n",
    "print(\"=\" * 60)\n",
    "# pd.DataFrame(data)\n",
    "# - pd.DataFrame(): Creates pandas DataFrame (2D table-like structure)\n",
    "# - data: Dictionary where keys become column names, values become column data\n",
    "#   - Each key-value pair: key = column name, value = list of values for that column\n",
    "# - Returns DataFrame with rows and columns\n",
    "# - DataFrame is the main pandas data structure (like Excel spreadsheet in Python)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', f'Ridge (Î±={best_ridge[\"alpha\"]})',\n",
    "              f'Lasso (Î±={best_lasso[\"alpha\"]})'],\n",
    "    'Test MSE': [lr_mse, best_ridge['mse'], best_lasso['mse']],\n",
    "    'Test RÂ²': [lr_r2, best_ridge['r2'], best_lasso['r2']]\n",
    "})\n",
    "print(\"\\nComparison Table:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ’¡ Quick Look - What to Notice in the Table Above:\")\n",
    "print(\"   - Look at the Test MSE column: Which model has the LOWEST MSE? (Lower is better!)\")\n",
    "print(\"   - Look at the Test RÂ² column: Which model has the HIGHEST RÂ²? (Higher is better!)\")\n",
    "print(\"   - Notice: All three models have SIMILAR performance (values are close to each other)\")\n",
    "print(\"   - Notice: The differences are SMALL - this is normal and realistic!\")\n",
    "print(\"   - Notice: Lasso has the best MSE (0.5483) and RÂ² (0.5816) - regularization helped!\")\n",
    "print(\"   - ğŸ’¡ Learning point: Small improvements (0.0076 MSE difference) are meaningful in practice!\")\n",
    "print(\"   - Regularization's value isn't always huge performance gains - it's about stability and robustness!\")\n",
    "\n",
    "# Add interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¡ Interpreting the Comparison | ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find best model\n",
    "best_mse_idx = comparison['Test MSE'].idxmin()  # Lower MSE is better\n",
    "best_r2_idx = comparison['Test RÂ²'].idxmax()    # Higher RÂ² is better (FIXED: was idxmin)\n",
    "best_model_mse = comparison.loc[best_mse_idx, 'Model']\n",
    "best_model_r2 = comparison.loc[best_r2_idx, 'Model']\n",
    "\n",
    "print(f\"\\nğŸ“Š Best Model by MSE: {best_model_mse}\")\n",
    "print(f\"   - Lowest error: {comparison['Test MSE'].min():.4f}\")\n",
    "print(f\"   - This model has the smallest prediction errors\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Best Model by RÂ²: {best_model_r2}\")\n",
    "print(f\"   - Highest RÂ²: {comparison['Test RÂ²'].max():.4f}\")\n",
    "print(f\"   - This model explains the most variance\")\n",
    "\n",
    "print(f\"\\nğŸ” Key Observations:\")\n",
    "mse_diff = comparison['Test MSE'].max() - comparison['Test MSE'].min()\n",
    "r2_diff = comparison['Test RÂ²'].max() - comparison['Test RÂ²'].min()\n",
    "\n",
    "if mse_diff < 0.01:\n",
    "    print(f\"   - âœ… All models perform similarly (MSE difference: {mse_diff:.4f})\")\n",
    "    print(f\"   - Regularization shows SMALL improvements - this is actually normal and realistic!\")\n",
    "    print(f\"   - Why small changes? The original Linear Regression model wasn't heavily overfitting\")\n",
    "    print(f\"   - This teaches us: Regularization doesn't always create dramatic improvements\")\n",
    "    print(f\"   - But regularization still helps: It stabilizes coefficients and prevents overfitting!\")\n",
    "    print(f\"   - Even small improvements matter in real-world applications\")\n",
    "else:\n",
    "    print(f\"   - âš ï¸  Significant performance difference (MSE range: {mse_diff:.4f})\")\n",
    "    print(f\"   - Regularization {'improved' if best_model_mse != 'Linear Regression' else 'did not improve'} performance\")\n",
    "    print(f\"   - This suggests the original model had overfitting issues that regularization solved!\")\n",
    "\n",
    "if r2_diff < 0.01:\n",
    "    print(f\"   - âœ… RÂ² scores are very close (difference: {r2_diff:.4f})\")\n",
    "else:\n",
    "    print(f\"   - âš ï¸  RÂ² scores differ (range: {r2_diff:.4f})\")\n",
    "\n",
    "print(f\"\\nğŸ“š What This Teaches Us:\")\n",
    "print(f\"   - Compare models using multiple metrics (MSE and RÂ²)\")\n",
    "print(f\"   - Lower MSE = better predictions (less error)\")\n",
    "print(f\"   - Higher RÂ² = better fit (explains more variance)\")\n",
    "print(f\"   - Regularization (Ridge/Lasso) helps when there's overfitting\")\n",
    "print(f\"   - âš ï¸ Important: Small improvements (like 0.0076 MSE difference) are NORMAL and REALISTIC!\")\n",
    "print(f\"   - Not every dataset will show dramatic improvements - that's okay!\")\n",
    "print(f\"   - Regularization's value: It stabilizes models and prevents overfitting, even if performance gains are modest\")\n",
    "print(f\"   - Lasso has advantage: automatic feature selection (removes irrelevant features)\")\n",
    "print(f\"   - In practice, regularization is about robustness and generalization, not just performance numbers\")\n",
    "\n",
    "# Check if Lasso removed features\n",
    "if best_lasso['n_features'] < len(X_data.columns):\n",
    "    print(f\"\\nğŸ’¡ Lasso Feature Selection:\")\n",
    "    print(f\"   - Lasso used only {best_lasso['n_features']}/{len(X_data.columns)} features\")\n",
    "    print(f\"   - Removed {len(X_data.columns) - best_lasso['n_features']} features (set coefficients to 0)\")\n",
    "    print(f\"   - This is Lasso's unique advantage: automatic feature selection!\")\n",
    "    print(f\"   - Simpler model (fewer features) = easier to interpret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.162344Z",
     "iopub.status.busy": "2025-12-25T19:19:04.162193Z",
     "iopub.status.idle": "2025-12-25T19:19:04.170182Z",
     "shell.execute_reply": "2025-12-25T19:19:04.169521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "5. Coefficient Comparison\n",
      "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª\n",
      "============================================================\n",
      "\n",
      "Coefficient Comparison (first 5 features):\n",
      "   Feature    Linear     Ridge     Lasso\n",
      "    MedInc  0.854383  0.848139  0.800957\n",
      "  HouseAge  0.122546  0.129512  0.127087\n",
      "  AveRooms -0.294410 -0.274522 -0.162759\n",
      " AveBedrms  0.339259  0.314804  0.206207\n",
      "Population -0.002308 -0.000024 -0.000000\n",
      "\n",
      "ğŸ’¡ Quick Look - What to Notice in the Table Above:\n",
      "   - Look at the 'Population' row: Linear= -0.002308, Ridge= -0.000024, Lasso= -0.000000\n",
      "   - Notice: Lasso set Population coefficient to EXACTLY 0.000000 (removed this feature!)\n",
      "   - Notice: Ridge shrunk it to -0.000024 (very small, but NOT zero - still keeps the feature)\n",
      "   - Look at other features: Compare how Ridge shrinks vs Lasso removes coefficients\n",
      "   - This shows Lasso's feature selection power - it can completely remove features! ğŸ¯\n",
      "\n",
      "Lasso shrinks many coefficients to zero (feature selection)\n",
      "Ù„Ø§Ø³Ùˆ ÙŠÙ‚Ù„Øµ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„ØµÙØ± (Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª)\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ Understanding Coefficient Differences | ÙÙ‡Ù… Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Coefficient Analysis:\n",
      "   - Linear Regression: 1 coefficients near zero\n",
      "   - Ridge: 1 coefficients near zero (shrinks but keeps all)\n",
      "   - Lasso: 1 coefficients set to zero (feature selection!)\n",
      "\n",
      "ğŸ” What This Shows:\n",
      "   - Ridge: Shrinks coefficients toward 0 but keeps all features\n",
      "   - Lasso: Can completely remove features (coefficient = 0)\n",
      "   - Lasso's sparsity: Only 7 features have non-zero coefficients\n",
      "\n",
      "ğŸ“Š Coefficient Shrinking:\n",
      "   - Ridge average change: 0.0250\n",
      "   - Lasso average change: 0.0695\n",
      "   - Lasso shrinks coefficients more aggressively\n",
      "\n",
      "ğŸ“š What This Teaches Us:\n",
      "   - Regularization reduces coefficient magnitudes (prevents overfitting)\n",
      "   - Ridge: Gentle shrinking, keeps all features\n",
      "   - Lasso: Aggressive shrinking, removes irrelevant features\n",
      "   - Smaller coefficients = simpler model = better generalization\n",
      "   - Lasso is useful when you have many features (automatic feature selection)\n",
      "   - Ridge is useful when all features might be relevant\n"
     ]
    }
   ],
   "source": [
    "# 5. Coefficient Comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"5. Coefficient Comparison\")\n",
    "print(\"Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª\")\n",
    "print(\"=\" * 60)\n",
    "# pd.DataFrame(data)\n",
    "# - pd.DataFrame(): Creates pandas DataFrame (2D table-like structure)\n",
    "# - data: Dictionary where keys become column names, values become column data\n",
    "#   - Each key-value pair: key = column name, value = list of values for that column\n",
    "# - Returns DataFrame with rows and columns\n",
    "# - DataFrame is the main pandas data structure (like Excel spreadsheet in Python)\n",
    "\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': X_data.columns,\n",
    "    'Linear': lr.coef_,\n",
    "    'Ridge': best_ridge['model'].coef_,\n",
    "    'Lasso': best_lasso['model'].coef_\n",
    "})\n",
    "print(\"\\nCoefficient Comparison (first 5 features):\")\n",
    "print(coef_comparison.head().to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ’¡ Quick Look - What to Notice in the Table Above:\")\n",
    "print(\"   - Look at the 'Population' row: Linear= -0.002308, Ridge= -0.000024, Lasso= -0.000000\")\n",
    "print(\"   - Notice: Lasso set Population coefficient to EXACTLY 0.000000 (removed this feature!)\")\n",
    "print(\"   - Notice: Ridge shrunk it to -0.000024 (very small, but NOT zero - still keeps the feature)\")\n",
    "print(\"   - Look at other features: Compare how Ridge shrinks vs Lasso removes coefficients\")\n",
    "print(\"   - This shows Lasso's feature selection power - it can completely remove features! ğŸ¯\")\n",
    "print(\"\\nLasso shrinks many coefficients to zero (feature selection)\")\n",
    "print(\"Ù„Ø§Ø³Ùˆ ÙŠÙ‚Ù„Øµ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„ØµÙØ± (Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª)\")\n",
    "\n",
    "# Add interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¡ Understanding Coefficient Differences | ÙÙ‡Ù… Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count zero coefficients\n",
    "lasso_zeros = (np.abs(best_lasso['model'].coef_) < 0.01).sum()\n",
    "ridge_zeros = (np.abs(best_ridge['model'].coef_) < 0.01).sum()\n",
    "linear_zeros = (np.abs(lr.coef_) < 0.01).sum()\n",
    "\n",
    "print(f\"\\nğŸ“Š Coefficient Analysis:\")\n",
    "print(f\"   - Linear Regression: {linear_zeros} coefficients near zero\")\n",
    "print(f\"   - Ridge: {ridge_zeros} coefficients near zero (shrinks but keeps all)\")\n",
    "print(f\"   - Lasso: {lasso_zeros} coefficients set to zero (feature selection!)\")\n",
    "\n",
    "print(f\"\\nğŸ” What This Shows:\")\n",
    "print(f\"   - Ridge: Shrinks coefficients toward 0 but keeps all features\")\n",
    "print(f\"   - Lasso: Can completely remove features (coefficient = 0)\")\n",
    "print(f\"   - Lasso's sparsity: Only {best_lasso['n_features']} features have non-zero coefficients\")\n",
    "\n",
    "# Compare coefficient magnitudes\n",
    "coef_diff_ridge = np.abs(lr.coef_ - best_ridge['model'].coef_)\n",
    "coef_diff_lasso = np.abs(lr.coef_ - best_lasso['model'].coef_)\n",
    "\n",
    "print(f\"\\nğŸ“Š Coefficient Shrinking:\")\n",
    "print(f\"   - Ridge average change: {coef_diff_ridge.mean():.4f}\")\n",
    "print(f\"   - Lasso average change: {coef_diff_lasso.mean():.4f}\")\n",
    "if coef_diff_lasso.mean() > coef_diff_ridge.mean():\n",
    "    print(f\"   - Lasso shrinks coefficients more aggressively\")\n",
    "\n",
    "print(f\"\\nğŸ“š What This Teaches Us:\")\n",
    "print(f\"   - Regularization reduces coefficient magnitudes (prevents overfitting)\")\n",
    "print(f\"   - Ridge: Gentle shrinking, keeps all features\")\n",
    "print(f\"   - Lasso: Aggressive shrinking, removes irrelevant features\")\n",
    "print(f\"   - Smaller coefficients = simpler model = better generalization\")\n",
    "print(f\"   - Lasso is useful when you have many features (automatic feature selection)\")\n",
    "print(f\"   - Ridge is useful when all features might be relevant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Coefficient Comparison | Ø§Ù„Ø®Ø·ÙˆØ© 5: Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª\n",
    "\n",
    "**BEFORE**: We've compared model performance (MSE, RÂ²). But what's happening \"under the hood\" with the coefficients?\n",
    "\n",
    "**AFTER**: We'll see how Ridge and Lasso actually change the coefficients compared to Linear Regression!\n",
    "\n",
    "**Why compare coefficients?**\n",
    "- **Understand regularization's effect**: How does it shrink coefficients?\n",
    "- **See Ridge vs Lasso difference**: Ridge shrinks smoothly, Lasso can set to zero\n",
    "- **Verify feature selection**: Lasso should have some coefficients exactly equal to zero\n",
    "- **Better intuition**: Seeing coefficient changes helps understand why regularization works!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Decision Framework - When to Use Ridge vs Lasso | Ø§Ù„Ø®Ø·ÙˆØ© 7: Ø¥Ø·Ø§Ø± Ø§Ù„Ù‚Ø±Ø§Ø± - Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù… Ø±ÙŠØ¯Ø¬ Ù…Ù‚Ø§Ø¨Ù„ Ù„Ø§Ø³Ùˆ\n",
    "\n",
    "**BEFORE**: You've learned how to build Ridge and Lasso models, but when should you use each one?\n",
    "\n",
    "**AFTER**: You'll have a clear decision framework to choose between Ridge, Lasso, or regular Linear Regression!\n",
    "\n",
    "**Why this matters**: Using the wrong regularization method can:\n",
    "- **Miss important features** â†’ Lasso removes features you need\n",
    "- **Keep irrelevant features** â†’ Ridge keeps all features even when some are noise\n",
    "- **Poor performance** â†’ Wrong method leads to worse predictions\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Decision Framework: Ridge vs Lasso vs Linear Regression | Ø¥Ø·Ø§Ø± Ø§Ù„Ù‚Ø±Ø§Ø±: Ø±ÙŠØ¯Ø¬ Ù…Ù‚Ø§Ø¨Ù„ Ù„Ø§Ø³Ùˆ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ\n",
    "\n",
    "**Key Question**: Should I use **LINEAR REGRESSION**, **RIDGE**, or **LASSO**?\n",
    "\n",
    "#### Decision Tree:\n",
    "\n",
    "```\n",
    "Do you have overfitting?\n",
    "â”œâ”€ NO â†’ Use LINEAR REGRESSION âœ…\n",
    "â”‚   â””â”€ Why? No need for regularization if model generalizes well\n",
    "â”‚\n",
    "â””â”€ YES â†’ Check your situation:\n",
    "    â”œâ”€ Many features (>20)? â†’ Continue to next step\n",
    "    â”‚\n",
    "    â”œâ”€ Need feature selection? â†’ Use LASSO âœ…\n",
    "    â”‚   â””â”€ Why? Lasso removes irrelevant features automatically\n",
    "    â”‚\n",
    "    â”œâ”€ Multicollinearity present? â†’ Use RIDGE âœ…\n",
    "    â”‚   â””â”€ Why? Ridge handles correlated features better\n",
    "    â”‚\n",
    "    â”œâ”€ All features important? â†’ Use RIDGE âœ…\n",
    "    â”‚   â””â”€ Why? Ridge keeps all features, just shrinks them\n",
    "    â”‚\n",
    "    â””â”€ Want interpretability? â†’ Use LASSO âœ…\n",
    "        â””â”€ Why? Fewer features = simpler model\n",
    "```\n",
    "\n",
    "#### Detailed Decision Process:\n",
    "\n",
    "```\n",
    "Step 1: Check if regularization is needed\n",
    "â”œâ”€ Train RÂ² >> Test RÂ²? â†’ YES, overfitting present\n",
    "â”‚   â””â”€ Use Ridge or Lasso\n",
    "â”‚\n",
    "â””â”€ Train RÂ² â‰ˆ Test RÂ²? â†’ NO, no overfitting\n",
    "    â””â”€ Use Linear Regression (simpler)\n",
    "\n",
    "Step 2: If overfitting, choose regularization type\n",
    "â”œâ”€ Do you have many features (>20)?\n",
    "â”‚   â”œâ”€ YES â†’ Continue to step 3\n",
    "â”‚   â””â”€ NO â†’ Try Ridge first (simpler)\n",
    "â”‚\n",
    "â”œâ”€ Do you need feature selection?\n",
    "â”‚   â”œâ”€ YES â†’ Use LASSO\n",
    "â”‚   â”‚   â””â”€ Why? Automatically removes irrelevant features\n",
    "â”‚   â””â”€ NO â†’ Continue to step 4\n",
    "â”‚\n",
    "â”œâ”€ Is there multicollinearity (correlated features)?\n",
    "â”‚   â”œâ”€ YES â†’ Use RIDGE\n",
    "â”‚   â”‚   â””â”€ Why? Ridge handles correlations better\n",
    "â”‚   â””â”€ NO â†’ Continue to step 5\n",
    "â”‚\n",
    "â””â”€ Are all features potentially important?\n",
    "    â”œâ”€ YES â†’ Use RIDGE\n",
    "    â”‚   â””â”€ Why? Keeps all features, just shrinks them\n",
    "    â””â”€ NO â†’ Use LASSO\n",
    "        â””â”€ Why? Removes irrelevant features\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Comparison Table: Linear vs Ridge vs Lasso | Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
    "\n",
    "| Method | When to Use | Pros | Cons | Example |\n",
    "|--------|-------------|------|------|---------|\n",
    "| **Linear Regression** | No overfitting, few features, interpretable | â€¢ Simple<br>â€¢ Fast<br>â€¢ Interpretable<br>â€¢ No hyperparameters | â€¢ Can overfit<br>â€¢ Sensitive to outliers<br>â€¢ Can't handle many features | Small dataset, < 10 features |\n",
    "| **Ridge (L2)** | Overfitting, multicollinearity, all features important | â€¢ Prevents overfitting<br>â€¢ Handles multicollinearity<br>â€¢ Keeps all features<br>â€¢ Stable | â€¢ Doesn't remove features<br>â€¢ All features contribute<br>â€¢ Less interpretable | Many correlated features, all potentially important |\n",
    "| **Lasso (L1)** | Overfitting, many features, need feature selection | â€¢ Prevents overfitting<br>â€¢ Automatic feature selection<br>â€¢ More interpretable<br>â€¢ Simpler models | â€¢ Can remove important features<br>â€¢ Unstable with correlated features<br>â€¢ May over-regularize | High-dimensional data, feature selection needed |\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… When to Use Each Method | Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù… ÙƒÙ„ Ø·Ø±ÙŠÙ‚Ø©\n",
    "\n",
    "#### Use Linear Regression when:\n",
    "1. **No Overfitting** âœ…\n",
    "   - Train and test performance are similar\n",
    "   - Model generalizes well\n",
    "   - **Example**: Small dataset, few features, good performance\n",
    "\n",
    "2. **Few Features** âœ…\n",
    "   - Less than 10-15 features\n",
    "   - All features are important\n",
    "   - **Example**: House price from size, bedrooms, age\n",
    "\n",
    "3. **Interpretability Critical** âœ…\n",
    "   - Need to understand exact coefficients\n",
    "   - No regularization complexity needed\n",
    "   - **Example**: Medical diagnosis, regulatory compliance\n",
    "\n",
    "#### Use Ridge Regression when:\n",
    "1. **Overfitting Present** âœ…\n",
    "   - Train RÂ² much higher than test RÂ²\n",
    "   - Model memorizes training data\n",
    "   - **Example**: Polynomial regression with high degree\n",
    "\n",
    "2. **Multicollinearity** âœ…\n",
    "   - Features are highly correlated\n",
    "   - Ridge handles correlations better than Lasso\n",
    "   - **Example**: House features (size, rooms, area all correlated)\n",
    "\n",
    "3. **All Features Important** âœ…\n",
    "   - Don't want to remove any features\n",
    "   - Just want to shrink coefficients\n",
    "   - **Example**: All features are domain-relevant\n",
    "\n",
    "4. **Many Features** âœ…\n",
    "   - 20+ features\n",
    "   - Need regularization but want to keep all features\n",
    "   - **Example**: 50+ features from feature engineering\n",
    "\n",
    "#### Use Lasso Regression when:\n",
    "1. **Feature Selection Needed** âœ…\n",
    "   - Many features, some are noise\n",
    "   - Want automatic feature selection\n",
    "   - **Example**: 100+ features, need to find important ones\n",
    "\n",
    "2. **Sparse Solution** âœ…\n",
    "   - Expect only few features matter\n",
    "   - Want interpretable model\n",
    "   - **Example**: Gene expression data (few genes matter)\n",
    "\n",
    "3. **High-Dimensional Data** âœ…\n",
    "   - More features than samples\n",
    "   - Need to reduce dimensionality\n",
    "   - **Example**: Text data with thousands of features\n",
    "\n",
    "---\n",
    "\n",
    "### âŒ When NOT to Use Each Method | Ù…ØªÙ‰ Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ÙƒÙ„ Ø·Ø±ÙŠÙ‚Ø©\n",
    "\n",
    "#### Don't use Linear Regression when:\n",
    "1. **Severe Overfitting** âŒ\n",
    "   - Train RÂ² >> Test RÂ²\n",
    "   - **Use Instead**: Ridge or Lasso\n",
    "\n",
    "2. **Many Features** âŒ\n",
    "   - 50+ features\n",
    "   - **Use Instead**: Ridge or Lasso\n",
    "\n",
    "3. **Multicollinearity** âŒ\n",
    "   - Highly correlated features\n",
    "   - **Use Instead**: Ridge\n",
    "\n",
    "#### Don't use Ridge when:\n",
    "1. **Feature Selection Needed** âŒ\n",
    "   - Want to remove irrelevant features\n",
    "   - **Use Instead**: Lasso\n",
    "\n",
    "2. **Sparse Solution Expected** âŒ\n",
    "   - Only few features matter\n",
    "   - **Use Instead**: Lasso\n",
    "\n",
    "#### Don't use Lasso when:\n",
    "1. **Multicollinearity Present** âŒ\n",
    "   - Features are highly correlated\n",
    "   - Lasso may randomly select one\n",
    "   - **Use Instead**: Ridge\n",
    "\n",
    "2. **All Features Important** âŒ\n",
    "   - Don't want to remove any features\n",
    "   - **Use Instead**: Ridge\n",
    "\n",
    "3. **More Features than Samples** âŒ\n",
    "   - Lasso can select at most n features (n = samples)\n",
    "   - **Use Instead**: Ridge or Elastic Net\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Real-World Examples | Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\n",
    "\n",
    "#### Example 1: House Price Prediction (10 features) âœ… LINEAR REGRESSION\n",
    "- **Features**: Size, bedrooms, age, location, etc. (10 total)\n",
    "- **Overfitting**: No (train RÂ² = 0.85, test RÂ² = 0.83)\n",
    "- **Decision**: âœ… Use Linear Regression\n",
    "- **Reasoning**: No overfitting, few features, all important\n",
    "\n",
    "#### Example 2: House Price Prediction (50 features) âœ… RIDGE\n",
    "- **Features**: Size, bedrooms, age, location, neighborhood stats, etc. (50 total)\n",
    "- **Overfitting**: Yes (train RÂ² = 0.95, test RÂ² = 0.75)\n",
    "- **Multicollinearity**: Yes (size, rooms, area all correlated)\n",
    "- **Decision**: âœ… Use Ridge Regression\n",
    "- **Reasoning**: Overfitting, many features, multicollinearity, all features potentially important\n",
    "\n",
    "#### Example 3: Gene Expression Analysis (1000 features) âœ… LASSO\n",
    "- **Features**: 1000 genes, only 10-20 matter\n",
    "- **Overfitting**: Yes (train RÂ² = 0.98, test RÂ² = 0.60)\n",
    "- **Feature Selection**: Critical (need to find important genes)\n",
    "- **Decision**: âœ… Use Lasso Regression\n",
    "- **Reasoning**: Many features, need feature selection, sparse solution expected\n",
    "\n",
    "#### Example 4: Sales Prediction (30 features, some noise) âš ï¸ TRY BOTH\n",
    "- **Features**: 30 features, some are noise\n",
    "- **Overfitting**: Yes (train RÂ² = 0.92, test RÂ² = 0.78)\n",
    "- **Decision**: âš ï¸ Try both Ridge and Lasso, compare\n",
    "- **Reasoning**: Overfitting present, some features may be noise, try both methods\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Key Takeaways | Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "\n",
    "1. **Start with Linear Regression** - Always try simplest model first\n",
    "2. **Check for overfitting** - Compare train vs test performance\n",
    "3. **Ridge for multicollinearity** - When features are correlated\n",
    "4. **Lasso for feature selection** - When you need to remove features\n",
    "5. **Tune alpha** - Critical hyperparameter for both methods\n",
    "6. **Scale features first** - Regularization requires scaled features\n",
    "7. **Try both** - Sometimes try Ridge and Lasso, pick the best\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Practice Decision-Making | Ù…Ù…Ø§Ø±Ø³Ø© Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±\n",
    "\n",
    "**Scenario 1**: Predicting house prices with 8 features (size, bedrooms, age, etc.)\n",
    "- **Overfitting**: No (train RÂ² = 0.88, test RÂ² = 0.86)\n",
    "- **Decision**: âœ… Linear Regression (no overfitting, few features)\n",
    "\n",
    "**Scenario 2**: Predicting sales with 50 features, many correlated\n",
    "- **Overfitting**: Yes (train RÂ² = 0.94, test RÂ² = 0.76)\n",
    "- **Multicollinearity**: Yes (many correlated features)\n",
    "- **Decision**: âœ… Ridge Regression (overfitting, multicollinearity, all features important)\n",
    "\n",
    "**Scenario 3**: Predicting disease from 500 gene expressions\n",
    "- **Overfitting**: Yes (train RÂ² = 0.97, test RÂ² = 0.65)\n",
    "- **Feature Selection**: Critical (only few genes matter)\n",
    "- **Decision**: âœ… Lasso Regression (many features, need feature selection, sparse solution)\n",
    "\n",
    "---\n",
    "\n",
    "**Connection to Next Steps**: \n",
    "- ğŸ““ **Example 2: Cross-Validation** - For proper evaluation of Ridge/Lasso models\n",
    "- ğŸ““ **Unit 3: Classification** - Same regularization concepts apply to classification\n",
    "- ğŸ““ **Unit 5, Example 1: Grid Search** - For tuning alpha hyperparameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â“ Common Student Questions | Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„Ù„Ø·Ù„Ø§Ø¨\n",
    "\n",
    "**Q: What's the difference between Ridge and Lasso?**\n",
    "- **Answer**: \n",
    "  - **Ridge (L2)**: Shrinks ALL coefficients toward zero, but keeps all features (no feature selection)\n",
    "  - **Lasso (L1)**: Shrinks some coefficients to EXACTLY zero (removes features - automatic feature selection!)\n",
    "  - **Key difference**: Ridge keeps all features, Lasso removes some features\n",
    "  - **Use Ridge**: When all features might be important, or multicollinearity present\n",
    "  - **Use Lasso**: When you need feature selection, or expect sparse solution\n",
    "\n",
    "**Q: What is alpha and how do I choose it?**\n",
    "- **Answer**: Alpha controls regularization strength:\n",
    "  - **Alpha = 0**: No regularization (same as Linear Regression)\n",
    "  - **Alpha = small (0.01, 0.1)**: Light regularization (slight shrinkage)\n",
    "  - **Alpha = large (1, 10, 100)**: Strong regularization (heavy shrinkage)\n",
    "  - **How to choose**: Use cross-validation (Unit 2, Example 2) to find optimal alpha\n",
    "  - **Rule of thumb**: Start with alpha=1, try 0.1, 1, 10, 100, pick best\n",
    "\n",
    "**Q: Why do I need to scale features before regularization?**\n",
    "- **Answer**: Regularization penalizes large coefficients:\n",
    "  - **Problem**: If features have different scales (age: 0-100, income: 0-100000), coefficients will be different sizes\n",
    "  - **Issue**: Regularization will unfairly penalize features with larger scales\n",
    "  - **Solution**: Scale all features to same range (StandardScaler) â†’ fair regularization\n",
    "  - **Rule**: ALWAYS scale features before Ridge/Lasso!\n",
    "\n",
    "**Q: When should I use Ridge vs Lasso?**\n",
    "- **Answer**: \n",
    "  - **Use Ridge**: Multicollinearity present, all features might be important, want to keep all features\n",
    "  - **Use Lasso**: Need feature selection, many features (some noise), expect sparse solution\n",
    "  - **Try both**: Compare performance, pick the one that works better for your data\n",
    "  - **Elastic Net**: Combines both (advanced, not covered here)\n",
    "\n",
    "**Q: Does regularization always improve performance?**\n",
    "- **Answer**: **Not always!** It depends:\n",
    "  - **If overfitting**: Regularization helps (reduces overfitting, improves test performance)\n",
    "  - **If no overfitting**: Regularization might hurt (unnecessary shrinkage)\n",
    "  - **Check**: Compare train vs test RÂ² - if similar, regularization might not help\n",
    "  - **Rule**: Use regularization when train RÂ² >> test RÂ² (overfitting detected)\n",
    "\n",
    "**Q: What happens if alpha is too high?**\n",
    "- **Answer**: **Underfitting** - model becomes too simple:\n",
    "  - **Problem**: Coefficients shrink too much â†’ model can't capture patterns\n",
    "  - **Sign**: Both train and test RÂ² are low (model too simple)\n",
    "  - **Solution**: Decrease alpha (try 0.1, 0.01, etc.)\n",
    "  - **Balance**: Need alpha high enough to prevent overfitting, but not too high to cause underfitting\n",
    "\n",
    "**Q: Can I use Ridge/Lasso for classification?**\n",
    "- **Answer**: **Yes!** Regularization works for both regression and classification:\n",
    "  - **Ridge/Lasso Regression**: For continuous targets (prices, temperatures)\n",
    "  - **Ridge/Lasso Logistic Regression**: For categorical targets (yes/no, classes)\n",
    "  - **Same concept**: Regularization prevents overfitting in both cases\n",
    "  - **We'll see this**: In Unit 3 (Classification) with regularized logistic regression\n",
    "\n",
    "**Q: How do I know if regularization helped?**\n",
    "- **Answer**: Compare before and after:\n",
    "  - **Before (Linear Regression)**: Train RÂ² = 0.95, Test RÂ² = 0.75 (overfitting!)\n",
    "  - **After (Ridge/Lasso)**: Train RÂ² = 0.85, Test RÂ² = 0.82 (better generalization!)\n",
    "  - **Good sign**: Test RÂ² improved, train-test gap reduced\n",
    "  - **Bad sign**: Both train and test RÂ² decreased (alpha too high, underfitting)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualization | Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø§Ù„ØªØµÙˆØ±\n",
    "\n",
    "**BEFORE**: We've compared models and coefficients using numbers. Now let's visualize the results!\n",
    "\n",
    "**AFTER**: We'll create plots showing:\n",
    "1. How alpha affects model performance (MSE vs Alpha)\n",
    "2. How coefficients differ between models (coefficient magnitudes)\n",
    "\n",
    "**Why visualize?**\n",
    "- **See patterns visually**: Graphs make it easier to understand the relationships\n",
    "- **Compare at a glance**: Visual comparison is often clearer than numbers\n",
    "- **Alpha effect**: See how different alpha values affect Ridge and Lasso\n",
    "- **Coefficient differences**: Visualize how Ridge shrinks vs Lasso removes coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T19:19:04.171869Z",
     "iopub.status.busy": "2025-12-25T19:19:04.171773Z",
     "iopub.status.idle": "2025-12-25T19:19:04.677282Z",
     "shell.execute_reply": "2025-12-25T19:19:04.677074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "6. Visualization\n",
      "Ø§Ù„ØªØµÙˆØ±\n",
      "============================================================\n",
      "\n",
      "âœ“ Plot saved as 'ridge_lasso_comparison.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ Understanding the Visualization:\n",
      "   ğŸ“Š Left Plot (Regularization vs Model Performance):\n",
      "      - Red dashed line = Linear Regression (baseline, Î± = 0)\n",
      "      - Blue line with circles = Ridge regression with different alpha values\n",
      "      - Orange line with squares = Lasso regression with different alpha values\n",
      "\n",
      "   âœ… IMPORTANT: Ridge and Linear Regression OVERLAP - This is CORRECT, not an error!\n",
      "      - Notice: Ridge line STARTS at exactly the same point as Linear Regression (MSE = 0.5559)\n",
      "      - Why? Because Î± = 0.01 means almost NO regularization (very close to Î± = 0)\n",
      "      - Mathematical fact: As Î± â†’ 0, Ridge â†’ Linear Regression (they become identical!)\n",
      "      - This perfectly demonstrates: Low alpha = almost no regularization = same as Linear Regression\n",
      "      - As alpha increases (10, 100), Ridge line moves away slightly (regularization kicks in)\n",
      "      - Lasso shows bigger changes because it removes features entirely!\n",
      "      - This visualization confirms what we learned: alpha controls regularization strength!\n",
      "\n",
      "   ğŸ“Š Right Plot (Coefficient Comparison):\n",
      "      - Shows absolute coefficient values for the three models\n",
      "      - Ridge bars are slightly shorter than Linear (coefficients shrunk)\n",
      "      - Lasso bars show some zeros (features removed!)\n",
      "      - This visualizes how regularization affects coefficients!\n",
      "\n",
      "============================================================\n",
      "Example 1 Complete! âœ“\n",
      "Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ 1! âœ“\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 6. Visualization\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"6. Visualization\")\n",
    "print(\"Ø§Ù„ØªØµÙˆØ±\")\n",
    "print(\"=\" * 60)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Alpha vs MSE\n",
    "axes[0].semilogx([r['alpha'] for r in ridge_results],\n",
    "                 [r['mse'] for r in ridge_results],\n",
    "                 'o-', label='Ridge', linewidth=2)\n",
    "axes[0].semilogx([l['alpha'] for l in lasso_results],\n",
    "                 [l['mse'] for l in lasso_results],\n",
    "                 's-', label='Lasso', linewidth=2)\n",
    "axes[0].axhline(lr_mse, color='r', linestyle='--', label='Linear Regression')\n",
    "axes[0].set_xlabel('Alpha (Regularization Strength)')\n",
    "axes[0].set_ylabel('Test MSE')\n",
    "axes[0].set_title('Regularization vs Model Performance')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Coefficient magnitudes\n",
    "n_features = len(lr.coef_)  # Get actual number of features from the model\n",
    "axes[1].bar(range(n_features), np.abs(lr.coef_), alpha=0.7, label='Linear', width=0.25)\n",
    "axes[1].bar([i + 0.25 for i in range(n_features)], np.abs(best_ridge['model'].coef_),\n",
    "            alpha=0.7, label='Ridge', width=0.25)\n",
    "axes[1].bar([i + 0.5 for i in range(n_features)], np.abs(best_lasso['model'].coef_),\n",
    "            alpha=0.7, label='Lasso', width=0.25)\n",
    "axes[1].set_xlabel('Feature Index')\n",
    "axes[1].set_ylabel('Absolute Coefficient Value')\n",
    "axes[1].set_title('Coefficient Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('ridge_lasso_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nâœ“ Plot saved as 'ridge_lasso_comparison.png'\")\n",
    "plt.show()\n",
    "\n",
    "# Add explanation about the visualization\n",
    "print(\"\\nğŸ’¡ Understanding the Visualization:\")\n",
    "print(\"   ğŸ“Š Left Plot (Regularization vs Model Performance):\")\n",
    "print(\"      - Red dashed line = Linear Regression (baseline, Î± = 0)\")\n",
    "print(\"      - Blue line with circles = Ridge regression with different alpha values\")\n",
    "print(\"      - Orange line with squares = Lasso regression with different alpha values\")\n",
    "print(\"\\n   âœ… IMPORTANT: Ridge and Linear Regression OVERLAP - This is CORRECT, not an error!\")\n",
    "print(\"      - Notice: Ridge line STARTS at exactly the same point as Linear Regression (MSE = 0.5559)\")\n",
    "print(\"      - Why? Because Î± = 0.01 means almost NO regularization (very close to Î± = 0)\")\n",
    "print(\"      - Mathematical fact: As Î± â†’ 0, Ridge â†’ Linear Regression (they become identical!)\")\n",
    "print(\"      - This perfectly demonstrates: Low alpha = almost no regularization = same as Linear Regression\")\n",
    "print(\"      - As alpha increases (10, 100), Ridge line moves away slightly (regularization kicks in)\")\n",
    "print(\"      - Lasso shows bigger changes because it removes features entirely!\")\n",
    "print(\"      - This visualization confirms what we learned: alpha controls regularization strength!\")\n",
    "print(\"\\n   ğŸ“Š Right Plot (Coefficient Comparison):\")\n",
    "print(\"      - Shows absolute coefficient values for the three models\")\n",
    "print(\"      - Ridge bars are slightly shorter than Linear (coefficients shrunk)\")\n",
    "print(\"      - Lasso bars show some zeros (features removed!)\")\n",
    "print(\"      - This visualizes how regularization affects coefficients!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 1 Complete! âœ“\")\n",
    "print(\"Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ 1! âœ“\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
