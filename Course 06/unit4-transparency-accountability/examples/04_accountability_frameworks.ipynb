{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Accountability Frameworks | Ø£Ø·Ø± Ø§Ù„Ù…Ø³Ø§Ø¡Ù„Ø©\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Accountability Frameworks | Ø£Ø·Ø± Ø§Ù„Ù…Ø³Ø§Ø¡Ù„Ø©\n",
    "\n",
    "## ğŸš¨ THE PROBLEM: We Need Accountability for AI Decisions | Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù†Ø­ØªØ§Ø¬ Ø§Ù„Ù…Ø³Ø§Ø¡Ù„Ø© Ø¹Ù† Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned counterfactual analysis for \"what if\" explanations. But we discovered:\n",
    "\n",
    "**How do we ensure accountability and responsibility for AI decisions?**\n",
    "\n",
    "**The Problem**: Transparent AI systems also need:\n",
    "- âŒ **Accountability frameworks** (who is responsible?)\n",
    "- âŒ **Responsibility mechanisms** (how to assign responsibility?)\n",
    "- âŒ **Audit trails** (how to track decisions?)\n",
    "- âŒ **Stakeholder accountability** (who answers for outcomes?)\n",
    "\n",
    "**We've learned:**\n",
    "- âœ… How to use SHAP for explanations (Notebook 1)\n",
    "- âœ… How to use LIME for fast explanations (Notebook 2)\n",
    "- âœ… How to use counterfactuals for \"what if\" scenarios (Notebook 3)\n",
    "- âœ… Multiple explanation methods\n",
    "\n",
    "**But we haven't learned:**\n",
    "- âŒ How to **define stakeholder responsibilities**\n",
    "- âŒ How to **create audit trails**\n",
    "- âŒ How to **establish responsibility mechanisms**\n",
    "- âŒ How to **ensure accountability** for AI decisions\n",
    "\n",
    "**We need accountability frameworks** to:\n",
    "1. Define stakeholder responsibilities\n",
    "2. Create audit trails\n",
    "3. Establish responsibility mechanisms\n",
    "4. Enable accountability for AI decisions\n",
    "\n",
    "**This notebook solves that problem** by teaching you accountability frameworks for AI systems!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 1: SHAP Explanations** - Understanding explainability\n",
    "- âœ… **Example 2: LIME Explanations** - Understanding local explanations\n",
    "- âœ… **Example 3: Counterfactual Analysis** - Understanding \"what if\" scenarios\n",
    "- âœ… **Basic Python knowledge**: Functions, data manipulation\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why accountability matters\n",
    "- Knowing how to structure accountability frameworks\n",
    "- Understanding stakeholder responsibilities\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is the FOURTH example in Unit 4** - it teaches you accountability!\n",
    "\n",
    "**Why this example FOURTH?**\n",
    "- **Before** you can ensure accountability, you need explainability (Examples 1-3)\n",
    "- **Before** you can implement HITL, you need accountability structures\n",
    "- **Before** you can build transparent systems, you need accountability\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Example 1: SHAP Explanations (explainability)\n",
    "- ğŸ““ Example 2: LIME Explanations (local explanations)\n",
    "- ğŸ““ Example 3: Counterfactual Analysis (\"what if\" scenarios)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Example 5: Human-in-the-Loop (HITL approaches)\n",
    "- ğŸ““ Example 6: Transparency Tools (transparency frameworks)\n",
    "\n",
    "**Why this order?**\n",
    "1. Accountability provides **responsibility structures** (needed for ethical AI)\n",
    "2. Accountability teaches **stakeholder roles** (critical for governance)\n",
    "3. Accountability shows **audit mechanisms** (essential for transparency)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Who Is Responsible? | Ø§Ù„Ù‚ØµØ©: Ù…Ù† Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ØŸ\n",
    "\n",
    "Imagine you're using an AI system that makes a wrong decision. **Before** accountability frameworks, you wouldn't know who to hold responsible (developers? data scientists? users?). **After** implementing accountability frameworks, you have clear responsibilities, audit trails, and accountability mechanisms!\n",
    "\n",
    "Same with AI: **Before** we have explanations but no accountability, now we learn accountability frameworks - define responsibilities, create audit trails, establish accountability! **After** accountability frameworks, we have responsible and accountable AI systems!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Accountability Frameworks Matter | Ù„Ù…Ø§Ø°Ø§ ØªÙ‡Ù… Ø£Ø·Ø± Ø§Ù„Ù…Ø³Ø§Ø¡Ù„Ø©ØŸ\n",
    "\n",
    "Accountability frameworks are essential for ethical AI:\n",
    "- **Responsibility**: Define who is responsible for AI decisions\n",
    "- **Transparency**: Enable tracking and auditing of decisions\n",
    "- **Trust**: Build user confidence through accountability\n",
    "- **Compliance**: Meet regulatory requirements for accountability\n",
    "- **Ethics**: Ensure responsible AI development and deployment\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Understand accountability frameworks\n",
    "2. Learn stakeholder responsibilities\n",
    "3. Create audit trails\n",
    "4. Establish responsibility mechanisms\n",
    "5. Implement model cards and data sheets\n",
    "6. Build accountability structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:59:18.942183Z",
     "iopub.status.busy": "2025-12-26T16:59:18.941984Z",
     "iopub.status.idle": "2025-12-26T16:59:21.368421Z",
     "shell.execute_reply": "2025-12-26T16:59:21.368248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 4 - Example 4: Accountability Frameworks\n",
      "================================================================================\n",
      "\n",
      "1. Stakeholder Responsibilities:\n",
      "\n",
      "Developers:\n",
      "  Accountability Level: 9\n",
      "  Responsibilities:\n",
      "    - Design fair and transparent algorithms\n",
      "    - Document model decisions and limitations\n",
      "    - Implement bias detection and mitigation\n",
      "    - Create model cards and documentation\n",
      "\n",
      "Data Scientists:\n",
      "  Accountability Level: 8\n",
      "  Responsibilities:\n",
      "    - Ensure data quality and representativeness\n",
      "    - Document data sources and preprocessing\n",
      "    - Identify potential biases in data\n",
      "    - Maintain data lineage\n",
      "\n",
      "Product Managers:\n",
      "  Accountability Level: 7\n",
      "  Responsibilities:\n",
      "    - Define ethical requirements\n",
      "    - Oversee deployment and monitoring\n",
      "    - Ensure compliance with regulations\n",
      "    - Manage stakeholder communication\n",
      "\n",
      "Legal:\n",
      "  Accountability Level: 9\n",
      "  Responsibilities:\n",
      "    - Ensure regulatory compliance\n",
      "    - Review model for legal risks\n",
      "    - Handle liability issues\n",
      "    - Manage data privacy requirements\n",
      "\n",
      "End Users:\n",
      "  Accountability Level: 5\n",
      "  Responsibilities:\n",
      "    - Use AI system responsibly\n",
      "    - Report issues and biases\n",
      "    - Provide feedback\n",
      "    - Understand system limitations\n",
      "\n",
      "2. Model Card:\n",
      "  Model: Loan Approval Classifier\n",
      "  Created: 2025-12-26\n",
      "  Performance: {'accuracy': 0.87, 'fairness_score': 0.92}\n",
      "\n",
      "3. Audit Trail:\n",
      "  Total audit entries: 7\n",
      "  Date range: 2025-11-26 19:59:20.218923 to 2025-12-08 19:59:20.218923\n",
      "\n",
      "4. Accountability Checklist:\n",
      "\n",
      "Pre-deployment:\n",
      "  [ ] Model documentation complete\n",
      "  [ ] Bias assessment performed\n",
      "  [ ] Fairness metrics calculated\n",
      "  [ ] Stakeholder review completed\n",
      "  [ ] Legal compliance verified\n",
      "\n",
      "Deployment:\n",
      "  [ ] Monitoring systems in place\n",
      "  [ ] Audit trail enabled\n",
      "  [ ] User notifications configured\n",
      "  [ ] Rollback plan prepared\n",
      "\n",
      "Post-deployment:\n",
      "  [ ] Regular performance monitoring\n",
      "  [ ] Fairness metrics tracking\n",
      "  [ ] User feedback collection\n",
      "  [ ] Periodic model audits\n",
      "  [ ] Incident response plan\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: stakeholder_accountability.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: audit_timeline.png\n",
      "âœ… Saved: accountability_checklist.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Clear stakeholder responsibilities ensure accountability\n",
      "2. Model cards document model characteristics and limitations\n",
      "3. Audit trails track all system decisions and changes\n",
      "4. Accountability checklists ensure comprehensive coverage\n",
      "5. Accountability frameworks are essential for trustworthy AI\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4: Interpretability, Transparency, and Accountability\n",
    "Example 4: Accountability Frameworks\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš« When Accountability Frameworks Hit a Limitation | Ø¹Ù†Ø¯Ù…Ø§ ØªØµÙ„ Ø£Ø·Ø± Ø§Ù„Ù…Ø³Ø§Ø¡Ù„Ø© Ø¥Ù„Ù‰ Ø­Ø¯\n",
    "\n",
    "### The Limitation We Discovered\n",
    "\n",
    "We've learned accountability frameworks for defining responsibilities. **But there's still a challenge:**\n",
    "\n",
    "**How do we incorporate human judgment into AI decision-making?**\n",
    "\n",
    "Accountability frameworks work well when:\n",
    "- âœ… We have clear responsibilities defined\n",
    "- âœ… We have audit trails in place\n",
    "- âœ… We have accountability mechanisms\n",
    "\n",
    "**But ethical AI systems also need:**\n",
    "- âŒ **Human oversight** (human judgment for critical decisions)\n",
    "- âŒ **Human-in-the-loop** (HITL) approaches\n",
    "- âŒ **Human review** for uncertain cases\n",
    "- âŒ **Human validation** of AI decisions\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "When we have accountability but no human oversight:\n",
    "- Critical decisions may be made without human judgment\n",
    "- Uncertain cases may not get human review\n",
    "- AI decisions may lack human validation\n",
    "- We may miss important context that humans understand\n",
    "\n",
    "### The Solution: Human-in-the-Loop (HITL) Approaches\n",
    "\n",
    "We need **human-in-the-loop approaches** to:\n",
    "1. Incorporate human judgment into AI decisions\n",
    "2. Enable human review for uncertain cases\n",
    "3. Provide human oversight for critical decisions\n",
    "4. Combine AI efficiency with human judgment\n",
    "\n",
    "**This is exactly what we'll learn in the next notebook: Human-in-the-Loop Approaches!**\n",
    "\n",
    "---\n",
    "\n",
    "## â¡ï¸ Next Steps | Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©\n",
    "\n",
    "**You've completed this notebook!** Now you understand:\n",
    "- âœ… How to use SHAP, LIME, and counterfactuals (Notebooks 1-3)\n",
    "- âœ… How to establish accountability frameworks (This notebook!)\n",
    "- âœ… **The limitation**: We need human oversight!\n",
    "\n",
    "**Next notebook**: `05_hitl_approaches.ipynb`\n",
    "- Learn about human-in-the-loop approaches\n",
    "- Understand human oversight mechanisms\n",
    "- Implement HITL for critical decisions\n",
    "- Combine AI with human judgment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}