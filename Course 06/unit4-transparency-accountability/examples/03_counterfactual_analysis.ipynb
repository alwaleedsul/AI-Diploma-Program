{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Counterfactual Analysis | Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¯ Ù„Ù„ÙˆØ§Ù‚Ø¹\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Counterfactual Analysis | Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¯ Ù„Ù„ÙˆØ§Ù‚Ø¹\n",
    "\n",
    "## ğŸš¨ THE PROBLEM: We Need \"What If\" Explanations | Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù†Ø­ØªØ§Ø¬ ØªÙØ³ÙŠØ±Ø§Øª \"Ù…Ø§Ø°Ø§ Ù„Ùˆ\"\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned LIME for fast, local explanations. But we discovered:\n",
    "\n",
    "**What if we need to understand what would change a prediction?**\n",
    "\n",
    "**The Problem**: Sometimes we need:\n",
    "- âŒ **\"What if\" scenarios** (what would change the outcome?)\n",
    "- âŒ **Actionable explanations** (what should I change to get a different result?)\n",
    "- âŒ **Counterfactual reasoning** (if X had been different, then Y would be different)\n",
    "- âŒ **Decision guidance** (how to achieve desired outcomes)\n",
    "\n",
    "**We've learned:**\n",
    "- âœ… How to use SHAP for explanations (Notebook 1)\n",
    "- âœ… How to use LIME for fast explanations (Notebook 2)\n",
    "- âœ… Feature importance and local explanations\n",
    "\n",
    "**But we haven't learned:**\n",
    "- âŒ How to generate **counterfactual examples**\n",
    "- âŒ How to answer **\"what if\" questions**\n",
    "- âŒ How to provide **actionable guidance**\n",
    "- âŒ How to show **what needs to change** for different outcomes\n",
    "\n",
    "**We need counterfactual analysis** to:\n",
    "1. Generate \"what if\" scenarios\n",
    "2. Show what would change a prediction\n",
    "3. Provide actionable guidance\n",
    "4. Enable decision-making support\n",
    "\n",
    "**This notebook solves that problem** by teaching you counterfactual analysis for \"what if\" explanations!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 1: SHAP Explanations** - Understanding explainability\n",
    "- âœ… **Example 2: LIME Explanations** - Understanding local explanations\n",
    "- âœ… **Basic Python knowledge**: Functions, data manipulation, ML concepts\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why counterfactuals matter\n",
    "- Knowing how to generate counterfactual examples\n",
    "- Understanding what-if analysis\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is the THIRD example in Unit 4** - it teaches you \"what if\" explanations!\n",
    "\n",
    "**Why this example THIRD?**\n",
    "- **Before** you can use counterfactuals, you need basic explainability (Examples 1-2)\n",
    "- **Before** you can ensure accountability, you need multiple explanation methods\n",
    "- **Before** you can build transparent systems, you need actionable explanations\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Example 1: SHAP Explanations (feature importance)\n",
    "- ğŸ““ Example 2: LIME Explanations (local explanations)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Example 4: Accountability Frameworks (accountability structures)\n",
    "- ğŸ““ Example 5: Human-in-the-Loop (HITL approaches)\n",
    "- ğŸ““ Example 6: Transparency Tools (transparency frameworks)\n",
    "\n",
    "**Why this order?**\n",
    "1. Counterfactuals provide **actionable explanations** (needed for decision-making)\n",
    "2. Counterfactuals teach **\"what if\" reasoning** (critical for understanding)\n",
    "3. Counterfactuals show **decision guidance** (essential for transparency)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: What Would Change the Outcome? | Ø§Ù„Ù‚ØµØ©: Ù…Ø§Ø°Ø§ Ø³ÙŠØºÙŠØ± Ø§Ù„Ù†ØªÙŠØ¬Ø©ØŸ\n",
    "\n",
    "Imagine you're applying for a loan and got rejected. **Before** counterfactuals, you'd know you were rejected but not what to change. **After** using counterfactual analysis, you can see \"if your credit score was 50 points higher, you would be approved\" - actionable guidance!\n",
    "\n",
    "Same with AI: **Before** we have explanations but not actionable guidance, now we learn counterfactuals - generate \"what if\" scenarios to show what would change predictions! **After** counterfactuals, we can provide actionable explanations!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Counterfactual Analysis Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¯ Ù„Ù„ÙˆØ§Ù‚Ø¹ØŸ\n",
    "\n",
    "Counterfactual analysis is essential for ethical AI:\n",
    "- **Actionable Guidance**: Show what needs to change for different outcomes\n",
    "- **Decision Support**: Help users understand how to achieve desired results\n",
    "- **Transparency**: Make AI decisions more understandable through \"what if\" scenarios\n",
    "- **Trust**: Build user confidence through actionable explanations\n",
    "- **Fairness**: Enable users to understand and act on AI decisions\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Understand counterfactual examples and their meaning\n",
    "2. Learn how to generate counterfactual examples\n",
    "3. Perform what-if analysis\n",
    "4. Provide actionable explanations\n",
    "5. Visualize counterfactual comparisons\n",
    "6. Interpret counterfactual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:59:15.419828Z",
     "iopub.status.busy": "2025-12-26T16:59:15.419527Z",
     "iopub.status.idle": "2025-12-26T16:59:17.114435Z",
     "shell.execute_reply": "2025-12-26T16:59:17.114237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 4 - Example 3: Counterfactual Analysis\n",
      "================================================================================\n",
      "\n",
      "Generating dataset...\n",
      "Dataset shape: (1000, 5)\n",
      "\n",
      "Training Random Forest model...\n",
      "Test Accuracy: 0.9667\n",
      "\n",
      "Original instance (rejected):\n",
      "  Features: {'age': np.float64(69.0), 'income': np.float64(5029.851084497952), 'credit_score': np.float64(639.4051645695864), 'debt_ratio': np.float64(0.5370358866525926)}\n",
      "  Prediction probability: 0.3900\n",
      "  Prediction: 0\n",
      "\n",
      "Generating counterfactual (to get approved)...\n",
      "Counterfactual found after 1 iterations: Target class reached\n",
      "  Prediction probability: 0.9500\n",
      "  Prediction: 1\n",
      "\n",
      "Performing what-if analysis on credit_score...\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: counterfactual_comparison.png\n",
      "âœ… Saved: what_if_analysis.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Counterfactuals show what needs to change to get a different outcome\n",
      "2. What-if analysis explores how changes in features affect predictions\n",
      "3. Counterfactuals help explain model decisions\n",
      "4. Counterfactuals are useful for actionable insights\n",
      "5. Counterfactual analysis improves model transparency\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4: Interpretability, Transparency, and Accountability\n",
    "Example 3: Counterfactual Analysis\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš« When Counterfactual Analysis Hits a Limitation | Ø¹Ù†Ø¯Ù…Ø§ ÙŠØµÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¯ Ù„Ù„ÙˆØ§Ù‚Ø¹ Ø¥Ù„Ù‰ Ø­Ø¯\n",
    "\n",
    "### The Limitation We Discovered\n",
    "\n",
    "We've learned counterfactual analysis for \"what if\" explanations. **But there's still a challenge:**\n",
    "\n",
    "**How do we ensure accountability and responsibility for AI decisions?**\n",
    "\n",
    "Counterfactual analysis works well when:\n",
    "- âœ… We can generate \"what if\" scenarios\n",
    "- âœ… We can provide actionable guidance\n",
    "- âœ… We can explain what would change outcomes\n",
    "\n",
    "**But transparent AI systems also need:**\n",
    "- âŒ **Accountability frameworks** (who is responsible?)\n",
    "- âŒ **Responsibility mechanisms** (how to assign responsibility?)\n",
    "- âŒ **Audit trails** (how to track decisions?)\n",
    "- âŒ **Stakeholder accountability** (who answers for outcomes?)\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "When we have explanations but no accountability:\n",
    "- We may not know who is responsible for AI decisions\n",
    "- We may not have mechanisms to track and audit decisions\n",
    "- We may not have clear responsibility structures\n",
    "- We may not be able to hold anyone accountable\n",
    "\n",
    "### The Solution: Accountability Frameworks\n",
    "\n",
    "We need **accountability frameworks** to:\n",
    "1. Define stakeholder responsibilities\n",
    "2. Create audit trails\n",
    "3. Establish responsibility mechanisms\n",
    "4. Enable accountability for AI decisions\n",
    "\n",
    "**This is exactly what we'll learn in the next notebook: Accountability Frameworks!**\n",
    "\n",
    "---\n",
    "\n",
    "## â¡ï¸ Next Steps | Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©\n",
    "\n",
    "**You've completed this notebook!** Now you understand:\n",
    "- âœ… How to use SHAP for explanations (Notebook 1)\n",
    "- âœ… How to use LIME for fast explanations (Notebook 2)\n",
    "- âœ… How to use counterfactuals for \"what if\" scenarios (This notebook!)\n",
    "- âœ… **The limitation**: We need accountability frameworks!\n",
    "\n",
    "**Next notebook**: `04_accountability_frameworks.ipynb`\n",
    "- Learn about accountability frameworks\n",
    "- Understand stakeholder responsibilities\n",
    "- Create audit trails\n",
    "- Establish responsibility mechanisms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}