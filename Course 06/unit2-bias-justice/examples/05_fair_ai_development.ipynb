{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Fair AI Development | ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø§Ø¯Ù„\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 2** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Fair AI Development | ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø§Ø¯Ù„\n",
    "\n",
    "## ğŸš¨ THE PROBLEM: We Need Systematic Fair AI Development | Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù†Ø­ØªØ§Ø¬ ØªØ·ÙˆÙŠØ±Ø§Ù‹ Ù…Ù†Ù‡Ø¬ÙŠØ§Ù‹ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø§Ø¯Ù„\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned how to ensure fair representation using PCA, autoencoders, and adversarial techniques. But we discovered:\n",
    "\n",
    "**How do we apply all these techniques to build fair AI systems from the start?**\n",
    "\n",
    "**The Problem**: We have many fairness techniques, but we need:\n",
    "- âŒ **Systematic approach** from data collection to deployment\n",
    "- âŒ **Best practices** for fair AI development\n",
    "- âŒ **Integration** of all techniques we've learned\n",
    "- âŒ **Real-world application** of fairness principles\n",
    "\n",
    "**We've learned:**\n",
    "- âœ… How to detect bias (Notebook 1)\n",
    "- âœ… How to mitigate bias (Notebook 2)\n",
    "- âœ… How to ensure fair representation (Notebook 3)\n",
    "- âœ… How to analyze bias cases (Notebook 4)\n",
    "\n",
    "**But we haven't learned:**\n",
    "- âŒ How to **systematically build** fair AI systems\n",
    "- âŒ How to **integrate** all fairness techniques\n",
    "- âŒ How to **prevent bias** from the start\n",
    "- âŒ How to **apply best practices** throughout development\n",
    "\n",
    "**We need systematic fair AI development practices** to:\n",
    "1. Integrate all fairness techniques we've learned\n",
    "2. Build fairness into the entire development lifecycle\n",
    "3. Apply best practices consistently\n",
    "4. Create truly fair AI systems from the start\n",
    "\n",
    "**This notebook solves that problem** by teaching you systematic approaches to fair AI development!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 1: Bias Detection** - Understanding how to detect bias\n",
    "- âœ… **Example 2: Bias Mitigation** - Understanding mitigation techniques\n",
    "- âœ… **Example 3: Fair Representation** - Understanding fair representation\n",
    "- âœ… **Example 4: Bias Case Studies** - Understanding real-world bias cases\n",
    "- âœ… **Basic Python knowledge**: Functions, data manipulation, ML concepts\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding how to build fair AI systems from the start\n",
    "- Knowing which practices to follow for fair development\n",
    "- Understanding human-in-the-loop approaches\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is the FIFTH and FINAL example in Unit 2** - it teaches you how to build fair AI systems from the start!\n",
    "\n",
    "**Why this example LAST?**\n",
    "- **Before** you can build fair systems, you need to detect bias (Example 1)\n",
    "- **Before** you can build fair systems, you need to know mitigation (Example 2)\n",
    "- **Before** you can build fair systems, you need fair representation (Example 3)\n",
    "- **Before** you can build fair systems, you need to learn from cases (Example 4)\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Example 1: Bias Detection (we know how to detect bias)\n",
    "- ğŸ““ Example 2: Bias Mitigation (we know how to fix bias)\n",
    "- ğŸ““ Example 3: Fair Representation (we know how to ensure fair features)\n",
    "- ğŸ““ Example 4: Bias Case Studies (we learned from real mistakes)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Unit 3: Privacy and Security (next unit in the course!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Fair development provides **best practices** (needed after learning all techniques)\n",
    "2. Fair development teaches **prevention** (better than fixing after the fact)\n",
    "3. Fair development shows **complete workflow** (data collection to deployment)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Building Right from the Start | Ø§Ù„Ù‚ØµØ©: Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©\n",
    "\n",
    "Imagine you're building a house. **Before** you start, you need to plan - choose the right location, design for safety, use quality materials. **After** planning, you build a house that's safe, durable, and meets all requirements!\n",
    "\n",
    "Same with AI: **Before** we learned to detect and fix bias, now we learn to build fair systems from the start - inclusive data collection, bias-aware algorithms, human-in-the-loop. **After** fair development, we have systems that are fair by design!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Fair AI Development Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø§Ø¯Ù„ØŸ\n",
    "\n",
    "Fair AI development is essential for ethical AI:\n",
    "- **Prevention**: Build fair systems from the start (better than fixing later)\n",
    "- **Efficiency**: Avoid costly fixes and rework\n",
    "- **Trust**: Demonstrate commitment to fairness\n",
    "- **Compliance**: Meet regulatory requirements\n",
    "- **Better Outcomes**: Fair systems lead to better decisions\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Understand inclusive data collection strategies\n",
    "2. Learn bias-aware algorithm design\n",
    "3. Understand human-in-the-loop approaches for fairness\n",
    "4. Learn best practices for fair AI development\n",
    "5. Build a complete fair AI development workflow\n",
    "6. Understand how to prevent bias from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:50.413048Z",
     "iopub.status.busy": "2025-12-26T16:58:50.412737Z",
     "iopub.status.idle": "2025-12-26T16:58:51.453449Z",
     "shell.execute_reply": "2025-12-26T16:58:51.453226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "\n",
      "ğŸ“š What each library does:\n",
      "   - numpy/pandas: Data manipulation and numerical operations\n",
      "   - matplotlib/seaborn: Create visualizations (charts, heatmaps)\n",
      "   - sklearn: Machine learning (models, metrics, preprocessing)\n",
      "   - fairlearn: Fairness tools (metrics, evaluation)\n",
      "   - os: File operations (saving images)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us build fair AI systems from the start\n",
    "\n",
    "import numpy as np  # For numerical operations: Arrays, calculations, random number generation\n",
    "import pandas as pd  # For data manipulation: DataFrames, data analysis\n",
    "import matplotlib.pyplot as plt  # For creating visualizations: Charts, graphs, comparisons\n",
    "import seaborn as sns  # For statistical visualizations: Heatmaps, advanced plots\n",
    "from sklearn.model_selection import train_test_split  # For splitting data: Separate training and testing sets\n",
    "from sklearn.ensemble import RandomForestClassifier  # For ML model: Classification algorithm\n",
    "from sklearn.preprocessing import StandardScaler  # For data preprocessing: Feature scaling\n",
    "from sklearn.metrics import accuracy_score, classification_report  # For model evaluation: Performance metrics\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference  # For fairness metrics: Fairlearn library\n",
    "import warnings  # For suppressing warnings: Clean output\n",
    "import os  # For file operations: Saving images\n",
    "\n",
    "# Suppress warnings: Clean output (fairlearn may show warnings)\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings: Suppress non-critical warnings\n",
    "\n",
    "# Configure plotting: Set default styles for better visualizations\n",
    "plt.rcParams['font.size'] = 10  # Font size: Make text readable (10pt is good for most displays)\n",
    "plt.rcParams['figure.figsize'] = (14, 8)  # Figure size: 14 inches wide, 8 inches tall (good for detailed charts)\n",
    "sns.set_style(\"whitegrid\")  # Style: White background with grid for clean look\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"\\nğŸ“š What each library does:\")\n",
    "print(\"   - numpy/pandas: Data manipulation and numerical operations\")\n",
    "print(\"   - matplotlib/seaborn: Create visualizations (charts, heatmaps)\")\n",
    "print(\"   - sklearn: Machine learning (models, metrics, preprocessing)\")\n",
    "print(\"   - fairlearn: Fairness tools (metrics, evaluation)\")\n",
    "print(\"   - os: File operations (saving images)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:51.465655Z",
     "iopub.status.busy": "2025-12-26T16:58:51.465541Z",
     "iopub.status.idle": "2025-12-26T16:58:51.467969Z",
     "shell.execute_reply": "2025-12-26T16:58:51.467791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š INCLUSIVE DATA COLLECTION STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "Different data collection strategies:\n",
      "  - Unbalanced: Majority group over-represented\n",
      "  - Balanced: Equal representation across groups\n",
      "  - Oversampled Minority: Minority groups over-represented (for fairness)\n",
      "\n",
      "Analyzing data collection strategies...\n",
      "\n",
      "Data Collection Strategies:\n",
      "\n",
      "Unbalanced:\n",
      "  Group_A: 800 samples (80.0%)\n",
      "  Group_B: 200 samples (20.0%)\n",
      "  Group_C: 0 samples (0.0%)\n",
      "\n",
      "Balanced:\n",
      "  Group_A: 400 samples (40.0%)\n",
      "  Group_B: 400 samples (40.0%)\n",
      "  Group_C: 200 samples (20.0%)\n",
      "\n",
      "Oversampled_Minority:\n",
      "  Group_A: 400 samples (33.3%)\n",
      "  Group_B: 400 samples (33.3%)\n",
      "  Group_C: 400 samples (33.3%)\n",
      "\n",
      "âœ… Data collection analysis complete!\n",
      "\n",
      "Key Insight: Inclusive data collection is the foundation of fair AI!\n"
     ]
    }
   ],
   "source": [
    "Step 2: Demonstrate inclusive data collection strategies\n",
    "This shows how different data collection approaches affect representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bias-Aware Algorithms and Human-in-the-Loop | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ÙˆØ§Ø¹ÙŠØ© Ø¨Ø§Ù„ØªØ­ÙŠØ² ÙˆØ§Ù„ØªØ¯Ø®Ù„ Ø§Ù„Ø¨Ø´Ø±ÙŠ\n",
    "\n",
    "### ğŸ“š Prerequisites (What You Need First)\n",
    "- âœ… **Library imports** (from Part 1) - Understanding data manipulation tools\n",
    "- âœ… **Understanding of bias** (from Examples 1-4) - Knowing how bias manifests\n",
    "- âœ… **Inclusive data collection** (from Step 2) - Understanding data collection strategies\n",
    "\n",
    "### ğŸ”— Relationship: What This Builds On\n",
    "This builds on inclusive data collection to show how to design algorithms and workflows that are fair by design!\n",
    "- Builds on: Inclusive data collection, bias detection, and mitigation techniques\n",
    "- Shows: How to incorporate fairness into algorithm design and evaluation workflows\n",
    "\n",
    "### ğŸ“– The Story\n",
    "**Before**: We collect inclusive data, but algorithms might still be biased.\n",
    "**After**: We design bias-aware algorithms and use human-in-the-loop evaluation to ensure fairness!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:51.468941Z",
     "iopub.status.busy": "2025-12-26T16:58:51.468868Z",
     "iopub.status.idle": "2025-12-26T16:58:51.473467Z",
     "shell.execute_reply": "2025-12-26T16:58:51.473288Z"
    }
   },
   "outputs": [],
   "source": [
    "Step 3: Bias-Aware Algorithms and Human-in-the-Loop\n",
    "This demonstrates how to build fair AI systems with bias-aware algorithms and human oversight\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:51.474324Z",
     "iopub.status.busy": "2025-12-26T16:58:51.474270Z",
     "iopub.status.idle": "2025-12-26T16:58:51.477603Z",
     "shell.execute_reply": "2025-12-26T16:58:51.477430Z"
    }
   },
   "outputs": [],
   "source": [
    "Step 4: Visualization Functions\n",
    "These functions create visualizations to compare different approaches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:51.478424Z",
     "iopub.status.busy": "2025-12-26T16:58:51.478375Z",
     "iopub.status.idle": "2025-12-26T16:58:52.276893Z",
     "shell.execute_reply": "2025-12-26T16:58:52.276699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 2 - Example 5: Practical Approaches to Fair AI Development\n",
      "================================================================================\n",
      "\n",
      "Generating dataset for fair AI development...\n",
      "Dataset shape: (2000, 6)\n",
      "\n",
      "================================================================================\n",
      "2. BIAS-AWARE ALGORITHMS\n",
      "================================================================================\n",
      "\n",
      "Baseline Model (No Fairness Constraints):\n",
      "  Accuracy: 0.9383\n",
      "  Demographic Parity Difference: 0.0477\n",
      "  Equalized Odds Difference: 0.0229\n",
      "\n",
      "Fairness-Constrained Model:\n",
      "  Accuracy: 0.9400\n",
      "  Demographic Parity Difference: 0.0614\n",
      "  Equalized Odds Difference: 0.0394\n",
      "\n",
      "================================================================================\n",
      "3. HUMAN-IN-THE-LOOP FAIRNESS EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Automated Predictions: 600\n",
      "Uncertain Cases (Human Review): 42\n",
      "Human Review Accuracy: 76.19%\n",
      "\n",
      "HITL Model Performance:\n",
      "  Accuracy: 0.9517\n",
      "  Demographic Parity Difference: 0.0431\n",
      "  Equalized Odds Difference: 0.0166\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Saved: fair_ai_data_collection.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: fair_ai_comparison.png\n",
      "âœ… Saved: fair_ai_hitl_workflow.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Inclusive data collection ensures representation of all groups\n",
      "2. Bias-aware algorithms incorporate fairness constraints during training\n",
      "3. Human-in-the-loop approaches improve fairness for uncertain cases\n",
      "4. Combining these approaches leads to more fair and trustworthy AI systems\n",
      "5. Continuous monitoring and evaluation are essential for maintaining fairness\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Step 5: Run the Complete Fair AI Development Pipeline\n",
    "This executes the entire workflow from data generation to visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary: What We Learned | Ø§Ù„Ù…Ù„Ø®Øµ: Ù…Ø§ ØªØ¹Ù„Ù…Ù†Ø§Ù‡\n",
    "\n",
    "**BEFORE this notebook**: We learned to detect and fix bias, but hadn't learned how to build fair systems from the start.\n",
    "\n",
    "**AFTER this notebook**: We can:\n",
    "- âœ… Understand inclusive data collection strategies\n",
    "- âœ… Design bias-aware algorithms\n",
    "- âœ… Implement human-in-the-loop approaches for fairness\n",
    "- âœ… Apply best practices for fair AI development\n",
    "- âœ… Build complete fair AI development workflows\n",
    "- âœ… Prevent bias from the start (better than fixing later!)\n",
    "\n",
    "### Key Takeaways | Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "\n",
    "1. **Inclusive Data Collection**: Foundation of fair AI - ensure all groups are represented\n",
    "2. **Bias-Aware Algorithms**: Incorporate fairness constraints during training\n",
    "3. **Human-in-the-Loop**: Use human judgment for uncertain cases to improve fairness\n",
    "4. **Prevention**: Building fair systems from the start is more efficient than fixing later\n",
    "5. **Complete Workflow**: Fair development requires attention at every stage (data â†’ model â†’ deployment)\n",
    "\n",
    "---\n",
    "\n",
    "## â¡ï¸ Transition to Unit 3: Privacy and Security | Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ­Ø¯Ø© 3: Ø§Ù„Ø®ØµÙˆØµÙŠØ© ÙˆØ§Ù„Ø£Ù…Ø§Ù†\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "We've completed Unit 2: Bias and Justice! We've learned:\n",
    "- âœ… How to detect bias in AI systems\n",
    "- âœ… How to mitigate bias using multiple techniques\n",
    "- âœ… How to ensure fair representation in data\n",
    "- âœ… How to build fair AI systems from the start\n",
    "\n",
    "### The Next Challenge: Privacy and Security\n",
    "\n",
    "**Fairness is important, but it's not the only ethical concern!**\n",
    "\n",
    "As we build AI systems, we also need to consider:\n",
    "- **Privacy**: How do we protect user data?\n",
    "- **Security**: How do we secure AI systems?\n",
    "- **Data Protection**: How do we comply with regulations like GDPR?\n",
    "\n",
    "**The Problem**: We've learned about fairness, but **AI systems also raise privacy and security concerns**:\n",
    "- AI systems collect and process personal data\n",
    "- AI systems may be vulnerable to attacks\n",
    "- AI systems must comply with privacy regulations\n",
    "\n",
    "**This is exactly what we'll learn in Unit 3: Privacy and Security!**\n",
    "\n",
    "---\n",
    "\n",
    "## â¡ï¸ Next Steps | Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©\n",
    "\n",
    "**You've completed Unit 2!** Now you understand:\n",
    "- âœ… How to detect and mitigate bias\n",
    "- âœ… How to ensure fair representation\n",
    "- âœ… How to build fair AI systems systematically\n",
    "\n",
    "**Next Unit**: `unit3-privacy-security/`\n",
    "- Learn about privacy protection in AI\n",
    "- Understand security vulnerabilities\n",
    "- Master GDPR compliance\n",
    "- Build secure and private AI systems\n",
    "\n",
    "**Congratulations!** ğŸ‰ You've completed Unit 2 and learned how to build fair AI systems from the ground up!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}