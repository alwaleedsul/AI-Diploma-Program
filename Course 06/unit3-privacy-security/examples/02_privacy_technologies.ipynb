{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Privacy-Enhancing Technologies (PETs) | ÿ™ŸÇŸÜŸäÿßÿ™ ÿ™ÿπÿ≤Ÿäÿ≤ ÿßŸÑÿÆÿµŸàÿµŸäÿ©\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 3** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Privacy-Enhancing Technologies (PETs) | ÿ™ŸÇŸÜŸäÿßÿ™ ÿ™ÿπÿ≤Ÿäÿ≤ ÿßŸÑÿÆÿµŸàÿµŸäÿ©\n",
    "\n",
    "## üö® THE PROBLEM: We Need to Compute on Encrypted Data | ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©: ŸÜÿ≠ÿ™ÿßÿ¨ ÿßŸÑÿ≠Ÿàÿ≥ÿ®ÿ© ÿπŸÑŸâ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÖÿ¥ŸÅÿ±ÿ©\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned basic data protection strategies like encryption, anonymization, and pseudonymization. But we discovered:\n",
    "\n",
    "**What if we need to compute on encrypted data without decrypting it?**\n",
    "\n",
    "**The Problem**: Advanced AI use cases often require:\n",
    "- ‚ùå **Computing on encrypted data** without decryption\n",
    "- ‚ùå **Collaborative computation** without sharing raw data\n",
    "- ‚ùå **Privacy-preserving machine learning** on sensitive data\n",
    "- ‚ùå **Advanced privacy guarantees** beyond basic protection\n",
    "\n",
    "**We've learned:**\n",
    "- ‚úÖ How to encrypt sensitive data (Notebook 1)\n",
    "- ‚úÖ How to anonymize and pseudonymize data\n",
    "- ‚úÖ Basic data protection strategies\n",
    "\n",
    "**But we haven't learned:**\n",
    "- ‚ùå How to **compute on encrypted data** without decrypting\n",
    "- ‚ùå How to enable **secure multi-party computation**\n",
    "- ‚ùå How to use **homomorphic encryption** for privacy-preserving ML\n",
    "- ‚ùå How to apply **advanced privacy technologies**\n",
    "\n",
    "**We need privacy-enhancing technologies (PETs)** to:\n",
    "1. Compute on encrypted data (homomorphic encryption)\n",
    "2. Enable secure multi-party computation\n",
    "3. Provide stronger privacy guarantees\n",
    "4. Support privacy-preserving machine learning\n",
    "\n",
    "**This notebook solves that problem** by teaching you advanced privacy-enhancing technologies like homomorphic encryption and secure multi-party computation!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites (What You Need First) | ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- ‚úÖ **Example 1: Data Protection** - Understanding basic protection strategies\n",
    "- ‚úÖ **Basic Python knowledge**: Functions, data manipulation\n",
    "- ‚úÖ **Understanding of encryption**: Basic encryption concepts (from Example 1)\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why advanced privacy technologies are needed\n",
    "- Knowing how homomorphic encryption works\n",
    "- Understanding secure multi-party computation concepts\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Where This Notebook Fits | ŸÖŸÉÿßŸÜ Ÿáÿ∞ÿß ÿßŸÑÿØŸÅÿ™ÿ±\n",
    "\n",
    "**This is the SECOND example in Unit 3** - it teaches you advanced privacy technologies!\n",
    "\n",
    "**Why this example SECOND?**\n",
    "- **Before** you can use advanced PETs, you need basic data protection (Example 1)\n",
    "- **Before** you can implement differential privacy, you need to understand PETs\n",
    "- **Before** you can ensure GDPR compliance, you need privacy technologies\n",
    "\n",
    "**Builds on**: \n",
    "- üìì Example 1: Data Protection (we learned basic protection, now we learn advanced!)\n",
    "\n",
    "**Leads to**: \n",
    "- üìì Example 3: Differential Privacy (mathematical privacy guarantees)\n",
    "- üìì Example 4: GDPR Compliance (regulatory compliance)\n",
    "- üìì Example 5: Secure Development (secure coding practices)\n",
    "\n",
    "**Why this order?**\n",
    "1. PETs provide **advanced solutions** (needed after basic protection)\n",
    "2. PETs enable **privacy-preserving ML** (critical for AI)\n",
    "3. PETs show **cutting-edge techniques** (homomorphic encryption, SMPC)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Computing Without Revealing | ÿßŸÑŸÇÿµÿ©: ÿßŸÑÿ≠Ÿàÿ≥ÿ®ÿ© ÿØŸàŸÜ ÿßŸÑŸÉÿ¥ŸÅ\n",
    "\n",
    "Imagine you're a bank that needs to calculate average account balances across multiple banks without revealing individual balances. **Before** advanced PETs, you'd have to share data (privacy risk!). **After** using secure multi-party computation, you can compute the average without any bank seeing others' data!\n",
    "\n",
    "Same with AI: **Before** we encrypt data but can't compute on it, now we learn homomorphic encryption - compute on encrypted data without decrypting! **After** PETs, we can train models on encrypted data while preserving privacy!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Privacy-Enhancing Technologies Matter | ŸÑŸÖÿßÿ∞ÿß ÿ™ŸáŸÖ ÿ™ŸÇŸÜŸäÿßÿ™ ÿ™ÿπÿ≤Ÿäÿ≤ ÿßŸÑÿÆÿµŸàÿµŸäÿ©ÿü\n",
    "\n",
    "Privacy-enhancing technologies are essential for ethical AI:\n",
    "- **Privacy-Preserving ML**: Train models on encrypted data\n",
    "- **Collaborative AI**: Enable multi-party computation without data sharing\n",
    "- **Strong Guarantees**: Provide mathematical privacy guarantees\n",
    "- **Compliance**: Meet strict privacy regulations\n",
    "- **Trust**: Build user confidence in privacy-preserving systems\n",
    "\n",
    "## Learning Objectives | ÿ£ŸáÿØÿßŸÅ ÿßŸÑÿ™ÿπŸÑŸÖ\n",
    "1. Understand homomorphic encryption concepts\n",
    "2. Learn secure multi-party computation (SMPC)\n",
    "3. Understand privacy-utility trade-offs\n",
    "4. Compare different PETs\n",
    "5. Apply PETs to privacy-preserving machine learning\n",
    "6. Understand when to use each technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:56.418702Z",
     "iopub.status.busy": "2025-12-26T16:58:56.418527Z",
     "iopub.status.idle": "2025-12-26T16:58:57.727116Z",
     "shell.execute_reply": "2025-12-26T16:58:57.726917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 3 - Example 2: Privacy-Enhancing Technologies (PETs)\n",
      "================================================================================\n",
      "\n",
      "1. Secure Multi-Party Computation (SMPC):\n",
      "  Party 1 data: 1000\n",
      "  Party 2 data: 2000\n",
      "  Party 3 data: 1500\n",
      "  Computed sum: 4500.0\n",
      "  Privacy preserved: True\n",
      "\n",
      "2. Homomorphic Encryption:\n",
      "  Encrypted value A: 100\n",
      "  Encrypted value B: 200\n",
      "  Encrypted sum (computed on encrypted data): 300\n",
      "  Actual sum: 125\n",
      "\n",
      "3. Privacy-Utility Trade-off Analysis:\n",
      "\n",
      "No Protection:\n",
      "  Privacy: 1\n",
      "  Utility: 10\n",
      "  Cost: 1\n",
      "\n",
      "Anonymization:\n",
      "  Privacy: 6\n",
      "  Utility: 8\n",
      "  Cost: 2\n",
      "\n",
      "Pseudonymization:\n",
      "  Privacy: 7\n",
      "  Utility: 7\n",
      "  Cost: 3\n",
      "\n",
      "Differential Privacy:\n",
      "  Privacy: 9\n",
      "  Utility: 6\n",
      "  Cost: 4\n",
      "\n",
      "SMPC:\n",
      "  Privacy: 10\n",
      "  Utility: 5\n",
      "  Cost: 9\n",
      "\n",
      "Homomorphic Encryption:\n",
      "  Privacy: 10\n",
      "  Utility: 4\n",
      "  Cost: 10\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: pet_comparison.png\n",
      "‚úÖ Saved: privacy_utility_tradeoff.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. SMPC allows computation on data without revealing individual values\n",
      "2. Homomorphic encryption enables computation on encrypted data\n",
      "3. Different PETs have different privacy-utility trade-offs\n",
      "4. Higher privacy often comes at the cost of utility or performance\n",
      "5. Choose PET based on specific privacy and utility requirements\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 3: Privacy, Security, and Data Protection\n",
    "Example 2: Privacy-Enhancing Technologies (PETs)\n",
    "This example demonstrates privacy-enhancing technologies:\n",
    "- Secure Multi-Party Computation (SMPC) concepts\n",
    "- Homomorphic encryption concepts\n",
    "- Privacy-utility trade-offs\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "# ============================================================================\n",
    "# SECURE MULTI-PARTY COMPUTATION (SMPC) SIMULATION\n",
    "# ============================================================================\n",
    "def smpc_sum_simulation(parties_data, n_parties=3):\n",
    "    \"\"\"\n",
    "    Simulate Secure Multi-Party Computation for computing sum\n",
    "    without revealing individual values\n",
    "    \"\"\"\n",
    "    # Each party adds random noise to their data\n",
    "    noise = [np.random.normal(0, 100) for _ in range(n_parties)]\n",
    "    noisy_data = [data + noise[i] for i, data in enumerate(parties_data)]\n",
    "    # Sum of noisy data\n",
    "    noisy_sum = sum(noisy_data)\n",
    "    # Remove noise to get actual sum (in real SMPC, this is done securely)\n",
    "    actual_sum = noisy_sum - sum(noise)\n",
    "    return {\n",
    "        'parties_data': parties_data, 'noisy_data': noisy_data,\n",
    "        'noisy_sum': noisy_sum,\n",
    "        'actual_sum': actual_sum,\n",
    "        'privacy_preserved': True\n",
    "    }\n",
    "# ============================================================================\n",
    "# HOMOMORPHIC ENCRYPTION CONCEPTS\n",
    "# ============================================================================\n",
    "def homomorphic_encryption_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate concept of homomorphic encryption\n",
    "    (simplified - real implementation is much more complex)\n",
    "    \"\"\"\n",
    "    # Simulate encrypted values (in reality, these would be encrypted)\n",
    "    encrypted_a = 100  # Encrypted value of 50\n",
    "    encrypted_b = 200  # Encrypted value of 75\n",
    "    # Homomorphic addition (can compute on encrypted data)\n",
    "    encrypted_sum = encrypted_a + encrypted_b  # Result: 300 (represents 125)\n",
    "    # In real homomorphic encryption, you can compute without decrypting\n",
    "    return {\n",
    "        'encrypted_a': encrypted_a,\n",
    "        'encrypted_b': encrypted_b,\n",
    "        'encrypted_sum': encrypted_sum,\n",
    "        'actual_a': 50,\n",
    "        'actual_b': 75,\n",
    "        'actual_sum': 125\n",
    "    }\n",
    "# ============================================================================\n",
    "# PRIVACY-UTILITY TRADE-OFF ANALYSIS\n",
    "# ============================================================================\n",
    "def analyze_privacy_utility_tradeoff():\n",
    "    \"\"\"\n",
    "    Analyze trade-offs between privacy and utility for different PETs\n",
    "    \"\"\"\n",
    "    technologies = {\n",
    "        'No Protection': {'privacy': 1, 'utility': 10, 'cost': 1, 'performance': 10},\n",
    "        'Anonymization': {'privacy': 6, 'utility': 8, 'cost': 2, 'performance': 9},\n",
    "        'Pseudonymization': {'privacy': 7, 'utility': 7, 'cost': 3, 'performance': 8},\n",
    "        'Differential Privacy': {'privacy': 9, 'utility': 6, 'cost': 4, 'performance': 7},\n",
    "        'SMPC': {'privacy': 10, 'utility': 5, 'cost': 9, 'performance': 4},\n",
    "        'Homomorphic Encryption': {'privacy': 10, 'utility': 4, 'cost': 10, 'performance': 3}\n",
    "    }\n",
    "    return technologies\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_pet_comparison(technologies):\n",
    "    \"\"\"\n",
    "    Plot comparison of Privacy-Enhancing Technologies\n",
    "    \"\"\"\n",
    "    tech_names = list(technologies.keys())\n",
    "    privacy_scores = [tech['privacy'] for tech in technologies.values()]\n",
    "    utility_scores = [tech['utility'] for tech in technologies.values()]\n",
    "    cost_scores = [tech['cost'] for tech in technologies.values()]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    # Privacy scores\n",
    "    axes[0].barh(tech_names, privacy_scores, color='#9b59b6', alpha=0.8)\n",
    "    axes[0].set_title('Privacy Level (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Privacy Score (1-10)')\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    axes[0].set_xlim([0, 11])\n",
    "    # Utility scores\n",
    "    axes[1].barh(tech_names, utility_scores, color='#2ecc71', alpha=0.8)\n",
    "    axes[1].set_title('Data Utility (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Utility Score (1-10)')\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    axes[1].set_xlim([0, 11])\n",
    "    # Cost scores\n",
    "    axes[2].barh(tech_names, cost_scores, color='#e74c3c', alpha=0.8)\n",
    "    axes[2].set_title('Implementation Cost (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_xlabel('Cost Score (1-10)')\n",
    "    axes[2].grid(axis='x', alpha=0.3)\n",
    "    axes[2].set_xlim([0, 11])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: pet_comparison.png\")\n",
    "    plt.close()\n",
    "def plot_privacy_utility_tradeoff(technologies):\n",
    "    \"\"\"\n",
    "    Plot privacy-utility trade-off curve\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    tech_names = list(technologies.keys())\n",
    "    privacy = [tech['privacy'] for tech in technologies.values()]\n",
    "    utility = [tech['utility'] for tech in technologies.values()]\n",
    "    scatter = ax.scatter(privacy, utility, s=200, alpha=0.7, c=range(len(tech_names)), cmap='viridis', edgecolors='black', linewidth=2)\n",
    "    for i, name in enumerate(tech_names):\n",
    "        ax.annotate(name, (privacy[i], utility[i]), \n",
    "                   xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    ax.set_xlabel('Privacy Level (1-10)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Data Utility (1-10)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Privacy-Utility Trade-off for Different PETs', fontsize=12, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim([0, 11])\n",
    "    ax.set_ylim([0, 11])\n",
    "    plt.colorbar(scatter, ax=ax, label='Technology Index')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: privacy_utility_tradeoff.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 3 - Example 2: Privacy-Enhancing Technologies (PETs)\")\n",
    "    print(\"=\"*80)\n",
    "    # SMPC demonstration\n",
    "    print(\"\\n1. Secure Multi-Party Computation (SMPC):\")\n",
    "    parties_data = [1000, 2000, 1500]  # Three parties' private data\n",
    "    smpc_result = smpc_sum_simulation(parties_data, n_parties=3)\n",
    "    print(f\"  Party 1 data: {smpc_result['parties_data'][0]}\")  # Party 1: First party's data\n",
    "    print(f\"  Party 2 data: {smpc_result['parties_data'][1]}\")  # Party 2: Second party's data\n",
    "    print(f\"  Party 3 data: {smpc_result['parties_data'][2]}\")  # Party 3: Third party's data\n",
    "    print(f\"  Computed sum: {smpc_result['actual_sum']}\")  # Sum: Computed sum without revealing individual values\n",
    "    print(f\"  Privacy preserved: {smpc_result['privacy_preserved']}\")  # Privacy: Whether privacy was preserved\n",
    "    \n",
    "    # Homomorphic encryption demonstration\n",
    "    print(\"\\n2. Homomorphic Encryption:\")\n",
    "    he_result = homomorphic_encryption_demo()  # Demo: Demonstrate homomorphic encryption concepts\n",
    "    print(f\"  Encrypted value A: {he_result['encrypted_a']}\")  # Encrypted A: First encrypted value\n",
    "    print(f\"  Encrypted value B: {he_result['encrypted_b']}\")  # Encrypted B: Second encrypted value\n",
    "    print(f\"  Encrypted sum (computed on encrypted data): {he_result['encrypted_sum']}\")  # Encrypted sum: Sum computed on encrypted data\n",
    "    print(f\"  Actual sum: {he_result['actual_sum']}\")  # Actual sum: Real sum of decrypted values\n",
    "    \n",
    "    # Privacy-utility trade-off\n",
    "    print(\"\\n3. Privacy-Utility Trade-off Analysis:\")\n",
    "    technologies = analyze_privacy_utility_tradeoff()  # Analyze: Get trade-off metrics for different PETs\n",
    "    for tech, metrics in technologies.items():  # Loop through technologies: Process each PET\n",
    "        print(f\"\\n{tech}:\")  # Print: Technology name\n",
    "        print(f\"  Privacy: {metrics['privacy']}\")  # Privacy: Privacy score (1-10)\n",
    "        print(f\"  Utility: {metrics['utility']}\")  # Utility: Data utility score (1-10)\n",
    "        print(f\"  Cost: {metrics['cost']}\")  # Cost: Implementation cost score (1-10)\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations...\")\n",
    "    print(\"=\"*80)\n",
    "    plot_pet_comparison(technologies)\n",
    "    plot_privacy_utility_tradeoff(technologies)\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. SMPC allows computation on data without revealing individual values\")\n",
    "    print(\"2. Homomorphic encryption enables computation on encrypted data\")\n",
    "    print(\"3. Different PETs have different privacy-utility trade-offs\")\n",
    "    print(\"4. Higher privacy often comes at the cost of utility or performance\")\n",
    "    print(\"5. Choose PET based on specific privacy and utility requirements\")\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üö´ When Privacy Technologies Hit a Limitation | ÿπŸÜÿØŸÖÿß ÿ™ÿµŸÑ ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿÆÿµŸàÿµŸäÿ© ÿ•ŸÑŸâ ÿ≠ÿØ\n",
    "\n",
    "### The Limitation We Discovered\n",
    "\n",
    "We've learned advanced privacy-enhancing technologies like homomorphic encryption and secure multi-party computation. **But there's still a challenge:**\n",
    "\n",
    "**How do we provide mathematical privacy guarantees?**\n",
    "\n",
    "Privacy technologies work well when:\n",
    "- ‚úÖ We can use homomorphic encryption for specific operations\n",
    "- ‚úÖ We can enable secure multi-party computation\n",
    "- ‚úÖ We understand privacy-utility trade-offs\n",
    "\n",
    "**But we need stronger guarantees:**\n",
    "- ‚ùå **Mathematical privacy guarantees** (not just techniques)\n",
    "- ‚ùå **Quantifiable privacy protection** (measurable privacy loss)\n",
    "- ‚ùå **Formal privacy definitions** (differential privacy)\n",
    "- ‚ùå **Provable privacy bounds** (epsilon-delta guarantees)\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "When we use privacy technologies without formal guarantees:\n",
    "- We don't know how much privacy we're actually providing\n",
    "- We can't quantify privacy loss\n",
    "- We can't prove our systems are private\n",
    "- We may think we're private but aren't\n",
    "\n",
    "### The Solution: Differential Privacy\n",
    "\n",
    "We need **differential privacy** to:\n",
    "1. Provide mathematical privacy guarantees\n",
    "2. Quantify privacy loss (epsilon parameter)\n",
    "3. Prove privacy protection formally\n",
    "4. Enable privacy-preserving data analysis with provable guarantees\n",
    "\n",
    "**This is exactly what we'll learn in the next notebook: Differential Privacy!**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Steps | ÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©\n",
    "\n",
    "**You've completed this notebook!** Now you understand:\n",
    "- ‚úÖ How to use basic data protection (Notebook 1)\n",
    "- ‚úÖ How to use advanced privacy technologies (This notebook!)\n",
    "- ‚úÖ **The limitation**: We need mathematical privacy guarantees!\n",
    "\n",
    "**Next notebook**: `03_differential_privacy.ipynb`\n",
    "- Learn about differential privacy and epsilon parameter\n",
    "- Understand mathematical privacy guarantees\n",
    "- Apply differential privacy to data analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}