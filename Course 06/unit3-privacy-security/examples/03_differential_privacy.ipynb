{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Differential Privacy | ÿßŸÑÿÆÿµŸàÿµŸäÿ© ÿßŸÑÿ™ŸÅÿßÿ∂ŸÑŸäÿ©\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 3** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Differential Privacy | ÿßŸÑÿÆÿµŸàÿµŸäÿ© ÿßŸÑÿ™ŸÅÿßÿ∂ŸÑŸäÿ©\n",
    "\n",
    "## üö® THE PROBLEM: We Need Mathematical Privacy Guarantees | ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©: ŸÜÿ≠ÿ™ÿßÿ¨ ÿ∂ŸÖÿßŸÜÿßÿ™ ÿÆÿµŸàÿµŸäÿ© ÿ±Ÿäÿßÿ∂Ÿäÿ©\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned advanced privacy-enhancing technologies like homomorphic encryption and secure multi-party computation. But we discovered:\n",
    "\n",
    "**How do we provide mathematical privacy guarantees?**\n",
    "\n",
    "**The Problem**: We need stronger guarantees:\n",
    "- ‚ùå **Mathematical privacy guarantees** (not just techniques)\n",
    "- ‚ùå **Quantifiable privacy protection** (measurable privacy loss)\n",
    "- ‚ùå **Formal privacy definitions** (differential privacy)\n",
    "- ‚ùå **Provable privacy bounds** (epsilon-delta guarantees)\n",
    "\n",
    "**We've learned:**\n",
    "- ‚úÖ How to use basic data protection (Notebook 1)\n",
    "- ‚úÖ How to use advanced privacy technologies (Notebook 2)\n",
    "- ‚úÖ Privacy-utility trade-offs\n",
    "\n",
    "**But we haven't learned:**\n",
    "- ‚ùå How to **quantify privacy** mathematically\n",
    "- ‚ùå How to **prove privacy protection** formally\n",
    "- ‚ùå How to use **differential privacy** for provable guarantees\n",
    "- ‚ùå How to **measure privacy loss** (epsilon parameter)\n",
    "\n",
    "**We need differential privacy** to:\n",
    "1. Provide mathematical privacy guarantees\n",
    "2. Quantify privacy loss (epsilon parameter)\n",
    "3. Prove privacy protection formally\n",
    "4. Enable privacy-preserving data analysis with provable guarantees\n",
    "\n",
    "**This notebook solves that problem** by teaching you differential privacy with mathematical guarantees!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites (What You Need First) | ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- ‚úÖ **Example 1: Data Protection** - Understanding basic protection\n",
    "- ‚úÖ **Example 2: Privacy Technologies** - Understanding PETs\n",
    "- ‚úÖ **Basic Python knowledge**: Functions, data manipulation\n",
    "- ‚úÖ **Basic statistics**: Understanding of means, counts, noise\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why mathematical guarantees matter\n",
    "- Knowing how epsilon parameter works\n",
    "- Understanding privacy-utility trade-offs in differential privacy\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Where This Notebook Fits | ŸÖŸÉÿßŸÜ Ÿáÿ∞ÿß ÿßŸÑÿØŸÅÿ™ÿ±\n",
    "\n",
    "**This is the THIRD example in Unit 3** - it teaches you mathematical privacy guarantees!\n",
    "\n",
    "**Why this example THIRD?**\n",
    "- **Before** you can use differential privacy, you need basic protection (Example 1)\n",
    "- **Before** you can use differential privacy, you need to understand PETs (Example 2)\n",
    "- **Before** you can ensure GDPR compliance, you need privacy guarantees\n",
    "\n",
    "**Builds on**: \n",
    "- üìì Example 1: Data Protection (basic protection strategies)\n",
    "- üìì Example 2: Privacy Technologies (advanced PETs)\n",
    "\n",
    "**Leads to**: \n",
    "- üìì Example 4: GDPR Compliance (regulatory compliance)\n",
    "- üìì Example 5: Secure Development (secure coding practices)\n",
    "\n",
    "**Why this order?**\n",
    "1. Differential privacy provides **mathematical guarantees** (strongest privacy)\n",
    "2. Differential privacy enables **provable privacy** (critical for compliance)\n",
    "3. Differential privacy shows **quantifiable protection** (epsilon parameter)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Provable Privacy | ÿßŸÑŸÇÿµÿ©: ÿßŸÑÿÆÿµŸàÿµŸäÿ© ÿßŸÑŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ•ÿ´ÿ®ÿßÿ™\n",
    "\n",
    "Imagine you're a scientist publishing research results. **Before** differential privacy, you'd say \"we anonymized the data\" but couldn't prove how private it was. **After** using differential privacy, you can say \"we provide (Œµ=0.5)-differential privacy\" - a mathematical guarantee!\n",
    "\n",
    "Same with AI: **Before** we use privacy techniques but can't prove privacy, now we learn differential privacy - add noise with epsilon parameter to get provable privacy guarantees! **After** differential privacy, we can mathematically prove our systems are private!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Differential Privacy Matters | ŸÑŸÖÿßÿ∞ÿß ÿ™ŸáŸÖ ÿßŸÑÿÆÿµŸàÿµŸäÿ© ÿßŸÑÿ™ŸÅÿßÿ∂ŸÑŸäÿ©ÿü\n",
    "\n",
    "Differential privacy is essential for ethical AI:\n",
    "- **Mathematical Guarantees**: Provable privacy protection\n",
    "- **Quantifiable Privacy**: Measure privacy loss (epsilon)\n",
    "- **Formal Definition**: Rigorous privacy definition\n",
    "- **Compliance**: Meet strict privacy regulations\n",
    "- **Trust**: Build confidence with provable guarantees\n",
    "\n",
    "## Learning Objectives | ÿ£ŸáÿØÿßŸÅ ÿßŸÑÿ™ÿπŸÑŸÖ\n",
    "1. Understand differential privacy and epsilon parameter\n",
    "2. Learn how to add noise for privacy\n",
    "3. Understand privacy-utility trade-offs\n",
    "4. Apply differential privacy to data analysis\n",
    "5. Compare different epsilon values\n",
    "6. Understand when to use differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:58:59.155383Z",
     "iopub.status.busy": "2025-12-26T16:58:59.155226Z",
     "iopub.status.idle": "2025-12-26T16:59:00.595951Z",
     "shell.execute_reply": "2025-12-26T16:59:00.595748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 3 - Example 3: Differential Privacy\n",
      "================================================================================\n",
      "\n",
      "Dataset: 1000 samples\n",
      "True mean: $50,289.98\n",
      "True count: 1000\n",
      "\n",
      "================================================================================\n",
      "Differential Privacy Demonstration\n",
      "================================================================================\n",
      "\n",
      "Epsilon (Œµ) = 0.1:\n",
      "  True mean: $50,289.98, Noisy mean: $49,126.14\n",
      "  Error: $1,163.84\n",
      "  True count: 1000, Noisy count: 984\n",
      "  Privacy level: 10.00 (higher = more private)\n",
      "\n",
      "Epsilon (Œµ) = 0.5:\n",
      "  True mean: $50,289.98, Noisy mean: $50,357.79\n",
      "  Error: $67.81\n",
      "  True count: 1000, Noisy count: 1001\n",
      "  Privacy level: 2.00 (higher = more private)\n",
      "\n",
      "Epsilon (Œµ) = 1.0:\n",
      "  True mean: $50,289.98, Noisy mean: $49,996.09\n",
      "  Error: $293.89\n",
      "  True count: 1000, Noisy count: 1002\n",
      "  Privacy level: 1.00 (higher = more private)\n",
      "\n",
      "Epsilon (Œµ) = 2.0:\n",
      "  True mean: $50,289.98, Noisy mean: $50,169.53\n",
      "  Error: $120.45\n",
      "  True count: 1000, Noisy count: 1000\n",
      "  Privacy level: 0.50 (higher = more private)\n",
      "\n",
      "Epsilon (Œµ) = 5.0:\n",
      "  True mean: $50,289.98, Noisy mean: $50,301.50\n",
      "  Error: $11.52\n",
      "  True count: 1000, Noisy count: 1000\n",
      "  Privacy level: 0.20 (higher = more private)\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: differential_privacy_analysis.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Differential privacy adds controlled noise to protect individual privacy\n",
      "2. Epsilon (Œµ) controls privacy level: smaller Œµ = more private\n",
      "3. There is a trade-off between privacy and data utility\n",
      "4. Differential privacy provides mathematical privacy guarantees\n",
      "5. Choose epsilon based on privacy requirements and acceptable error\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 3: Privacy, Security, and Data Protection\n",
    "Example 3: Differential Privacy\n",
    "This example demonstrates differential privacy concepts:\n",
    "- Adding noise for privacy\n",
    "- Privacy-utility trade-offs\n",
    "- Epsilon (Œµ) parameter\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "# ============================================================================\n",
    "# DIFFERENTIAL PRIVACY IMPLEMENTATION\n",
    "# ============================================================================\n",
    "def add_laplace_noise(value, epsilon=1.0, sensitivity=1.0):\n",
    "    \"\"\"\n",
    "    Add Laplace noise for differential privacy\n",
    "    epsilon (Œµ): privacy parameter (smaller = more private)\n",
    "    sensitivity: maximum change in output from changing one record\n",
    "    \"\"\"\n",
    "    scale = sensitivity / epsilon\n",
    "    noise = np.random.laplace(0, scale)\n",
    "    return value + noise\n",
    "def differentially_private_mean(data, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Compute differentially private mean\n",
    "    \"\"\"\n",
    "    true_mean = np.mean(data)\n",
    "    sensitivity = (data.max() - data.min()) / len(data)\n",
    "    noisy_mean = add_laplace_noise(true_mean, epsilon, sensitivity)\n",
    "    return true_mean, noisy_mean\n",
    "def differentially_private_count(data, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Compute differentially private count\n",
    "    \"\"\"\n",
    "    true_count = len(data)\n",
    "    sensitivity = 1.0  # Adding\n",
    "    noisy_count = add_laplace_noise(true_count, epsilon, sensitivity)\n",
    "    return true_count, max(0, int(noisy_count))  # Ensure non-negative\n",
    "# ============================================================================\n",
    "# PRIVACY-UTILITY TRADE-OFF\n",
    "# ============================================================================\n",
    "def analyze_epsilon_impact(data, epsilon_values):\n",
    "    \"\"\"\n",
    "    Analyze how different epsilon values affect privacy and utility\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    true_mean = np.mean(data)\n",
    "    true_count = len(data)\n",
    "    for epsilon in epsilon_values:\n",
    "        # Compute multiple times to show variance\n",
    "        noisy_means = []\n",
    "        noisy_counts = []\n",
    "        for _ in range(10):\n",
    "            _, noisy_mean = differentially_private_mean(data, epsilon)\n",
    "            _, noisy_count = differentially_private_count(data, epsilon)\n",
    "            noisy_means.append(noisy_mean)\n",
    "            noisy_counts.append(noisy_count)\n",
    "        mean_error = np.mean([abs(m - true_mean) for m in noisy_means])\n",
    "        count_error = np.mean([abs(c - true_count) for c in noisy_counts])\n",
    "        results.append({\n",
    "            'epsilon': epsilon, 'privacy_level': 1.0 / epsilon,  # Higher epsilon = less private\n",
    "            'mean_error': mean_error,\n",
    "            'count_error': count_error,\n",
    "            'noisy_mean_avg': np.mean(noisy_means),\n",
    "            'noisy_count_avg': np.mean(noisy_counts)\n",
    "        })\n",
    "    return results\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_differential_privacy_comparison(data, epsilon_values):\n",
    "    \"\"\"\n",
    "    Plot comparison of differential privacy with different epsilon values\n",
    "    \"\"\"\n",
    "    results = analyze_epsilon_impact(data, epsilon_values)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    epsilons = [r['epsilon'] for r in results]\n",
    "    mean_errors = [r['mean_error'] for r in results]\n",
    "    count_errors = [r['count_error'] for r in results]\n",
    "    privacy_levels = [r['privacy_level'] for r in results]\n",
    "    # Mean error vs epsilon\n",
    "    axes[0, 0].plot(epsilons, mean_errors, marker='o', linewidth=2, markersize=8, color='#e74c3c')\n",
    "    axes[0, 0].set_xlabel('Epsilon (Œµ)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Mean Error', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Privacy vs Accuracy: Mean Estimation', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    axes[0, 0].set_xscale('log')\n",
    "    # Count error vs epsilon\n",
    "    axes[0, 1].plot(epsilons, count_errors, marker='s', linewidth=2, markersize=8, color='#3498db')\n",
    "    axes[0, 1].set_xlabel('Epsilon (Œµ)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Count Error', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_title('Privacy vs Accuracy: Count Estimation', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    axes[0, 1].set_xscale('log')\n",
    "    # Privacy level\n",
    "    axes[1, 0].bar(range(len(epsilons)), privacy_levels, color='#9b59b6', alpha=0.8)\n",
    "    axes[1, 0].set_xlabel('Epsilon Value Index', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Privacy Level (Higher is Better)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_title('Privacy Level by Epsilon', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xticks(range(len(epsilons)))\n",
    "    axes[1, 0].set_xticklabels([f'Œµ={e:.2f}' for e in epsilons], rotation=15)\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    # Privacy-utility trade-off\n",
    "    axes[1, 1].scatter(privacy_levels, mean_errors, s=200, alpha=0.7, \n",
    "                      c=epsilons, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Privacy Level', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Mean Error (Lower is Better)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_title('Privacy-Utility Trade-off', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "    cbar.set_label('Epsilon (Œµ)', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: differential_privacy_analysis.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 3 - Example 3: Differential Privacy\")\n",
    "    print(\"=\"*80)\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    data = np.random.normal(50000, 15000, 1000)  # Salary data\n",
    "    print(f\"\\nDataset: {len(data)} samples\")\n",
    "    print(f\"True mean: ${np.mean(data):,.2f}\")\n",
    "    print(f\"True count: {len(data)}\")\n",
    "    # Demonstrate differential privacy\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Differential Privacy Demonstration\")\n",
    "    print(\"=\"*80)\n",
    "    epsilon_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "    for epsilon in epsilon_values:\n",
    "        true_mean, noisy_mean = differentially_private_mean(data, epsilon)\n",
    "        true_count, noisy_count = differentially_private_count(data, epsilon)\n",
    "        print(f\"\\nEpsilon (Œµ) = {epsilon}:\")\n",
    "        print(f\"  True mean: ${true_mean:,.2f}, Noisy mean: ${noisy_mean:,.2f}\")\n",
    "        print(f\"  Error: ${abs(noisy_mean - true_mean):,.2f}\")\n",
    "        print(f\"  True count: {true_count}, Noisy count: {noisy_count}\")\n",
    "        print(f\"  Privacy level: {1.0 / epsilon:.2f} (higher = more private)\")\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations...\")\n",
    "    print(\"=\"*80)\n",
    "    plot_differential_privacy_comparison(data, epsilon_values)\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. Differential privacy adds controlled noise to protect individual privacy\")\n",
    "    print(\"2. Epsilon (Œµ) controls privacy level: smaller Œµ = more private\")\n",
    "    print(\"3. There is a trade-off between privacy and data utility\")\n",
    "    print(\"4. Differential privacy provides mathematical privacy guarantees\")\n",
    "    print(\"5. Choose epsilon based on privacy requirements and acceptable error\")\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üö´ When Differential Privacy Hits a Limitation | ÿπŸÜÿØŸÖÿß ÿ™ÿµŸÑ ÿßŸÑÿÆÿµŸàÿµŸäÿ© ÿßŸÑÿ™ŸÅÿßÿ∂ŸÑŸäÿ© ÿ•ŸÑŸâ ÿ≠ÿØ\n",
    "\n",
    "### The Limitation We Discovered\n",
    "\n",
    "We've learned differential privacy with mathematical guarantees. **But there's still a challenge:**\n",
    "\n",
    "**How do we ensure our AI systems comply with privacy regulations like GDPR?**\n",
    "\n",
    "Differential privacy works well when:\n",
    "- ‚úÖ We can add noise to queries\n",
    "- ‚úÖ We can quantify privacy loss (epsilon)\n",
    "- ‚úÖ We can prove mathematical privacy guarantees\n",
    "\n",
    "**But real-world AI systems must also:**\n",
    "- ‚ùå **Comply with regulations** (GDPR, CCPA, etc.)\n",
    "- ‚ùå **Implement data subject rights** (right to access, deletion, etc.)\n",
    "- ‚ùå **Document privacy practices** (privacy impact assessments)\n",
    "- ‚ùå **Meet legal requirements** (consent, data minimization, etc.)\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "When we have privacy techniques but don't comply with regulations:\n",
    "- We may violate privacy laws\n",
    "- We may face legal penalties\n",
    "- We may not meet data subject rights\n",
    "- We may not document our privacy practices properly\n",
    "\n",
    "### The Solution: GDPR Compliance\n",
    "\n",
    "We need **GDPR compliance practices** to:\n",
    "1. Implement data subject rights\n",
    "2. Document privacy practices\n",
    "3. Meet legal requirements\n",
    "4. Ensure regulatory compliance\n",
    "\n",
    "**This is exactly what we'll learn in the next notebook: GDPR Compliance!**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Steps | ÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©\n",
    "\n",
    "**You've completed this notebook!** Now you understand:\n",
    "- ‚úÖ How to use basic data protection (Notebook 1)\n",
    "- ‚úÖ How to use advanced privacy technologies (Notebook 2)\n",
    "- ‚úÖ How to use differential privacy (This notebook!)\n",
    "- ‚úÖ **The limitation**: We need regulatory compliance!\n",
    "\n",
    "**Next notebook**: `04_gdpr_compliance.ipynb`\n",
    "- Learn about GDPR requirements\n",
    "- Implement data subject rights\n",
    "- Document privacy practices\n",
    "- Ensure regulatory compliance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}