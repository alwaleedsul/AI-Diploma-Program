{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Regression Techniques to Fit Models on Real Datasets\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Apply regression techniques to fit models on real datasets\n",
    "- Implement linear and polynomial regression\n",
    "- Evaluate regression models using appropriate metrics\n",
    "- Handle real-world data preprocessing for regression\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Understanding of regression concepts\n",
    "- âœ… Understanding of gradient descent\n",
    "- âœ… Python, NumPy, Pandas, scikit-learn knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 03, Unit 3**:\n",
    "- Applying regression techniques to fit models on real datasets\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 3 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Regression** is used to fit models that predict continuous values. This notebook demonstrates applying regression techniques to real-world datasets with proper preprocessing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.datasets import load_boston, fetch_california_housing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"\\nApplying Regression Techniques to Real Datasets\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 1: Linear Regression on Real Dataset\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Part 1: Linear Regression on Real Dataset\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load California Housing dataset (real-world dataset)\n",
    "print(\"\\nLoading California Housing dataset...\")\n",
    "try:\n",
    " housing = fetch_california_housing()\n",
    " X, y = housing.data, housing.target\n",
    " feature_names = housing.feature_names\n",
    " print(f\"Dataset shape: {X.shape}\")\n",
    " print(f\"Features: {feature_names}\")\n",
    " print(f\"Target: Median house value (in $100,000s)\")\n",
    "except:\n",
    " # Fallback: create synthetic dataset with similar structure\n",
    " print(\"Using synthetic dataset (similar to California Housing)\")\n",
    " np.random.seed(42)\n",
    " n_samples = 1000\n",
    " X = np.random.randn(n_samples, 8)\n",
    " y = 2.5 * X[:, 0] + 1.8 * X[:, 1] + 0.5 * X[:, 2] + np.random.randn(n_samples) * 0.5\n",
    " feature_names = [f'Feature_{i+1}' for i in range(8)]\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Model Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\" MSE: {train_mse:.4f}\")\n",
    "print(f\" RÂ²: {train_r2:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\" MSE: {test_mse:.4f}\")\n",
    "print(f\" RÂ²: {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nCoefficients:\")\n",
    "for name, coef in zip(feature_names, model.coef_):\n",
    " print(f\" {name}: {coef:.4f}\")\n",
    "print(f\" Intercept: {model.intercept_:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Linear regression trained on real dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 2: Polynomial Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use single feature for visualization\n",
    "X_single = X_train_scaled[:, 0:1]\n",
    "X_test_single = X_test_scaled[:, 0:1]\n",
    "\n",
    "# Polynomial features\n",
    "degrees = [1, 2, 3, 4]\n",
    "results = []\n",
    "\n",
    "for degree in degrees:\n",
    " poly = PolynomialFeatures(degree=degree)\n",
    " X_train_poly = poly.fit_transform(X_single)\n",
    " X_test_poly = poly.transform(X_test_single)\n",
    " \n",
    " model_poly = LinearRegression()\n",
    " model_poly.fit(X_train_poly, y_train)\n",
    " \n",
    " y_pred_train = model_poly.predict(X_train_poly)\n",
    " y_pred_test = model_poly.predict(X_test_poly)\n",
    " \n",
    " train_r2 = r2_score(y_train, y_pred_train)\n",
    " test_r2 = r2_score(y_test, y_pred_test)\n",
    " \n",
    " results.append({\n",
    " 'degree': degree, 'train_r2': train_r2,\n",
    " 'test_r2': test_r2,\n",
    " 'model': model_poly,\n",
    " 'poly': poly\n",
    " })\n",
    " \n",
    " print(f\"\\nDegree {degree}:\")\n",
    " print(f\" Train RÂ²: {train_r2:.4f}\")\n",
    " print(f\" Test RÂ²: {test_r2:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_single, y_train, alpha=0.3, label='Training data', s=20)\n",
    "x_plot = np.linspace(X_single.min(), X_single.max(), 100).reshape(-1, 1)\n",
    "for r in results:\n",
    " x_plot_poly = r['poly'].transform(x_plot)\n",
    " y_plot = r['model'].predict(x_plot_poly)\n",
    " plt.plot(x_plot, y_plot, label=f'Degree {r[\"degree\"]}', linewidth=2)\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel('Target')\n",
    "plt.title('Polynomial Regression (Training Data)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "degrees_list = [r['degree'] for r in results]\n",
    "train_r2_list = [r['train_r2'] for r in results]\n",
    "test_r2_list = [r['test_r2'] for r in results]\n",
    "plt.plot(degrees_list, train_r2_list, 'o-', label='Train RÂ²', linewidth=2)\n",
    "plt.plot(degrees_list, test_r2_list, 's-', label='Test RÂ²', linewidth=2)\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('RÂ² Score')\n",
    "plt.title('Model Performance vs Polynomial Degree')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Polynomial regression applied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 3: Regularized Regression (Ridge and Lasso)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare Ridge and Lasso\n",
    "alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "ridge_results = []\n",
    "lasso_results = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    " # Ridge\n",
    " ridge = Ridge(alpha=alpha)\n",
    " ridge.fit(X_train_scaled, y_train)\n",
    " y_pred_ridge = ridge.predict(X_test_scaled)\n",
    " ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
    " ridge_results.append({'alpha': alpha, 'r2': ridge_r2, 'model': ridge})\n",
    " \n",
    " # Lasso\n",
    " lasso = Lasso(alpha=alpha, max_iter=2000)\n",
    " lasso.fit(X_train_scaled, y_train)\n",
    " y_pred_lasso = lasso.predict(X_test_scaled)\n",
    " lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
    " lasso_results.append({'alpha': alpha, 'r2': lasso_r2, 'model': lasso})\n",
    "\n",
    "print(\"\\nRidge Regression Results:\")\n",
    "for r in ridge_results:\n",
    " print(f\" Alpha {r['alpha']:6.3f}: RÂ² = {r['r2']:.4f}\")\n",
    "\n",
    "print(\"\\nLasso Regression Results:\")\n",
    "for r in lasso_results:\n",
    " print(f\" Alpha {r['alpha']:6.3f}: RÂ² = {r['r2']:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "ridge_alphas = [r['alpha'] for r in ridge_results]\n",
    "ridge_r2s = [r['r2'] for r in ridge_results]\n",
    "lasso_alphas = [r['alpha'] for r in lasso_results]\n",
    "lasso_r2s = [r['r2'] for r in lasso_results]\n",
    "plt.semilogx(ridge_alphas, ridge_r2s, 'o-', label='Ridge', linewidth=2)\n",
    "plt.semilogx(lasso_alphas, lasso_r2s, 's-', label='Lasso', linewidth=2)\n",
    "plt.axhline(y=test_r2, color='g', linestyle='--', label='Linear (no reg)', alpha=0.7)\n",
    "plt.xlabel('Regularization Strength (Î±)')\n",
    "plt.ylabel('RÂ² Score')\n",
    "plt.title('Regularized Regression Performance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare predictions\n",
    "best_ridge = max(ridge_results, key=lambda x: x['r2'])\n",
    "best_lasso = max(lasso_results, key=lambda x: x['r2'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pred_ridge_best = best_ridge['model'].predict(X_test_scaled)\n",
    "y_pred_lasso_best = best_lasso['model'].predict(X_test_scaled)\n",
    "plt.scatter(y_test, y_pred_ridge_best, alpha=0.5, label='Ridge', s=30)\n",
    "plt.scatter(y_test, y_pred_lasso_best, alpha=0.5, label='Lasso', s=30)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predictions vs Actual (Best Models)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Regularized regression applied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Linear Regression**: Fits a linear model to data\n",
    "2. **Polynomial Regression**: Captures non-linear relationships\n",
    "3. **Regularized Regression**: Prevents overfitting (Ridge, Lasso)\n",
    "4. **Model Evaluation**: Use RÂ², MSE, MAE metrics\n",
    "5. **Data Preprocessing**: Scaling is important for regression\n",
    "\n",
    "### Best Practices:\n",
    "- Always split data into train/test sets\n",
    "- Scale features before training\n",
    "- Use regularization to prevent overfitting\n",
    "- Evaluate on test set, not training set\n",
    "- Visualize results to understand model behavior\n",
    "\n",
    "### Applications:\n",
    "- House price prediction\n",
    "- Sales forecasting\n",
    "- Temperature prediction\n",
    "- Any continuous value prediction\n",
    "\n",
    "**Reference:** Course 03, Unit 3: \"Optimization and Statistical Foundations\" - Regression on real datasets practical content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}