{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron, MLP, and Deep Learning Framework Setup\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand deep learning fundamentals compared to traditional ML\n",
    "- Implement basic perceptron from scratch\n",
    "- Build Multi-Layer Perceptron (MLP) models\n",
    "- Set up TensorFlow and PyTorch environments\n",
    "- Compare TensorFlow and PyTorch approaches\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Understanding of basic machine learning concepts\n",
    "- ‚úÖ Python 3.8+ installed\n",
    "- ‚úÖ Basic NumPy knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 08, Unit 1**:\n",
    "- Deep learning fundamentals compared to traditional ML\n",
    "- Setting up TensorFlow and PyTorch\n",
    "- Implementing basic perceptron and MLP\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 1 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Deep Learning** is a subset of machine learning that uses neural networks with multiple layers to learn hierarchical representations of data. Unlike traditional ML, deep learning can automatically discover features from raw data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ Google Colab Setup (Run this first if using Colab)\n",
    "ÿØŸÑŸäŸÑ ÿ•ÿπÿØÿßÿØ Google Colab (ŸÇŸÖ ÿ®ÿ™ÿ¥ÿ∫ŸäŸÑ Ÿáÿ∞ÿß ÿ£ŸàŸÑÿßŸã ÿ•ÿ∞ÿß ŸÉŸÜÿ™ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ Colab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Inputs & üì§ Outputs | ÿßŸÑŸÖÿØÿÆŸÑÿßÿ™ ŸàÿßŸÑŸÖÿÆÿ±ÿ¨ÿßÿ™\n",
    "\n",
    "**Inputs:** What we use in this notebook\n",
    "\n",
    "- Libraries and concepts as introduced in this notebook; see prerequisites and code comments.\n",
    "\n",
    "**Outputs:** What you'll see when you run the cells\n",
    "\n",
    "- Printed results, figures, and summaries as shown when you run the cells.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try importing TensorFlow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    HAS_TF = True\n",
    "    print(f\"‚úÖ TensorFlow {tf.__version__} imported successfully!\")\n",
    "except ImportError:\n",
    "    HAS_TF = False\n",
    "    print(\"‚ö†Ô∏è  TensorFlow not available. Install with: pip install tensorflow\")\n",
    "\n",
    "# Try importing PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    HAS_TORCH = True\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} imported successfully!\")\n",
    "except ImportError:\n",
    "    HAS_TORCH = False\n",
    "    print(\"‚ö†Ô∏è  PyTorch not available. Install with: pip install torch\")\n",
    "\n",
    "print(\"‚úÖ NumPy and Matplotlib ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Deep Learning vs Traditional ML\n",
    "\n",
    "Let's compare the fundamental differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Deep Learning vs Traditional ML\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison = {\n",
    "    \"Feature Engineering\": {\n",
    "        \"Traditional ML\": \"Manual feature extraction required\", \"Deep Learning\": \"Automatic feature learning from raw data\"\n",
    "    },\n",
    "    \"Data Requirements\": {\n",
    "        \"Traditional ML\": \"Works well with small to medium datasets\",\n",
    "        \"Deep Learning\": \"Requires large datasets for best performance\"\n",
    "    },\n",
    "    \"Model Complexity\": {\n",
    "        \"Traditional ML\": \"Simpler, more interpretable models\",\n",
    "        \"Deep Learning\": \"Complex, hierarchical representations\"\n",
    "    },\n",
    "    \"Performance\": {\n",
    "        \"Traditional ML\": \"Good for structured data\",\n",
    "        \"Deep Learning\": \"Excels with unstructured data (images, text, audio)\"\n",
    "    },\n",
    "    \"Training Time\": {\n",
    "        \"Traditional ML\": \"Faster training\",\n",
    "        \"Deep Learning\": \"Longer training, benefits from GPUs\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for aspect, details in comparison.items():\n",
    "    print(f\"\\n{aspect}:\")\n",
    "    print(f\"  Traditional ML: {details['Traditional ML']}\")\n",
    "    print(f\"  Deep Learning: {details['Deep Learning']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Key Insight: Deep learning automatically learns features, making it powerful for complex patterns!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Perceptron Implementation\n",
    "\n",
    "A perceptron is the simplest neural network - a single neuron with weights and bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"Simple Perceptron implementation from scratch\"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Multi-Layer Perceptron (MLP) with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TF:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MLP with TensorFlow/Keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Multi-Layer Perceptron (MLP) with PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MLP with PyTorch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Deep Learning vs Traditional ML**: Automatic feature learning, requires more data, better for unstructured data\n",
    "2. **Perceptron**: Single neuron, can learn simple linear patterns (e.g., AND gate)\n",
    "3. **MLP (Multi-Layer Perceptron)**: Multiple layers of neurons, can learn complex non-linear patterns\n",
    "4. **TensorFlow/Keras**: High-level API, easier to use, great for rapid prototyping\n",
    "5. **PyTorch**: More flexible, imperative style, better for research and custom architectures\n",
    "\n",
    "### Framework Comparison:\n",
    "- **TensorFlow**: Industry standard, production-ready, extensive ecosystem\n",
    "- **PyTorch**: Research-friendly, dynamic computation graphs, intuitive API\n",
    "\n",
    "### When to Use:\n",
    "- **TensorFlow**: Production deployment, large-scale systems, when you need TF Serving\n",
    "- **PyTorch**: Research, experimentation, when you need dynamic graphs\n",
    "\n",
    "**Reference:** Course 08, Unit 1: \"Deep learning fundamentals compared to traditional ML\", \"Setting up TensorFlow and PyTorch\", and \"Implementing basic perceptron and MLP\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}