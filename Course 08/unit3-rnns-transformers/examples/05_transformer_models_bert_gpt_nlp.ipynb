{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Transformer Models (BERT, GPT) for NLP Tasks\n",
        "\n",
        "## ðŸ“š Learning Objectives\n",
        "\n",
        "By completing this notebook, you will:\n",
        "- Use BERT for NLP tasks\n",
        "- Use GPT for NLP tasks\n",
        "- Apply transformers to classification\n",
        "- Apply transformers to generation\n",
        "- Fine-tune transformer models\n",
        "\n",
        "## ðŸ”— Prerequisites\n",
        "\n",
        "- âœ… Understanding of transformers\n",
        "- âœ… Understanding of BERT and GPT\n",
        "- âœ… Hugging Face Transformers knowledge\n",
        "\n",
        "---\n",
        "\n",
        "## Official Structure Reference\n",
        "\n",
        "This notebook covers practical activities from **Course 08, Unit 3**:\n",
        "- Using Transformer models like BERT and GPT for NLP tasks\n",
        "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 3 Practical Content\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "**Transformer models** like BERT and GPT have revolutionized NLP, providing powerful pre-trained models for various text understanding and generation tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n",
        "import torch\n",
        "\n",
        "print(\"âœ… Libraries imported!\")\n",
        "print(\"\\nTransformer Models: BERT and GPT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nBERT (Bidirectional Encoder Representations):\")\n",
        "print(\"  - Bidirectional context\")\n",
        "print(\"  - Masked language modeling\")\n",
        "print(\"  - Good for understanding tasks\")\n",
        "\n",
        "print(\"\\nGPT (Generative Pre-trained Transformer):\")\n",
        "print(\"  - Autoregressive generation\")\n",
        "print(\"  - Left-to-right context\")\n",
        "print(\"  - Good for generation tasks\")\n",
        "\n",
        "print(\"\\nNLP Tasks:\")\n",
        "print(\"  - Text classification\")\n",
        "print(\"  - Named entity recognition\")\n",
        "print(\"  - Question answering\")\n",
        "print(\"  - Text generation\")\n",
        "\n",
        "print(\"\\nâœ… Transformer models concepts understood!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
