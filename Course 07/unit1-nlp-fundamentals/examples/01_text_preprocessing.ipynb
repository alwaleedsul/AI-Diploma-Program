{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Text Preprocessing\n",
        "\n",
        "## ğŸ“š Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
        "\n",
        "This notebook demonstrates key concepts through hands-on examples.\n",
        "\n",
        "By completing this notebook, you will:\n",
        "- Understand the core concepts\n",
        "- See practical implementations\n",
        "- Be ready for exercises\n",
        "\n",
        "## ğŸ”— Prerequisites | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
        "\n",
        "- âœ… Python 3.8+ installed\n",
        "- âœ… Required libraries (see `requirements.txt`)\n",
        "- âœ… Basic Python knowledge\n",
        "\n",
        "---\n",
        "\n",
        "## Code Example | Ù…Ø«Ø§Ù„ Ø§Ù„ÙƒÙˆØ¯\n",
        "\n",
        "Run the code below to see the demonstration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Unit 1 - Example 1: Text Preprocessing\n",
        "Ø§Ù„ÙˆØ­Ø¯Ø© 1 - Ù…Ø«Ø§Ù„ 1: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù…Ø³Ø¨Ù‚Ø§Ù‹\n",
        "\n",
        "This example demonstrates:\n",
        "1. Text tokenization\n",
        "2. Text normalization\n",
        "3. Stop word removal\n",
        "4. Stemming and lemmatization\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Example 1: Text Preprocessing\")\n",
        "print(\"Ù…Ø«Ø§Ù„ 1: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù…Ø³Ø¨Ù‚Ø§Ù‹\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Sample text\n",
        "# Ù†Øµ Ù†Ù…ÙˆØ°Ø¬ÙŠ\n",
        "sample_text = \"\"\"\n",
        "Natural Language Processing (NLP) is a branch of artificial intelligence\n",
        "that helps computers understand, interpret, and manipulate human language.\n",
        "NLP combines computational linguistics with machine learning.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nOriginal Text:\")\n",
        "print(\"Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:\")\n",
        "print(sample_text)\n",
        "\n",
        "# 1. Tokenization\n",
        "# Ø§Ù„ØªÙ‚Ø·ÙŠØ¹\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"1. Tokenization\")\n",
        "print(\"Ø§Ù„ØªÙ‚Ø·ÙŠØ¹\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def simple_tokenize(text):\n",
        "    \"\"\"\n",
        "    Simple tokenization by splitting on whitespace.\n",
        "    ØªÙ‚Ø·ÙŠØ¹ Ø¨Ø³ÙŠØ· Ø¨ØªÙ‚Ø³ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡.\n",
        "    \"\"\"\n",
        "    # Remove extra whitespace and split\n",
        "    tokens = text.lower().split()\n",
        "    return tokens\n",
        "\n",
        "tokens = simple_tokenize(sample_text)\n",
        "print(f\"\\nTokens: {tokens}\")\n",
        "print(f\"Number of tokens: {len(tokens)}\")\n",
        "\n",
        "# 2. Remove Punctuation\n",
        "# Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"2. Remove Punctuation\")\n",
        "print(\"Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"\n",
        "    Remove punctuation from text.\n",
        "    Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù…Ù† Ø§Ù„Ù†Øµ.\n",
        "    \"\"\"\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "cleaned_text = remove_punctuation(sample_text)\n",
        "print(f\"\\nCleaned text:\\n{cleaned_text}\")\n",
        "\n",
        "# 3. Stop Word Removal\n",
        "# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"3. Stop Word Removal\")\n",
        "print(\"Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Common English stop words\n",
        "# Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©\n",
        "stop_words = {'is', 'a', 'the', 'that', 'this', 'with', 'and', 'or', 'but'}\n",
        "\n",
        "def remove_stop_words(tokens, stop_words):\n",
        "    \"\"\"\n",
        "    Remove stop words from tokens.\n",
        "    Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ© Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ².\n",
        "    \"\"\"\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "filtered_tokens = remove_stop_words(tokens, stop_words)\n",
        "print(f\"\\nTokens after stop word removal: {filtered_tokens}\")\n",
        "\n",
        "# 4. Word Frequency\n",
        "# ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"4. Word Frequency Analysis\")\n",
        "print(\"ØªØ­Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "word_freq = Counter(filtered_tokens)\n",
        "print(\"\\nWord Frequencies:\")\n",
        "print(\"ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª:\")\n",
        "for word, freq in word_freq.most_common():\n",
        "    print(f\"  {word}: {freq}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Example completed successfully!\")\n",
        "print(\"ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## âœ… Summary | Ø§Ù„Ù…Ù„Ø®Øµ\n",
        "\n",
        "Great job completing this example!\n",
        "\n",
        "**What you learned:**\n",
        "- Core concepts demonstrated in the code\n",
        "- Practical implementation details\n",
        "\n",
        "**Next steps:**\n",
        "- Complete the exercises in `exercises/` folder\n",
        "- Review the quiz materials\n",
        "- Proceed to the next example\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ’¡ Tip:** If you see errors, make sure:\n",
        "- All libraries are installed: `pip install -r requirements.txt`\n",
        "- You're using Python 3.8+\n",
        "- Cells are executed in order\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}