{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Text Preprocessing\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 07, Unit 1** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Text Preprocessing\n",
    "\n",
    "## ğŸ“š Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "\n",
    "This notebook demonstrates key concepts through hands-on examples.\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the core concepts\n",
    "- See practical implementations\n",
    "- Be ready for exercises\n",
    "\n",
    "## ğŸ”— Prerequisites | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "- âœ… Python 3.8+ installed\n",
    "- âœ… Required libraries (see `requirements.txt`)\n",
    "- âœ… Basic Python knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Code Example | Ù…Ø«Ø§Ù„ Ø§Ù„ÙƒÙˆØ¯\n",
    "\n",
    "Run the code below to see the demonstration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualization: Word Frequency Chart\n",
    "# ØªØµÙˆØ±: Ù…Ø®Ø·Ø· ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Example word frequencies (from the code above)\n",
    "    words = ['natural', 'language', 'processing', 'nlp', 'artificial', 'intelligence']\n",
    "    frequencies = [2, 2, 1, 1, 1, 1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(words, frequencies, color='steelblue', alpha=0.7)\n",
    "    plt.xlabel('Words | Ø§Ù„ÙƒÙ„Ù…Ø§Øª', fontsize=12)\n",
    "    plt.ylabel('Frequency | Ø§Ù„ØªÙƒØ±Ø§Ø±', fontsize=12)\n",
    "    plt.title('Word Frequency Analysis | ØªØ­Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª', fontsize=14, pad=20)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"âœ… Word frequency chart displayed\")\n",
    "except ImportError:\n",
    "    print(\"Note: Install matplotlib for visualizations\")\n",
    "    print(\"Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª matplotlib Ù„Ù„ØªØµÙˆØ±Ø§Øª\")\n",
    "\n",
    "\"\"\"\n",
    "Unit 1 - Example 1: Text Preprocessing\n",
    "Ø§Ù„ÙˆØ­Ø¯Ø© 1 - Ù…Ø«Ø§Ù„ 1: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù…Ø³Ø¨Ù‚Ø§Ù‹\n",
    "\n",
    "This example demonstrates:\n",
    "1. Text tokenization\n",
    "2. Text normalization\n",
    "3. Stop word removal\n",
    "4. Stemming and lemmatization\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Text Preprocessing\")\n",
    "print(\"Ù…Ø«Ø§Ù„ 1: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù…Ø³Ø¨Ù‚Ø§Ù‹\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample text\n",
    "# Ù†Øµ Ù†Ù…ÙˆØ°Ø¬ÙŠ\n",
    "sample_text = \"\"\"\n",
    "Natural Language Processing (NLP) is a branch of artificial intelligence\n",
    "that helps computers understand, interpret, and manipulate human language.\n",
    "NLP combines computational linguistics with machine learning.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nOriginal Text:\")\n",
    "print(\"Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:\")\n",
    "print(sample_text)\n",
    "\n",
    "# 1. Tokenization\n",
    "# Ø§Ù„ØªÙ‚Ø·ÙŠØ¹\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"1. Tokenization\")\n",
    "print(\"Ø§Ù„ØªÙ‚Ø·ÙŠØ¹\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    \"\"\"\n",
    "    Simple tokenization by splitting on whitespace.\n",
    "    ØªÙ‚Ø·ÙŠØ¹ Ø¨Ø³ÙŠØ· Ø¨ØªÙ‚Ø³ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡.\n",
    "    \"\"\"\n",
    "    # Remove extra whitespace and split\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "tokens = simple_tokenize(sample_text)\n",
    "print(f\"\\nTokens: {tokens}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n",
    "\n",
    "# 2. Remove Punctuation\n",
    "# Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. Remove Punctuation\")\n",
    "print(\"Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Remove punctuation from text.\n",
    "    Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù…Ù† Ø§Ù„Ù†Øµ.\n",
    "    \"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "cleaned_text = remove_punctuation(sample_text)\n",
    "print(f\"\\nCleaned text:\\n{cleaned_text}\")\n",
    "\n",
    "# 3. Stop Word Removal\n",
    "# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. Stop Word Removal\")\n",
    "print(\"Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Common English stop words\n",
    "# Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©\n",
    "stop_words = {'is', 'a', 'the', 'that', 'this', 'with', 'and', 'or', 'but'}\n",
    "\n",
    "def remove_stop_words(tokens, stop_words):\n",
    "    \"\"\"\n",
    "    Remove stop words from tokens.\n",
    "    Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ© Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ².\n",
    "    \"\"\"\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "filtered_tokens = remove_stop_words(tokens, stop_words)\n",
    "print(f\"\\nTokens after stop word removal: {filtered_tokens}\")\n",
    "\n",
    "# 4. Word Frequency\n",
    "# ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. Word Frequency Analysis\")\n",
    "print(\"ØªØ­Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "word_freq = Counter(filtered_tokens)\n",
    "print(\"\\nWord Frequencies:\")\n",
    "print(\"ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª:\")\n",
    "for word, freq in word_freq.most_common():\n",
    "    print(f\"  {word}: {freq}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example completed successfully!\")\n",
    "print(\"ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualize word frequencies\n",
    "# ØªØµÙˆØ± ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if 'word_freq' in locals() and word_freq:\n",
    "        # Get top 10 most frequent words\n",
    "        top_words = word_freq.most_common(10) if hasattr(word_freq, 'most_common') else list(word_freq.items())[:10]\n",
    "        words = [w[0] if isinstance(w, tuple) else w for w in top_words]\n",
    "        freqs = [w[1] if isinstance(w, tuple) else word_freq[w] for w in top_words]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bars = plt.bar(words, freqs, color='steelblue', alpha=0.8, edgecolor='navy', linewidth=1.5)\n",
    "        plt.xlabel('Words | Ø§Ù„ÙƒÙ„Ù…Ø§Øª', fontsize=13, fontweight='bold')\n",
    "        plt.ylabel('Frequency | Ø§Ù„ØªÙƒØ±Ø§Ø±', fontsize=13, fontweight='bold')\n",
    "        plt.title('Top 10 Word Frequencies | Ø£Ø¹Ù„Ù‰ 10 ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø­ÙŠØ« Ø§Ù„ØªÙƒØ±Ø§Ø±', fontsize=15, pad=20, fontweight='bold')\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, freq in zip(bars, freqs):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{freq}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"\\nâœ… Word frequency visualization displayed!\")\n",
    "        print(\"ØªÙ… Ø¹Ø±Ø¶ ØªØµÙˆØ± ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Word frequency data not available for visualization\")\n",
    "except ImportError:\n",
    "    print(\"\\nğŸ“¦ To see word frequency visualization, install:\")\n",
    "    print(\"   pip install matplotlib\")\n",
    "    print(\"\\nÙ…Ù„Ø§Ø­Ø¸Ø©: Ù„Ø±Ø¤ÙŠØ© Ø§Ù„ØªØµÙˆØ±ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª:\")\n",
    "    print(\"   pip install matplotlib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Summary | Ø§Ù„Ù…Ù„Ø®Øµ\n",
    "\n",
    "Great job completing this example!\n",
    "\n",
    "**What you learned:**\n",
    "- Core concepts demonstrated in the code\n",
    "- Practical implementation details\n",
    "\n",
    "**Next steps:**\n",
    "- Complete the exercises in `exercises/` folder\n",
    "- Review the quiz materials\n",
    "- Proceed to the next example\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ Tip:** If you see errors, make sure:\n",
    "- All libraries are installed: `pip install -r requirements.txt`\n",
    "- You're using Python 3.8+\n",
    "- Cells are executed in order\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}