# Unit 4: Deep Learning for NLP | التعلم العميق لمعالجة اللغة الطبيعية
## AIAT 121 - Natural Language Processing

### Learning Objectives | أهداف التعلم

By the end of this unit, students will be able to:
- Understand RNNs and LSTMs for sequences
- Work with Transformer architecture
- Use pre-trained language models (BERT, GPT)
- Build deep learning models for NLP tasks
- Fine-tune language models

---

## Topics Covered | المواضيع المغطاة

1. **RNNs and LSTMs**
   - Recurrent Neural Networks
   - Long Short-Term Memory
   - Sequence modeling
   - Applications in NLP

2. **Transformers**
   - Attention mechanism
   - Transformer architecture
   - Self-attention
   - Encoder-decoder models

3. **Pre-trained Language Models**
   - BERT (Bidirectional Encoder Representations)
   - GPT (Generative Pre-trained Transformer)
   - Using Hugging Face Transformers
   - Fine-tuning

4. **Applications**
   - Text generation
   - Question answering
   - Named Entity Recognition
   - Machine translation basics

---

**Unit Duration:** 3 weeks  
**Difficulty:** Advanced  
**Prerequisites:** Units 1-3 completion, Deep Learning basics

