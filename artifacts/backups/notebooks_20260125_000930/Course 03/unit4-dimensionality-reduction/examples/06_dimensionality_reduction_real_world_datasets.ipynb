{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Applying Dimensionality Reduction to Real-World Datasets (Images and Text)\n",
        "\n",
        "## ðŸ“š Learning Objectives\n",
        "\n",
        "By completing this notebook, you will:\n",
        "- Apply dimensionality reduction techniques to real-world image datasets\n",
        "- Apply dimensionality reduction techniques to text data\n",
        "- Compare PCA, SVD, and t-SNE on different data types\n",
        "- Evaluate dimensionality reduction performance\n",
        "\n",
        "## ðŸ”— Prerequisites\n",
        "\n",
        "- âœ… Understanding of PCA, SVD, and t-SNE\n",
        "- âœ… Understanding of dimensionality reduction concepts\n",
        "- âœ… Python, NumPy, scikit-learn knowledge\n",
        "\n",
        "---\n",
        "\n",
        "## Official Structure Reference\n",
        "\n",
        "This notebook covers practical activities from **Course 03, Unit 4**:\n",
        "- Writing code to apply dimensionality reduction techniques on real-world datasets including images and text data\n",
        "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 4 Practical Content\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "**Dimensionality reduction** is crucial for handling high-dimensional real-world data. This notebook demonstrates applying PCA, SVD, and t-SNE to image and text datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.datasets import load_digits, fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Libraries imported!\")\n",
        "print(\"\\nApplying Dimensionality Reduction to Real-World Datasets\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Part 1: Dimensionality Reduction on Image Data\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Part 1: Dimensionality Reduction on Image Data\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load digit images dataset\n",
        "digits = load_digits()\n",
        "X_images = digits.data\n",
        "y_images = digits.target\n",
        "images = digits.images\n",
        "\n",
        "print(f\"\\nImage dataset shape: {X_images.shape}\")\n",
        "print(f\"Original dimension: {X_images.shape[1]} (8x8 pixels)\")\n",
        "print(f\"Number of samples: {X_images.shape[0]}\")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_images_scaled = scaler.fit_transform(X_images)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_images_scaled)\n",
        "print(f\"\\nPCA reduced to: {X_pca.shape}\")\n",
        "print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "# Apply t-SNE (takes longer)\n",
        "print(\"\\nApplying t-SNE (this may take a minute)...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "X_tsne = tsne.fit_transform(X_images_scaled[:1000])  # Use subset for speed\n",
        "print(f\"t-SNE reduced to: {X_tsne.shape}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_images, cmap='tab10', alpha=0.6, s=20)\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title(f'PCA (2D)\\nVariance: {pca.explained_variance_ratio_.sum():.2%}')\n",
        "plt.colorbar(scatter, label='Digit')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_images[:1000], cmap='tab10', alpha=0.6, s=20)\n",
        "plt.xlabel('t-SNE 1')\n",
        "plt.ylabel('t-SNE 2')\n",
        "plt.title('t-SNE (2D)')\n",
        "plt.colorbar(scatter, label='Digit')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Show original images\n",
        "plt.subplot(1, 3, 3)\n",
        "sample_indices = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
        "fig_grid = np.zeros((8*3, 8*4))\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    row = (i // 4) * 8\n",
        "    col = (i % 4) * 8\n",
        "    fig_grid[row:row+8, col:col+8] = images[idx]\n",
        "plt.imshow(fig_grid, cmap='gray')\n",
        "plt.title('Sample Original Images')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Dimensionality reduction applied to image data!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Part 2: Dimensionality Reduction on Text Data\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 2: Dimensionality Reduction on Text Data\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load text dataset\n",
        "print(\"\\nLoading 20 Newsgroups dataset...\")\n",
        "try:\n",
        "    newsgroups = fetch_20newsgroups(subset='train', categories=['alt.atheism', 'sci.space', 'rec.autos'], \n",
        "                                    shuffle=True, random_state=42)\n",
        "    texts = newsgroups.data[:500]  # Use subset\n",
        "    labels = newsgroups.target[:500]\n",
        "    category_names = [newsgroups.target_names[i] for i in labels]\n",
        "    print(f\"Loaded {len(texts)} text documents\")\n",
        "    print(f\"Categories: {set(category_names)}\")\n",
        "except:\n",
        "    print(\"Dataset not available, using synthetic text data\")\n",
        "    texts = [f\"Document {i} contains text about topic {i%3}\" for i in range(500)]\n",
        "    labels = np.array([i % 3 for i in range(500)])\n",
        "    category_names = ['Topic 0', 'Topic 1', 'Topic 2']\n",
        "\n",
        "# Convert text to TF-IDF vectors\n",
        "print(\"\\nConverting text to TF-IDF vectors...\")\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', max_df=0.95, min_df=2)\n",
        "X_text = vectorizer.fit_transform(texts)\n",
        "print(f\"TF-IDF matrix shape: {X_text.shape}\")\n",
        "print(f\"High-dimensional text representation: {X_text.shape[1]} features\")\n",
        "\n",
        "# Apply SVD (works with sparse matrices)\n",
        "svd = TruncatedSVD(n_components=2, random_state=42)\n",
        "X_svd = svd.fit_transform(X_text)\n",
        "print(f\"\\nSVD reduced to: {X_svd.shape}\")\n",
        "print(f\"Variance explained: {svd.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "# Apply PCA (needs dense matrix, so use SVD first for efficiency)\n",
        "pca_text = PCA(n_components=2)\n",
        "X_text_dense = X_text.toarray()  # Convert to dense (may be memory intensive)\n",
        "X_pca_text = pca_text.fit_transform(X_text_dense)\n",
        "print(f\"PCA reduced to: {X_pca_text.shape}\")\n",
        "print(f\"Variance explained: {pca_text.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "scatter = plt.scatter(X_svd[:, 0], X_svd[:, 1], c=labels, cmap='viridis', alpha=0.6, s=30)\n",
        "plt.xlabel('SVD Component 1')\n",
        "plt.ylabel('SVD Component 2')\n",
        "plt.title(f'SVD on Text Data\\nVariance: {svd.explained_variance_ratio_.sum():.2%}')\n",
        "plt.colorbar(scatter, label='Category')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "scatter = plt.scatter(X_pca_text[:, 0], X_pca_text[:, 1], c=labels, cmap='viridis', alpha=0.6, s=30)\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title(f'PCA on Text Data\\nVariance: {pca_text.explained_variance_ratio_.sum():.2%}')\n",
        "plt.colorbar(scatter, label='Category')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Dimensionality reduction applied to text data!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Concepts:\n",
        "1. **Image Data**: High-dimensional pixel vectors, benefit from PCA/t-SNE\n",
        "2. **Text Data**: High-dimensional TF-IDF vectors, benefit from SVD/PCA\n",
        "3. **PCA**: Linear, preserves global structure, works on dense matrices\n",
        "4. **SVD**: Linear, works on sparse matrices (good for text)\n",
        "5. **t-SNE**: Non-linear, preserves local structure, good for visualization\n",
        "\n",
        "### Best Practices:\n",
        "- Standardize data before PCA\n",
        "- Use SVD for sparse matrices (text data)\n",
        "- Use t-SNE for visualization (may be slow)\n",
        "- Consider variance explained when selecting components\n",
        "- Evaluate based on downstream task performance\n",
        "\n",
        "### Applications:\n",
        "- Image compression and visualization\n",
        "- Text document clustering\n",
        "- Feature extraction for ML models\n",
        "- Data exploration and visualization\n",
        "\n",
        "**Reference:** Course 03, Unit 4: \"Dimensionality Reduction\" - Real-world datasets practical content"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}