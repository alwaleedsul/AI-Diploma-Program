{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Counterfactual Analysis | ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ∂ÿßÿØ ŸÑŸÑŸàÿßŸÇÿπ\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Counterfactual Analysis | ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ∂ÿßÿØ ŸÑŸÑŸàÿßŸÇÿπ\n",
    "\n",
    "## üö® THE PROBLEM: We Need \"What If\" Explanations | ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©: ŸÜÿ≠ÿ™ÿßÿ¨ ÿ™ŸÅÿ≥Ÿäÿ±ÿßÿ™ \"ŸÖÿßÿ∞ÿß ŸÑŸà\"\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned LIME for fast, local explanations. But we discovered:\n",
    "\n",
    "**What if we need to understand what would change a prediction?**\n",
    "\n",
    "**The Problem**: Sometimes we need:\n",
    "- ‚ùå **\"What if\" scenarios** (what would change the outcome?)\n",
    "- ‚ùå **Actionable explanations** (what should I change to get a different result?)\n",
    "- ‚ùå **Counterfactual reasoning** (if X had been different, then Y would be different)\n",
    "- ‚ùå **Decision guidance** (how to achieve desired outcomes)\n",
    "\n",
    "**We've learned:**\n",
    "- ‚úÖ How to use SHAP for explanations (Notebook 1)\n",
    "- ‚úÖ How to use LIME for fast explanations (Notebook 2)\n",
    "- ‚úÖ Feature importance and local explanations\n",
    "\n",
    "**But we haven't learned:**\n",
    "- ‚ùå How to generate **counterfactual examples**\n",
    "- ‚ùå How to answer **\"what if\" questions**\n",
    "- ‚ùå How to provide **actionable guidance**\n",
    "- ‚ùå How to show **what needs to change** for different outcomes\n",
    "\n",
    "**We need counterfactual analysis** to:\n",
    "1. Generate \"what if\" scenarios\n",
    "2. Show what would change a prediction\n",
    "3. Provide actionable guidance\n",
    "4. Enable decision-making support\n",
    "\n",
    "**This notebook solves that problem** by teaching you counterfactual analysis for \"what if\" explanations!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites (What You Need First) | ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- ‚úÖ **Example 1: SHAP Explanations** - Understanding explainability\n",
    "- ‚úÖ **Example 2: LIME Explanations** - Understanding local explanations\n",
    "- ‚úÖ **Basic Python knowledge**: Functions, data manipulation, ML concepts\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why counterfactuals matter\n",
    "- Knowing how to generate counterfactual examples\n",
    "- Understanding what-if analysis\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Where This Notebook Fits | ŸÖŸÉÿßŸÜ Ÿáÿ∞ÿß ÿßŸÑÿØŸÅÿ™ÿ±\n",
    "\n",
    "**This is the THIRD example in Unit 4** - it teaches you \"what if\" explanations!\n",
    "\n",
    "**Why this example THIRD?**\n",
    "- **Before** you can use counterfactuals, you need basic explainability (Examples 1-2)\n",
    "- **Before** you can ensure accountability, you need multiple explanation methods\n",
    "- **Before** you can build transparent systems, you need actionable explanations\n",
    "\n",
    "**Builds on**: \n",
    "- üìì Example 1: SHAP Explanations (feature importance)\n",
    "- üìì Example 2: LIME Explanations (local explanations)\n",
    "\n",
    "**Leads to**: \n",
    "- üìì Example 4: Accountability Frameworks (accountability structures)\n",
    "- üìì Example 5: Human-in-the-Loop (HITL approaches)\n",
    "- üìì Example 6: Transparency Tools (transparency frameworks)\n",
    "\n",
    "**Why this order?**\n",
    "1. Counterfactuals provide **actionable explanations** (needed for decision-making)\n",
    "2. Counterfactuals teach **\"what if\" reasoning** (critical for understanding)\n",
    "3. Counterfactuals show **decision guidance** (essential for transparency)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: What Would Change the Outcome? | ÿßŸÑŸÇÿµÿ©: ŸÖÿßÿ∞ÿß ÿ≥Ÿäÿ∫Ÿäÿ± ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ©ÿü\n",
    "\n",
    "Imagine you're applying for a loan and got rejected. **Before** counterfactuals, you'd know you were rejected but not what to change. **After** using counterfactual analysis, you can see \"if your credit score was 50 points higher, you would be approved\" - actionable guidance!\n",
    "\n",
    "Same with AI: **Before** we have explanations but not actionable guidance, now we learn counterfactuals - generate \"what if\" scenarios to show what would change predictions! **After** counterfactuals, we can provide actionable explanations!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Counterfactual Analysis Matters | ŸÑŸÖÿßÿ∞ÿß ŸäŸáŸÖ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ∂ÿßÿØ ŸÑŸÑŸàÿßŸÇÿπÿü\n",
    "\n",
    "Counterfactual analysis is essential for ethical AI:\n",
    "- **Actionable Guidance**: Show what needs to change for different outcomes\n",
    "- **Decision Support**: Help users understand how to achieve desired results\n",
    "- **Transparency**: Make AI decisions more understandable through \"what if\" scenarios\n",
    "- **Trust**: Build user confidence through actionable explanations\n",
    "- **Fairness**: Enable users to understand and act on AI decisions\n",
    "\n",
    "## Learning Objectives | ÿ£ŸáÿØÿßŸÅ ÿßŸÑÿ™ÿπŸÑŸÖ\n",
    "1. Understand counterfactual examples and their meaning\n",
    "2. Learn how to generate counterfactual examples\n",
    "3. Perform what-if analysis\n",
    "4. Provide actionable explanations\n",
    "5. Visualize counterfactual comparisons\n",
    "6. Interpret counterfactual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:59:15.419828Z",
     "iopub.status.busy": "2025-12-26T16:59:15.419527Z",
     "iopub.status.idle": "2025-12-26T16:59:17.114435Z",
     "shell.execute_reply": "2025-12-26T16:59:17.114237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 4 - Example 3: Counterfactual Analysis\n",
      "================================================================================\n",
      "\n",
      "Generating dataset...\n",
      "Dataset shape: (1000, 5)\n",
      "\n",
      "Training Random Forest model...\n",
      "Test Accuracy: 0.9667\n",
      "\n",
      "Original instance (rejected):\n",
      "  Features: {'age': np.float64(69.0), 'income': np.float64(5029.851084497952), 'credit_score': np.float64(639.4051645695864), 'debt_ratio': np.float64(0.5370358866525926)}\n",
      "  Prediction probability: 0.3900\n",
      "  Prediction: 0\n",
      "\n",
      "Generating counterfactual (to get approved)...\n",
      "Counterfactual found after 1 iterations: Target class reached\n",
      "  Prediction probability: 0.9500\n",
      "  Prediction: 1\n",
      "\n",
      "Performing what-if analysis on credit_score...\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: counterfactual_comparison.png\n",
      "‚úÖ Saved: what_if_analysis.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Counterfactuals show what needs to change to get a different outcome\n",
      "2. What-if analysis explores how changes in features affect predictions\n",
      "3. Counterfactuals help explain model decisions\n",
      "4. Counterfactuals are useful for actionable insights\n",
      "5. Counterfactual analysis improves model transparency\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4: Interpretability, Transparency, and Accountability\n",
    "Example 3: Counterfactual Analysis\n",
    "This example demonstrates counterfactual analysis for model interpretability:\n",
    "- Generating counterfactual examples\n",
    "- What-if analysis\n",
    "- Model decision explanations\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "# ============================================================================\n",
    "# COUNTERFACTUAL GENERATION\n",
    "# ============================================================================\n",
    "def generate_counterfactual(model, X_instance, X_train, feature_names, target\n",
    "class =1, max\n",
    "iterations =100):\n",
    "    \"\"\"\n",
    "    Generate counterfactual example by perturbing features\n",
    "    \"\"\"\n",
    "    # Get original prediction\n",
    "    original\n",
    "pred = model.predict_proba(X_instance)[0, 1]\n",
    "    original\n",
    "class = model.predict(X_instance)[0]\n",
    "    if original\n",
    "class == target\n",
    "class:\n",
    "        return X_instance.copy(), 0, \"Already in target class\"\n",
    "    # Initialize counterfactual\n",
    "    counterfactual = X\n",
    "instance.copy()\n",
    "    # Feature ranges from training data\n",
    "    feature\n",
    "ranges = {\n",
    "        i: (X_train[:, i].min(), X_train[:, i].max())\n",
    "        for i in range(X_train.shape[1])\n",
    "    }\n",
    "    # Iteratively modify features\n",
    "    for iteration in range(max_iterations):\n",
    "        # Try modifying each feature\n",
    "        best\n",
    "change = None\n",
    "        best\n",
    "score = original\n",
    "pred\n",
    "        for feature_idx in range(X_instance.shape[1]):\n",
    "            # Try increasing feature\n",
    "            test\n",
    "cf = counterfactual.copy()\n",
    "            step = (feature_ranges[feature_idx][1] - feature_ranges[feature_idx][0]) * 0.1\n",
    "            test_cf[0, feature_idx] = min(\n",
    "                test_cf[0, feature_idx] + step,\n",
    "                feature_ranges[feature_idx][1]\n",
    "            )\n",
    "            new\n",
    "pred = model.predict_proba(test_cf)[0, 1]\n",
    "            # Check if we're moving toward target class\n",
    "            if target\n",
    "class == 1 and new_pred > best_score:\n",
    "                best\n",
    "score = new\n",
    "pred\n",
    "                best\n",
    "change = (feature_idx, step)\n",
    "            elif target\n",
    "class == 0 and new_pred < best_score:\n",
    "                best\n",
    "score = new\n",
    "pred\n",
    "                best\n",
    "change = (feature_idx, -step)\n",
    "        if best_change is None:\n",
    "            break\n",
    "        # Apply best change\n",
    "        feature_idx, change = best\n",
    "change\n",
    "        counterfactual[0, feature_idx] += change\n",
    "        counterfactual[0, feature_idx] = np.clip(\n",
    "            counterfactual[0, feature_idx],\n",
    "            feature_ranges[feature_idx][0],\n",
    "            feature_ranges[feature_idx][1]\n",
    "        )\n",
    "        # Check if we've reached target class\n",
    "        new\n",
    "pred = model.predict_proba(counterfactual)[0, 1]\n",
    "        new\n",
    "class = model.predict(counterfactual)[0]\n",
    "        if new\n",
    "class == target\n",
    "class:\n",
    "            return counterfactual, iteration + 1, \"Target class reached\"\n",
    "    return counterfactual, max_iterations, \"Max iterations reached\"\n",
    "# ============================================================================\n",
    "# WHAT-IF ANALYSIS\n",
    "# ============================================================================\n",
    "def what_if_analysis(model, X_instance, feature_names, feature_to_change, values_to_test):\n",
    "    \"\"\"\n",
    "    Perform what-if analysis by changing a single feature\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for value in values_to_test:\n",
    "        X\n",
    "test = X\n",
    "instance.copy()\n",
    "        feature\n",
    "idx = feature\n",
    "names.index(feature_to_change)\n",
    "        X_test[0, feature_idx] = value\n",
    "        pred\n",
    "proba = model.predict_proba(X_test)[0, 1]\n",
    "        pred\n",
    "class = model.predict(X_test)[0]\n",
    "        results.append({\n",
    "            'value': value, 'prediction_probability': pred_proba,\n",
    "            'prediction_class': pred_class\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "# ============================================================================\n",
    "# GENERATE DATASET\n",
    "# ============================================================================\n",
    "def generate_dataset(n\n",
    "samples =1000):\n",
    "    \"\"\"\n",
    "    Generate synthetic dataset for counterfactual analysis\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    age = np.random.randint(25, 70, n_samples)\n",
    "    income = np.random.normal(60000, 25000, n_samples)\n",
    "    credit\n",
    "score = np.random.normal(650, 100, n_samples)\n",
    "    debt\n",
    "ratio = np.random.uniform(0.1, 0.6, n_samples)\n",
    "    approval\n",
    "prob = (credit_score\n",
    "850 * 0.4 +\n",
    "                     (income\n",
    "100000) * 0.3 +\n",
    "                     (1 - debt_ratio) * 0.2 +\n",
    "                     (age\n",
    "70) * 0.1 +\n",
    "                     np.random.normal(0, 0.05, n_samples))\n",
    "    approval = (approval_prob > 0.5).astype(int)\n",
    "    df = pd.DataFrame({\n",
    "        'age': age, 'income': income,\n",
    "        'credit_score': credit_score,\n",
    "        'debt_ratio': debt_ratio,\n",
    "        'approved': approval\n",
    "    })\n",
    "    return df\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_counterfactual_comparison(X_original, X_counterfactual, feature_names, original_pred, cf_pred):\n",
    "    \"\"\"\n",
    "    Plot comparison between original and counterfactual\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    # Feature comparison\n",
    "    features = feature\n",
    "names\n",
    "    original\n",
    "values = X\n",
    "original[0]\n",
    "    cf\n",
    "values = X\n",
    "counterfactual[0]\n",
    "    changes = cf\n",
    "values - original_values\n",
    "    x = np.arange(len(features))\n",
    "    width = 0.35\n",
    "    axes[0].bar(x - width/2, original_values, width, label='Original', alpha=0.8, color='#e74c3c')\n",
    "    axes[0].bar(x + width/2, cf_values, width, label='Counterfactual', alpha=0.8, color='#2ecc71')\n",
    "    axes[0].set_xlabel('Features', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Feature Values', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Original vs Counterfactual Feature Values', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(features, rotation=15)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    # Feature changes\n",
    "    colors = ['green' if c > 0 else 'red' for c in changes]\n",
    "    axes[1].barh(features, changes, color=colors, alpha=0.7)\n",
    "    axes[1].set_xlabel('Change in Feature Value', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Feature Changes to Achieve Counterfactual', fontsize=12, fontweight='bold')\n",
    "    axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit4-transparency-accountability', dpi=300, bbox\n",
    "inches ='tight')\n",
    "    print(\"‚úÖ Saved: counterfactual_comparison.png\")\n",
    "    plt.close()\n",
    "def plot_what_if_analysis(what_if_df, feature_name):\n",
    "    \"\"\"\n",
    "    Plot what-if analysis results\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(what_if_df['value'], what_if_df['prediction_probability'], \n",
    "           marker='o', linewidth=2, markersize=8, color='#3498db')\n",
    "    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Decision Threshold')\n",
    "    ax.set_xlabel(feature_name, fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Prediction Probability', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'What-If Analysis: {feature_name}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit4-transparency-accountability', dpi=300, bbox\n",
    "inches ='tight')\n",
    "    print(\"‚úÖ Saved: what_if_analysis.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if_\n",
    "name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 4 - Example 3: Counterfactual Analysis\")\n",
    "    print(\"=\"*80)\n",
    "    # Generate dataset\n",
    "    print(\"\\nGenerating dataset...\")\n",
    "    df = generate\n",
    "dataset(n\n",
    "samples =1000)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    # Prepare data\n",
    "    feature\n",
    "names = ['age', 'income', 'credit_score', 'debt_ratio']\n",
    "    X = df[feature_names].values\n",
    "    y = df['approved'].values\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y\n",
    "test = train\n",
    "test\n",
    "split(\n",
    "        X, y, test\n",
    "size =0.3, random\n",
    "state =42, stratify=y\n",
    "    )\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train\n",
    "scaled = scaler.fit_transform(X_train)\n",
    "    X_test\n",
    "scaled = scaler.transform(X_test)\n",
    "    # Train model\n",
    "    print(\"\\nTraining Random Forest model...\")\n",
    "    model = RandomForestClassifier(n\n",
    "estimators =100, random\n",
    "state =42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    test\n",
    "acc = accuracy\n",
    "score(y_test, model.predict(X_test_scaled))\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    # Find a rejected instance to generate counterfactual\n",
    "    rejected\n",
    "indices = np.where(model.predict(X_test_scaled) == 0)[0]\n",
    "    if len(rejected_indices) > 0:\n",
    "        sample\n",
    "idx = rejected\n",
    "indices[0]\n",
    "        X\n",
    "instance = X\n",
    "test\n",
    "scaled[sample_idx:sample_idx+1]\n",
    "        print(f\"\\nOriginal instance (rejected):\")\n",
    "        print(f\"  Features: {dict(zip(feature_names, X_test[sample_idx]))}\")\n",
    "        print(f\"  Prediction probability: {model.predict_proba(X_instance)[0, 1]:.4f}\")\n",
    "        print(f\"  Prediction: {model.predict(X_instance)[0]}\")\n",
    "        # Generate counterfactual\n",
    "        print(\"\\nGenerating counterfactual (to get approved)...\")\n",
    "        X_counterfactual, iterations, status = generate\n",
    "counterfactual(\n",
    "            model, X_instance, X_train_scaled, feature_names, target\n",
    "class =1\n",
    "        )\n",
    "        print(f\"Counterfactual found after {iterations} iterations: {status}\")\n",
    "        print(f\"  Prediction probability: {model.predict_proba(X_counterfactual)[0, 1]:.4f}\")\n",
    "        print(f\"  Prediction: {model.predict(X_counterfactual)[0]}\")\n",
    "        # What-if analysis\n",
    "        print(\"\\nPerforming what-if analysis on credit_score...\")\n",
    "        credit\n",
    "scores = np.linspace(500, 800, 50)\n",
    "        what_if\n",
    "df = what\n",
    "if\n",
    "analysis(\n",
    "            model, X_instance, feature_names, 'credit_score', credit_scores\n",
    "        )\n",
    "        # Create visualizations\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Creating Visualizations...\")\n",
    "        print(\"=\"*80)\n",
    "        original\n",
    "pred = model.predict_proba(X_instance)[0, 1]\n",
    "        cf\n",
    "pred = model.predict_proba(X_counterfactual)[0, 1]\n",
    "        plot_counterfactual_comparison(X_instance, X_counterfactual, feature_names, \n",
    "                                      original_pred, cf_pred)\n",
    "        plot_what_if_analysis(what_if_df, 'credit_score')\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. Counterfactuals show what needs to change to get a different outcome\")\n",
    "    print(\"2. What-if analysis explores how changes in features affect predictions\")\n",
    "    print(\"3. Counterfactuals help explain model decisions\")\n",
    "    print(\"4. Counterfactuals are useful for actionable insights\")\n",
    "    print(\"5. Counterfactual analysis improves model transparency\")\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üö´ When Counterfactual Analysis Hits a Limitation | ÿπŸÜÿØŸÖÿß ŸäÿµŸÑ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ∂ÿßÿØ ŸÑŸÑŸàÿßŸÇÿπ ÿ•ŸÑŸâ ÿ≠ÿØ\n",
    "\n",
    "### The Limitation We Discovered\n",
    "\n",
    "We've learned counterfactual analysis for \"what if\" explanations. **But there's still a challenge:**\n",
    "\n",
    "**How do we ensure accountability and responsibility for AI decisions?**\n",
    "\n",
    "Counterfactual analysis works well when:\n",
    "- ‚úÖ We can generate \"what if\" scenarios\n",
    "- ‚úÖ We can provide actionable guidance\n",
    "- ‚úÖ We can explain what would change outcomes\n",
    "\n",
    "**But transparent AI systems also need:**\n",
    "- ‚ùå **Accountability frameworks** (who is responsible?)\n",
    "- ‚ùå **Responsibility mechanisms** (how to assign responsibility?)\n",
    "- ‚ùå **Audit trails** (how to track decisions?)\n",
    "- ‚ùå **Stakeholder accountability** (who answers for outcomes?)\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "When we have explanations but no accountability:\n",
    "- We may not know who is responsible for AI decisions\n",
    "- We may not have mechanisms to track and audit decisions\n",
    "- We may not have clear responsibility structures\n",
    "- We may not be able to hold anyone accountable\n",
    "\n",
    "### The Solution: Accountability Frameworks\n",
    "\n",
    "We need **accountability frameworks** to:\n",
    "1. Define stakeholder responsibilities\n",
    "2. Create audit trails\n",
    "3. Establish responsibility mechanisms\n",
    "4. Enable accountability for AI decisions\n",
    "\n",
    "**This is exactly what we'll learn in the next notebook: Accountability Frameworks!**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Steps | ÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©\n",
    "\n",
    "**You've completed this notebook!** Now you understand:\n",
    "- ‚úÖ How to use SHAP for explanations (Notebook 1)\n",
    "- ‚úÖ How to use LIME for fast explanations (Notebook 2)\n",
    "- ‚úÖ How to use counterfactuals for \"what if\" scenarios (This notebook!)\n",
    "- ‚úÖ **The limitation**: We need accountability frameworks!\n",
    "\n",
    "**Next notebook**: `04_accountability_frameworks.ipynb`\n",
    "- Learn about accountability frameworks\n",
    "- Understand stakeholder responsibilities\n",
    "- Create audit trails\n",
    "- Establish responsibility mechanisms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
