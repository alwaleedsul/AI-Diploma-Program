{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression with Regularization\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand L1 (Lasso) and L2 (Ridge) regularization\n",
    "- Implement Ridge and Lasso regression using scikit-learn\n",
    "- Compare regularization effects on model coefficients\n",
    "- Select optimal regularization parameters\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Understanding of linear regression\n",
    "- âœ… Python 3.8+ installed\n",
    "- âœ… scikit-learn, pandas, numpy, matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 04, Unit 1**:\n",
    "- Implementing Ridge and Lasso regression with regularization\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 1 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Regularization\n",
    "\n",
    "**Regularization** prevents overfitting by penalizing large coefficients:\n",
    "- **Ridge (L2)**: Penalizes sum of squared coefficients\n",
    "- **Lasso (L1)**: Penalizes sum of absolute coefficients (can set coefficients to zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt_\n",
    "print(\"âœ… Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data with multiple features_np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Create features with some correlation_X = np.random.randn(n_samples, 5)\n",
    "# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (important for regularization)\n",
    "scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"Training set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Ordinary Least Squares (OLS), Ridge, Lasso_\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing Regression Models:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# OLS_ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train)_ols_pred =  ols.predict(X_test_scaled)\n",
    "ols_pred = ols.predict(X_test_scaled)_ols_mse =  mean_squared_error(y_test, ols_pred)\n",
    "ols_mse = mean_squared_error(y_test, ols_pred)_ols_r2 =  r2_score(y_test, ols_pred)\n",
    "ols_r2 = r2_score(y_test, ols_pred)\n",
    "\n",
    "# Ridge Regression (alpha = 1.0)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)_ridge_pred =  ridge.predict(X_test_scaled)\n",
    "ridge_pred = ridge.predict(X_test_scaled)_ridge_mse =  mean_squared_error(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)_ridge_r2 =  r2_score(y_test, ridge_pred)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "\n",
    "# Lasso Regression (alpha = 0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_scaled, y_train)_lasso_pred =  lasso.predict(X_test_scaled)\n",
    "lasso_pred = lasso.predict(X_test_scaled)_lasso_mse =  mean_squared_error(y_test, lasso_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)_lasso_r2 =  r2_score(y_test, lasso_pred)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "print(f\"\\nOLS - MSE: {ols_mse:.4f}, RÂ²: {ols_r2:.4f}\")\n",
    "print(f\"Ridge - MSE: {ridge_mse:.4f}, RÂ²: {ridge_r2:.4f}\")\n",
    "print(f\"Lasso - MSE: {lasso_mse:.4f}, RÂ²: {lasso_r2:.4f}\")\n",
    "\n",
    "# Compare coefficients_\n",
    "print(\"\\nCoefficients Comparison:\")\n",
    "print(f\"OLS coefficients: {ols.coef_}\")\n",
    "print(f\"Ridge coefficients: {ridge.coef_}\")\n",
    "print(f\"Lasso coefficients: {lasso.coef_} (note: some may be zero)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tuning Regularization Parameter (Alpha)\n",
    "\n",
    "Let's see how different alpha values affect model performance and coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha values_alphas = np.logspace(-4, 2, 50)\n",
    "ridge_coefs = []_lasso_coefs =  []\n",
    "lasso_coefs = []_ridge_scores =  []\n",
    "ridge_scores = []_lasso_scores =  []\n",
    "lasso_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Ridge_ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "ridge_coefs.append(ridge.coef_)\n",
    "ridge_scores.append(ridge.score(X_test_scaled, y_test))\n",
    "    \n",
    "    # Lasso_lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "lasso_coefs.append(lasso.coef_)\n",
    "lasso_scores.append(lasso.score(X_test_scaled, y_test))\n",
    "\n",
    "ridge_coefs = np.array(ridge_coefs)_lasso_coefs =  np.array(lasso_coefs)\n",
    "lasso_coefs = np.array(lasso_coefs)\n",
    "print(f\"Tested {len(alphas)} alpha values from {alphas[0]:.4f} to {alphas[-1]:.2f}\")\n",
    "print(f\"Best Ridge RÂ²: {max(ridge_scores):.4f} at alpha={alphas[np.argmax(ridge_scores)]:.4f}\")\n",
    "print(f\"Best Lasso RÂ²: {max(lasso_scores):.4f} at alpha={alphas[np.argmax(lasso_scores)]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Ridge Regression (L2)**: Shrinks coefficients but doesn't eliminate them\n",
    "2. **Lasso Regression (L1)**: Can set coefficients to zero (feature selection)\n",
    "3. **Alpha parameter**: Controls regularization strength (higher = more regularization)\n",
    "4. **Feature scaling**: Essential before applying regularization\n",
    "\n",
    "### Applications:\n",
    "- Preventing overfitting\n",
    "- Handling multicollinearity\n",
    "- Feature selection (Lasso)\n",
    "- Improving model generalization\n",
    "\n",
    "**Reference:** Course 04, Unit 1: \"Implementing Ridge and Lasso regression with regularization\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}