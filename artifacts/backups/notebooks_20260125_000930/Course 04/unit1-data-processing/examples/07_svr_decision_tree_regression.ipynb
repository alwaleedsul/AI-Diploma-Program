{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) and Tree-Based Regression\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Build SVR models with different kernels (linear, RBF, polynomial)\n",
    "- Implement decision tree and random forest regression\n",
    "- Compare tree-based models with SVR\n",
    "- Understand when to use each approach\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Understanding of regression concepts\n",
    "- âœ… Python 3.8+ installed\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 04, Unit 1**:\n",
    "- Building SVR models with different kernels\n",
    "- Implementing decision tree and random forest regression\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 1 Practical Content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection \n",
    "import train_test_split\n",
    "from sklearn.svm \n",
    "import SVR\n",
    "from sklearn.tree \n",
    "import DecisionTreeRegressor\n",
    "from sklearn.ensemble \n",
    "import RandomForestRegressor\n",
    "from sklearn.metrics \n",
    "import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing \n",
    "import StandardScaler_\n",
    "print(\"âœ… Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linear data_np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)_y =  np.sin(X).ravel() + 0.1 * np.random.randn(100)\n",
    "y = np.sin(X).ravel() + 0.1 * np.random.randn(100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Support Vector Regression with Different Kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR with different kernels_kernels = ['linear', 'rbf', 'poly']\n",
    "svr_models = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SVR Models with Different Kernels:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for kernel in kernels:\n",
    "    svr = SVR(kernel=kernel, C=100, gamma='scale', epsilon=0.1)\n",
    "    svr.fit(X_train_scaled, y_train)_y_pred =  svr.predict(X_test_scaled)\n",
    "    y_pred = svr.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)_r2 =  r2_score(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    svr_models[kernel] = {'model': svr, 'mse': mse, 'r2': r2}\n",
    "    print(f\"\\n{kernel.upper()} Kernel:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RÂ²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Decision Tree and Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor_dt = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)_dt_pred =  dt.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)_dt_mse =  mean_squared_error(y_test, dt_pred)\n",
    "dt_mse = mean_squared_error(y_test, dt_pred)_dt_r2 =  r2_score(y_test, dt_pred)\n",
    "dt_r2 = r2_score(y_test, dt_pred)\n",
    "\n",
    "# Random Forest Regressor_rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)_rf_mse =  mean_squared_error(y_test, rf_pred)\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)_rf_r2 =  r2_score(y_test, rf_pred)\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Tree-Based Regression Models:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDecision Tree:\")\n",
    "print(f\"  MSE: {dt_mse:.4f}\")\n",
    "print(f\"  RÂ²: {dt_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nRandom Forest:\")\n",
    "print(f\"  MSE: {rf_mse:.4f}\")\n",
    "print(f\"  RÂ²: {rf_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **SVR Kernels**: Linear (simple), RBF (non-linear), Polynomial (curved)\n",
    "2. **Decision Tree**: Simple, interpretable, prone to overfitting\n",
    "3. **Random Forest**: Ensemble of trees, more robust, less overfitting\n",
    "4. **When to use**: SVR for non-linear, Tree-based for interpretability\n",
    "\n",
    "**Reference:** Course 04, Unit 1: \"Building SVR models with different kernels\" and \"Implementing decision tree and random forest regression\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}