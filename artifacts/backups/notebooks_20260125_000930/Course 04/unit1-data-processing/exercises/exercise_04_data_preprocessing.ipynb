{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 1 - Exercise 4: Data Preprocessing Practice\n",
    "## Ø£Ø³Ø§Ù„ÙŠØ¨ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - ØªÙ…Ø±ÙŠÙ† 4: Ù…Ù…Ø§Ø±Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**GDI Theme**: Financial Investigations - Preparing transaction data for fraud detection models\n",
    "\n",
    "## Instructions:\n",
    "1. Load the sample dataset provided below\n",
    "2. Identify numerical and categorical features\n",
    "3. Apply feature scaling (StandardScaler and MinMaxScaler)\n",
    "4. Encode categorical variables (LabelEncoder and OneHotEncoder)\n",
    "5. Split data into training and testing sets\n",
    "6. Compare different preprocessing methods\n",
    "7. Create visualizations comparing before/after scaling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns_\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Generate Sample Dataset\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 1: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ù…ÙˆØ°Ø¬ÙŠØ©"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# Set random seed for reproducibility_np.random.seed(73)\n",
    "\n",
    "# Generate sample financial transaction data (GDI Theme: Financial Investigations)\n",
    "print(\"ğŸ“¥ Generating sample financial transaction data...\")\n",
    "print(\"Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø§Ù„ÙŠØ© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©...\")\n",
    "print(\"   GDI Theme: Financial Investigations\n",
    "Terrorism Financing Detection\\n\")\n",
    "\n",
    "# Create sample dataset with mixed data types_n_samples = 500_data = {\n",
    "    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n",
    "    'transaction_time': np.random.uniform(0, 24, n_samples),\n",
    "    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n",
    "    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n",
    "    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n",
    "    'customer_age': np.random.randint(18, 80, n_samples),\n",
    "    'account_balance': np.random.uniform(100, 50000, n_samples),\n",
    "    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"âœ… Sample dataset created!\")\n",
    "print(f\"   ğŸ“Š Shape: {df.shape}\")\n",
    "print(f\"   ğŸ“Š Columns: {list(df.columns)}\")\n",
    "print(f\"\\nğŸ“‹ Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nğŸ“‹ First few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Identify Feature Types\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 2: ØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Separate numerical and categorical features\n",
    "# Hint: Use df.select_dtypes(include=['number']) for numerical\n",
    "# Hint: Use df.select_dtypes(include=['object']) for categorical\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Feature Scaling - StandardScaler\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 3: ØªØ­Ø¬ÙŠÙ… Ø§Ù„Ù…ÙŠØ²Ø§Øª - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Apply StandardScaler to numerical features\n",
    "# Steps:\n",
    "# 1. Select numerical features\n",
    "# 2. Create StandardScaler object\n",
    "# 3. Fit and transform the features\n",
    "# 4. Display before/after statistics (mean, std)\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Feature Scaling - MinMaxScaler\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 4: ØªØ­Ø¬ÙŠÙ… Ø§Ù„Ù…ÙŠØ²Ø§Øª - MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Apply MinMaxScaler to numerical features\n",
    "# Steps:\n",
    "# 1. Create MinMaxScaler object\n",
    "# 2. Fit and transform numerical features\n",
    "# 3. Display before/after statistics (min, max)\n",
    "# 4. Compare with StandardScaler results\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Categorical Encoding - LabelEncoder\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 5: ØªØ±Ù…ÙŠØ² Ø§Ù„ÙØ¦Ø§Øª - LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Apply LabelEncoder to ordinal categorical features\n",
    "# Steps:\n",
    "# 1. Select ordinal categorical feature (e.g., risk_level)\n",
    "# 2. Create LabelEncoder object\n",
    "# 3. Fit and transform the feature\n",
    "# 4. Display mapping (original values -> encoded values)\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Categorical Encoding - OneHotEncoder\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 6: ØªØ±Ù…ÙŠØ² Ø§Ù„ÙØ¦Ø§Øª - OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Apply OneHotEncoder to nominal categorical features\n",
    "# Steps:\n",
    "# 1. Select nominal categorical features\n",
    "# 2. Create OneHotEncoder object\n",
    "# 3. Fit and transform the features\n",
    "# 4. Convert to DataFrame for better visualization\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Train-Test Split\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 7: ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Split data into training and testing sets\n",
    "# Steps:\n",
    "# 1. Prepare features (X) - all columns except target\n",
    "# 2. Prepare target (y) - risk_level\n",
    "# 3. Use train_test_split with test_size=0.2, random_state=73\n",
    "# 4. Display shapes of train/test sets\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Complete Preprocessing Pipeline\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 8: Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ÙƒØ§Ù…Ù„"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Create a complete preprocessing pipeline\n",
    "# Steps:\n",
    "# 1. Split data first (train/test)\n",
    "# 2. Scale numerical features on training data\n",
    "# 3. Apply scaling to test data (using scaler fitted on train)\n",
    "# 4. Encode categorical features\n",
    "# 5. Combine scaled numerical + encoded categorical features\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Visualization - Compare Before/After Scaling\n",
    "### Ø§Ù„Ù…Ù‡Ù…Ø© 9: Ø§Ù„ØªØµÙˆØ± - Ù…Ù‚Ø§Ø±Ù†Ø© Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø¬ÙŠÙ…"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "# TODO: Create visualizations comparing original vs scaled features\n",
    "# Steps:\n",
    "# 1. Plot distribution of original numerical feature\n",
    "# 2. Plot distribution after StandardScaler\n",
    "# 3. Plot distribution after MinMaxScaler\n",
    "# 4. Use subplots to show side-by-side comparison\n",
    "\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Exercise Complete!\n",
    "\n",
    "**What You Learned:**\n",
    "- âœ… Feature scaling (StandardScaler vs MinMaxScaler)\n",
    "- âœ… Categorical encoding (LabelEncoder vs OneHotEncoder)\n",
    "- âœ… Train-test split for proper evaluation\n",
    "- âœ… Complete preprocessing pipeline\n",
    "- âœ… GDI context: Preparing financial data for fraud detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}