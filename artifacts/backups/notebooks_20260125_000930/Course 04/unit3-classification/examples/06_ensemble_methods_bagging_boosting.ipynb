{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Techniques: Bagging and Boosting\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand ensemble methods (Bagging, Boosting)\n",
    "- Experiment with ensemble techniques to improve model performance\n",
    "- Compare bagging vs boosting approaches\n",
    "- Apply ensemble methods to classification problems\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Understanding of decision trees and classification\n",
    "- âœ… Python 3.8+ installed\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 04, Unit 3**:\n",
    "- Experimenting with ensemble techniques (Bagging, Boosting) to improve prediction accuracy\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 3 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Ensemble Methods\n",
    "\n",
    "**Ensemble methods** combine multiple models to improve performance:\n",
    "- **Bagging**: Parallel training, reduces variance (e.g., Random Forest)\n",
    "- **Boosting**: Sequential training, reduces bias (e.g., AdaBoost, Gradient Boosting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets \n",
    "import make_classification\n",
    "from sklearn.model_selection \n",
    "import train_test_split\n",
    "from sklearn.tree \n",
    "import DecisionTreeClassifier\n",
    "from sklearn.ensemble \n",
    "import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics \n",
    "import accuracy_score, classification_report_\n",
    "print(\"âœ… Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Base Model (Single Decision Tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model: Single decision tree_base_tree = DecisionTreeClassifier(random_state=42)\n",
    "base_tree.fit(X_train, y_train)_base_pred =  base_tree.predict(X_test)\n",
    "base_pred = base_tree.predict(X_test)_base_acc =  accuracy_score(y_test, base_pred)\n",
    "base_acc = accuracy_score(y_test, base_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Base Model: Single Decision Tree\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {base_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bagging (Random Forest is a type of Bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Classifier_bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100,\n",
    "    random_state=42)\n",
    "bagging.fit(X_train, y_train)_bagging_pred =  bagging.predict(X_test)\n",
    "bagging_pred = bagging.predict(X_test)_bagging_acc =  accuracy_score(y_test, bagging_pred)\n",
    "bagging_acc = accuracy_score(y_test, bagging_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Bagging Classifier (100 trees)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {bagging_acc:.4f}\")\n",
    "print(f\"Improvement over base: {bagging_acc - base_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Boosting Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost_adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "adaboost.fit(X_train, y_train)_adaboost_pred =  adaboost.predict(X_test)\n",
    "adaboost_pred = adaboost.predict(X_test)_adaboost_acc =  accuracy_score(y_test, adaboost_pred)\n",
    "adaboost_acc = accuracy_score(y_test, adaboost_pred)\n",
    "\n",
    "# Gradient Boosting_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)_gb_pred =  gb.predict(X_test)\n",
    "gb_pred = gb.predict(X_test)_gb_acc =  accuracy_score(y_test, gb_pred)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Boosting Methods:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"AdaBoost Accuracy: {adaboost_acc:.4f}\")\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Comparison Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Base Tree:        {base_acc:.4f}\")\n",
    "print(f\"Bagging:          {bagging_acc:.4f} (+{bagging_acc-base_acc:.4f})\")\n",
    "print(f\"AdaBoost:         {adaboost_acc:.4f} (+{adaboost_acc-base_acc:.4f})\")\n",
    "print(f\"Gradient Boost:   {gb_acc:.4f} (+{gb_acc-base_acc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Bagging**: Trains models in parallel, averages predictions (reduces variance)\n",
    "2. **Boosting**: Trains models sequentially, focuses on errors (reduces bias)\n",
    "3. **Ensemble Benefit**: Multiple models outperform single models\n",
    "4. **When to use**: Bagging for high variance models, Boosting for high bias models\n",
    "\n",
    "**Reference:** Course 04, Unit 3: \"Experimenting with ensemble techniques (Bagging, Boosting)\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}