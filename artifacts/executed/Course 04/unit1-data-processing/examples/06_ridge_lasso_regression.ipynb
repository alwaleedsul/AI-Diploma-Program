{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression with Regularization\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand L1 (Lasso) and L2 (Ridge) regularization\n",
    "- Implement Ridge and Lasso regression using scikit-learn\n",
    "- Compare regularization effects on model coefficients\n",
    "- Select optimal regularization parameters\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Understanding of linear regression\n",
    "- âœ… Python 3.8+ installed\n",
    "- âœ… scikit-learn, pandas, numpy, matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 04, Unit 1**:\n",
    "- Implementing Ridge and Lasso regression with regularization\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 1 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Regularization\n",
    "\n",
    "**Regularization** prevents overfitting by penalizing large coefficients:\n",
    "- **Ridge (L2)**: Penalizes sum of squared coefficients\n",
    "- **Lasso (L1)**: Penalizes sum of absolute coefficients (can set coefficients to zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:04:05.519818Z",
     "iopub.status.busy": "2026-01-15T20:04:05.519613Z",
     "iopub.status.idle": "2026-01-15T20:04:06.491280Z",
     "shell.execute_reply": "2026-01-15T20:04:06.491068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:04:06.492244Z",
     "iopub.status.busy": "2026-01-15T20:04:06.492155Z",
     "iopub.status.idle": "2026-01-15T20:04:06.494896Z",
     "shell.execute_reply": "2026-01-15T20:04:06.494711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (80, 5)\n",
      "Test set: (20, 5)\n"
     ]
    }
   ],
   "source": [
    "# Generate sample data with multiple features\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Create features with some correlation\n",
    "X = np.random.randn(n_samples, 5)\n",
    "# Target: linear combination with noise\n",
    "y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (important for regularization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:04:06.495704Z",
     "iopub.status.busy": "2026-01-15T20:04:06.495640Z",
     "iopub.status.idle": "2026-01-15T20:04:06.499386Z",
     "shell.execute_reply": "2026-01-15T20:04:06.499220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Comparing Regression Models:\n",
      "============================================================\n",
      "\n",
      "OLS - MSE: 0.2522, RÂ²: 0.9307\n",
      "Ridge - MSE: 0.2485, RÂ²: 0.9317\n",
      "Lasso - MSE: 0.2877, RÂ²: 0.9210\n",
      "\n",
      "Coefficients Comparison:\n",
      "OLS coefficients: [ 1.81013528e+00  1.52436569e+00 -9.56148284e-01  2.13842701e-02\n",
      " -1.44130926e-03]\n",
      "Ridge coefficients: [ 1.78506301  1.50092755 -0.94120793  0.02251134 -0.00526234]\n",
      "Lasso coefficients: [ 1.69898937  1.39673767 -0.84141364  0.         -0.        ] (note: some may be zero)\n"
     ]
    }
   ],
   "source": [
    "# Compare: Ordinary Least Squares (OLS), Ridge, Lasso\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing Regression Models:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# OLS\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "ols_pred = ols.predict(X_test_scaled)\n",
    "ols_mse = mean_squared_error(y_test, ols_pred)\n",
    "ols_r2 = r2_score(y_test, ols_pred)\n",
    "\n",
    "# Ridge Regression (alpha = 1.0)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "ridge_pred = ridge.predict(X_test_scaled)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "\n",
    "# Lasso Regression (alpha = 0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "lasso_pred = lasso.predict(X_test_scaled)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "\n",
    "print(f\"\\nOLS - MSE: {ols_mse:.4f}, RÂ²: {ols_r2:.4f}\")\n",
    "print(f\"Ridge - MSE: {ridge_mse:.4f}, RÂ²: {ridge_r2:.4f}\")\n",
    "print(f\"Lasso - MSE: {lasso_mse:.4f}, RÂ²: {lasso_r2:.4f}\")\n",
    "\n",
    "# Compare coefficients\n",
    "print(\"\\nCoefficients Comparison:\")\n",
    "print(f\"OLS coefficients: {ols.coef_}\")\n",
    "print(f\"Ridge coefficients: {ridge.coef_}\")\n",
    "print(f\"Lasso coefficients: {lasso.coef_} (note: some may be zero)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tuning Regularization Parameter (Alpha)\n",
    "\n",
    "Let's see how different alpha values affect model performance and coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:04:06.500106Z",
     "iopub.status.busy": "2026-01-15T20:04:06.500052Z",
     "iopub.status.idle": "2026-01-15T20:04:06.527567Z",
     "shell.execute_reply": "2026-01-15T20:04:06.527398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 50 alpha values from 0.0001 to 100.00\n",
      "Best Ridge RÂ²: 0.9324 at alpha=2.5595\n",
      "Best Lasso RÂ²: 0.9307 at alpha=0.0001\n"
     ]
    }
   ],
   "source": [
    "# Test different alpha values\n",
    "alphas = np.logspace(-4, 2, 50)\n",
    "ridge_coefs = []\n",
    "lasso_coefs = []\n",
    "ridge_scores = []\n",
    "lasso_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Ridge\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    ridge_coefs.append(ridge.coef_)\n",
    "    ridge_scores.append(ridge.score(X_test_scaled, y_test))\n",
    "    \n",
    "    # Lasso\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    lasso_coefs.append(lasso.coef_)\n",
    "    lasso_scores.append(lasso.score(X_test_scaled, y_test))\n",
    "\n",
    "ridge_coefs = np.array(ridge_coefs)\n",
    "lasso_coefs = np.array(lasso_coefs)\n",
    "\n",
    "print(f\"Tested {len(alphas)} alpha values from {alphas[0]:.4f} to {alphas[-1]:.2f}\")\n",
    "print(f\"Best Ridge RÂ²: {max(ridge_scores):.4f} at alpha={alphas[np.argmax(ridge_scores)]:.4f}\")\n",
    "print(f\"Best Lasso RÂ²: {max(lasso_scores):.4f} at alpha={alphas[np.argmax(lasso_scores)]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Ridge Regression (L2)**: Shrinks coefficients but doesn't eliminate them\n",
    "2. **Lasso Regression (L1)**: Can set coefficients to zero (feature selection)\n",
    "3. **Alpha parameter**: Controls regularization strength (higher = more regularization)\n",
    "4. **Feature scaling**: Essential before applying regularization\n",
    "\n",
    "### Applications:\n",
    "- Preventing overfitting\n",
    "- Handling multicollinearity\n",
    "- Feature selection (Lasso)\n",
    "- Improving model generalization\n",
    "\n",
    "**Reference:** Course 04, Unit 1: \"Implementing Ridge and Lasso regression with regularization\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
