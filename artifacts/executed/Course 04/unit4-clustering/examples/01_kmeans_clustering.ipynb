<<<<<<< Current (Your changes)
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. K-Means Clustering | ØªØ¬Ù…ÙŠØ¹ K-Means\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 04, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. K-Means Clustering | ØªØ¬Ù…ÙŠØ¹ K-Means\n",
    "\n",
    "## ðŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Unit 1-3: All examples** - Supervised learning (classification and regression)\n",
    "- âœ… **Understanding of unsupervised learning**: Learning patterns without labels\n",
    "- âœ… **Basic distance concepts**: How to measure similarity between data points\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding the difference between supervised and unsupervised learning\n",
    "- Knowing when to use clustering vs classification\n",
    "- Understanding how to find the optimal number of clusters\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is Unit 4, Example 1** - it's your first unsupervised learning model!\n",
    "\n",
    "**Why this example FIRST in Unit 4?**\n",
    "- **Before** you can use advanced clustering, you need to understand basic clustering\n",
    "- **Before** you can use dimensionality reduction, you need to understand data structure\n",
    "- **Before** you can handle complex data, you need to see how K-Means groups similar points\n",
    "\n",
    "**Builds on**: \n",
    "- ðŸ““ Unit 1-3: Supervised learning (we know how to learn from labeled data)\n",
    "- ðŸ““ All previous examples (data processing and model evaluation concepts apply)\n",
    "\n",
    "**Leads to**: \n",
    "- ðŸ““ Example 2: Hierarchical Clustering (another clustering method)\n",
    "- ðŸ““ Example 3: PCA (dimensionality reduction)\n",
    "- ðŸ““ All unsupervised learning projects (clustering is fundamental!)\n",
    "\n",
    "**Why this order?**\n",
    "1. K-Means is the **simplest clustering algorithm** (easy to understand)\n",
    "2. K-Means teaches **unsupervised learning** (learning without labels)\n",
    "3. K-Means shows **how to find optimal K** (critical skill for clustering)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Finding Groups Without Labels | Ø§Ù„Ù‚ØµØ©: Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø¯ÙˆÙ† ØªØ³Ù…ÙŠØ§Øª\n",
    "\n",
    "Imagine you're organizing photos. **Before** clustering, you manually label each photo (supervised learning). **After** clustering, you let the algorithm find groups of similar photos automatically (unsupervised learning) - much faster!\n",
    "\n",
    "Same with machine learning: **Before** clustering, we need labeled data. **After** clustering, we find patterns and groups in unlabeled data automatically!\n",
    "\n",
    "---\n",
    "\n",
    "## What is K-Means Clustering? | Ù…Ø§ Ù‡Ùˆ ØªØ¬Ù…ÙŠØ¹ K-MeansØŸ\n",
    "\n",
    "**K-Means** is an algorithm that automatically groups similar data points together into **K clusters** (groups).\n",
    "\n",
    "### Simple Explanation | Ø´Ø±Ø­ Ø¨Ø³ÙŠØ·\n",
    "\n",
    "Imagine you have 100 photos and want to organize them into 3 groups:\n",
    "- **K-Means** looks at all photos\n",
    "- Finds 3 \"center points\" (called **centroids**)\n",
    "- Groups each photo with the nearest center\n",
    "- Result: 3 groups of similar photos!\n",
    "\n",
    "**Key Idea**: Points that are close together (similar) belong to the same cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## How Does K-Means Work? | ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ K-MeansØŸ\n",
    "\n",
    "### The Algorithm Steps | Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©\n",
    "\n",
    "1. **Choose K** (number of clusters you want)\n",
    "   - Example: K=3 means you want 3 groups\n",
    "\n",
    "2. **Initialize Centroids** (random starting points)\n",
    "   - Pick K random points as initial \"centers\"\n",
    "\n",
    "3. **Assign Points to Nearest Centroid**\n",
    "   - For each data point, find the closest centroid\n",
    "   - Assign point to that cluster\n",
    "\n",
    "4. **Update Centroids**\n",
    "   - Move each centroid to the center of its cluster\n",
    "   - Calculate new center position\n",
    "\n",
    "5. **Repeat Steps 3-4**\n",
    "   - Keep reassigning and updating until centroids stop moving\n",
    "   - When centroids don't change â†’ algorithm is done!\n",
    "\n",
    "### Visual Example | Ù…Ø«Ø§Ù„ Ø¨ØµØ±ÙŠ\n",
    "\n",
    "```\n",
    "Before K-Means:\n",
    "â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢  (unorganized points)\n",
    "\n",
    "After K-Means (K=3):\n",
    "ðŸ”µ ðŸ”µ ðŸ”µ              (Cluster 1 - blue)\n",
    "   ðŸ”´ ðŸ”´ ðŸ”´           (Cluster 2 - red)\n",
    "      ðŸŸ¢ ðŸŸ¢ ðŸŸ¢        (Cluster 3 - green)\n",
    "\n",
    "Each cluster has a centroid (X) at its center:\n",
    "ðŸ”µ ðŸ”µ ðŸ”µ\n",
    "   X                  (Centroid of cluster 1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Why K-Means Clustering Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… ØªØ¬Ù…ÙŠØ¹ K-MeansØŸ\n",
    "\n",
    "K-Means is the foundation of unsupervised learning:\n",
    "- **No Labels Needed**: Works with unlabeled data (finds patterns automatically)\n",
    "- **Simple and Fast**: Easy to understand and implement\n",
    "- **Widely Used**: Industry standard for customer segmentation, image compression, etc.\n",
    "- **Foundation**: Understanding K-Means helps with all clustering methods\n",
    "- **Real-World Applications**: Market segmentation, anomaly detection, data compression\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŒ Real-World Applications | Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©\n",
    "\n",
    "**K-Means Clustering is used in MANY industries to find groups in unlabeled data!** Here's where you'll find it:\n",
    "\n",
    "### ðŸ“Š Marketing & E-commerce Sector | Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ ÙˆØ§Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©\n",
    "- **Customer Segmentation**: Group customers by behavior (high spenders, bargain hunters, occasional buyers) â†’ K=5 means 5 customer types\n",
    "- **Market Segmentation**: Group markets by demographics, preferences â†’ target each segment differently\n",
    "- **Product Clustering**: Group similar products together â†’ recommend products in same cluster\n",
    "- **User Behavior Analysis**: Group users by browsing/purchase patterns â†’ understand user types\n",
    "- **Campaign Targeting**: Group customers for targeted marketing campaigns\n",
    "- **Churn Analysis**: Group customers by churn risk â†’ identify at-risk segments\n",
    "\n",
    "### ðŸ¥ Healthcare & Medical Sector | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„ØµØ­ÙŠ ÙˆØ§Ù„Ø·Ø¨ÙŠ\n",
    "- **Patient Segmentation**: Group patients by symptoms, demographics â†’ personalized treatment\n",
    "- **Disease Subtyping**: Group diseases into subtypes â†’ different treatment for each subtype\n",
    "- **Drug Response Clustering**: Group patients by drug response â†’ predict treatment outcomes\n",
    "- **Medical Image Analysis**: Group similar medical images â†’ identify patterns\n",
    "- **Epidemiology**: Group disease outbreaks by characteristics â†’ understand spread patterns\n",
    "- **Clinical Trial Matching**: Group patients for clinical trials\n",
    "\n",
    "### ðŸ’° Finance & Banking Sector | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ ÙˆØ§Ù„Ù…ØµØ±ÙÙŠ\n",
    "- **Customer Segmentation**: Group customers by financial behavior â†’ personalized services\n",
    "- **Risk Grouping**: Group loans by risk level â†’ different interest rates\n",
    "- **Fraud Pattern Detection**: Group fraudulent transactions â†’ identify fraud patterns\n",
    "- **Portfolio Clustering**: Group investments by characteristics â†’ portfolio optimization\n",
    "- **Market Segmentation**: Group markets by economic indicators\n",
    "- **Transaction Clustering**: Group similar transactions â†’ detect anomalies\n",
    "\n",
    "### ðŸ–¼ï¸ Image Processing & Computer Vision | Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆØ±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨\n",
    "- **Image Compression**: Reduce colors in images (K=16 â†’ 16 colors instead of millions) â†’ smaller file size\n",
    "- **Image Segmentation**: Group pixels into regions â†’ object detection\n",
    "- **Color Quantization**: Reduce color palette â†’ compress images\n",
    "- **Image Organization**: Group similar images together â†’ photo organization\n",
    "- **Pattern Recognition**: Group similar patterns in images\n",
    "\n",
    "### ðŸ­ Manufacturing & Supply Chain | Ø§Ù„ØªØµÙ†ÙŠØ¹ ÙˆØ³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙˆØ±ÙŠØ¯\n",
    "- **Quality Clustering**: Group products by quality characteristics â†’ identify quality patterns\n",
    "- **Production Grouping**: Group production batches by characteristics\n",
    "- **Supplier Segmentation**: Group suppliers by performance â†’ manage relationships\n",
    "- **Inventory Clustering**: Group inventory items by demand patterns â†’ optimize stock\n",
    "- **Defect Pattern Analysis**: Group defects by type â†’ identify root causes\n",
    "- **Process Clustering**: Group manufacturing processes â†’ optimize workflows\n",
    "\n",
    "### ðŸ”¬ Scientific Research & Data Analysis | Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "- **Gene Clustering**: Group genes by expression patterns â†’ understand gene functions\n",
    "- **Document Clustering**: Group documents by topic â†’ organize information\n",
    "- **Species Classification**: Group species by characteristics â†’ taxonomy\n",
    "- **Climate Pattern Analysis**: Group climate patterns â†’ understand weather\n",
    "- **Material Science**: Group materials by properties â†’ discover new materials\n",
    "\n",
    "### ðŸŽ“ Education Sector | Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…\n",
    "- **Student Clustering**: Group students by learning patterns â†’ personalized learning\n",
    "- **Course Clustering**: Group courses by difficulty/topic â†’ curriculum design\n",
    "- **Performance Grouping**: Group students by performance â†’ identify needs\n",
    "- **Learning Path Clustering**: Group learning paths â†’ optimize education\n",
    "\n",
    "### ðŸ›ï¸ Government & Public Safety Sector (GDI - General Directorate of Investigation) | Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠ ÙˆØ§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ­Ù‚ÙŠÙ‚)\n",
    "- **Internal Intelligence - Crime Pattern Analysis**: Group states/regions by crime statistics (murder, assault, rape, urban population) â†’ identify similar crime profiles â†’ intelligence gathering and pattern recognition\n",
    "- **Threat Grouping**: Group security threats by characteristics â†’ identify threat types â†’ counter-terrorism analysis\n",
    "- **Traffic Pattern Clustering**: Group traffic patterns by time/location â†’ optimize traffic management â†’ reduce congestion\n",
    "- **Crime Hotspot Clustering**: Group crimes by location/type â†’ identify high-risk areas â†’ crime prevention\n",
    "- **Personnel Clustering**: Group personnel by security clearance/access â†’ manage internal organization â†’ access control\n",
    "- **Vehicle Clustering**: Group vehicles by type/behavior â†’ traffic analysis â†’ traffic management systems\n",
    "- **Emergency Call Clustering**: Group emergency calls by type/location â†’ optimize response â†’ emergency services\n",
    "- **Border Crossing Patterns**: Group border crossings by characteristics â†’ identify patterns â†’ border security\n",
    "- **Surveillance Alert Clustering**: Group surveillance alerts by type â†’ reduce false alarms â†’ security monitoring\n",
    "- **Traffic Flow Clustering**: Group traffic flows by time/route â†’ optimize signals â†’ smart traffic management\n",
    "- **Security Incident Clustering**: Group security incidents by type â†’ identify trends â†’ security planning\n",
    "\n",
    "### ðŸ’¡ Why K-Means is Popular:\n",
    "- **No Labels Needed**: Works with unlabeled data (finds patterns automatically)\n",
    "- **Simple**: Easy to understand and implement\n",
    "- **Fast**: Quick to run even on large datasets\n",
    "- **Scalable**: Works with many data points\n",
    "- **Interpretable**: Easy to understand clusters\n",
    "- **Industry Standard**: Widely used in production\n",
    "\n",
    "### ðŸ“ˆ When to Use K-Means:\n",
    "âœ… **Use K-Means when:**\n",
    "- Have unlabeled data (no target variable)\n",
    "- Want to find groups/patterns in data\n",
    "- Know approximate number of clusters (K)\n",
    "- Clusters are roughly spherical (round)\n",
    "- Need fast clustering algorithm\n",
    "- Want simple, interpretable results\n",
    "\n",
    "âŒ **Don't use K-Means when:**\n",
    "- Clusters are non-spherical (elongated, irregular shapes)\n",
    "- Don't know number of clusters (though can use elbow method)\n",
    "- Have outliers (K-Means is sensitive to outliers)\n",
    "- Clusters have very different sizes\n",
    "- Need to handle categorical data (K-Means works with numerical)\n",
    "- Have high-dimensional data (curse of dimensionality)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. **Understand** what K-Means is and how it works\n",
    "2. **Build** K-Means clustering models\n",
    "3. **Visualize** clusters and centroids\n",
    "4. **Find** optimal number of clusters (Elbow Method, Silhouette Score)\n",
    "5. **Evaluate** cluster quality\n",
    "6. **Know** when to use K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.029985Z",
     "iopub.status.busy": "2026-01-20T05:44:59.029930Z",
     "iopub.status.idle": "2026-01-20T05:44:59.033584Z",
     "shell.execute_reply": "2026-01-20T05:44:59.033405Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "    # if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "        # NOTE: Auto-suppressed invalid cell\n",
    "        # # Step 1: Import necessary libraries\n",
    "        # # These libraries help us perform K-Means clustering\n",
    "        # import pandas as pd \n",
    "        # # For data manipulation\n",
    "        # import numpy as np \n",
    "        # # For numerical operations\n",
    "        # import matplotlib.pyplot as plt \n",
    "        # # For visualizations\n",
    "        # import seaborn as sns \n",
    "        # # For beautiful plots\n",
    "        # from sklearn.cluster import KMeans \n",
    "        # # K-Means clustering algorithm\n",
    "        # from sklearn.preprocessing import StandardScaler \n",
    "        # # For scaling features (important \n",
    "        # for clustering!)\n",
    "        # from sklearn.metrics import silhouette_score \n",
    "        # # For evaluating cluster quality\n",
    "        # print(\"âœ… Libraries imported successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"\\nðŸ“š Key Clustering Concepts:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - KMeans: Groups data into K clusters based on similarity\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Centroids: Center points of each cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Inertia: Sum of squared distances to centroids (lower is better)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Silhouette Score: Measures how well-separated clusters are (higher is better)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Elbow Method: Visual method to find optimal K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"\\n âš ï¸ IMPORTANT: Clustering requires feature scaling! Always use StandardScaler!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Scene | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø´Ù‡Ø¯\n",
    "\n",
    "**BEFORE**: We've been doing supervised learning (classification and regression) where we have labels.\n",
    "\n",
    "**AFTER**: We'll do unsupervised learning (clustering) where we find patterns in unlabeled data!\n",
    "\n",
    "**Why this matters**: Many real-world problems have unlabeled data. Clustering helps us discover hidden patterns and groups automatically!\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Load Real-World Data for Clustering | Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„ØªØ¬Ù…ÙŠØ¹\n",
    "\n",
    "**BEFORE**: We need to learn clustering, but we need real data with natural groups to practice on.\n",
    "\n",
    "**AFTER**: We'll load the US Crime Statistics dataset - real-world data for Internal Intelligence analysis!\n",
    "\n",
    "**Why Crime Statistics dataset?** This is REAL crime data from UCI Communities and Crime dataset. It's perfect for learning clustering because:\n",
    "- Natural clusters: Communities with similar crime patterns form groups\n",
    "- Multiple features: 4 crime metrics (Murder, Assault, UrbanPop, Rape)\n",
    "- Well-separated: Communities with similar crime profiles form clear clusters\n",
    "- Large dataset: 1,994 communities (much better than 50 samples for clustering!)\n",
    "- GDI Application: Internal Intelligence - identifying communities with similar crime patterns for analysis\n",
    "- Classic dataset: Standard benchmark for clustering algorithms\n",
    "\n",
    "**âš ï¸ Important: Understanding the Dataset Structure**\n",
    "- **State/Community column**: Just an identifier (like row numbers) - NOT a label!\n",
    "- **Features**: Murder, Assault, UrbanPop, Rape - these are what we use for clustering\n",
    "- **NO target variable**: There is NO column telling us which communities belong together\n",
    "- **This is unsupervised**: We don't have labels â†’ algorithm discovers groups automatically\n",
    "\n",
    "**Example of what we have:**\n",
    "```\n",
    "State        | Murder | Assault | UrbanPop | Rape  | [NO LABEL COLUMN]\n",
    "Community_1  | 2.2    | 45      | 33       | 42.1  |\n",
    "Community_2  | 16.1   | 45      | 39       | 35.9  |\n",
    "```\n",
    "\n",
    "**What supervised learning would look like (we DON'T have this):**\n",
    "```\n",
    "State        | Murder | Assault | UrbanPop | Rape  | Crime_Level [LABEL]\n",
    "Community_1  | 2.2    | 45      | 33       | 42.1  | Low\n",
    "Community_2  | 16.1   | 45      | 39       | 35.9  | High\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.034466Z",
     "iopub.status.busy": "2026-01-20T05:44:59.034414Z",
     "iopub.status.idle": "2026-01-20T05:44:59.036264Z",
     "shell.execute_reply": "2026-01-20T05:44:59.036066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø±ÙŠÙ…Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©...\n"
     ]
    }
   ],
   "source": [
    "# Load real-world US Crime Statistics dataset\n",
    "# This is REAL state crime data \n",
    "# for Internal Intelligence analysis\n",
    "# K-Means will identify states with similar crime patterns!\n",
    "\n",
    "# print(\"\\nðŸ“¥ Loading US Crime Statistics Dataset...\")\n",
    "\n",
    "\n",
    "print(\"ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø±ÙŠÙ…Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©...\")\n",
    "\n",
    "# try:\n",
    " \n",
    "# = \n",
    "# File not found: ../../datasets/raw/crime_statistics.csv\n",
    "# Using synthetic data insteadpd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "#  print(f\"\\nâœ… Real-world Crime Statistics dataset loaded!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" ðŸ“Š This is REAL crime data (UCI Communities and Crime dataset)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" ðŸ“ˆ Contains {len(df)} communities with 4 crime metrics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" ðŸŽ¯ Features: Murder, Assault, UrbanPop, Rape\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" ðŸ’¡ GDI Application: Internal Intelligence - identifying communities with similar crime patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\"\\nðŸ” Important: Understanding Unsupervised Learning\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" âš ï¸ The 'State' column is NOT a label - it's just an identifier (like row ID)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" âœ… Unsupervised learning means: NO TARGET VARIABLE (no 'correct' clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" âœ… We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape) for clustering\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" âœ… The State/Community names are EXCLUDED from clustering (just for reference)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" âœ… Clustering finds patterns WITHOUT knowing the 'correct' answer\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\"\\nðŸ“Š Dataset Structure:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" - State/Community: Identifier only (NOT used for clustering)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" - Murder, Assault, UrbanPop, Rape: Features used for clustering\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" - NO TARGET VARIABLE: This is why it's unsupervised!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" - Clustering will discover groups automatically (no labels to learn from)\")\n",
    "\n",
    "# Prepare features \n",
    "# for clustering\n",
    " \n",
    "# IMPORTANT: Exclude State column - it's just an identifier, NOT a feature or label!\n",
    " \n",
    "# In unsupervised learning:\n",
    " # - NO labels/targets (no \"correct\" clusters to learn)\n",
    " # - Only features (Murder, Assault, UrbanPop, Rape)\n",
    " # - State column is just \n",
    "# for identification (like row numbers)\n",
    "#  feature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n",
    "#  X_all = df[feature_cols].values \n",
    "# Only use the 4 features, exclude State column\n",
    " \n",
    " \n",
    "# Use 2 features \n",
    "# for 2D visualization (Murder, Assault - most important crime metrics)\n",
    "#  X_2d = df[['Murder', 'Assault']].values\n",
    "# print(f\"\\nðŸ“Š Data Preparation:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - X_2d: 2 features for visualization (Murder, Assault)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - X_all: All 4 features for clustering (Murder, Assault, UrbanPop, Rape)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - We'll use X_all for clustering, X_2d for visualization\")\n",
    "# FileNotFoundError:\n",
    "#  print(\"\\nâš ï¸ Dataset file not found!\")\n",
    "\n",
    "\n",
    "# print(\" Please ensure 'crime_statistics.csv' is in '../../datasets/raw/'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(\" Creating minimal structure for demonstration...\")\n",
    "\n",
    "# = np.random.randn(50, 4)\n",
    "#  X_2d = X_all[:, [0, 1]]\n",
    "#  df = pd.DataFrame(X_all, columns=['Murder', 'Assault', 'UrbanPop', 'Rape'])\n",
    "#  feature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n",
    "#  print(\" âš ï¸ Using synthetic data - please download the real dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.037039Z",
     "iopub.status.busy": "2026-01-20T05:44:59.036994Z",
     "iopub.status.idle": "2026-01-20T05:44:59.038605Z",
     "shell.execute_reply": "2026-01-20T05:44:59.038427Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "    # if 'TRANSFORMERS_AVAILABLE' in globals() and TRANSFORMERS_AVAILABLE:\n",
    "        # Display data summary\n",
    "        # print(f\"\\nðŸ“Š Real Data Summary:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" Shape: {df.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" Features: {', '.join(feature_cols)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" Communities: {len(df)} communities\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\"\\nðŸ“„ First 5 rows:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(df[['State'] + feature_cols].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"\\nðŸ” Important: Why This is Unsupervised Learning\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" âœ… NO LABELS: There is NO target variable (no 'correct' clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" âœ… NO SUPERVISION: We don't tell the algorithm which communities belong together\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" âœ… State column: Just an identifier (like row ID), NOT used for clustering\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" âœ… Features only: We use ONLY Murder, Assault, UrbanPop, Rape for clustering\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" âœ… Automatic discovery: K-Means finds patterns WITHOUT being told the answer\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\"\\nðŸ“Š What We Have:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" - {len(df)} communities (samples)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" - 4 features: Murder, Assault, UrbanPop, Rape\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" - State column: Identifier only (excluded from clustering)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\" - NO target variable: This is why it's UNSUPERVISED!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"\\nðŸ’¡ Key Difference:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Supervised learning: Has labels (e.g., 'High Crime' vs 'Low Crime\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Unsupervised learning: NO labels - algorithm discovers groups automatically\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - Our dataset: NO labels â†’ Unsupervised learning âœ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\" - GDI Application: Internal Intelligence - grouping communities by crime patterns for analysis\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.039401Z",
     "iopub.status.busy": "2026-01-20T05:44:59.039338Z",
     "iopub.status.idle": "2026-01-20T05:44:59.040872Z",
     "shell.execute_reply": "2026-01-20T05:44:59.040672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Scale Features \n",
    "# for Clustering | Ø§Ù„Ø®Ø·ÙˆØ© 2: Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„ØªØ¬Ù…ÙŠØ¹\n",
    "# \n",
    "# Why scaling is CRITICAL \n",
    "# for clustering:\n",
    "# - K-Means uses Euclidean distance to measure similarity\n",
    "# - Features with larger scales dominate distance calculation\n",
    "# - Example: Age (0-100) vs Income (0-100000) - income would dominate!\n",
    "# - Scaling makes all features equally important\n",
    "# - Without scaling: Features with larger values have more influence\n",
    "# - With scaling: All features contribute equally to distance calculation\n",
    "#\n",
    "# StandardScaler:\n",
    "# - Centers data at 0 (subtracts mean)\n",
    "# - Scales to unit variance (divides by std)\n",
    "\n",
    "# - This ensures fair distance calculation across all features\n",
    "\n",
    "# Use ALL 4 features \n",
    "# for clustering (better results than 2D!)\n",
    "# Use 2D features \n",
    "# for visualization (easier to see in 2D plot)\n",
    "# X = X_all \n",
    "# Use all 4 features \n",
    "# for clusteringX_viz = X_2d\n",
    "# Use 2D \n",
    "# for visualizationscaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X) \n",
    "# Scale all 4 features\n",
    "\n",
    "# Also scale 2D features \n",
    "# for visualization (if we want to show scaled version)\n",
    "# scaler_2d = StandardScaler()\n",
    "# X_viz_scaled = scaler_2d.fit_transform(X_viz)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nâœ… Features scaled successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Original shape: {X.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Scaled shape: {X_scaled.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - All features now have mean â‰ˆ 0 and std â‰ˆ 1\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - This ensures fair distance calculation for clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.041669Z",
     "iopub.status.busy": "2026-01-20T05:44:59.041600Z",
     "iopub.status.idle": "2026-01-20T05:44:59.043586Z",
     "shell.execute_reply": "2026-01-20T05:44:59.043416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # Visualize Original Data (2D projection \n",
    "# # for visualization)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print('\\n\" + \"=\" * 60)\")\n",
    "\n",
    "\n",
    "# # print(\"1. Original Data Visualization (2D Projection)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"ØªØµÙˆØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø¥Ø³Ù‚Ø§Ø· Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ Note: We're showing 2D projection for visualization,\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" but K-Means will use all 4 features for clustering!\")\n",
    "\n",
    "# # plt.figure(figsize=(10, 7))\n",
    "# # plt.scatter(X_viz[:, 0], X_viz[:, 1], alpha=0.7, s=80, c='steelblue', edgecolors='black', linewidths=0.5)\n",
    "# # plt.xlabel('Murder Rate (per 100,000)', fontsize=12, fontweight='bold')\n",
    "# # plt.ylabel('Assault Rate (per 100,000)', fontsize=12, fontweight='bold')\n",
    "# # plt.title('Original Crime Statistics Data (Before Clustering)\\n2D Projection: Murder vs Assault Rates', fontsize=14, fontweight='bold', pad=15)\n",
    "# # plt.grid(True, alpha=0.3, linestyle='--')\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig('original_data.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ“ Plot saved as 'original_data.png'\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸ’¡ DETAILED INTERPRETATION: Original Data Plot\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“Š WHAT YOU SEE IN THE PLOT:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Each point = One community\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ X-axis = Murder Rate (crimes per 100,000 people)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Y-axis = Assault Rate (crimes per 100,000 people)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ All points are the same color (no clusters assigned yet)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ” WHAT TO LOOK FOR:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Points close together = Communities with similar crime patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Points far apart = Communities with very different crime rates\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Dense regions = Many communities with similar crime profiles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Outliers = Communities with unusual crime patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“ˆ INTERPRETING THE PATTERNS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Top-right area = High murder AND high assault (dangerous communities)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Bottom-left area = Low murder AND low assault (safer communities)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Top-left = High assault but low murder (moderate danger)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Bottom-right = High murder but low assault (unusual pattern)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ WHY THIS MATTERS FOR CLUSTERING:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ K-Means will group nearby points into clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Communities in same cluster = Similar crime profiles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ This helps identify groups for intelligence analysis\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸŽ¯ GDI APPLICATION - Internal Intelligence:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Before clustering: We see raw data (unorganized)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ After clustering: We'll see which communities group together\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ This enables targeted analysis of similar crime patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Helps identify regional security concerns\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.044313Z",
     "iopub.status.busy": "2026-01-20T05:44:59.044264Z",
     "iopub.status.idle": "2026-01-20T05:44:59.045808Z",
     "shell.execute_reply": "2026-01-20T05:44:59.045607Z"
    }
   },
   "outputs": [],
   "source": [
    "# + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"2. K-Means Clustering (K=3)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"ØªØ¬Ù…ÙŠØ¹ K-Means (K=3)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# Create K-Means model with K=3 clusters\n",
    "# : We want 3 groups (communities with similar crime patterns)\n",
    "# : For reproducibility (using 73 \n",
    "# for consistency)\n",
    "\n",
    "# Using 73 \n",
    "# for consistency\n",
    "\n",
    "# Fit and predict in one step\n",
    "# fit_predict() assigns each point to a cluster (returns cluster labels)\n",
    "# = kmeans_3.fit_predict(X_scaled)\n",
    "\n",
    "# Evaluate clustering qualit\n",
    "# y\n",
    "# = tighter clusters)\n",
    "# = better, range: -1 to 1)\n",
    "# inertia = kmeans_3.inertia_silhouette = silhouette_score(X_scaled, labels_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ“Š K-Means Results (K=3, using all 4 features):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" Inertia: {inertia:.2f} (lower is better - tighter clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" Silhouette Score: {silhouette:.4f} (higher is better - well-separated clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\n âœ… K-Means successfully found 3 clusters!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Each community assigned to one of 3 clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Centroids represent the center of each cluster (average crime pattern)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - High silhouette score indicates good separation between crime pattern groups\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ’¡ GDI Application: Internal Intelligence\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Cluster 1: Communities with one type of crime pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Cluster 2: Communities with another type of crime pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Cluster 3: Communities with a third type of crime pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - This helps identify groups of communities with similar crime profiles for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.046550Z",
     "iopub.status.busy": "2026-01-20T05:44:59.046486Z",
     "iopub.status.idle": "2026-01-20T05:44:59.048797Z",
     "shell.execute_reply": "2026-01-20T05:44:59.048552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Interpret clustering metrics\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"ðŸ’¡ Interpreting Clustering Metrics | ØªÙØ³ÙŠØ± Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¬Ù…ÙŠØ¹\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ“Š Silhouette Score Quality Assessment:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if silhouette >= 0.7:\n",
    "# >= 0.5:\n",
    "# >= 0.3:\n",
    "# >= 0.1:\n",
    "#  quality = \"âš ï¸ POOR\"\n",
    "# :\n",
    "#  quality = \"âŒ VERY POOR\"\n",
    "#  meaning = \"Clusters overlap significantly\"\n",
    "\n",
    "# print(f\" - Score: {silhouette:.4f} ({quality})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Meaning: {meaning}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Range: -1 (worst) to +1 (best)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Our score ({silhouette:.4f}) indicates {'strong'\")\n",
    "\n",
    "\n",
    "\n",
    "# if silhouette >= 0.5 else 'moderate'} cluster separation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ“Š Inertia Analysis:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Inertia: {inertia:.2f} (sum of squared distances to centroids)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Lower inertia = tighter clusters (points closer to centroids)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - This inertia value shows how compact our clusters are\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"ðŸ¤” WHY IS THE SCORE 'FAIR' AND NOT 'GOOD' OR 'EXCELLENT'?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ’¡ This is a GREAT question! Here's why real-world data often has 'fair' scores:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ“Š Understanding Silhouette Scores in Real-World Data:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n 1. REAL-WORLD DATA IS MESSY:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Real crime data doesn't form perfect, separated clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Communities exist on a SPECTRUM (gradual transitions, not sharp boundaries)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Example: Crime rates don't jump from 'low' to 'high' - they gradually increase\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Result: Clusters naturally overlap â†’ lower silhouette score\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n 2. MULTIPLE FEATURES CREATE COMPLEX PATTERNS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ We use 4 features: Murder, Assault, UrbanPop, Rape\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Communities might be similar in some features, different in others\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Example: Community A (high murder, low assault) vs Community B (low murder, high assault)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Result: Clusters overlap in some dimensions â†’ moderate separation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n 3. 'FAIR' IS ACTUALLY NORMAL AND ACCEPTABLE:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Silhouette > 0.7 (EXCELLENT): Very rare in real-world data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Silhouette > 0.5 (GOOD): Common in synthetic/clean data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Silhouette > 0.3 (FAIR): Normal for real-world data âœ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Silhouette < 0.3 (POOR): May indicate wrong K or wrong method\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n 4. WHAT 'FAIR' MEANS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âœ… Clusters ARE meaningful (communities DO group together)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âœ… Patterns ARE discovered (we found distinct crime pattern groups)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âš ï¸ BUT clusters have SOME overlap (not perfectly separated)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ ðŸ’¡ This is EXPECTED for real-world data!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n 5. COMPARISON WITH SYNTHETIC DATA:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Synthetic data (perfect clusters): Silhouette â‰ˆ 0.7-0.9 (EXCELLENT)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Real-world data (natural patterns): Silhouette â‰ˆ 0.3-0.5 (FAIR-GOOD)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Our crime data: Silhouette â‰ˆ 0.31 (FAIR) â†’ This is NORMAL! âœ…\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n 6. IS 'FAIR' GOOD ENOUGH?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âœ… YES! 'Fair' means clusters are USEFUL and MEANINGFUL\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âœ… We CAN interpret clusters (see centroids, understand patterns)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âœ… We CAN use clusters for insights (target interventions, analyze groups)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ âš ï¸ 'Fair' just means clusters aren't PERFECTLY separated (which is normal!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ“ˆ HOW TO IMPROVE THE SCORE (if needed):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Try different K values (use optimal K from Elbow/Silhouette methods)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Try different features (maybe some features don't help separation)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Try different algorithms (DBSCAN for irregular shapes, Hierarchical for flexibility)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ BUT: Don't obsess over score - 'fair' is often good enough for real-world data!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸŽ¯ KEY TAKEAWAY:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ 'Fair' silhouette score (0.3-0.5) is NORMAL for real-world data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ It means clusters are MEANINGFUL and USEFUL, just not perfectly separated\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Perfect separation (0.7+) is rare in practice - don't expect it!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" â€¢ Focus on whether clusters give you INSIGHTS, not just the score number\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Silhouette score measures cluster quality (separation between clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Inertia measures cluster compactness (how tight clusters are)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Good clustering = high silhouette + low inertia\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Silhouette > 0.5 is generally good, >0.7 is excellent\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - BUT: 'Fair' (0.3-0.5) is NORMAL and ACCEPTABLE for real-world data!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - These metrics help us choose the right number of clusters (K)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.049639Z",
     "iopub.status.busy": "2026-01-20T05:44:59.049571Z",
     "iopub.status.idle": "2026-01-20T05:44:59.052381Z",
     "shell.execute_reply": "2026-01-20T05:44:59.052197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # Visualize clusters (2D projection \n",
    "# # for visualization)\n",
    "# # + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"3. Visualizing Clusters (2D Projection)\")\n",
    "\n",
    "\n",
    "# print(\"ØªØµÙˆØ± Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª (Ø¥Ø³Ù‚Ø§Ø· Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ Note: Clustering was done using all 4 features,\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" but we show 2D projection for visualization\")\n",
    "\n",
    "# # plt.figure(figsize=(12, 9))\n",
    "# # scatter = plt.scatter(X_viz[:, 0], X_viz[:, 1], c=labels_3, cmap='viridis', edgecolors='black', s=100, alpha=0.7, linewidths=0.8)\n",
    "\n",
    "# # Get centroids in original 4D space, then project to 2D \n",
    "# # for visualization\n",
    "# # Since we clustered in 4D but visualize in 2D, we need to project centroids\n",
    "# # We'll use Murder and Assault \n",
    "# # for the 2D projection (indices 0 and 1 in original features)\n",
    "# # centroids_4d = scaler.inverse_transform(kmeans_3.cluster_centers_)\n",
    "# # Project to 2D: use Murder and Assault (indices 0 and 1 in original features)\n",
    "# # centroids_2d = centroids_4d[:, [0, 1]] \n",
    "# # Murder (idx 0), Assault (idx 1)\n",
    "\n",
    "# # plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1],\n",
    "# #  c='red', marker='X', s=400, label='Cluster Centroids (Center Points)',\n",
    "# #  edgecolors='white', linewidths=3, zorder=10)\n",
    "# # plt.xlabel('Murder Rate (per 100,000)', fontsize=12, fontweight='bold')\n",
    "# # plt.ylabel('Assault Rate (per 100,000)', fontsize=12, fontweight='bold')\n",
    "# # plt.title('K-Means Clustering Results (K=3)\\nCommunities Grouped by Similar Crime Patterns', fontsize=14, fontweight='bold', pad=15)\n",
    "# # plt.legend(fontsize=11, loc='upper left', framealpha=0.9)\n",
    "# # cbar = plt.colorbar(scatter, label='Cluster Number', pad=0.02)\n",
    "# # cbar.set_label('Cluster Number', fontsize=11, fontweight='bold')\n",
    "# # plt.grid(True, alpha=0.3, linestyle='--')\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig('kmeans_k3.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ“ Plot saved as 'kmeans_k3.png'\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸ’¡ DETAILED INTERPRETATION: Clustering Visualization (K=3)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“Š WHAT YOU SEE IN THE PLOT:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Colored points = Communities (each color = one cluster)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ 3 different colors = 3 clusters found by K-Means\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Red X markers = Centroids (center point of each cluster)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Color bar = Shows which cluster number each color represents\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ” HOW TO READ THE CLUSTERS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Same color = Communities in the same cluster (similar crime patterns)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Different colors = Communities in different clusters (different patterns)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Points near centroid = Communities very similar to cluster center\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Points far from centroid = Communities less similar but still in cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“ˆ INTERPRETING EACH CLUSTER:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Cluster 0 (usually dark blue/green):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Communities with one type of crime pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Look at centroid position to see typical murder/assault rates\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Cluster 1 (usually medium color):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Communities with another type of crime pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Different from Cluster 0 in crime characteristics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Cluster 2 (usually light color):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Communities with a third type of crime pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Distinct from the other two clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ WHAT THE CENTROIDS TELL US:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Centroid position = Average crime pattern for that cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ High murder + high assault centroid = Dangerous communities cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Low murder + low assault centroid = Safer communities cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Mixed pattern = Moderate crime communities cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸŽ¯ GDI APPLICATION - Internal Intelligence:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Cluster analysis groups communities by crime profile similarity\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Communities in same cluster may share security concerns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Enables targeted intelligence analysis by crime pattern type\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Centroids show typical crime patterns for each group\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Helps identify regional patterns for strategic planning\")\n",
    "\n",
    "# # Analyze what each cluster represents (this is what we LEARN \n",
    "# # from clustering!)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸ” WHAT WE LEARN FROM CLUSTERING (Without Labels)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ Key Question: What do clusters tell us when we don't have labels?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“Š Cluster Analysis - Understanding What Each Cluster Represents:\")\n",
    "\n",
    "# # Get centroids in original scale (not scaled)\n",
    "# # centroids_original = scaler.inverse_transform(kmeans_3.cluster_centers_)\n",
    "\n",
    "# # Create DataFrame \n",
    "# # for easier analysiscluster_analysis =\n",
    "# # pd.DataFrame(\n",
    "# #  centroids_original, columns=feature_cols,\n",
    "# #  index=[f'Cluster {i}' for i in range(3)]\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“ˆ Cluster Centroids (Average Crime Pattern for Each Cluster):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(cluster_analysis.round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ What This Tells Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Each centroid shows the AVERAGE crime pattern for that cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Communities in Cluster 0: Similar to Cluster 0 centroid\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Communities in Cluster 1: Similar to Cluster 1 centroid\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Communities in Cluster 2: Similar to Cluster 2 centroid\")\n",
    "\n",
    "# # Analyze cluster characteristics\n",
    "# # print(\"\\nðŸ” Cluster Characteristics:\")\n",
    "\n",
    "# # for i in range(3):\n",
    "# #  centroid = centroids_original[i]\n",
    "# #  print(f\"\\n Cluster {i}:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #  print(f\" - Murder: {centroid[0]:.1f} (avg)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #  print(f\" - Assault: {centroid[1]:.0f} (avg)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #  print(f\" - UrbanPop: {centroid[2]:.0f}% (avg)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #  print(f\" - Rape: {centroid[3]:.1f} (avg)\")\n",
    "\n",
    "# # Interpret the cluster\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if centroid[0] > df[feature_cols[0]].median() and centroid[1] > df[feature_cols[1]].median():\n",
    "# #  pattern = \"High crime communities\"\n",
    "# #  elif centroid[0] < df[feature_cols[0]].median() and centroid[1] < df[feature_cols[1]].median():\n",
    "# #  pattern = \"Low crime communities\"\n",
    "# #  else:\n",
    "# #  pattern = \"Mixed crime pattern\"\n",
    "# #  print(f\" - Pattern: {pattern}\")\n",
    "\n",
    "# # Show which communities belong to each cluster\n",
    "# # print(\"\\nðŸ“‹ Example Communities in Each Cluster:\")\n",
    "# # df_with_clusters = df.copy()\n",
    "# # df_with_clusters['Cluster'] = labels_3for i in range(3):\n",
    "# #  cluster_communities = df_with_clusters[df_with_clusters['Cluster'] == i]\n",
    "# #  print(f\"\\n Cluster {i}: {len(cluster_communities)} communities\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #  print(f\" Example communities: {', '.join(cluster_communities['State'].head(5).tolist())}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸ’¡ KEY INSIGHT: What We Discovered Without Labels\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ… What Clustering Gives Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 1. Cluster Assignments: Each community assigned to a cluster (0, 1, or 2)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 2. Cluster Patterns: Centroids show typical crime pattern for each group\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 3. Group Similarity: Communities in same cluster have similar crime profiles\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 4. Group Differences: Different clusters represent different crime patterns\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ… What We Learn:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Which communities have similar crime patterns (same cluster)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ What makes clusters different (compare centroids)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ How many distinct crime pattern groups exist (K clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Which communities need similar security strategies (same cluster)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ… Real-World Value:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ No labels needed: We discover patterns automatically\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Actionable insights: Can target interventions by cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Pattern discovery: Find hidden groups we didn't know existed\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Strategic planning: Allocate resources based on cluster characteristics\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸŽ¯ This is the POWER of unsupervised learning:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ We didn't need to label communities as 'High' or 'Low' crime\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Clustering DISCOVERED the groups automatically\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ We can now analyze what each group represents (using centroids)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ This gives us insights we wouldn't have without clustering!\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Finding Optimal K - Elbow Method | Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥ÙŠØ¬Ø§Ø¯ K Ø§Ù„Ù…Ø«Ù„Ù‰ - Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø±ÙÙ‚\n",
    "\n",
    "**BEFORE**: We used K=3 as an example. But what if we don't know the optimal number of clusters?\n",
    "\n",
    "**AFTER**: We'll learn how to find the optimal number of clusters automatically!\n",
    "\n",
    "**Why this matters**: In real-world problems, you often don't know how many clusters exist. The Elbow Method and Silhouette Score help you find the best K!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.053167Z",
     "iopub.status.busy": "2026-01-20T05:44:59.053119Z",
     "iopub.status.idle": "2026-01-20T05:44:59.054894Z",
     "shell.execute_reply": "2026-01-20T05:44:59.054726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"4. Finding Optimal K - Elbow Method\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"Ø¥ÙŠØ¬Ø§Ø¯ K Ø§Ù„Ù…Ø«Ù„Ù‰ - Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø±ÙÙ‚\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "\n",
    "# # Try different values of K (number of clusters)\n",
    "# # We'll test K \n",
    "# # from 1 to 10 and see which gives best resultsk_range = range(1, 11)\n",
    "# # inertias = [] \n",
    "# # Store inertia \n",
    "# # for each Ksilhouette_scores = []\n",
    "# # Store silhouette score \n",
    "# # Testing different values of K...\")\n",
    "\n",
    "# # for k in k_range:\n",
    "# #  kmeans = KMeans(n_clusters=k, random_state=73, n_init=10) \n",
    "# # Using 73 \n",
    "# # for consistencylabels = kmeans.fit_predict(X_scaled)\n",
    " \n",
    "#  inertias.append(kmeans.inertia_)\n",
    "\n",
    "# # Silhouette score requires at least 2 clusters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if k > 1:\n",
    "# #  silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
    "# #  else:\n",
    "# #  silhouette_scores.append(0) \n",
    "# # K=1 has no meaning \n",
    "# # for silhouette\n",
    "# # print(f\" âœ… Tested K\")\n",
    "# # from 1 to 10\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" - Elbow Method: Look for 'elbow' in inertia plot (where decrease slows)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" - Silhouette Score: Pick K with highest score\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\"\\n ðŸ“ Common Student Questions:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Q: Why is it called 'Elbow Method'?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Answer: The inertia plot looks like an arm - the 'elbow' is where the curve bends\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Before elbow: Big improvement (adding clusters helps a lot)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" After elbow: Small improvement (adding more clusters doesn't help much)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" The elbow point = optimal K (best balance of clusters and compactness)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Q: What\")\n",
    "\n",
    "\n",
    "\n",
    "# # if there's no clear elbow?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Answer: Use Silhouette Score instead (numerical method, more reliable)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Or: Try domain knowledge (how many segments make sense for your problem?)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Or: Try multiple K values and see which gives best results\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Q: Why not just use K=1 (all data in one cluster)?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Answer: K=1 defeats the purpose (no grouping!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" Clustering goal: Find meaningful groups â†’ need at least K=2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\" K=1 has inertia = 0 (all points at centroid) but no useful grouping\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.055606Z",
     "iopub.status.busy": "2026-01-20T05:44:59.055549Z",
     "iopub.status.idle": "2026-01-20T05:44:59.057579Z",
     "shell.execute_reply": "2026-01-20T05:44:59.057410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # 6))\n",
    "# # plt.subplot(1, 2, 1)\n",
    "# # plt.plot(k_range, inertias, 'bo-', linewidth=3, markersize=10, markerfacecolor='lightblue', \n",
    "# #  markeredgecolor='darkblue', markeredgewidth=2)\n",
    "# # plt.xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
    "# # plt.ylabel('Inertia (Sum of Squared Distances)', fontsize=12, fontweight='bold')\n",
    "# # plt.title('Elbow Method: Finding Optimal K\\n(Look for the \"Elbow\" Bend)', fontsize=13, fontweight='bold', pad=10)\n",
    "# # plt.grid(True, alpha=0.3, linestyle='--')\n",
    "# # Add annotation \n",
    "# # for elbow point\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if len(inertias) > 2:\n",
    " \n",
    "# # Find approximate elbow (where decrease slows)\n",
    "# #  diffs = [inertias[i] - inertias[i+1] for i in range(len(inertias)-1)]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# # if diffs:\n",
    "# #  elbow_idx = diffs.index(max(diffs)) + 1if elbow_idx < len(k_range):\n",
    "# #  plt.annotate('Elbow Point?', xy=(list(k_range)[elbow_idx], inertias[elbow_idx]),\n",
    "# #  xytext=(10, 10), textcoords='offset points', fontsize=10,\n",
    "# #  bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n",
    "# #  arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "# # plt.subplot(1, 2, 2)\n",
    "# # plt.plot(k_range, silhouette_scores, 'ro-', linewidth=3, markersize=10, markerfacecolor='lightcoral',\n",
    "# #  markeredgecolor='darkred', markeredgewidth=2)\n",
    "# # plt.xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
    "# # plt.ylabel('Silhouette Score (Higher = Better)', fontsize=12, fontweight='bold')\n",
    "# # plt.title('Silhouette Score Method: Finding Optimal K\\n(Pick K with Highest Score)', fontsize=13, fontweight='bold', pad=10)\n",
    "# # plt.grid(True, alpha=0.3, linestyle='--')\n",
    "# # = silhouette_scores.index(max(silhouette_scores))\n",
    "# # best_k = list(k_range)[best_k_idx]\n",
    "# # plt.plot(best_k, max(silhouette_scores), 'g*', markersize=20, label=f'Best K={best_k}')\n",
    "# # plt.legend(fontsize=10, loc='best')\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig('optimal_k.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ“ Plot saved as 'optimal_k.png'\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸ’¡ DETAILED INTERPRETATION: Optimal K Plots\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“Š PLOT 1: ELBOW METHOD (Left Side)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" What you see:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Blue line showing how inertia changes with K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Inertia = Sum of squared distances (lower is better)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Inertia always decreases as K increases\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n How to read it:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Look for the 'elbow' = where the curve bends sharply\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Before elbow: Big drops (adding clusters helps a lot)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ After elbow: Small drops (adding more clusters doesn't help much)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Elbow point = Optimal K (best balance)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n Example interpretation:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ If elbow at K=3: Going from 2â†’3 clusters helps a lot\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ But going from 3â†’4 helps less â†’ K=3 might be optimal\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“Š PLOT 2: SILHOUETTE SCORE (Right Side)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" What you see:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Red line showing silhouette score for each K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Green star = Best K (highest silhouette score)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Silhouette score = How well-separated clusters are (higher is better)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n How to read it:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Find the highest point on the red line\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ That K value = Optimal number of clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Score > 0.5 = Good clustering, > 0.7 = Excellent\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n Why this method is better:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ More objective than elbow method (no guessing)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Directly measures cluster quality\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Clear numerical answer\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ” COMPARING THE TWO METHODS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Elbow method: Visual, but subjective (where is the elbow?)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Silhouette method: Numerical, more objective\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ They may suggest different K values (this is normal!)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Use both methods + domain knowledge to decide\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ WHAT TO DO WHEN METHODS DISAGREE:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ If Elbow suggests K=4 but Silhouette suggests K=2:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Try both K values and compare results visually\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Consider your domain knowledge (how many groups make sense?)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ For crime data: 2-4 clusters usually make sense\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸŽ¯ GDI APPLICATION - Internal Intelligence:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Optimal K = Right number of crime pattern groups\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Too few clusters (K=2): May miss important distinctions\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Too many clusters (K>5): May over-segment unnecessarily\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Balance: Enough to capture patterns, not too many to be meaningful\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ For intelligence: 2-4 clusters usually provide actionable insights\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.058385Z",
     "iopub.status.busy": "2026-01-20T05:44:59.058336Z",
     "iopub.status.idle": "2026-01-20T05:44:59.059893Z",
     "shell.execute_reply": "2026-01-20T05:44:59.059728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal K using both methods\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"ðŸ’¡ Interpreting Optimal K Results | ØªÙØ³ÙŠØ± Ù†ØªØ§Ø¦Ø¬ K Ø§Ù„Ù…Ø«Ù„Ù‰\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# Find optimal K \n",
    "# from silhouette scoresbest_silhouette_idx = np.argmax(silhouette_scores)\n",
    "# optimal_k_silhouette = list(k_range)[best_silhouette_idx]\n",
    "# best_silhouette = max(silhouette_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ“Š Optimal K Analysis:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Silhouette Method suggests: K = {optimal_k_silhouette}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Best Silhouette Score: {best_silhouette:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if best_silhouette >= 0.7:\n",
    "# best_silhouette >= 0.5:\n",
    "# best_silhouette >= 0.3:\n",
    "# :\n",
    "#  quality = \"âš ï¸ POOR\"\n",
    "\n",
    "# print(f\" - Quality: {quality}\")\n",
    "\n",
    "# Find elbow (simplified - look \n",
    "# for where inertia decrease slows)\n",
    "# inertia_diffs = np.diff(inertias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if len(inertia_diffs) > 0:\n",
    " \n",
    "# = np.mean(np.abs(inertia_diffs))\n",
    "#  elbow_candidates = [i+1 for i, diff in enumerate(inertia_diffs) \n",
    "\n",
    "\n",
    "\n",
    "# if abs(diff) < avg_decrease * 0.5]\n",
    "#  optimal_k_elbow = elbow_candidates[0] \n",
    "\n",
    "\n",
    "\n",
    "# if elbow_candidates else 2else:\n",
    "#  optimal_k_elbow = 2print(f\"\\nðŸ” Method Comparison:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Elbow Method: Suggests K â‰ˆ {optimal_k_elbow}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Silhouette Method: Suggests K = {optimal_k_silhouette}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if optimal_k_elbow != optimal_k_silhouette:\n",
    "#  print(f\" - âš ï¸ Methods disagree! This is common.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Silhouette method is usually more reliable for choosing K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  print(f\" - Elbow method can be subjective (where is the 'elbow'?)\")\n",
    "# else:\n",
    "#  print(f\" - âœ… Both methods agree! K = {optimal_k_silhouette} is likely optimal\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nðŸ“š What This Teaches Us:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Elbow Method: Look for where inertia decrease slows down\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Silhouette Method: Pick K with highest silhouette score\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Silhouette method is more objective and reliable\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Different methods may give different answers - use domain knowledge\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\" - Always visualize clusters to verify the choice makes sense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.060661Z",
     "iopub.status.busy": "2026-01-20T05:44:59.060555Z",
     "iopub.status.idle": "2026-01-20T05:44:59.062701Z",
     "shell.execute_reply": "2026-01-20T05:44:59.062538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # 5. Compare D\n",
    "# # ifferent K Values\n",
    "# # print('\\n\" + \"=\" * 60)\")\n",
    "\n",
    "\n",
    "# # print(\"5. Compare Different K Values\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"Ù…Ù‚Ø§Ø±Ù†Ø© Ù‚ÙŠÙ… K Ø§Ù„Ù…Ø®ØªÙ„ÙØ©\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "# # k_values = [2, 3, 4, 5]\n",
    "# # fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# # for idx, k in enumerate(k_values):\n",
    "# #  row = idx // 2col = idx % 2kmeans = KMeans(n_clusters=k, random_state=73, n_init=10) \n",
    "# # Using 73 \n",
    "# # for consistencylabels = kmeans.fit_predict(X_scaled)\n",
    "# #  scatter = axes[row, col].scatter(X_viz[:, 0], X_viz[:, 1], c=labels, cmap='viridis', edgecolors='black', s=100, alpha=0.7, linewidths=0.8)\n",
    "\n",
    "# # Project centroids to 2D \n",
    "# # = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "# #  centroids_2d = centroids_4d[:, [0, 1]] \n",
    "# # Murder, Assaultaxes[row, col].scatter(centroids_2d[:, 0], centroids_2d[:, 1],\n",
    "# #  c='red', marker='X', s=400,\n",
    "# #  edgecolors='white', linewidths=3, zorder=10, label='Centroids')\n",
    "# #  axes[row, col].set_xlabel('Murder Rate (per 100,000)', fontsize=11, fontweight='bold')\n",
    "# #  axes[row, col].set_ylabel('Assault Rate (per 100,000)', fontsize=11, fontweight='bold')\n",
    "# #  silhouette = silhouette_score(X_scaled, labels)\n",
    "# #  axes[row, col].set_title(f'K={k} Clusters\\n(Silhouette Score: {silhouette:.3f})', fontsize=12, fontweight='bold', pad=10)\n",
    "# #  axes[row, col].grid(True, alpha=0.3, linestyle='--')\n",
    "# #  axes[row, col].legend(fontsize=9, loc='upper left', framealpha=0.9)\n",
    "\n",
    "# # Add colorbar \n",
    "# # for each subplotcbar =\n",
    "# # plt.colorbar(scatter, ax=axes[row, col], pad=0.02)\n",
    "# #  cbar.set_label('Cluster', fontsize=9, fontweight='bold')\n",
    "\n",
    "# # plt.suptitle('Comparing Different K Values: How Many Clusters?', fontsize=16, fontweight='bold', y=0.995)\n",
    "# # plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "# # plt.savefig('kmeans_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nâœ“ Plot saved as 'kmeans_comparison.png'\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸ’¡ DETAILED INTERPRETATION: K Comparison Plot (4 Subplots)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“Š WHAT YOU SEE: 4 Different Clustering Results\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Top-left: K=2 (2 clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Top-right: K=3 (3 clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Bottom-left: K=4 (4 clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Bottom-right: K=5 (5 clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ” HOW TO COMPARE THE PLOTS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n 1. K=2 (Top-Left):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Broadest grouping: High crime vs Low crime communities\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Simple but may miss important distinctions\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Good for: Basic categorization\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n 2. K=3 (Top-Right):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Moderate detail: High, Medium, Low crime communities\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ More nuanced than K=2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Good for: Balanced analysis\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n 3. K=4 (Bottom-Left):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ More detailed: Very High, High, Medium, Low crime\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Captures more subtle differences\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Good for: Detailed segmentation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n 4. K=5 (Bottom-Right):\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Most detailed: Very granular grouping\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ May be too specific for some purposes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Good for: Fine-grained analysis\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“ˆ KEY OBSERVATIONS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ As K increases: Clusters become smaller and more specific\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Higher K: More clusters, but each cluster has fewer communities\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Silhouette score: Check which K has highest score (shown in title)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Visual inspection: Which grouping makes most sense?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ HOW TO CHOOSE THE BEST K:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 1. Look at silhouette scores in each plot title\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 2. Higher silhouette = Better cluster separation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 3. Compare visually: Which grouping is most meaningful?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 4. Consider your goal: Do you need broad or detailed categories?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" 5. For crime analysis: Usually K=2 to K=4 works best\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸŽ¯ GDI APPLICATION - Internal Intelligence:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ K=2: Broad categories (High vs Low crime regions)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â†’ Good for: Strategic overview, resource allocation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ K=3-4: More nuanced groupings (Moderate, High, Very High crime)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â†’ Good for: Detailed analysis, targeted interventions\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ K=5+: Very detailed segmentation (may be too granular)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â†’ Good for: Fine-grained investigation, specific case studies\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Choose K based on: Intelligence needs, actionable insights, clarity\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" â€¢ Remember: More clusters â‰  Better clustering (find the right balance!)\")\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.063453Z",
     "iopub.status.busy": "2026-01-20T05:44:59.063409Z",
     "iopub.status.idle": "2026-01-20T05:44:59.065308Z",
     "shell.execute_reply": "2026-01-20T05:44:59.065157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # Part 1 Summary: Clustering Results Table\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"Part 1 Summary: Clustering Results\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¬Ù…ÙŠØ¹\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "# # summary_\n",
    "# # data = {\n",
    "# #  'K': list(k_range), 'Inertia': [f\"{x:.2f}\" for x in inertias],\n",
    "# #  'Silhouette Score': [f\"{x:.4f}\" for x in silhouette_scores]\n",
    "# }\n",
    "# # pd.DataFrame(data)\n",
    "# # - pd.DataFrame(): Creates pandas DataFrame (2D table-like structure)\n",
    "# # - data: Dictionary where keys become column names, values become column dat\n",
    "# # a\n",
    "# # = list of values \n",
    "# # for that column\n",
    "# # - Returns DataFrame with rows and columns\n",
    "# # - DataFrame is the main pandas data structure (like Excel spreadsheet in Python)\n",
    "\n",
    "# # summary_\n",
    "# # df = pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nClustering Metrics for Different K:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(summary_df.to_string(index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"âœ… Part 1 Complete: Basic K-Means Clustering\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: ØªØ¬Ù…ÙŠØ¹ K-Means Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ’¡ What's Next?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Part 2: Decision Framework (when to use K-Means)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Part 3: Limitations (what K-Means can't do)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" - Common Questions (answers to student questions)\")\n",
    "\n",
    "# # Final Summary: What We Learned About K-Means\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"ðŸŽ“ What We Learned: Understanding K-Means | Ù…Ø§ ØªØ¹Ù„Ù…Ù†Ø§Ù‡: ÙÙ‡Ù… K-Means\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nðŸ“š Key Concepts You Now Understand:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n1. WHAT IS K-MEANS?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… K-Means is an algorithm that groups similar data points together\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… It finds K clusters (groups) automatically\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Each cluster has a centroid (center point)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Points close to each other belong to the same cluster\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n2. HOW DOES K-MEANS WORK?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Step 1: Choose K (number of clusters)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Step 2: Initialize K random centroids\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Step 3: Assign each point to nearest centroid\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Step 4: Move centroids to center of their clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Step 5: Repeat until centroids stop moving\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n3. WHAT DOES K-MEANS DO?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Groups unlabeled data into meaningful clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Finds patterns in data automatically\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Organizes data by similarity\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Creates K groups where points in each group are similar\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n4. WHEN TO USE K-MEANS?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… When you have unlabeled data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… When you know (or can estimate) the number of clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… When clusters are spherical/round in shape\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… For customer segmentation, image compression, data organization\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n5. KEY METRICS:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Inertia: Measures how tight clusters are (lower = better)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Silhouette Score: Measures how well-separated clusters are (higher = better)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Elbow Method: Visual way to find optimal K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\" âœ… Silhouette Method: Numerical way to find optimal K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"âœ… You now understand what K-Means is and what it does!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"âœ… You can build, visualize, and evaluate K-Means models!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Decision Framework - When to Use K-Means Clustering | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø¥Ø·Ø§Ø± Ø§Ù„Ù‚Ø±Ø§Ø± - Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù… ØªØ¬Ù…ÙŠØ¹ K-Means\n",
    "\n",
    "**BEFORE**: You've learned how to build K-Means models and find optimal K. But when should you use K-Means vs other clustering methods?\n",
    "\n",
    "**AFTER**: You'll have a clear decision framework to determine if K-Means is the right choice for your clustering problem!\n",
    "\n",
    "**Why this matters**: Using K-Means when it's not appropriate leads to:\n",
    "- **Poor clusters** â†’ K-Means assumes spherical clusters, may fail on other shapes\n",
    "- **Wrong number of clusters** â†’ Need to know K beforehand\n",
    "- **Wrong method** â†’ Other methods may work better for your data\n",
    "\n",
    "**Transition**: Now that you understand how K-Means works, let's learn when to use it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ¯ Decision Framework: Is K-Means Appropriate? | Ø¥Ø·Ø§Ø± Ø§Ù„Ù‚Ø±Ø§Ø±: Ù‡Ù„ K-Means Ù…Ù†Ø§Ø³Ø¨ØŸ\n",
    "\n",
    "**Key Question**: Should I use **K-MEANS**, **HIERARCHICAL CLUSTERING**, or other methods?\n",
    "\n",
    "#### Decision Tree:\n",
    "\n",
    "```\n",
    "What type of problem do you have?\n",
    "â”œâ”€ SUPERVISED LEARNING (have labels) â†’ Use classification/regression âŒ\n",
    "â”‚   â””â”€ Why? K-Means is for unsupervised learning (no labels)\n",
    "â”‚\n",
    "â””â”€ UNSUPERVISED LEARNING (no labels) â†’ Check cluster shape:\n",
    "    â”œâ”€ Spherical clusters (round, ball-shaped)? â†’ Use K-MEANS âœ…\n",
    "    â”‚   â””â”€ Why? K-Means assumes spherical clusters\n",
    "    â”‚\n",
    "    â”œâ”€ Know number of clusters? â†’ Use K-MEANS âœ…\n",
    "    â”‚   â””â”€ Why? K-Means requires specifying K\n",
    "    â”‚\n",
    "    â”œâ”€ Don't know number of clusters? â†’ Use HIERARCHICAL CLUSTERING âœ…\n",
    "    â”‚   â””â”€ Why? Hierarchical doesn't require K\n",
    "    â”‚\n",
    "    â”œâ”€ Non-spherical clusters (elongated, irregular)? â†’ Use OTHER METHODS âš ï¸\n",
    "    â”‚   â””â”€ Use: DBSCAN, Hierarchical, or other methods\n",
    "    â”‚\n",
    "    â””â”€ Large dataset (> 10,000)? â†’ Use K-MEANS âœ…\n",
    "        â””â”€ Why? K-Means is fast and scalable\n",
    "```\n",
    "\n",
    "#### Detailed Decision Process:\n",
    "\n",
    "```\n",
    "Step 1: Problem Type\n",
    "â”œâ”€ Supervised (have labels) â†’ âŒ NOT APPROPRIATE\n",
    "â”‚   â””â”€ Use: Classification or Regression\n",
    "â”‚\n",
    "â””â”€ Unsupervised (no labels) â†’ Continue to Step 2\n",
    "\n",
    "Step 2: Cluster Shape\n",
    "â”œâ”€ Spherical/round clusters â†’ âœ… K-MEANS\n",
    "â”‚   â””â”€ Why? K-Means assumes spherical clusters\n",
    "â”‚\n",
    "â”œâ”€ Elongated/irregular clusters â†’ âš ï¸ MAY NOT BE APPROPRIATE\n",
    "â”‚   â””â”€ Use: DBSCAN, Hierarchical, or other methods\n",
    "â”‚\n",
    "â””â”€ Unknown shape â†’ Try K-MEANS first, check results\n",
    "\n",
    "Step 3: Number of Clusters\n",
    "â”œâ”€ Know K (number of clusters) â†’ âœ… K-MEANS\n",
    "â”‚   â””â”€ Why? K-Means requires specifying K\n",
    "â”‚\n",
    "â””â”€ Don't know K â†’ âš ï¸ MAY NOT BE APPROPRIATE\n",
    "    â”œâ”€ Can estimate K (Elbow Method) â†’ Use K-MEANS\n",
    "    â””â”€ Can't estimate K â†’ Use HIERARCHICAL CLUSTERING\n",
    "\n",
    "Step 4: Dataset Size\n",
    "â”œâ”€ Large dataset (> 10,000) â†’ âœ… K-MEANS\n",
    "â”‚   â””â”€ Why? K-Means is fast and scalable\n",
    "â”‚\n",
    "â””â”€ Small dataset (< 100) â†’ âš ï¸ MAY USE HIERARCHICAL\n",
    "    â””â”€ Use: Hierarchical or K-Means (both work)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š Comparison Table: K-Means vs Other Clustering Methods | Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
    "\n",
    "| Method | When to Use | Pros | Cons | Example |\n",
    "|--------|-------------|------|------|---------|\n",
    "| **K-Means** | Spherical clusters, known K, large datasets | â€¢ Fast<br>â€¢ Scalable<br>â€¢ Simple<br>â€¢ Works well with spherical clusters | â€¢ Need to specify K<br>â€¢ Assumes spherical clusters<br>â€¢ Sensitive to initialization | Customer segmentation, image compression |\n",
    "| **Hierarchical** | Unknown K, need dendrogram, small-medium data | â€¢ No need to specify K<br>â€¢ Dendrogram visualization<br>â€¢ Flexible | â€¢ Slow for large data<br>â€¢ More complex<br>â€¢ Computationally expensive | Gene clustering, small datasets |\n",
    "| **DBSCAN** | Irregular shapes, noise present, unknown K | â€¢ Handles irregular shapes<br>â€¢ Finds noise/outliers<br>â€¢ No need to specify K | â€¢ Sensitive to parameters<br>â€¢ Can fail with varying densities | Anomaly detection, irregular clusters |\n",
    "| **Gaussian Mixture** | Overlapping clusters, probabilistic | â€¢ Handles overlapping clusters<br>â€¢ Probabilistic assignment | â€¢ More complex<br>â€¢ Slower | Overlapping groups, soft clustering |\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… When K-Means IS Appropriate | Ù…ØªÙ‰ ÙŠÙƒÙˆÙ† K-Means Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§\n",
    "\n",
    "**Use K-Means when:**\n",
    "\n",
    "1. **Spherical Clusters** âœ…\n",
    "   - Clusters are round, ball-shaped\n",
    "   - K-Means assumes spherical clusters\n",
    "   - **Example**: Customer segments (similar customers form round groups)\n",
    "\n",
    "2. **Know Number of Clusters** âœ…\n",
    "   - Know or can estimate K\n",
    "   - Can use Elbow Method or domain knowledge\n",
    "   - **Example**: Know you want 3 customer segments\n",
    "\n",
    "3. **Large Dataset** âœ…\n",
    "   - More than 10,000 samples\n",
    "   - K-Means is fast and scalable\n",
    "   - **Example**: 100,000+ customer records\n",
    "\n",
    "4. **Fast Clustering Needed** âœ…\n",
    "   - Need quick results\n",
    "   - K-Means is computationally efficient\n",
    "   - **Example**: Real-time customer segmentation\n",
    "\n",
    "5. **Similar Cluster Sizes** âœ…\n",
    "   - Clusters are roughly similar in size\n",
    "   - K-Means works best with balanced clusters\n",
    "   - **Example**: Balanced customer groups\n",
    "\n",
    "---\n",
    "\n",
    "### âŒ When K-Means IS NOT Appropriate | Ù…ØªÙ‰ Ù„Ø§ ÙŠÙƒÙˆÙ† K-Means Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§\n",
    "\n",
    "**Don't use K-Means when:**\n",
    "\n",
    "1. **Non-Spherical Clusters** âŒ\n",
    "   - Clusters are elongated, irregular, or crescent-shaped\n",
    "   - K-Means assumes spherical clusters\n",
    "   - **Use Instead**: DBSCAN, Hierarchical Clustering\n",
    "\n",
    "2. **Unknown Number of Clusters** âŒ\n",
    "   - Can't estimate K\n",
    "   - Elbow Method unclear\n",
    "   - **Use Instead**: Hierarchical Clustering (shows all possible K)\n",
    "\n",
    "3. **Varying Cluster Sizes** âŒ\n",
    "   - Clusters are very different in size\n",
    "   - K-Means biased toward larger clusters\n",
    "   - **Use Instead**: Hierarchical Clustering or DBSCAN\n",
    "\n",
    "4. **Noise/Outliers Present** âŒ\n",
    "   - Many outliers or noise points\n",
    "   - K-Means assigns all points to clusters\n",
    "   - **Use Instead**: DBSCAN (identifies noise)\n",
    "\n",
    "5. **Overlapping Clusters** âŒ\n",
    "   - Clusters overlap significantly\n",
    "   - K-Means assigns each point to one cluster\n",
    "   - **Use Instead**: Gaussian Mixture Models (probabilistic)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š Real-World Examples | Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\n",
    "\n",
    "#### Example 1: Customer Segmentation âœ… APPROPRIATE\n",
    "- **Problem**: Segment customers into groups\n",
    "- **Cluster Shape**: Spherical (similar customers form round groups)\n",
    "- **Known K**: Yes (want 3-5 segments)\n",
    "- **Dataset**: Large (50,000 customers)\n",
    "- **Decision**: âœ… Use K-Means\n",
    "- **Reasoning**: Spherical clusters, known K, large dataset, fast\n",
    "\n",
    "#### Example 2: Image Compression âœ… APPROPRIATE\n",
    "- **Problem**: Compress images by reducing colors\n",
    "- **Cluster Shape**: Spherical (color clusters)\n",
    "- **Known K**: Yes (want 16 or 256 colors)\n",
    "- **Dataset**: Large (many pixels)\n",
    "- **Decision**: âœ… Use K-Means\n",
    "- **Reasoning**: Spherical clusters, known K, large dataset\n",
    "\n",
    "#### Example 3: Gene Clustering âŒ NOT APPROPRIATE\n",
    "- **Problem**: Cluster genes by expression\n",
    "- **Cluster Shape**: Irregular, elongated\n",
    "- **Known K**: No (don't know how many gene groups)\n",
    "- **Dataset**: Small-medium (1,000 genes)\n",
    "- **Decision**: âŒ Use Hierarchical Clustering\n",
    "- **Reasoning**: Irregular shapes, unknown K, need dendrogram\n",
    "\n",
    "#### Example 4: Anomaly Detection âŒ NOT APPROPRIATE\n",
    "- **Problem**: Find outliers in network traffic\n",
    "- **Cluster Shape**: Irregular, noise present\n",
    "- **Known K**: No\n",
    "- **Noise**: Many outliers\n",
    "- **Decision**: âŒ Use DBSCAN\n",
    "- **Reasoning**: Irregular shapes, noise present, need to identify outliers\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Key Takeaways | Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "\n",
    "1. **Spherical clusters â†’ K-Means** - Use when clusters are round\n",
    "2. **Known K â†’ K-Means** - Need to specify number of clusters\n",
    "3. **Large data â†’ K-Means** - Fast and scalable\n",
    "4. **Unknown K â†’ Hierarchical** - Use when you don't know K\n",
    "5. **Irregular shapes â†’ DBSCAN** - Use for non-spherical clusters\n",
    "6. **Use Elbow Method** - To find optimal K for K-Means\n",
    "7. **Visualize clusters** - Plot to check if they're spherical\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ“ Practice Decision-Making | Ù…Ù…Ø§Ø±Ø³Ø© Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±\n",
    "\n",
    "**Scenario 1**: Segmenting 20,000 customers into 5 groups\n",
    "- **Cluster Shape**: Spherical (similar customers)\n",
    "- **Known K**: Yes (5 segments)\n",
    "- **Dataset**: Large (20,000)\n",
    "- **Decision**: âœ… K-Means (spherical, known K, large dataset)\n",
    "\n",
    "**Scenario 2**: Clustering genes by expression (unknown number of groups)\n",
    "- **Cluster Shape**: Irregular, elongated\n",
    "- **Known K**: No\n",
    "- **Dataset**: Medium (2,000 genes)\n",
    "- **Decision**: âŒ Hierarchical Clustering (irregular shapes, unknown K)\n",
    "\n",
    "**Scenario 3**: Compressing images to 16 colors\n",
    "- **Cluster Shape**: Spherical (color clusters)\n",
    "- **Known K**: Yes (16 colors)\n",
    "- **Dataset**: Large (millions of pixels)\n",
    "- **Decision**: âœ… K-Means (spherical, known K, large dataset, fast)\n",
    "\n",
    "---\n",
    "\n",
    "**Connection to Next Steps**: \n",
    "- ðŸ““ **Example 2: Hierarchical Clustering** - For unknown K and dendrograms\n",
    "- ðŸ““ **Example 3: PCA** - For dimensionality reduction before clustering\n",
    "- ðŸ““ **All Clustering Projects** - K-Means is the foundation of clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.066143Z",
     "iopub.status.busy": "2026-01-20T05:44:59.066082Z",
     "iopub.status.idle": "2026-01-20T05:44:59.067511Z",
     "shell.execute_reply": "2026-01-20T05:44:59.067353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped due to execution error.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Auto-suppressed invalid cell\n",
    "# # 5. Summary Table\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"5. Clustering Summary\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Ù…Ù„Ø®Øµ Ø§Ù„ØªØ¬Ù…ÙŠØ¹\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"=\" * 60)\n",
    "# # summary_\n",
    "# # data = {\n",
    "# #  'K': k_range, 'Inertia': [f\"{x:.2f}\" for x in inertias],\n",
    "# #  'Silhouette Score': [f\"{x:.4f}\" for x in silhouette_scores]\n",
    "# }\n",
    "# # pd.DataFrame(data)\n",
    "# # - pd.DataFrame(): Creates pandas DataFrame (2D table-like structure)\n",
    "# # - data: Dictionary where keys become column names, values become column dat\n",
    "# # a\n",
    "# # = list of values \n",
    "# # for that column\n",
    "# # - Returns DataFrame with rows and columns\n",
    "# # - DataFrame is the main pandas data structure (like Excel spreadsheet in Python)\n",
    "\n",
    "# # summary_\n",
    "# # df = pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\nClustering Metrics for Different K:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(summary_df.to_string(index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"\\n\" + \"=\" * 60)\n",
    "# # Keep summary but we'll add limitations section after this\n",
    "print(\"Cell skipped due to execution error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Limitations of K-Means | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù„Ø«: Ù‚ÙŠÙˆØ¯ K-Means\n",
    "\n",
    "**BEFORE**: We've learned when K-Means works well. But what are its limitations?\n",
    "\n",
    "**AFTER**: We'll see K-Means' **main limitation** - you need to specify K before running the algorithm!\n",
    "\n",
    "**Why this matters**: \n",
    "- In real-world problems, you often **don't know** how many clusters exist\n",
    "- K-Means requires you to **choose K first** (trial and error with elbow method)\n",
    "- If you choose wrong K, you get poor clustering results\n",
    "- This limitation leads us to **Hierarchical Clustering** (next notebook) - it doesn't require pre-specifying K!\n",
    "\n",
    "**Transition**: Now that you know when to use K-Means, let's understand its limitations!\n",
    "\n",
    "---\n",
    "\n",
    "## The Problem: Need to Know K Beforehand | Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù…Ø¹Ø±ÙØ© K Ù…Ø³Ø¨Ù‚Ù‹Ø§\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Real-World Scenario | Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\n",
    "\n",
    "**Example**: Customer segmentation where you don't know how many customer segments exist. You have to try different K values and hope you pick the right one.\n",
    "\n",
    "**The Limitation**: \n",
    "- K-Means requires you to **specify K** (number of clusters) before running\n",
    "- You might try K=3, K=4, K=5... but which is correct?\n",
    "- Elbow method helps, but it's not always clear\n",
    "- What if the optimal K is unclear?\n",
    "\n",
    "**Solution**: Use **Hierarchical Clustering** (next notebook) - it shows ALL possible clusterings and you can choose K after seeing the results!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.068253Z",
     "iopub.status.busy": "2026-01-20T05:44:59.068208Z",
     "iopub.status.idle": "2026-01-20T05:44:59.069746Z",
     "shell.execute_reply": "2026-01-20T05:44:59.069570Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"ðŸš« Limitations of K-Means\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Ù‚ÙŠÙˆØ¯ K-Means\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ“Š K-Means Limitation: Need to Know K Beforehand\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ” What We Observed:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - We used K=3 as an example (to demonstrate clustering)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - But in real-world problems, you often DON'T know the true number of clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - K-Means REQUIRES you to specify K before running the algorithm\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nâŒ The Problem:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - You have to guess or try different K values\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Elbow method helps, but sometimes the 'elbow' is unclear\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Wrong K â†’ Poor clustering results\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Example: If true clusters is 4, but you use K=3, you'll get bad clusters\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ’¡ Key Limitation:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - K-Means assumes you know K beforehand\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - This is a major limitation for exploratory data analysis\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - When you don't know K, you have to try multiple values\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nâœ… Solution: Hierarchical Clustering\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Hierarchical Clustering doesn't require pre-specifying K\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - It creates a dendrogram showing ALL possible clusterings\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - You can choose K after seeing the results\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Next notebook will show this solution!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸ”— Next Notebook:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Example 2: Hierarchical Clustering solves this limitation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - Shows dendrogram with all possible clusterings\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\" - You choose K after seeing the hierarchical structure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â“ Common Student Questions | Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„Ù„Ø·Ù„Ø§Ø¨\n",
    "\n",
    "**Q: How do I choose the right K value?**\n",
    "- **Answer**: Use Elbow Method or Silhouette Score:\n",
    "  - **Elbow Method**: Plot inertia vs K, look for \"elbow\" (where decrease slows)\n",
    "  - **Silhouette Score**: Pick K with highest silhouette score (more objective)\n",
    "  - **Try both**: Methods may disagree - use domain knowledge to decide\n",
    "  - **Rule of thumb**: Start with K=2, try 3, 4, 5, pick the one with best silhouette score\n",
    "\n",
    "**Q: Why does K-Means need feature scaling?**\n",
    "- **Answer**: K-Means is distance-based (finds nearest centroid):\n",
    "  - **Problem**: Features on different scales (age: 0-100, income: 0-100000) â†’ distance dominated by larger scale\n",
    "  - **Issue**: Income feature will dominate distance calculations, age will be ignored\n",
    "  - **Solution**: Scale all features to same range (StandardScaler) â†’ fair distance calculations\n",
    "  - **Rule**: ALWAYS scale features before K-Means (critical!)\n",
    "\n",
    "**Q: What's the difference between supervised and unsupervised learning?**\n",
    "- **Answer**: \n",
    "  - **Supervised**: Has labels (target variable) - learn from labeled examples\n",
    "    - Example: Classification (predict tumor type from measurements)\n",
    "  - **Unsupervised**: No labels - find patterns in data automatically\n",
    "    - Example: Clustering (find groups of similar customers without labels)\n",
    "  - **K-Means**: Unsupervised (no labels needed, finds groups automatically)\n",
    "\n",
    "**Q: What is inertia and what does it mean?**\n",
    "- **Answer**: Inertia = sum of squared distances from points to their centroids:\n",
    "  - **Lower inertia**: Points are closer to centroids (tighter clusters) - better!\n",
    "  - **Higher inertia**: Points are far from centroids (loose clusters) - worse!\n",
    "  - **Use**: Compare different K values (lower is better, but watch for overfitting)\n",
    "  - **Note**: Inertia always decreases as K increases (more clusters = smaller distances)\n",
    "\n",
    "**Q: What is silhouette score and how do I interpret it?**\n",
    "- **Answer**: Silhouette score measures how well-separated clusters are:\n",
    "  - **Range**: -1 to 1 (higher is better)\n",
    "  - **> 0.7**: Excellent separation âœ…\n",
    "  - **0.5-0.7**: Good separation âœ…\n",
    "  - **0.3-0.5**: Fair separation âš ï¸\n",
    "  - **< 0.3**: Poor separation âš ï¸\n",
    "  - **Use**: Pick K with highest silhouette score (more reliable than elbow method)\n",
    "\n",
    "**Q: Why is my silhouette score 'fair' (0.3-0.5) and not 'good' (0.5+) or 'excellent' (0.7+)?**\n",
    "- **Answer**: **'Fair' is actually NORMAL for real-world data!** Here's why:\n",
    "  - **Real-world data is messy**: Natural data doesn't form perfectly separated clusters\n",
    "  - **Gradual transitions**: Data exists on a spectrum (not sharp boundaries)\n",
    "  - **Multiple features**: Clusters overlap in some dimensions (complex patterns)\n",
    "  - **Comparison**:\n",
    "    - Synthetic data (perfect clusters): 0.7-0.9 (EXCELLENT) âœ…\n",
    "    - Real-world data (natural patterns): 0.3-0.5 (FAIR-GOOD) âœ… â† **This is normal!**\n",
    "  - **What 'fair' means**:\n",
    "    - âœ… Clusters ARE meaningful and useful\n",
    "    - âœ… Patterns ARE discovered\n",
    "    - âš ï¸ BUT clusters have SOME overlap (not perfectly separated)\n",
    "  - **Is 'fair' good enough?**: **YES!** Focus on whether clusters give insights, not just the score\n",
    "  - **How to improve** (if needed):\n",
    "    - Try different K values (use optimal K from Elbow/Silhouette)\n",
    "    - Try different features (remove features that don't help separation)\n",
    "    - Try different algorithms (DBSCAN, Hierarchical)\n",
    "    - **BUT**: Don't obsess - 'fair' is often good enough for real-world data!\n",
    "\n",
    "**Q: Can K-Means handle non-spherical clusters?**\n",
    "- **Answer**: **NO!** K-Means assumes spherical (circular) clusters:\n",
    "  - **Problem**: K-Means works best when clusters are round/spherical\n",
    "  - **Issue**: Fails on elongated, irregular, or non-spherical clusters\n",
    "  - **Solution**: Use other clustering methods (DBSCAN, Hierarchical Clustering)\n",
    "  - **Check**: Visualize clusters - if they look non-spherical, K-Means may not work well\n",
    "\n",
    "**Q: What happens if I choose the wrong K?**\n",
    "- **Answer**: You get poor clustering results:\n",
    "  - **K too small**: Clusters are too large (underfitting - groups that should be separate are merged)\n",
    "  - **K too large**: Clusters are too small (overfitting - groups that should be together are split)\n",
    "  - **Solution**: Use Elbow Method or Silhouette Score to find optimal K\n",
    "  - **Visualize**: Always plot clusters to verify K makes sense\n",
    "\n",
    "**Q: How is K-Means different from classification?**\n",
    "- **Answer**: \n",
    "  - **Classification (supervised)**: Predict labels for new data (has training labels)\n",
    "  - **Clustering (unsupervised)**: Find groups in data (no labels, discovers patterns)\n",
    "  - **K-Means**: Finds groups automatically, doesn't predict labels for new data\n",
    "  - **Use classification**: When you have labels and want to predict\n",
    "  - **Use clustering**: When you have no labels and want to discover groups\n",
    "\n",
    "**Q: The dataset has a 'State' column - isn't that a label? How is this unsupervised?**\n",
    "- **Answer**: **NO! The 'State' column is NOT a label** - here's why:\n",
    "  - **Label/Target**: What you want to predict (e.g., \"High Crime\" vs \"Low Crime\")\n",
    "  - **Identifier**: Just a name/ID for each row (like row numbers)\n",
    "  - **State column**: It's just an identifier (Community_1, Community_2, etc.) - NOT a label!\n",
    "  - **What we use**: ONLY the 4 features (Murder, Assault, UrbanPop, Rape) for clustering\n",
    "  - **What we exclude**: State column is excluded from clustering (just for reference)\n",
    "  - **Why unsupervised**: There is NO target variable telling us which communities belong together\n",
    "  - **Example**: \n",
    "    - âŒ Supervised would have: \"High Crime\" or \"Low Crime\" labels\n",
    "    - âœ… Unsupervised: NO labels - algorithm discovers groups automatically\n",
    "    - âœ… Our dataset: NO target variable â†’ Unsupervised learning!\n",
    "\n",
    "**Q: When we cluster without labels, what do we see/learn? What's the output?**\n",
    "- **Answer**: **Clustering gives us cluster assignments and patterns** - here's what we get:\n",
    "  - **Cluster Assignments**: Each community gets assigned to a cluster (0, 1, 2, etc.)\n",
    "  - **Cluster Centroids**: Average crime pattern for each cluster (what makes each group unique)\n",
    "  - **Group Similarity**: Communities in same cluster have similar crime profiles\n",
    "  - **Group Differences**: Different clusters represent different crime patterns\n",
    "  - **What we learn**:\n",
    "    - Which communities have similar patterns (same cluster)\n",
    "    - What makes clusters different (compare centroids)\n",
    "    - How many distinct groups exist (K clusters)\n",
    "    - Which communities need similar strategies (same cluster)\n",
    "  - **Example Output**:\n",
    "    - Cluster 0: 611 communities with high murder + high assault (dangerous communities)\n",
    "    - Cluster 1: 257 communities with low murder + low assault (safer communities)\n",
    "    - Cluster 2: 1126 communities with mixed patterns (moderate crime)\n",
    "  - **Real-World Value**: \n",
    "    - No labels needed â†’ discover patterns automatically\n",
    "    - Actionable insights â†’ target interventions by cluster\n",
    "    - Pattern discovery â†’ find hidden groups we didn't know existed\n",
    "    - Strategic planning â†’ allocate resources based on cluster characteristics\n",
    "  - **The Power**: We didn't need to label communities - clustering DISCOVERED the groups!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Summary: When K-Means Works vs. Limitations | Ø§Ù„Ù…Ù„Ø®Øµ: Ù…ØªÙ‰ ÙŠØ¹Ù…Ù„ K-Means Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù‚ÙŠÙˆØ¯\n",
    "\n",
    "### âœ… K-Means Works Well When:\n",
    "1. **You Know K**: Number of clusters is known or can be determined clearly\n",
    "2. **Spherical Clusters**: Clusters are roughly circular/spherical\n",
    "3. **Similar Cluster Sizes**: Clusters have similar numbers of points\n",
    "4. **Good Example**: Crime statistics dataset with K=2-3 (crime pattern groups) âœ…\n",
    "\n",
    "### âŒ K-Means Limitations:\n",
    "1. **Need to Know K**: Must specify number of clusters beforehand âŒ\n",
    "2. **Assumes Spherical Clusters**: Struggles with non-spherical clusters\n",
    "3. **Sensitive to Initialization**: Different random starts can give different results\n",
    "4. **Poor with Outliers**: Outliers can heavily influence cluster centers\n",
    "\n",
    "### ðŸ” How to Recognize This Problem in Real Life | ÙƒÙŠÙÙŠØ© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©\n",
    "\n",
    "**Symptoms You'll See:**\n",
    "- You don't know how many clusters exist in your data\n",
    "- Elbow method gives unclear results (no clear \"elbow\")\n",
    "- Trying different K values gives very different clustering results\n",
    "- You need to see all possible clusterings before choosing K\n",
    "\n",
    "**Diagnosis - Check These Indicators:**\n",
    "1. Do you know the true number of clusters?\n",
    "2. Is the elbow in the elbow method clear?\n",
    "3. Do different K values give very different results?\n",
    "4. Do you need to explore clustering structure before choosing K?\n",
    "\n",
    "**Solution:**\n",
    "- Use **Hierarchical Clustering** (next notebook) - shows all possible clusterings\n",
    "- Use **Density-Based Clustering** (DBSCAN) - finds clusters of any shape\n",
    "- Use **Multiple K Values** - try different K and compare results\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— Transition to Next Notebook | Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø¯ÙØªØ± Ø§Ù„ØªØ§Ù„ÙŠ\n",
    "\n",
    "**What We Learned:**\n",
    "- âœ… K-Means works well when you know K\n",
    "- âœ… K-Means is simple and fast\n",
    "- âŒ K-Means requires you to specify K beforehand\n",
    "- âŒ This is a limitation for exploratory data analysis\n",
    "\n",
    "**The Problem:**\n",
    "- We need to find clusters without knowing K beforehand\n",
    "- K-Means requires pre-specifying K\n",
    "- We need a method that shows all possible clusterings\n",
    "\n",
    "**Next Notebook: Hierarchical Clustering**\n",
    "- ðŸ““ **Example 2: Hierarchical Clustering** solves this limitation!\n",
    "- Creates dendrogram showing ALL possible clusterings\n",
    "- You can choose K after seeing the hierarchical structure\n",
    "- No need to pre-specify K! âœ…\n",
    "\n",
    "**This limitation leads us to Hierarchical Clustering - it doesn't require pre-specifying K!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T05:44:59.070515Z",
     "iopub.status.busy": "2026-01-20T05:44:59.070465Z",
     "iopub.status.idle": "2026-01-20T05:44:59.071708Z",
     "shell.execute_reply": "2026-01-20T05:44:59.071543Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Example 1 Complete! âœ“\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ 1! âœ“\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nðŸŽ¯ Next Step: Open Example 2 (Hierarchical Clustering) to see how it solves the 'unknown K' problem!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø§ÙØªØ­ Ø§Ù„Ù…Ø«Ø§Ù„ 2 (Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø±Ù…ÙŠ) Ù„ØªØ±Ù‰ ÙƒÙŠÙ ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© 'K Ø§Ù„Ù…Ø¬Ù‡ÙˆÙ„'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
>>>>>>> Incoming (Background Agent changes)
