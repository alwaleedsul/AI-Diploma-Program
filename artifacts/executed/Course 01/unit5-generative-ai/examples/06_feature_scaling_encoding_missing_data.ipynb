{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Feature Scaling, Encoding, and Handling Missing Data in Medical Datasets\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Implement feature scaling\n",
    "- Encode categorical features\n",
    "- Handle missing data\n",
    "- Apply preprocessing techniques\n",
    "- Prepare medical datasets for ML\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Understanding of data preprocessing\n",
    "- âœ… Scikit-learn knowledge\n",
    "- âœ… Pandas knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 01, Unit 5**:\n",
    "- Implementing feature scaling, encoding, and handling missing data in a medical dataset\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 5 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Feature scaling, encoding, and missing data handling** are critical preprocessing steps that ensure data is ready for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:49:25.395617Z",
     "iopub.status.busy": "2026-01-16T23:49:25.395435Z",
     "iopub.status.idle": "2026-01-16T23:49:26.091225Z",
     "shell.execute_reply": "2026-01-16T23:49:26.091013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported!\n",
      "\n",
      "Feature Scaling, Encoding, and Missing Data Handling\n",
      "============================================================\n",
      "\n",
      "Feature Scaling:\n",
      "  - StandardScaler: Mean=0, Std=1\n",
      "  - MinMaxScaler: Range [0,1]\n",
      "  - RobustScaler: Median and IQR\n",
      "\n",
      "Encoding:\n",
      "  - Label Encoding: Integer labels\n",
      "  - One-Hot Encoding: Binary columns\n",
      "  - Ordinal Encoding: Ordered categories\n",
      "\n",
      "Missing Data:\n",
      "  - Simple Imputation: Mean/median/mode\n",
      "  - KNN Imputation: Nearest neighbors\n",
      "  - Drop missing: Remove rows/columns\n",
      "\n",
      "âœ… Preprocessing concepts understood!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"\\nFeature Scaling, Encoding, and Missing Data Handling\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nFeature Scaling:\")\n",
    "print(\"  - StandardScaler: Mean=0, Std=1\")\n",
    "print(\"  - MinMaxScaler: Range [0,1]\")\n",
    "print(\"  - RobustScaler: Median and IQR\")\n",
    "\n",
    "print(\"\\nEncoding:\")\n",
    "print(\"  - Label Encoding: Integer labels\")\n",
    "print(\"  - One-Hot Encoding: Binary columns\")\n",
    "print(\"  - Ordinal Encoding: Ordered categories\")\n",
    "\n",
    "print(\"\\nMissing Data:\")\n",
    "print(\"  - Simple Imputation: Mean/median/mode\")\n",
    "print(\"  - KNN Imputation: Nearest neighbors\")\n",
    "print(\"  - Drop missing: Remove rows/columns\")\n",
    "\n",
    "print(\"\\nâœ… Preprocessing concepts understood!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
