{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 5 - Example 16: GPU Workflows & RAPIDS\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 5** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 5 - Example 16: GPU Workflows & RAPIDS\n",
    "\n",
    "## üîó Building on Examples 14 & 15 | ÿßŸÑÿ®ŸÜÿßÿ° ÿπŸÑŸâ ÿßŸÑŸÖÿ´ÿßŸÑŸäŸÜ 14 Ÿà 15\n",
    "\n",
    "**From Example 14 (Dask) & Example 15 (PySpark):**\n",
    "- We learned distributed computing with Dask and PySpark\n",
    "- Both are great for CPU-based distributed processing\n",
    "- But for GPU acceleration, we need RAPIDS\n",
    "\n",
    "**This notebook solves that problem!**\n",
    "- We'll learn **RAPIDS** - GPU-accelerated data science ecosystem\n",
    "- We'll see **complete workflows** on GPU (cuDF, cuML)\n",
    "- We'll understand **GPU-accelerated data science** pipelines\n",
    "\n",
    "**This adds GPU acceleration to our distributed computing toolkit!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:52.075510Z",
     "iopub.status.busy": "2026-01-22T15:12:52.075289Z",
     "iopub.status.idle": "2026-01-22T15:12:52.082567Z",
     "shell.execute_reply": "2026-01-22T15:12:52.082270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Running on local machine\n",
      "   For Colab setup, see: DOCS/COLAB_SETUP.md\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Google Colab Setup (Run this first if using Colab)\n",
    "# ÿØŸÑŸäŸÑ ÿ•ÿπÿØÿßÿØ Google Colab (ŸÇŸÖ ÿ®ÿ™ÿ¥ÿ∫ŸäŸÑ Ÿáÿ∞ÿß ÿ£ŸàŸÑÿßŸã ÿ•ÿ∞ÿß ŸÉŸÜÿ™ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ Colab)\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if running on Colab\n",
    "try:\n",
    "    IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "except NameError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üåê Detected Google Colab environment\")\n",
    "    print(\"üìã To enable GPU:\")\n",
    "    print(\"   1. Click: Runtime ‚Üí Change runtime type\")\n",
    "    print(\"   2. Set Hardware accelerator: GPU\")\n",
    "    print(\"   3. Click Save\")\n",
    "    print(\"\\n‚è≥ Installing RAPIDS for GPU acceleration...\")\n",
    "    print(\"   (This may take 5-10 minutes)\")\n",
    "    \n",
    "    # Install RAPIDS\n",
    "    !pip install -q cudf-cu11 cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n",
    "    \n",
    "    print(\"\\n‚úÖ RAPIDS installed!\")\n",
    "    print(\"üîÑ Please restart runtime: Runtime ‚Üí Restart runtime\")\n",
    "    print(\"   Then run this cell again to verify installation.\")\n",
    "else:\n",
    "    print(\"üíª Running on local machine\")\n",
    "    print(\"   For Colab setup, see: DOCS/COLAB_SETUP.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:52.101367Z",
     "iopub.status.busy": "2026-01-22T15:12:52.101163Z",
     "iopub.status.idle": "2026-01-22T15:12:53.079110Z",
     "shell.execute_reply": "2026-01-22T15:12:53.078795Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression as skLinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.080747Z",
     "iopub.status.busy": "2026-01-22T15:12:53.080586Z",
     "iopub.status.idle": "2026-01-22T15:12:53.083565Z",
     "shell.execute_reply": "2026-01-22T15:12:53.083319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† RAPIDS not available - Using simulation\n",
      "======================================================================\n",
      "Example 16: GPU Workflows & RAPIDS | ÿ≥Ÿäÿ± ÿπŸÖŸÑ GPU Ÿà RAPIDS\n",
      "======================================================================\n",
      "\n",
      "üìö Prerequisites: Example 14 completed, basic GPU knowledge\n",
      "üîó This is the SECOND example in Unit 5 - GPU workflows\n",
      "üéØ Goal: Master GPU-accelerated data science with RAPIDS\n"
     ]
    }
   ],
   "source": [
    "# Try to import RAPIDS\n",
    "try:\n",
    "    import cudf\n",
    "    import cuml\n",
    "    from cuml.linear_model import LinearRegression\n",
    "    CUDF_AVAILABLE = True\n",
    "    RAPIDS_AVAILABLE = True  # For RAPIDS-specific features\n",
    "    print(\"‚úì RAPIDS is available\")\n",
    "except ImportError:\n",
    "    CUDF_AVAILABLE = False\n",
    "    RAPIDS_AVAILABLE = False\n",
    "    print(\"‚ö† RAPIDS not available - Using simulation\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 16: GPU Workflows & RAPIDS | ÿ≥Ÿäÿ± ÿπŸÖŸÑ GPU Ÿà RAPIDS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìö Prerequisites: Example 14 completed, basic GPU knowledge\")\n",
    "print(\"üîó This is the SECOND example in Unit 5 - GPU workflows\")\n",
    "print(\"üéØ Goal: Master GPU-accelerated data science with RAPIDS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.084985Z",
     "iopub.status.busy": "2026-01-22T15:12:53.084858Z",
     "iopub.status.idle": "2026-01-22T15:12:53.086651Z",
     "shell.execute_reply": "2026-01-22T15:12:53.086403Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. DATA PROCESSING WORKFLOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.087883Z",
     "iopub.status.busy": "2026-01-22T15:12:53.087793Z",
     "iopub.status.idle": "2026-01-22T15:12:53.259134Z",
     "shell.execute_reply": "2026-01-22T15:12:53.258811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. GPU Data Processing Workflow\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚ö† Simulating GPU workflow with pandas\n",
      "CPU processing time: 0.0191 seconds\n",
      "Speedup: 0.15x\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. GPU Data Processing Workflow\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 500000\n",
    "data = {\n",
    "'id': range(n_samples), 'value1': np.random.randn(n_samples),\n",
    "'value2': np.random.randn(n_samples), 'category': np.random.choice(['A', 'B', 'C'], n_samples),\n",
    "'score': np.random.randint(0, 100, n_samples)\n",
    "}\n",
    "df_pandas = pd.DataFrame(data)\n",
    "if RAPIDS_AVAILABLE:\n",
    "    print(\"\\nUsing cuDF (GPU)...\")\n",
    "    df_gpu = cudf.DataFrame(data)\n",
    "    # GPU operations\n",
    "    start_time = time.time()\n",
    "    result_gpu = df_gpu.groupby('category').agg({\n",
    "        'value1': 'mean', 'value2': 'std',\n",
    "        'score': ['mean', 'max']\n",
    "    })\n",
    "    gpu_time = time.time() - start_time\n",
    "    print(f\"GPU processing time: {gpu_time:.4f} seconds\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Simulating GPU workflow with pandas\")\n",
    "    df_gpu = df_pandas.copy()\n",
    "    start_time = time.time()\n",
    "    result_gpu = df_gpu.groupby('category').agg({\n",
    "'value1': 'mean', 'value2': 'std',\n",
    "'score': ['mean', 'max']\n",
    "})\n",
    "time.sleep(0.1)  # Simulate faster GPU\n",
    "gpu_time = time.time() - start_time\n",
    "# CPU comparison\n",
    "start_time = time.time()\n",
    "result_cpu = df_pandas.groupby('category').agg({\n",
    "'value1': 'mean', 'value2': 'std',\n",
    "'score': ['mean', 'max']\n",
    "})\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU processing time: {cpu_time:.4f} seconds\")\n",
    "print(f\"Speedup: {cpu_time/gpu_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.260609Z",
     "iopub.status.busy": "2026-01-22T15:12:53.260508Z",
     "iopub.status.idle": "2026-01-22T15:12:53.262430Z",
     "shell.execute_reply": "2026-01-22T15:12:53.262160Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. MACHINE LEARNING WORKFLOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.263717Z",
     "iopub.status.busy": "2026-01-22T15:12:53.263616Z",
     "iopub.status.idle": "2026-01-22T15:12:53.284953Z",
     "shell.execute_reply": "2026-01-22T15:12:53.284653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. GPU Machine Learning Workflow\n",
      "----------------------------------------------------------------------\n",
      "‚ö† Simulating GPU ML workflow\n",
      "CPU ML training time: 0.0103 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. GPU Machine Learning Workflow\")\n",
    "print(\"-\" * 70)\n",
    "X = df_pandas[['value1', 'value2', 'score']].values\n",
    "y = df_pandas['value1'] * 2 + df_pandas['value2'] * 1.5 + np.random.randn(n_samples) * 0.1\n",
    "if RAPIDS_AVAILABLE:\n",
    "    X_gpu = cudf.DataFrame({'value1': X[:, 0], 'value2': X[:, 1], 'score': X[:, 2]})\n",
    "    y_gpu = cudf.Series(y)\n",
    "    start_time = time.time()\n",
    "    gpu_model = LinearRegression()\n",
    "    gpu_model.fit(X_gpu, y_gpu)\n",
    "    gpu_ml_time = time.time() - start_time\n",
    "    print(f\"GPU ML training time: {gpu_ml_time:.4f} seconds\")\n",
    "else:\n",
    "    print(\"‚ö† Simulating GPU ML workflow\")\n",
    "    gpu_ml_time = 0.5\n",
    "start_time = time.time()\n",
    "cpu_model = skLinearRegression()\n",
    "cpu_model.fit(X, y)\n",
    "cpu_ml_time = time.time() - start_time\n",
    "print(f\"CPU ML training time: {cpu_ml_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.286307Z",
     "iopub.status.busy": "2026-01-22T15:12:53.286209Z",
     "iopub.status.idle": "2026-01-22T15:12:53.287986Z",
     "shell.execute_reply": "2026-01-22T15:12:53.287734Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. VISUALIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.289221Z",
     "iopub.status.busy": "2026-01-22T15:12:53.289133Z",
     "iopub.status.idle": "2026-01-22T15:12:53.590134Z",
     "shell.execute_reply": "2026-01-22T15:12:53.589844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Creating Workflow Comparison\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Workflow comparison saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Creating Workflow Comparison\")\n",
    "print(\"-\" * 70)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('RAPIDS GPU Workflow Performance', fontsize=16, weight='bold')\n",
    "# Data processing comparison\n",
    "ops = ['Data Processing\\n ', 'ML Training\\n ML']\n",
    "cpu_times = [cpu_time, cpu_ml_time]\n",
    "gpu_times = [gpu_time, gpu_ml_time]\n",
    "x = np.arange(len(ops))\n",
    "width = 0.35\n",
    "bars1 = axes[0].bar(x - width/2, cpu_times, width, label='CPU (pandas/scikit-learn)',\n",
    "color='#FF6B6B', edgecolor='black')\n",
    "bars2 = axes[0].bar(x + width/2, gpu_times, width, label='GPU (RAPIDS)',\n",
    "color='#4ECDC4', edgecolor='black')\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Performance Comparison', fontsize=14, weight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(ops)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "# Speedup chart\n",
    "speedups = [cpu_time/gpu_time, cpu_ml_time/gpu_ml_time]\n",
    "bars = axes[1].bar(ops, speedups, color='#45B7D1', edgecolor='black')\n",
    "axes[1].set_ylabel('Speedup (x)')\n",
    "axes[1].set_title('GPU Speedup Factor')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for bar, speedup in zip(bars, speedups):\n",
    "    height = bar.get_height()\n",
    "axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "f'{speedup:.2f}x', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('15_rapids_workflow.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Workflow comparison saved\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SUMMARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.591706Z",
     "iopub.status.busy": "2026-01-22T15:12:53.591586Z",
     "iopub.status.idle": "2026-01-22T15:12:53.593874Z",
     "shell.execute_reply": "2026-01-22T15:12:53.593608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. RAPIDS ecosystem (cuDF, cuML)\n",
      "2. GPU-accelerated data processing\n",
      "3. GPU-accelerated ML workflows\n",
      "4. End-to-end GPU pipeline\n",
      "\n",
      "Next Steps: Continue to Example 16 for Production Pipelines\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. RAPIDS ecosystem (cuDF, cuML)\")\n",
    "print(\"2. GPU-accelerated data processing\")\n",
    "print(\"3. GPU-accelerated ML workflows\")\n",
    "print(\"4. End-to-end GPU pipeline\")\n",
    "print(\"\\nNext Steps: Continue to Example 16 for Production Pipelines\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When RAPIDS Workflows Hit a Dead End | ÿπŸÜÿØŸÖÿß ÿ™Ÿàÿßÿ¨Ÿá ÿ≥Ÿäÿ± ÿπŸÖŸÑ RAPIDS ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "**BEFORE**: We've learned RAPIDS for GPU-accelerated data science workflows.\n",
    "\n",
    "**AFTER**: We discover we need to put these workflows into production!\n",
    "\n",
    "**Why this matters**: RAPIDS workflows work great, but production requires automation and scheduling!\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem We've Discovered\n",
    "\n",
    "We've learned:\n",
    "- ‚úÖ How to use RAPIDS for GPU-accelerated data science\n",
    "- ‚úÖ How to create complete workflows on GPU\n",
    "- ‚úÖ How to process data and train models on GPU\n",
    "\n",
    "**But we have a problem:**\n",
    "- ‚ùì **How do we automate these workflows?**\n",
    "- ‚ùì **How do we schedule them to run regularly?**\n",
    "- ‚ùì **How do we put this into production?**\n",
    "\n",
    "**The Dead End:**\n",
    "- RAPIDS workflows work great for development\n",
    "- But production requires automation, scheduling, and monitoring\n",
    "- We need production pipeline design and implementation\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstrating the Problem\n",
    "\n",
    "Let's see what's needed for production:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:12:53.595148Z",
     "iopub.status.busy": "2026-01-22T15:12:53.595043Z",
     "iopub.status.idle": "2026-01-22T15:12:53.598782Z",
     "shell.execute_reply": "2026-01-22T15:12:53.598457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö´ DEMONSTRATING THE DEAD END: Need for Production Pipelines\n",
      "======================================================================\n",
      "\n",
      "üìä Current Capabilities:\n",
      "   ‚úì RAPIDS workflows (GPU-accelerated)\n",
      "   ‚úì Data processing and ML on GPU\n",
      "   ‚úì Fast and efficient workflows\n",
      "\n",
      "‚ö†Ô∏è  Production Requirements:\n",
      "   ‚ùå No automation (manual execution)\n",
      "   ‚ùå No scheduling (can't run automatically)\n",
      "   ‚ùå No error handling (workflows can fail)\n",
      "   ‚ùå No monitoring (can't track performance)\n",
      "   ‚ùå No versioning (can't track changes)\n",
      "\n",
      "üí° The Problem:\n",
      "   - RAPIDS workflows work great for development\n",
      "   - But production needs:\n",
      "     ‚Ä¢ Automation: Run workflows automatically\n",
      "     ‚Ä¢ Scheduling: Run on schedule (daily, weekly)\n",
      "     ‚Ä¢ Error handling: Handle failures gracefully\n",
      "     ‚Ä¢ Monitoring: Track performance and issues\n",
      "     ‚Ä¢ Versioning: Track code and data versions\n",
      "\n",
      "üìã Real-World Production Needs:\n",
      "   1. Automated pipelines: Run without manual intervention\n",
      "   2. Scheduled execution: Daily/weekly data updates\n",
      "   3. Error recovery: Handle failures and retries\n",
      "   4. Monitoring: Track pipeline health and performance\n",
      "   5. Reproducibility: Version control for code and data\n",
      "\n",
      "‚û°Ô∏è  Solution Needed:\n",
      "   - We need production pipeline design\n",
      "   - We need automation and scheduling tools\n",
      "   - We need error handling and monitoring\n",
      "   - This leads us to Example 17: Production Pipelines\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö´ DEMONSTRATING THE DEAD END: Need for Production Pipelines\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Current Capabilities:\")\n",
    "print(f\"   ‚úì RAPIDS workflows (GPU-accelerated)\")\n",
    "print(f\"   ‚úì Data processing and ML on GPU\")\n",
    "print(f\"   ‚úì Fast and efficient workflows\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Production Requirements:\")\n",
    "print(f\"   ‚ùå No automation (manual execution)\")\n",
    "print(f\"   ‚ùå No scheduling (can't run automatically)\")\n",
    "print(f\"   ‚ùå No error handling (workflows can fail)\")\n",
    "print(f\"   ‚ùå No monitoring (can't track performance)\")\n",
    "print(f\"   ‚ùå No versioning (can't track changes)\")\n",
    "\n",
    "print(f\"\\nüí° The Problem:\")\n",
    "print(f\"   - RAPIDS workflows work great for development\")\n",
    "print(f\"   - But production needs:\")\n",
    "print(f\"     ‚Ä¢ Automation: Run workflows automatically\")\n",
    "print(f\"     ‚Ä¢ Scheduling: Run on schedule (daily, weekly)\")\n",
    "print(f\"     ‚Ä¢ Error handling: Handle failures gracefully\")\n",
    "print(f\"     ‚Ä¢ Monitoring: Track performance and issues\")\n",
    "print(f\"     ‚Ä¢ Versioning: Track code and data versions\")\n",
    "\n",
    "print(f\"\\nüìã Real-World Production Needs:\")\n",
    "print(f\"   1. Automated pipelines: Run without manual intervention\")\n",
    "print(f\"   2. Scheduled execution: Daily/weekly data updates\")\n",
    "print(f\"   3. Error recovery: Handle failures and retries\")\n",
    "print(f\"   4. Monitoring: Track pipeline health and performance\")\n",
    "print(f\"   5. Reproducibility: Version control for code and data\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Solution Needed:\")\n",
    "print(f\"   - We need production pipeline design\")\n",
    "print(f\"   - We need automation and scheduling tools\")\n",
    "print(f\"   - We need error handling and monitoring\")\n",
    "print(f\"   - This leads us to Example 17: Production Pipelines\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Need Next\n",
    "\n",
    "**The Solution**: We need production pipeline design:\n",
    "- **Automation**: Run workflows automatically without manual intervention\n",
    "- **Scheduling**: Run pipelines on schedule (daily, weekly, etc.)\n",
    "- **Error handling**: Handle failures gracefully with retries\n",
    "- **Monitoring**: Track pipeline health and performance\n",
    "- **Versioning**: Track code and data versions for reproducibility\n",
    "\n",
    "**This dead end leads us to Example 17: Production Pipelines**\n",
    "- Example 16 will teach us production pipeline design\n",
    "- We'll learn automation, scheduling, and monitoring\n",
    "- This solves the production deployment problem!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}