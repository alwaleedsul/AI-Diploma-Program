{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 5 - Example 16: Production Pipelines\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 05, Unit 5** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 5 - Example 16: Production Pipelines\n",
    "\n",
    "## üîó Solving the Problem from Example 15 | ÿ≠ŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÖŸÜ ÿßŸÑŸÖÿ´ÿßŸÑ 15\n",
    "\n",
    "**Remember the dead end from Example 15?**\n",
    "- We learned RAPIDS for GPU-accelerated workflows\n",
    "- But we needed to put these workflows into production\n",
    "- We needed automation, scheduling, and monitoring\n",
    "\n",
    "**This notebook solves that problem!**\n",
    "- We'll learn **production pipeline design**\n",
    "- We'll learn **automation and scheduling**\n",
    "- We'll learn **error handling and monitoring**\n",
    "\n",
    "**This solves the production deployment problem from Example 15!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.000293Z",
     "iopub.status.busy": "2026-01-15T20:08:32.000163Z",
     "iopub.status.idle": "2026-01-15T20:08:32.681655Z",
     "shell.execute_reply": "2026-01-15T20:08:32.681428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Example 16: Production Pipelines | ÿÆÿ∑Ÿàÿ∑ ÿßŸÑÿ•ŸÜÿ™ÿßÿ¨\n",
      "======================================================================\n",
      "\n",
      "üìö Prerequisites: Examples 14-15 completed, pipeline knowledge\n",
      "üîó This is the THIRD example in Unit 5 - production pipelines\n",
      "üéØ Goal: Master building production-ready ML pipelines\n",
      "Reference: Study 16.pdf before running this code example.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "# Note: Using just 'pipeline.log' since notebook runs from examples/ directory\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.FileHandler('pipeline.log'), logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 16: Production Pipelines | ÿÆÿ∑Ÿàÿ∑ ÿßŸÑÿ•ŸÜÿ™ÿßÿ¨\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìö Prerequisites: Examples 14-15 completed, pipeline knowledge\")\n",
    "print(\"üîó This is the THIRD example in Unit 5 - production pipelines\")\n",
    "print(\"üéØ Goal: Master building production-ready ML pipelines\")\n",
    "print(\"Reference: Study 16.pdf before running this code example.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CREATE SAMPLE DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.682694Z",
     "iopub.status.busy": "2026-01-15T20:08:32.682603Z",
     "iopub.status.idle": "2026-01-15T20:08:32.685599Z",
     "shell.execute_reply": "2026-01-15T20:08:32.685317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating Sample Data\n",
      "----------------------------------------------------------------------\n",
      "‚úì Created dataset with 1000 rows\n",
      "‚úì Missing values: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Creating Sample Data\")\n",
    "print(\"-\" * 70)\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "data = {\n",
    "'feature1': np.random.randn(n_samples), 'feature2': np.random.randn(n_samples),\n",
    "'feature3': np.random.randn(n_samples), 'target': np.random.randn(n_samples)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# Introduce some missing values\n",
    "missing_indices = np.random.choice(df.index, size=50, replace=False)\n",
    "df.loc[missing_indices[:25], 'feature1'] = np.nan\n",
    "df.loc[missing_indices[25:], 'feature2'] = np.nan\n",
    "print(f\"‚úì Created dataset with {len(df)} rows\")\n",
    "print(f\"‚úì Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.686422Z",
     "iopub.status.busy": "2026-01-15T20:08:32.686353Z",
     "iopub.status.idle": "2026-01-15T20:08:32.687662Z",
     "shell.execute_reply": "2026-01-15T20:08:32.687480Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. BUILD PRODUCTION PIPELINE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.688532Z",
     "iopub.status.busy": "2026-01-15T20:08:32.688478Z",
     "iopub.status.idle": "2026-01-15T20:08:32.697708Z",
     "shell.execute_reply": "2026-01-15T20:08:32.697537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 23:08:32,689 - INFO - Starting pipeline execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 23:08:32,693 - INFO - Train set: 800 samples, Test set: 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 23:08:32,694 - INFO - Training pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 23:08:32,696 - INFO - Pipeline trained successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 23:08:32,696 - INFO - MSE: 1.0702, R¬≤: -0.0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Building Production Pipeline\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚úì Pipeline executed successfully\n",
      "MSE: 1.0702, R¬≤ Score: -0.0327\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n2. Building Production Pipeline\")\n",
    "print(\"-\" * 70)\n",
    "try:\n",
    "    logger.info(\"Starting pipeline execution\")\n",
    "    # Prepare data\n",
    "    X = df[['feature1', 'feature2', 'feature3']]\n",
    "    y = df['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    logger.info(f\"Train set: {len(X_train)} samples, Test set: {len(X_test)} samples\")\n",
    "    # Handle missing values first (must be done before pipeline)\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    X_test = X_test.fillna(X_train.mean())\n",
    "    # Verify no NaN values remain\n",
    "    if X_train.isnull().sum().sum() > 0 or X_test.isnull().sum().sum() > 0:\n",
    "        logger.warning(\"Some NaN values remain after fillna, filling with 0\")\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_test = X_test.fillna(0)\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "('scaler', StandardScaler()), ('model', LinearRegression())\n",
    "    ])\n",
    "    # Train pipeline\n",
    "    logger.info(\"Training pipeline...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # Evaluate\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    logger.info(f\"Pipeline trained successfully\")\n",
    "    logger.info(f\"MSE: {mse:.4f}, R¬≤: {r2:.4f}\")\n",
    "    print(f\"\\n‚úì Pipeline executed successfully\")\n",
    "    print(f\"MSE: {mse:.4f}, R¬≤ Score: {r2:.4f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Pipeline execution failed: {str(e)}\", exc_info=True)\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.698488Z",
     "iopub.status.busy": "2026-01-15T20:08:32.698433Z",
     "iopub.status.idle": "2026-01-15T20:08:32.699671Z",
     "shell.execute_reply": "2026-01-15T20:08:32.699514Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. SAVE PIPELINE METADATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.700485Z",
     "iopub.status.busy": "2026-01-15T20:08:32.700421Z",
     "iopub.status.idle": "2026-01-15T20:08:32.702505Z",
     "shell.execute_reply": "2026-01-15T20:08:32.702321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Saving Pipeline Metadata\n",
      "----------------------------------------------------------------------\n",
      "‚úì Pipeline metadata saved\n",
      "‚úì     \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n3. Saving Pipeline Metadata\")\n",
    "print(\"-\" * 70)\n",
    "metadata = {\n",
    "'pipeline_version': '1.0', 'created_at': datetime.now().isoformat(), 'train_samples': len(X_train),\n",
    "'test_samples': len(X_test), 'metrics': {\n",
    "'mse': float(mse),\n",
    "'r2': float(r2)\n",
    "}, 'features': list(X.columns)\n",
    "}\n",
    "with open('pipeline_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"‚úì Pipeline metadata saved\")\n",
    "print(\"‚úì     \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.703296Z",
     "iopub.status.busy": "2026-01-15T20:08:32.703220Z",
     "iopub.status.idle": "2026-01-15T20:08:32.704746Z",
     "shell.execute_reply": "2026-01-15T20:08:32.704583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary\n",
      "======================================================================\n",
      "\n",
      "Key Concepts Covered:\n",
      "1. Pipeline design and structure\n",
      "2. Error handling and logging\n",
      "3. Metadata and versioning\n",
      "4. Production best practices\n",
      "\n",
      "Next Steps: Continue to Example 17 for Performance Optimization\n",
      " :    17  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey Concepts Covered:\")\n",
    "print(\"1. Pipeline design and structure\")\n",
    "print(\"2. Error handling and logging\")\n",
    "print(\"3. Metadata and versioning\")\n",
    "print(\"4. Production best practices\")\n",
    "print(\"\\nNext Steps: Continue to Example 17 for Performance Optimization\")\n",
    "print(\" :    17  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When Production Pipelines Hit a Dead End | ÿπŸÜÿØŸÖÿß ÿ™Ÿàÿßÿ¨Ÿá ÿÆÿ∑Ÿàÿ∑ ÿßŸÑÿ•ŸÜÿ™ÿßÿ¨ ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "**BEFORE**: We've learned to build production pipelines.\n",
    "\n",
    "**AFTER**: We discover pipelines work but are slow - we need optimization!\n",
    "\n",
    "**Why this matters**: Production pipelines must be fast and efficient - optimization is essential!\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem We've Discovered\n",
    "\n",
    "We've learned:\n",
    "- ‚úÖ How to build production pipelines\n",
    "- ‚úÖ How to handle errors and logging\n",
    "- ‚úÖ How to save metadata and versioning\n",
    "\n",
    "**But we have a problem:**\n",
    "- ‚ùì **What if the pipeline is too slow?**\n",
    "- ‚ùì **What if we need to optimize performance?**\n",
    "- ‚ùì **What if we need to reduce resource usage?**\n",
    "\n",
    "**The Dead End:**\n",
    "- Pipelines work correctly\n",
    "- But they may be slow or inefficient\n",
    "- We need performance optimization techniques\n",
    "\n",
    "---\n",
    "\n",
    "### Demonstrating the Problem\n",
    "\n",
    "Let's see why optimization is needed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T20:08:32.705521Z",
     "iopub.status.busy": "2026-01-15T20:08:32.705471Z",
     "iopub.status.idle": "2026-01-15T20:08:32.812386Z",
     "shell.execute_reply": "2026-01-15T20:08:32.812103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö´ DEMONSTRATING THE DEAD END: Need for Performance Optimization\n",
      "======================================================================\n",
      "\n",
      "üìä Current Pipeline Performance:\n",
      "   ‚úì Pipeline works correctly\n",
      "   ‚úì Error handling in place\n",
      "   ‚úì Logging and metadata saved\n",
      "\n",
      "‚ö†Ô∏è  Performance Issues:\n",
      "   - Pipeline execution time: May be slow for large datasets\n",
      "   - Resource usage: May consume too much memory/CPU\n",
      "   - Scalability: May not scale well with data size\n",
      "\n",
      "üí° The Problem:\n",
      "   - Pipelines work, but may be inefficient\n",
      "   - Need to optimize:\n",
      "     ‚Ä¢ Reduce execution time\n",
      "     ‚Ä¢ Reduce memory usage\n",
      "     ‚Ä¢ Improve scalability\n",
      "     ‚Ä¢ Optimize data processing steps\n",
      "\n",
      "üìã Optimization Needs:\n",
      "   1. Code optimization: Faster algorithms, vectorization\n",
      "   2. Memory optimization: Reduce memory footprint\n",
      "   3. Parallel processing: Use multiple cores/GPUs\n",
      "   4. Caching: Avoid redundant computations\n",
      "   5. Profiling: Identify bottlenecks\n",
      "\n",
      "‚û°Ô∏è  Solution Needed:\n",
      "   - We need performance optimization techniques\n",
      "   - We need profiling tools to find bottlenecks\n",
      "   - We need optimization strategies\n",
      "   - This leads us to Example 17: Performance Optimization\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö´ DEMONSTRATING THE DEAD END: Need for Performance Optimization\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import time\n",
    "\n",
    "print(f\"\\nüìä Current Pipeline Performance:\")\n",
    "print(f\"   ‚úì Pipeline works correctly\")\n",
    "print(f\"   ‚úì Error handling in place\")\n",
    "print(f\"   ‚úì Logging and metadata saved\")\n",
    "\n",
    "# Simulate slow pipeline\n",
    "print(f\"\\n‚ö†Ô∏è  Performance Issues:\")\n",
    "print(f\"   - Pipeline execution time: May be slow for large datasets\")\n",
    "print(f\"   - Resource usage: May consume too much memory/CPU\")\n",
    "print(f\"   - Scalability: May not scale well with data size\")\n",
    "\n",
    "# Time a simple operation to show potential slowness\n",
    "start_time = time.time()\n",
    "# Simulate some processing\n",
    "time.sleep(0.1)  # Simulate processing time\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüí° The Problem:\")\n",
    "print(f\"   - Pipelines work, but may be inefficient\")\n",
    "print(f\"   - Need to optimize:\")\n",
    "print(f\"     ‚Ä¢ Reduce execution time\")\n",
    "print(f\"     ‚Ä¢ Reduce memory usage\")\n",
    "print(f\"     ‚Ä¢ Improve scalability\")\n",
    "print(f\"     ‚Ä¢ Optimize data processing steps\")\n",
    "\n",
    "print(f\"\\nüìã Optimization Needs:\")\n",
    "print(f\"   1. Code optimization: Faster algorithms, vectorization\")\n",
    "print(f\"   2. Memory optimization: Reduce memory footprint\")\n",
    "print(f\"   3. Parallel processing: Use multiple cores/GPUs\")\n",
    "print(f\"   4. Caching: Avoid redundant computations\")\n",
    "print(f\"   5. Profiling: Identify bottlenecks\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Solution Needed:\")\n",
    "print(f\"   - We need performance optimization techniques\")\n",
    "print(f\"   - We need profiling tools to find bottlenecks\")\n",
    "print(f\"   - We need optimization strategies\")\n",
    "print(f\"   - This leads us to Example 17: Performance Optimization\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Need Next\n",
    "\n",
    "**The Solution**: We need performance optimization:\n",
    "- **Code optimization**: Faster algorithms, vectorization, efficient data structures\n",
    "- **Memory optimization**: Reduce memory footprint, efficient data types\n",
    "- **Parallel processing**: Use multiple cores/GPUs effectively\n",
    "- **Caching**: Avoid redundant computations\n",
    "- **Profiling**: Identify and fix bottlenecks\n",
    "\n",
    "**This dead end leads us to Example 17: Performance Optimization**\n",
    "- Example 17 will teach us optimization techniques\n",
    "- We'll learn profiling and bottleneck identification\n",
    "- This solves the performance problem for production pipelines!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}