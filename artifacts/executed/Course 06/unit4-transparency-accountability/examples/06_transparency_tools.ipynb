{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Transparency Tools | Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø´ÙØ§ÙÙŠØ©\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Transparency Tools | Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø´ÙØ§ÙÙŠØ©\n",
    "\n",
    "## ğŸš¨ THE PROBLEM: We Need Comprehensive Transparency Frameworks | Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù†Ø­ØªØ§Ø¬ Ø£Ø·Ø± Ø´ÙØ§ÙÙŠØ© Ø´Ø§Ù…Ù„Ø©\n",
    "\n",
    "**Remember the limitation from the previous notebook?**\n",
    "\n",
    "We learned human-in-the-loop approaches for incorporating human judgment. But we discovered:\n",
    "\n",
    "**How do we integrate all transparency tools into a comprehensive framework?**\n",
    "\n",
    "**The Problem**: Comprehensive transparency also needs:\n",
    "- âŒ **Integrated transparency tools** (combine all explanation methods)\n",
    "- âŒ **Transparency frameworks** (systematic approach to transparency)\n",
    "- âŒ **Tool comparison** (choose the right tool for each situation)\n",
    "- âŒ **Complete transparency solutions** (end-to-end transparency)\n",
    "\n",
    "**We've learned:**\n",
    "- âœ… How to use SHAP, LIME, and counterfactuals (Notebooks 1-3)\n",
    "- âœ… How to establish accountability (Notebook 4)\n",
    "- âœ… How to implement HITL (Notebook 5)\n",
    "- âœ… Individual transparency tools\n",
    "\n",
    "**But we haven't learned:**\n",
    "- âŒ How to **compare and integrate** different explanation methods\n",
    "- âŒ How to create **comprehensive transparency frameworks**\n",
    "- âŒ How to **choose the right tool** for each situation\n",
    "- âŒ How to **build complete transparency solutions**\n",
    "\n",
    "**We need transparency tools and frameworks** to:\n",
    "1. Compare and integrate different explanation methods\n",
    "2. Create comprehensive transparency frameworks\n",
    "3. Choose the right tool for each situation\n",
    "4. Build complete transparency solutions\n",
    "\n",
    "**This notebook solves that problem** by teaching you transparency tools and frameworks!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 1: SHAP Explanations** - Understanding SHAP\n",
    "- âœ… **Example 2: LIME Explanations** - Understanding LIME\n",
    "- âœ… **Example 3: Counterfactual Analysis** - Understanding counterfactuals\n",
    "- âœ… **Example 4: Accountability Frameworks** - Understanding accountability\n",
    "- âœ… **Example 5: HITL Approaches** - Understanding human oversight\n",
    "- âœ… **Basic Python knowledge**: Functions, data manipulation\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding how to compare transparency tools\n",
    "- Knowing which tool to use when\n",
    "- Understanding transparency frameworks\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is the SIXTH and FINAL example in Unit 4** - it teaches you comprehensive transparency!\n",
    "\n",
    "**Why this example LAST?**\n",
    "- **Before** you can integrate tools, you need to understand individual tools (Examples 1-3)\n",
    "- **Before** you can build frameworks, you need accountability and HITL (Examples 4-5)\n",
    "- **Before** you can deploy systems, you need comprehensive transparency\n",
    "\n",
    "**Builds on**: \n",
    "- ğŸ““ Example 1: SHAP Explanations (explainability)\n",
    "- ğŸ““ Example 2: LIME Explanations (local explanations)\n",
    "- ğŸ““ Example 3: Counterfactual Analysis (\"what if\" scenarios)\n",
    "- ğŸ““ Example 4: Accountability Frameworks (accountability)\n",
    "- ğŸ““ Example 5: HITL Approaches (human oversight)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Unit 5: Governance and Regulations (next unit in the course!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Transparency tools provide **comprehensive framework** (needed after learning all tools)\n",
    "2. Transparency tools teach **tool selection** (critical for practical application)\n",
    "3. Transparency tools show **complete solutions** (essential for deployment)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Complete Transparency | Ø§Ù„Ù‚ØµØ©: Ø§Ù„Ø´ÙØ§ÙÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©\n",
    "\n",
    "Imagine you're building an AI system. **Before** comprehensive transparency, you'd have individual tools but wouldn't know how to integrate them (fragmented!). **After** using transparency frameworks, you have a systematic approach - compare tools, choose the right one, integrate everything - complete transparency!\n",
    "\n",
    "Same with AI: **Before** we have individual transparency tools but no framework, now we learn transparency tools - compare methods, create frameworks, build complete solutions! **After** transparency tools, we have comprehensive transparent AI systems!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Transparency Tools Matter | Ù„Ù…Ø§Ø°Ø§ ØªÙ‡Ù… Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø´ÙØ§ÙÙŠØ©ØŸ\n",
    "\n",
    "Transparency tools are essential for ethical AI:\n",
    "- **Integration**: Combine all explanation methods into frameworks\n",
    "- **Selection**: Choose the right tool for each situation\n",
    "- **Completeness**: Build end-to-end transparency solutions\n",
    "- **Trust**: Build user confidence through comprehensive transparency\n",
    "- **Compliance**: Meet transparency requirements systematically\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Compare different transparency tools\n",
    "2. Understand when to use each tool\n",
    "3. Create transparency frameworks\n",
    "4. Integrate explanation methods\n",
    "5. Build comprehensive transparency solutions\n",
    "6. Evaluate transparency tool effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T16:23:43.507162Z",
     "iopub.status.busy": "2026-01-17T16:23:43.507090Z",
     "iopub.status.idle": "2026-01-17T16:23:44.464038Z",
     "shell.execute_reply": "2026-01-17T16:23:44.463767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 4 - Example 6: Transparency Tools\n",
      "================================================================================\n",
      "\n",
      "Transparency Tools Comparison:\n",
      "\n",
      "SHAP:\n",
      "  Interpretability: 9\n",
      "  Ease of Use: 8\n",
      "  Model Agnostic: True\n",
      "  Local Explanations: True\n",
      "\n",
      "LIME:\n",
      "  Interpretability: 8\n",
      "  Ease of Use: 9\n",
      "  Model Agnostic: True\n",
      "  Local Explanations: True\n",
      "\n",
      "Partial Dependence:\n",
      "  Interpretability: 7\n",
      "  Ease of Use: 7\n",
      "  Model Agnostic: False\n",
      "  Local Explanations: False\n",
      "\n",
      "Feature Importance:\n",
      "  Interpretability: 6\n",
      "  Ease of Use: 9\n",
      "  Model Agnostic: False\n",
      "  Local Explanations: False\n",
      "\n",
      "Counterfactuals:\n",
      "  Interpretability: 9\n",
      "  Ease of Use: 6\n",
      "  Model Agnostic: True\n",
      "  Local Explanations: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Saved: transparency_tools_comparison.png\n",
      "\n",
      "âœ… Example completed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4: Interpretability, Transparency, and Accountability\n",
    "Example 6: Transparency Tools\n",
    "This example demonstrates transparency tools and frameworks for AI systems.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "def compare_transparency_tools():\n",
    "    tools = {\n",
    "        'SHAP': {'interpretability': 9, 'ease_of_use': 8, 'model_agnostic': True, 'local_explanations': True},\n",
    "        'LIME': {'interpretability': 8, 'ease_of_use': 9, 'model_agnostic': True, 'local_explanations': True},\n",
    "        'Partial Dependence': {'interpretability': 7, 'ease_of_use': 7, 'model_agnostic': False, 'local_explanations': False},\n",
    "        'Feature Importance': {'interpretability': 6, 'ease_of_use': 9, 'model_agnostic': False, 'local_explanations': False},\n",
    "        'Counterfactuals': {'interpretability': 9, 'ease_of_use': 6, 'model_agnostic': True, 'local_explanations': True}\n",
    "    }\n",
    "    return tools\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 4 - Example 6: Transparency Tools\")\n",
    "    print(\"=\"*80)\n",
    "    tools = compare_transparency_tools()\n",
    "    print(\"\\nTransparency Tools Comparison:\")\n",
    "    for tool, metrics in tools.items():\n",
    "        print(f\"\\n{tool}:\")\n",
    "        print(f\"  Interpretability: {metrics['interpretability']}\")\n",
    "        print(f\"  Ease of Use: {metrics['ease_of_use']}\")\n",
    "        print(f\"  Model Agnostic: {metrics['model_agnostic']}\")\n",
    "        print(f\"  Local Explanations: {metrics['local_explanations']}\")\n",
    "    tools_list = list(tools.keys())\n",
    "    interpretability = [tools[t]['interpretability'] for t in tools_list]\n",
    "    ease_of_use = [tools[t]['ease_of_use'] for t in tools_list]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    axes[0].bar(tools_list, interpretability, color='#3498db')\n",
    "    axes[0].set_title('Interpretability Score', fontweight='bold')\n",
    "    axes[0].set_ylabel('Score (1-10)')\n",
    "    axes[0].tick_params(axis='x', rotation=15)\n",
    "    axes[1].bar(tools_list, ease_of_use, color='#2ecc71')\n",
    "    axes[1].set_title('Ease of Use Score', fontweight='bold')\n",
    "    axes[1].set_ylabel('Score (1-10)')\n",
    "    axes[1].tick_params(axis='x', rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nâœ… Saved: transparency_tools_comparison.png\")\n",
    "    plt.close()\n",
    "    print(\"\\nâœ… Example completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â¡ï¸ Transition to Unit 5: Governance and Regulations | Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ­Ø¯Ø© 5: Ø§Ù„Ø­ÙˆÙƒÙ…Ø© ÙˆØ§Ù„Ù„ÙˆØ§Ø¦Ø­\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "We've completed Unit 4: Transparency and Accountability! We've learned:\n",
    "- âœ… How to explain AI decisions (SHAP, LIME, counterfactuals)\n",
    "- âœ… How to establish accountability frameworks\n",
    "- âœ… How to implement human-in-the-loop approaches\n",
    "- âœ… How to build comprehensive transparency solutions\n",
    "\n",
    "### The Next Challenge: Governance and Regulations\n",
    "\n",
    "**Transparency and accountability are important, but they're not the only ethical concerns!**\n",
    "\n",
    "As we build AI systems, we also need to consider:\n",
    "- **Governance**: How do we govern AI development and deployment?\n",
    "- **Regulations**: What laws and regulations apply to AI?\n",
    "- **Compliance**: How do we comply with AI regulations?\n",
    "- **Legal Challenges**: What legal issues arise with AI?\n",
    "\n",
    "**The Problem**: We've learned about transparency and accountability, but **AI systems also raise governance and regulatory concerns**:\n",
    "- AI systems must comply with laws and regulations\n",
    "- AI systems need governance frameworks\n",
    "- AI systems face legal challenges\n",
    "- AI systems require regulatory compliance\n",
    "\n",
    "**This is exactly what we'll learn in Unit 5: Governance and Regulations!**\n",
    "\n",
    "---\n",
    "\n",
    "## â¡ï¸ Next Steps | Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©\n",
    "\n",
    "**You've completed Unit 4!** Now you understand:\n",
    "- âœ… How to explain AI decisions\n",
    "- âœ… How to ensure accountability\n",
    "- âœ… How to build transparent AI systems\n",
    "\n",
    "**Next Unit**: `unit5-governance-regulations/`\n",
    "- Learn about global AI regulations\n",
    "- Understand industry-specific regulations\n",
    "- Master governance frameworks\n",
    "- Navigate legal challenges in AI\n",
    "\n",
    "**Congratulations!** ğŸ‰ You've completed Unit 4 and learned how to build transparent and accountable AI systems!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
