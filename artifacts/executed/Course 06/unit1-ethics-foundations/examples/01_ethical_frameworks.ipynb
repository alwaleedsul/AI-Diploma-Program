{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Ethical Frameworks for AI | ÿßŸÑÿ£ÿ∑ÿ± ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ© ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Basic Python\n",
    "- ‚úÖ Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 06, Unit 1** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Ethical Frameworks for AI | ÿßŸÑÿ£ÿ∑ÿ± ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ© ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä\n",
    "\n",
    "## üö® THE PROBLEM: How Do We Make Ethical Decisions About AI? | ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©: ŸÉŸäŸÅ ŸÜÿ™ÿÆÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ÿ£ÿÆŸÑÿßŸÇŸäÿ© ÿ≠ŸàŸÑ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸäÿü\n",
    "\n",
    "**Imagine this scenario:**\n",
    "\n",
    "An autonomous vehicle is driving down a road when suddenly, a group of pedestrians steps into the street. The AI must make a split-second decision:\n",
    "- **Option A**: Swerve and hit a wall, potentially killing the passenger\n",
    "- **Option B**: Continue forward, potentially killing the pedestrians\n",
    "- **Option C**: Try to minimize harm, but risk both\n",
    "\n",
    "**The Problem**: Without a structured way to think about ethics, this decision becomes arbitrary. Different people would make different choices based on:\n",
    "- Gut feelings\n",
    "- Personal values\n",
    "- Cultural background\n",
    "- Emotional state\n",
    "\n",
    "**We need a systematic approach** to evaluate ethical decisions in AI systems!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites (What You Need First) | ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have:\n",
    "- ‚úÖ **Python 3.8+** installed\n",
    "- ‚úÖ **Basic Python knowledge**: Variables, dictionaries, lists, functions\n",
    "- ‚úÖ **Interest in ethics**: Understanding that AI decisions have ethical implications\n",
    "- ‚úÖ **Libraries installed**: matplotlib, numpy, pandas (see `DOCS/INSTALLATION_GUIDE.md`)\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding how to structure ethical analysis\n",
    "- Comparing different ethical perspectives\n",
    "- Applying frameworks to real AI scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Where This Notebook Fits | ŸÖŸÉÿßŸÜ Ÿáÿ∞ÿß ÿßŸÑÿØŸÅÿ™ÿ±\n",
    "\n",
    "**This is the FIRST example** - it's the foundation for all ethical analysis!\n",
    "\n",
    "**Why this notebook FIRST?**\n",
    "- You need to understand ethical frameworks BEFORE analyzing specific AI ethics issues\n",
    "- All other ethics notebooks use these frameworks\n",
    "- Understanding frameworks now = better ethical reasoning later\n",
    "\n",
    "**Builds on**: \n",
    "- Python basics (from prerequisites)\n",
    "- General understanding of ethics\n",
    "\n",
    "**Leads to**: \n",
    "- üìì Example 2: Ethical Decision-Making (uses these frameworks!)\n",
    "- üìì Example 3: Case Study Analysis (applies frameworks to real cases!)\n",
    "- üìì Unit 2: Bias and Justice (uses ethical frameworks to evaluate fairness!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Frameworks provide **vocabulary** for ethical analysis (needed for all units)\n",
    "2. Frameworks teach **different perspectives** (needed for comprehensive analysis)\n",
    "3. Frameworks show **how to think ethically** (needed for decision-making)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Different Lenses for Ethical Decisions | ÿßŸÑŸÇÿµÿ©: ÿπÿØÿ≥ÿßÿ™ ŸÖÿÆÿ™ŸÑŸÅÿ© ŸÑŸÑŸÇÿ±ÿßÿ±ÿßÿ™ ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ©\n",
    "\n",
    "Imagine you're a judge deciding a case. **Before** learning ethical frameworks, you might make decisions based on gut feeling or personal opinion. **After** learning frameworks, you can analyze decisions through multiple ethical lenses: \"What maximizes happiness?\" (Utilitarianism), \"What follows moral rules?\" (Deontology), \"What shows good character?\" (Virtue Ethics). Each framework gives you a different perspective!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Ethical Frameworks for AI? | ŸÑŸÖÿßÿ∞ÿß ÿßŸÑÿ£ÿ∑ÿ± ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ© ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸäÿü\n",
    "\n",
    "AI systems make decisions that affect people's lives. Ethical frameworks help us:\n",
    "- **Evaluate AI decisions** systematically\n",
    "- **Compare different perspectives** on what's right\n",
    "- **Make better choices** when designing AI systems\n",
    "- **Justify decisions** to stakeholders\n",
    "\n",
    "## Learning Objectives | ÿ£ŸáÿØÿßŸÅ ÿßŸÑÿ™ÿπŸÑŸÖ\n",
    "1. Understand five major ethical frameworks\n",
    "2. Compare frameworks' strengths and weaknesses\n",
    "3. Apply frameworks to AI scenarios\n",
    "4. See how different frameworks lead to different conclusions\n",
    "5. Understand when to use each framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Scene | ÿßŸÑÿ¨ÿ≤ÿ° ÿßŸÑÿ£ŸàŸÑ: ÿ•ÿπÿØÿßÿØ ÿßŸÑŸÖÿ¥ŸáÿØ\n",
    "\n",
    "**Before**: We have AI systems making decisions, but we don't have a systematic way to evaluate whether those decisions are ethical.\n",
    "\n",
    "**After**: We'll learn five ethical frameworks and see how each one evaluates AI decisions differently!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:13:11.246440Z",
     "iopub.status.busy": "2026-01-22T15:13:11.246332Z",
     "iopub.status.idle": "2026-01-22T15:13:11.665665Z",
     "shell.execute_reply": "2026-01-22T15:13:11.665343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully!\n",
      "\n",
      "üìö What each library does:\n",
      "   - os: File operations (saving images)\n",
      "   - matplotlib: Create visualizations (charts, graphs)\n",
      "   - numpy: Numerical operations (arrays, calculations)\n",
      "   - pandas: Data manipulation (optional, for advanced analysis)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us with data manipulation and visualization\n",
    "import os  # For file operations: Working with file paths and saving images\n",
    "import matplotlib.pyplot as plt  # For creating visualizations: Charts, graphs, plots\n",
    "import numpy as np  # For numerical operations: Arrays, mathematical calculations\n",
    "import pandas as pd  # For data manipulation: DataFrames, data analysis (optional but useful)\n",
    "\n",
    "# Configure matplotlib settings: Set default figure size and font size for better visualizations\n",
    "plt.rcParams['font.size'] = 10  # Font size: Make text readable (10pt is good for most displays)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)  # Figure size: 12 inches wide, 8 inches tall (good for detailed charts)\n",
    "\n",
    "print(\" Libraries imported successfully!\")\n",
    "print(\"\\nüìö What each library does:\")\n",
    "print(\"   - os: File operations (saving images)\")\n",
    "print(\"   - matplotlib: Create visualizations (charts, graphs)\")\n",
    "print(\"   - numpy: Numerical operations (arrays, calculations)\")\n",
    "print(\"   - pandas: Data manipulation (optional, for advanced analysis)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:13:11.684108Z",
     "iopub.status.busy": "2026-01-22T15:13:11.683919Z",
     "iopub.status.idle": "2026-01-22T15:13:11.689030Z",
     "shell.execute_reply": "2026-01-22T15:13:11.688717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìñ DEFINING ETHICAL FRAMEWORKS\n",
      "================================================================================\n",
      "\n",
      "Each framework answers: 'How do we decide what's ethically right?'\n",
      "Different frameworks = Different answers = Different perspectives on AI ethics\n",
      "\n",
      " Defined 5 ethical frameworks:\n",
      "   - Utilitarianism (ÿßŸÑŸÜŸÅÿπŸäÿ©): Maximize overall happiness\n",
      "   - Deontology (ÿßŸÑŸàÿßÿ¨ÿ®Ÿäÿ©): Follow moral rules and duties\n",
      "   - Virtue Ethics (ÿ£ÿÆŸÑÿßŸÇ ÿßŸÑŸÅÿ∂ŸäŸÑÿ©): Develop good character and virtues\n",
      "   - Rights-Based Ethics (ÿ£ÿÆŸÑÿßŸÇŸäÿßÿ™ ÿßŸÑÿ≠ŸÇŸàŸÇ): Protect individual rights\n",
      "   - Care Ethics (ÿ£ÿÆŸÑÿßŸÇŸäÿßÿ™ ÿßŸÑÿ±ÿπÿßŸäÿ©): Emphasize relationships and care\n",
      "\n",
      "üí° Each framework offers a different perspective on what's ethically right!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define our ethical frameworks\n",
    "# Think of this as a dictionary of ethical \"lenses\" - each framework is a different way to view ethical decisions\n",
    "\n",
    "# BEFORE: We don't have a structured way to think about ethics\n",
    "# AFTER: We'll have five frameworks, each with strengths, weaknesses, and applications\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìñ DEFINING ETHICAL FRAMEWORKS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEach framework answers: 'How do we decide what's ethically right?'\")\n",
    "print(\"Different frameworks = Different answers = Different perspectives on AI ethics\\n\")\n",
    "\n",
    "frameworks = {\n",
    "    'Utilitarianism': {\n",
    "        'name_en': 'Utilitarianism',  # Framework name: English name for this ethical theory\n",
    "        'name_ar': 'ÿßŸÑŸÜŸÅÿπŸäÿ©',  # Framework name: Arabic translation\n",
    "        'focus': 'Maximize overall happiness',  # Core principle: What this framework cares about most\n",
    "        'focus_ar': 'ÿ™ÿπÿ∏ŸäŸÖ ÿßŸÑÿ≥ÿπÿßÿØÿ© ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸäÿ©',  # Core principle: Arabic translation\n",
    "        'ai_application': 'AI that benefits the greatest number of people',  # How it applies to AI: What this framework would recommend for AI\n",
    "        'ai_application_ar': 'ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿßŸÑÿ∞Ÿä ŸäŸÅŸäÿØ ÿ£ŸÉÿ®ÿ± ÿπÿØÿØ ŸÖŸÜ ÿßŸÑŸÜÿßÿ≥',  # AI application: Arabic translation\n",
    "        'strength': 8,  # Strengths score: How well this framework works (1-10, higher = better)\n",
    "        'weakness': 6,  # Weaknesses score: How problematic this framework is (1-10, lower = better)\n",
    "        'practicality': 7  # Practicality score: How easy it is to apply in practice (1-10, higher = easier)\n",
    "    },\n",
    "    'Deontology': {\n",
    "        'name_en': 'Deontology',  # Framework name: Duty-based ethics\n",
    "        'name_ar': 'ÿßŸÑŸàÿßÿ¨ÿ®Ÿäÿ©',  # Arabic name\n",
    "        'focus': 'Follow moral rules and duties',  # Core principle: Rules matter more than outcomes\n",
    "        'focus_ar': 'ÿßÿ™ÿ®ÿßÿπ ÿßŸÑŸÇŸàÿßÿπÿØ ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ© ŸàÿßŸÑŸàÿßÿ¨ÿ®ÿßÿ™',  # Arabic translation\n",
    "        'ai_application': 'AI that follows ethical principles regardless of outcomes',  # AI application: Rules-based AI\n",
    "        'ai_application_ar': 'ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿßŸÑÿ∞Ÿä Ÿäÿ™ÿ®ÿπ ÿßŸÑŸÖÿ®ÿßÿØÿ¶ ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ© ÿ®ÿ∫ÿ∂ ÿßŸÑŸÜÿ∏ÿ± ÿπŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨',  # Arabic\n",
    "        'strength': 7,  # Strengths: Good at protecting principles\n",
    "        'weakness': 5,  # Weaknesses: Can be rigid\n",
    "        'practicality': 6  # Practicality: Moderate - rules can be complex\n",
    "    },\n",
    "    'Virtue Ethics': {\n",
    "        'name_en': 'Virtue Ethics',  # Framework name: Character-based ethics\n",
    "        'name_ar': 'ÿ£ÿÆŸÑÿßŸÇ ÿßŸÑŸÅÿ∂ŸäŸÑÿ©',  # Arabic name\n",
    "        'focus': 'Develop good character and virtues',  # Core principle: Good character leads to good actions\n",
    "        'focus_ar': 'ÿ™ÿ∑ŸàŸäÿ± ÿßŸÑÿ¥ÿÆÿµŸäÿ© ÿßŸÑÿ¨ŸäÿØÿ© ŸàÿßŸÑŸÅÿ∂ÿßÿ¶ŸÑ',  # Arabic translation\n",
    "        'ai_application': 'AI that reflects good character traits (honesty, fairness)',  # AI application: Virtuous AI\n",
    "        'ai_application_ar': 'ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿßŸÑÿ∞Ÿä ŸäÿπŸÉÿ≥ ÿµŸÅÿßÿ™ ÿßŸÑÿ¥ÿÆÿµŸäÿ© ÿßŸÑÿ¨ŸäÿØÿ© (ÿßŸÑÿµÿØŸÇÿå ÿßŸÑÿπÿØÿßŸÑÿ©)',  # Arabic\n",
    "        'strength': 6,  # Strengths: Focuses on character\n",
    "        'weakness': 7,  # Weaknesses: Hard to define virtues clearly\n",
    "        'practicality': 5  # Practicality: Lower - virtues are abstract\n",
    "    },\n",
    "    'Rights-Based': {\n",
    "        'name_en': 'Rights-Based Ethics',  # Framework name: Rights-focused ethics\n",
    "        'name_ar': 'ÿ£ÿÆŸÑÿßŸÇŸäÿßÿ™ ÿßŸÑÿ≠ŸÇŸàŸÇ',  # Arabic name\n",
    "        'focus': 'Protect individual rights',  # Core principle: Individual rights are paramount\n",
    "        'focus_ar': 'ÿ≠ŸÖÿßŸäÿ© ÿßŸÑÿ≠ŸÇŸàŸÇ ÿßŸÑŸÅÿ±ÿØŸäÿ©',  # Arabic translation\n",
    "        'ai_application': 'AI that respects human rights (privacy, autonomy)',  # AI application: Rights-respecting AI\n",
    "        'ai_application_ar': 'ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿßŸÑÿ∞Ÿä Ÿäÿ≠ÿ™ÿ±ŸÖ ÿ≠ŸÇŸàŸÇ ÿßŸÑÿ•ŸÜÿ≥ÿßŸÜ (ÿßŸÑÿÆÿµŸàÿµŸäÿ©ÿå ÿßŸÑÿßÿ≥ÿ™ŸÇŸÑÿßŸÑŸäÿ©)',  # Arabic\n",
    "        'strength': 9,  # Strengths: Very strong at protecting individuals\n",
    "        'weakness': 4,  # Weaknesses: Can conflict with collective good\n",
    "        'practicality': 8  # Practicality: High - rights are well-defined\n",
    "    },\n",
    "    'Care Ethics': {\n",
    "        'name_en': 'Care Ethics',  # Framework name: Relationship-focused ethics\n",
    "        'name_ar': 'ÿ£ÿÆŸÑÿßŸÇŸäÿßÿ™ ÿßŸÑÿ±ÿπÿßŸäÿ©',  # Arabic name\n",
    "        'focus': 'Emphasize relationships and care',  # Core principle: Relationships and care matter\n",
    "        'focus_ar': 'ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ÿπŸÑŸâ ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ŸàÿßŸÑÿ±ÿπÿßŸäÿ©',  # Arabic translation\n",
    "        'ai_application': 'AI that considers relationships and emotional well-being',  # AI application: Caring AI\n",
    "        'ai_application_ar': 'ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿßŸÑÿ∞Ÿä Ÿäÿ£ÿÆÿ∞ ŸÅŸä ÿßŸÑÿßÿπÿ™ÿ®ÿßÿ± ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ŸàÿßŸÑÿ±ŸÅÿßŸáŸäÿ© ÿßŸÑÿπÿßÿ∑ŸÅŸäÿ©',  # Arabic\n",
    "        'strength': 7,  # Strengths: Good at considering relationships\n",
    "        'weakness': 6,  # Weaknesses: Can be subjective\n",
    "        'practicality': 6  # Practicality: Moderate - relationships are complex\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\" Defined 5 ethical frameworks:\")\n",
    "for key, framework in frameworks.items():\n",
    "    print(f\"   - {framework['name_en']} ({framework['name_ar']}): {framework['focus']}\")\n",
    "print(\"\\nüí° Each framework offers a different perspective on what's ethically right!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:13:11.690485Z",
     "iopub.status.busy": "2026-01-22T15:13:11.690366Z",
     "iopub.status.idle": "2026-01-22T15:13:12.054242Z",
     "shell.execute_reply": "2026-01-22T15:13:12.053952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä CREATING FRAMEWORK COMPARISON VISUALIZATION\n",
      "================================================================================\n",
      "\n",
      "This visualization shows:\n",
      "  - Strengths: How well each framework works\n",
      "  - Weaknesses: How problematic each framework is\n",
      "  - Practicality: How easy each framework is to apply\n",
      "\n",
      "Creating comparison chart...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: ethical_frameworks_comparison.png\n",
      " Framework comparison visualization complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create framework comparison visualization\n",
    "# This shows us how frameworks compare in strengths, weaknesses, and practicality\n",
    "\n",
    "# BEFORE: We have framework data but no visual comparison\n",
    "# AFTER: We'll have a clear bar chart showing how frameworks compare\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä CREATING FRAMEWORK COMPARISON VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis visualization shows:\")\n",
    "print(\"  - Strengths: How well each framework works\")\n",
    "print(\"  - Weaknesses: How problematic each framework is\")\n",
    "print(\"  - Practicality: How easy each framework is to apply\\n\")\n",
    "\n",
    "def create_framework_comparison():\n",
    "    \"\"\"\n",
    "    Create a bar chart comparing ethical frameworks.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    1. Extract framework names and scores from the frameworks dictionary\n",
    "    2. Create grouped bar chart with three series (strengths, weaknesses, practicality)\n",
    "    3. Add labels, colors, and formatting for clarity\n",
    "    4. Save the visualization as an image\n",
    "    \n",
    "    ‚è∞ WHEN to use: After defining frameworks - see how they compare visually\n",
    "    üí° WHY use: Visual comparison makes it easy to identify which frameworks are strongest\n",
    "    \"\"\"\n",
    "    # Extract data: Get framework information from dictionary\n",
    "    framework_names = [f['name_en'] for f in frameworks.values()]  # Get names: Extract English names for x-axis labels\n",
    "    strengths = [f['strength'] for f in frameworks.values()]  # Get strengths: Extract strength scores for comparison\n",
    "    weaknesses = [f['weakness'] for f in frameworks.values()]  # Get weaknesses: Extract weakness scores for comparison\n",
    "    practicality = [f['practicality'] for f in frameworks.values()]  # Get practicality: Extract practicality scores for comparison\n",
    "    \n",
    "    # Set up chart: Prepare for creating grouped bar chart\n",
    "    x = np.arange(len(framework_names))  # X positions: Create array of positions for each framework (0, 1, 2, 3, 4)\n",
    "    width = 0.25  # Bar width: Set width of each bar (0.25 = 25% of spacing, leaves room for 3 bars per group)\n",
    "    \n",
    "    # Create figure: Initialize the plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))  # Create plot: 14 inches wide, 8 inches tall (good size for detailed chart)\n",
    "    \n",
    "    # Create bars: Draw three sets of bars for each framework\n",
    "    bars1 = ax.bar(x - width, strengths, width, label='Strengths', \n",
    "                   color='#2ecc71', alpha=0.8)  # Strengths bars: Green bars, offset left, show framework strengths\n",
    "    bars2 = ax.bar(x, weaknesses, width, label='Weaknesses', \n",
    "                   color='#e74c3c', alpha=0.8)  # Weaknesses bars: Red bars, centered, show framework weaknesses\n",
    "    bars3 = ax.bar(x + width, practicality, width, label='Practicality', \n",
    "                   color='#3498db', alpha=0.8)  # Practicality bars: Blue bars, offset right, show framework practicality\n",
    "    \n",
    "    # Add labels: Make chart readable\n",
    "    ax.set_xlabel('Ethical Framework', fontsize=12, fontweight='bold')  # X-axis label: Describe what x-axis shows\n",
    "    ax.set_ylabel('Score (1-10)', fontsize=12, fontweight='bold')  # Y-axis label: Describe what y-axis shows (score scale)\n",
    "    ax.set_title('Ethical Frameworks Comparison', fontsize=14, fontweight='bold', pad=20)  # Title: Main heading for the chart\n",
    "    \n",
    "    # Configure x-axis: Set framework names as labels\n",
    "    ax.set_xticks(x)  # Set tick positions: Place ticks at each framework position\n",
    "    ax.set_xticklabels(framework_names, rotation=15, ha='right')  # Set tick labels: Use framework names, rotate for readability\n",
    "    \n",
    "    # Add legend: Explain what each color means\n",
    "    ax.legend(fontsize=10)  # Show legend: Display color-coded legend (green=strengths, red=weaknesses, blue=practicality)\n",
    "    \n",
    "    # Set y-axis limits: Ensure consistent scale\n",
    "    ax.set_ylim(0, 10)  # Y-axis range: Set scale from 0 to 10 (matches our scoring system)\n",
    "    \n",
    "    # Add grid: Make values easier to read\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')  # Y-axis grid: Light gray dashed lines help read values\n",
    "    \n",
    "    # Add value labels: Show exact scores on bars\n",
    "    for bars in [bars1, bars2, bars3]:  # Loop through bar groups: Process each set of bars\n",
    "        for bar in bars:  # Loop through individual bars: Process each bar in the group\n",
    "            height = bar.get_height()  # Get bar height: Extract the value this bar represents\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,  # Position text: Center text on top of bar\n",
    "                   f'{int(height)}',  # Text content: Show the score as integer\n",
    "                   ha='center', va='bottom', fontsize=9)  # Text alignment: Center horizontally, place above bar\n",
    "    \n",
    "    # Save visualization: Export as image file\n",
    "    plt.tight_layout()  # Adjust layout: Prevent label cutoff\n",
    "    output_path = 'ethical_frameworks_comparison.png'  # File path: Save in same directory as notebook\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')  # Save image: High resolution (300 dpi), tight bounding box\n",
    "    print(\" Saved: ethical_frameworks_comparison.png\")  # Success message: Confirm file was saved\n",
    "    plt.close()  # Close figure: Free up memory\n",
    "\n",
    "# Run the visualization\n",
    "print(\"Creating comparison chart...\")\n",
    "create_framework_comparison()\n",
    "print(\" Framework comparison visualization complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Applying Frameworks to the Autonomous Vehicle Problem | ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ£ÿ∑ÿ± ÿπŸÑŸâ ŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑŸÖÿ±ŸÉÿ®ÿ© ÿßŸÑŸÖÿ≥ÿ™ŸÇŸÑÿ©\n",
    "\n",
    "Now let's apply our frameworks to the **exact problem** we started with - the autonomous vehicle dilemma!\n",
    "\n",
    "**The Scenario**: An autonomous vehicle must choose between:\n",
    "- **Option A**: Swerve and hit a wall, potentially killing the passenger\n",
    "- **Option B**: Continue forward, potentially killing the pedestrians\n",
    "- **Option C**: Try to minimize harm, but risk both\n",
    "\n",
    "Let's see how each framework evaluates this problem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T15:13:12.055781Z",
     "iopub.status.busy": "2026-01-22T15:13:12.055656Z",
     "iopub.status.idle": "2026-01-22T15:13:12.060830Z",
     "shell.execute_reply": "2026-01-22T15:13:12.060560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöó APPLYING FRAMEWORKS TO AUTONOMOUS VEHICLE PROBLEM\n",
      "================================================================================\n",
      "\n",
      "Scenario: Autonomous vehicle must choose between:\n",
      "  Option A: Swerve and hit wall (kill passenger)\n",
      "  Option B: Continue forward (kill pedestrians)\n",
      "  Option C: Try to minimize harm (risk both)\n",
      "\n",
      "Analyzing autonomous vehicle problem with frameworks...\n",
      "Framework Evaluations:\n",
      "\n",
      "Utilitarianism:\n",
      "------------------------------------------------------------\n",
      "  Option A: Kill 1 passenger - minimize total harm\n",
      "  Option B: Kill multiple pedestrians - maximize harm\n",
      "  Option C: Uncertain outcome - hard to calculate\n",
      "  Recommendation: Option A (minimize total deaths)\n",
      "  Reasoning: Maximize overall good by minimizing total deaths\n",
      "\n",
      "Deontology:\n",
      "------------------------------------------------------------\n",
      "  Option A: Violates duty to protect passenger\n",
      "  Option B: Violates duty to protect pedestrians\n",
      "  Option C: Uncertain - violates clear duties\n",
      "  Recommendation: No clear answer - all violate duties\n",
      "  Reasoning: Moral rules conflict - no perfect solution\n",
      "\n",
      "Rights-Based:\n",
      "------------------------------------------------------------\n",
      "  Option A: Violates passenger right to life\n",
      "  Option B: Violates pedestrian rights to life\n",
      "  Option C: Uncertain - may violate all rights\n",
      "  Recommendation: No clear answer - all violate rights\n",
      "  Reasoning: All options violate someone's right to life\n",
      "\n",
      "Virtue Ethics:\n",
      "------------------------------------------------------------\n",
      "  Option A: Shows courage but not justice\n",
      "  Option B: Shows no virtue - reckless\n",
      "  Option C: Shows prudence - trying to minimize harm\n",
      "  Recommendation: Option C (most virtuous)\n",
      "  Reasoning: Shows prudence and care for all lives\n",
      "\n",
      "Care Ethics:\n",
      "------------------------------------------------------------\n",
      "  Option A: Abandons passenger relationship\n",
      "  Option B: Abandons pedestrian relationships\n",
      "  Option C: Tries to care for all relationships\n",
      "  Recommendation: Option C (cares for all)\n",
      "  Reasoning: Considers relationships with all affected parties\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è THE LIMITATION: Frameworks Give Different Answers!\n",
      "================================================================================\n",
      "\n",
      "Notice that:\n",
      "  - Utilitarianism recommends Option A\n",
      "  - Virtue Ethics recommends Option C\n",
      "  - Deontology and Rights-Based find no clear answer\n",
      "  - Care Ethics recommends Option C\n",
      "\n",
      "üö´ This is a DEAD END: We have frameworks, but they conflict!\n",
      "   We need a way to resolve these conflicts...\n",
      "   ‚Üí This leads us to the next notebook: Ethical Decision-Making!\n",
      "\n",
      "‚úÖ Framework analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Apply frameworks to the autonomous vehicle problem\n",
    "# This demonstrates how different frameworks give different answers to the same problem\n",
    "\n",
    "# BEFORE: We have frameworks but haven't seen them applied to our original problem\n",
    "# AFTER: We'll see how each framework evaluates the autonomous vehicle dilemma\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöó APPLYING FRAMEWORKS TO AUTONOMOUS VEHICLE PROBLEM\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nScenario: Autonomous vehicle must choose between:\")\n",
    "print(\"  Option A: Swerve and hit wall (kill passenger)\")\n",
    "print(\"  Option B: Continue forward (kill pedestrians)\")\n",
    "print(\"  Option C: Try to minimize harm (risk both)\\n\")\n",
    "\n",
    "def analyze_autonomous_vehicle_problem():\n",
    "    \"\"\"\n",
    "    Analyze the autonomous vehicle problem using different ethical frameworks.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    1. Define how each framework evaluates the three options\n",
    "    2. Show that different frameworks lead to different recommendations\n",
    "    3. Demonstrate the limitation: frameworks conflict!\n",
    "    \n",
    "    ‚è∞ WHEN to use: After learning frameworks - see them applied to real problem\n",
    "    üí° WHY use: Shows that frameworks give different answers - creates need for decision-making process\n",
    "    \"\"\"\n",
    "    # Define framework evaluations: How each framework evaluates the problem\n",
    "    # Why a dictionary? Each framework has its own evaluation, easy to compare\n",
    "    framework_evaluations = {\n",
    "        'Utilitarianism': {  # Framework 1: Utilitarian perspective\n",
    "            'option_a': 'Kill 1 passenger - minimize total harm',\n",
    "            'option_b': 'Kill multiple pedestrians - maximize harm',\n",
    "            'option_c': 'Uncertain outcome - hard to calculate',\n",
    "            'recommendation': 'Option A (minimize total deaths)',\n",
    "            'reasoning': 'Maximize overall good by minimizing total deaths'\n",
    "        },\n",
    "        'Deontology': {  # Framework 2: Deontological perspective\n",
    "            'option_a': 'Violates duty to protect passenger',\n",
    "            'option_b': 'Violates duty to protect pedestrians',\n",
    "            'option_c': 'Uncertain - violates clear duties',\n",
    "            'recommendation': 'No clear answer - all violate duties',\n",
    "            'reasoning': 'Moral rules conflict - no perfect solution'\n",
    "        },\n",
    "        'Rights-Based': {  # Framework 3: Rights-based perspective\n",
    "            'option_a': 'Violates passenger right to life',\n",
    "            'option_b': 'Violates pedestrian rights to life',\n",
    "            'option_c': 'Uncertain - may violate all rights',\n",
    "            'recommendation': 'No clear answer - all violate rights',\n",
    "            'reasoning': 'All options violate someone\\'s right to life'\n",
    "        },\n",
    "        'Virtue Ethics': {  # Framework 4: Virtue ethics perspective\n",
    "            'option_a': 'Shows courage but not justice',\n",
    "            'option_b': 'Shows no virtue - reckless',\n",
    "            'option_c': 'Shows prudence - trying to minimize harm',\n",
    "            'recommendation': 'Option C (most virtuous)',\n",
    "            'reasoning': 'Shows prudence and care for all lives'\n",
    "        },\n",
    "        'Care Ethics': {  # Framework 5: Care ethics perspective\n",
    "            'option_a': 'Abandons passenger relationship',\n",
    "            'option_b': 'Abandons pedestrian relationships',\n",
    "            'option_c': 'Tries to care for all relationships',\n",
    "            'recommendation': 'Option C (cares for all)',\n",
    "            'reasoning': 'Considers relationships with all affected parties'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print evaluations: Show how each framework evaluates the problem\n",
    "    print(\"Framework Evaluations:\\n\")\n",
    "    for framework, evaluation in framework_evaluations.items():  # Loop through frameworks: Process each framework\n",
    "        print(f\"{framework}:\")  # Framework header: Show framework name\n",
    "        print(\"-\" * 60)  # Separator: Visual divider\n",
    "        print(f\"  Option A: {evaluation['option_a']}\")  # Option A evaluation: Framework's view\n",
    "        print(f\"  Option B: {evaluation['option_b']}\")  # Option B evaluation: Framework's view\n",
    "        print(f\"  Option C: {evaluation['option_c']}\")  # Option C evaluation: Framework's view\n",
    "        print(f\"  Recommendation: {evaluation['recommendation']}\")  # Recommendation: What framework suggests\n",
    "        print(f\"  Reasoning: {evaluation['reasoning']}\")  # Reasoning: Why framework recommends this\n",
    "        print()  # Blank line: Spacing\n",
    "    \n",
    "    # Show the conflict: Different frameworks give different answers\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è THE LIMITATION: Frameworks Give Different Answers!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nNotice that:\")\n",
    "    print(\"  - Utilitarianism recommends Option A\")\n",
    "    print(\"  - Virtue Ethics recommends Option C\")\n",
    "    print(\"  - Deontology and Rights-Based find no clear answer\")\n",
    "    print(\"  - Care Ethics recommends Option C\")\n",
    "    print(\"\\nüö´ This is a DEAD END: We have frameworks, but they conflict!\")\n",
    "    print(\"   We need a way to resolve these conflicts...\")\n",
    "    print(\"   ‚Üí This leads us to the next notebook: Ethical Decision-Making!\")\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Analyzing autonomous vehicle problem with frameworks...\")\n",
    "analyze_autonomous_vehicle_problem()\n",
    "print(\"\\n‚úÖ Framework analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö´ When Ethical Frameworks Hit a Dead End | ÿπŸÜÿØŸÖÿß ÿ™ÿµŸÑ ÿßŸÑÿ£ÿ∑ÿ± ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ© ÿ•ŸÑŸâ ÿ∑ÿ±ŸäŸÇ ŸÖÿ≥ÿØŸàÿØ\n",
    "\n",
    "### The Limitation We Discovered\n",
    "\n",
    "We've learned five ethical frameworks, and we've seen how they can evaluate AI scenarios. **But there's a critical problem:**\n",
    "\n",
    "**Different frameworks give different answers to the same ethical question!**\n",
    "\n",
    "As we saw with the autonomous vehicle problem:\n",
    "- **Utilitarianism** recommends Option A (minimize total deaths)\n",
    "- **Virtue Ethics** recommends Option C (most virtuous approach)\n",
    "- **Deontology** and **Rights-Based** find no clear answer (all options violate principles)\n",
    "- **Care Ethics** recommends Option C (cares for all relationships)\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "When frameworks conflict, we're back to the original problem:\n",
    "- **How do we decide** which framework to follow?\n",
    "- **How do we resolve** conflicts between frameworks?\n",
    "- **How do we make** a final ethical decision when frameworks disagree?\n",
    "\n",
    "### The Solution: Ethical Decision-Making Framework\n",
    "\n",
    "We need a **systematic process** to:\n",
    "1. Apply multiple frameworks\n",
    "2. Resolve conflicts between them\n",
    "3. Make a final, justified decision\n",
    "\n",
    "**This is exactly what we'll learn in the next notebook: Ethical Decision-Making!**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Steps | ÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©\n",
    "\n",
    "**You've completed this notebook!** Now you understand:\n",
    "- ‚úÖ What ethical frameworks are\n",
    "- ‚úÖ How different frameworks evaluate AI scenarios\n",
    "- ‚úÖ **The limitation**: Frameworks can conflict!\n",
    "\n",
    "**Next notebook**: `02_ethical_decision_making.ipynb`\n",
    "- Learn how to resolve framework conflicts\n",
    "- Develop a systematic decision-making process\n",
    "- Make justified ethical decisions even when frameworks disagree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Comparing Ethical Frameworks | ÿßŸÑÿ¨ÿ≤ÿ° ÿßŸÑÿ´ÿßŸÑÿ´: ŸÖŸÇÿßÿ±ŸÜÿ© ÿßŸÑÿ£ÿ∑ÿ± ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿ©\n",
    "\n",
    "### üìö Prerequisites (What You Need First)\n",
    "-  **Frameworks defined** (from Part 2) - Understanding the five ethical frameworks\n",
    "-  **Visualization libraries** (from Part 1) - Understanding matplotlib\n",
    "\n",
    "### üîó Relationship: What This Builds On\n",
    "This builds on Part 2 - we now visualize and compare the frameworks we defined!\n",
    "- Builds on: Framework definitions, matplotlib\n",
    "- Shows: How frameworks compare in strengths, weaknesses, and practicality\n",
    "\n",
    "### üìñ The Story\n",
    "**Before visualization**: We have framework definitions but can't easily see how they compare.\n",
    "**After visualization**: We can see at a glance which frameworks are strongest, which have weaknesses, and which are most practical!\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Applying Frameworks to AI Scenarios | ÿßŸÑÿ¨ÿ≤ÿ° ÿßŸÑÿ±ÿßÿ®ÿπ: ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ£ÿ∑ÿ± ÿπŸÑŸâ ÿ≥ŸäŸÜÿßÿ±ŸäŸàŸáÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä\n",
    "\n",
    "### üìö Prerequisites (What You Need First)\n",
    "-  **Frameworks defined** (from Part 2) - Understanding the frameworks\n",
    "-  **Comparison visualization** (from Part 3) - Understanding how frameworks compare\n",
    "\n",
    "### üîó Relationship: What This Builds On\n",
    "This shows how to actually USE the frameworks we learned!\n",
    "- Builds on: Framework definitions, comparison understanding\n",
    "- Shows: How different frameworks evaluate real AI scenarios differently\n",
    "\n",
    "### üìñ The Story\n",
    "**Before application**: We know what frameworks are but don't know how to use them.\n",
    "**After application**: We can evaluate any AI scenario through multiple ethical lenses and see how different frameworks lead to different conclusions!\n",
    "# ============================================================================\n",
    "# VISUALIZATION 1: Framework Comparison Bar Chart\n",
    "# ============================================================================\n",
    "def create_framework_comparison():\n",
    "    \"\"\"Create a bar chart comparing ethical frameworks\"\"\"\n",
    "    framework_names = [f['name_en'] for f in frameworks.values()]\n",
    "    strengths = [f['strength'] for f in frameworks.values()]\n",
    "    weaknesses = [f['weakness'] for f in frameworks.values()]\n",
    "    practicality = [f['practicality'] for f in frameworks.values()]\n",
    "    x = np.arange(len(framework_names))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    bars1 = ax.bar(x - width, strengths, width, label='Strengths', \n",
    "                   color='#2ecc71', alpha=0.8)\n",
    "    bars2 = ax.bar(x, weaknesses, width, label='Weaknesses', \n",
    "                   color='#e74c3c', alpha=0.8)\n",
    "    bars3 = ax.bar(x + width, practicality, width, label='Practicality', \n",
    "                   color='#3498db', alpha=0.8)\n",
    "    ax.set_xlabel('Ethical Framework', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score (1-10)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Ethical Frameworks Comparison', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(framework_names, rotation=15, ha='right')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height)}',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    # In Jupyter notebooks, __file__ is not available, so we save to current directory\n",
    "    output_path = 'ethical_frameworks_comparison.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(\" Saved: ethical_frameworks_comparison.png\")\n",
    "    plt.close()\n",
    "# Step 4: Apply frameworks to real AI scenarios\n",
    "# This shows us how different frameworks evaluate the same AI scenarios differently\n",
    "\n",
    "# BEFORE: We know frameworks but don't know how to apply them to real situations\n",
    "# AFTER: We'll see how each framework evaluates different AI scenarios\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ APPLYING FRAMEWORKS TO AI SCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis analysis shows:\")\n",
    "print(\"  - How different frameworks evaluate the same AI scenario\")\n",
    "print(\"  - Which frameworks are most applicable to different scenarios\")\n",
    "print(\"  - How framework choice affects ethical evaluation\\n\")\n",
    "\n",
    "def create_ai_scenario_analysis():\n",
    "    \"\"\"\n",
    "    Analyze how different frameworks apply to AI scenarios.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    1. Define real-world AI scenarios (autonomous vehicles, healthcare AI, etc.)\n",
    "    2. Rate each framework's applicability to each scenario (1-10)\n",
    "    3. Create heatmap visualization showing framework-scenario matrix\n",
    "    4. Use color coding to show which frameworks work best for which scenarios\n",
    "    \n",
    "    ‚è∞ WHEN to use: After understanding frameworks - see how to apply them\n",
    "    üí° WHY use: Shows that different frameworks are better for different scenarios\n",
    "    \"\"\"\n",
    "    # Define scenarios: Real-world AI applications we'll evaluate\n",
    "    scenarios = {\n",
    "        'Autonomous Vehicles': {  # Scenario 1: Self-driving cars\n",
    "            'Utilitarianism': 9,  # High score: Maximizes safety for most people\n",
    "            'Deontology': 7,  # Medium-high: Follows safety rules\n",
    "            'Virtue Ethics': 6,  # Medium: Focuses on responsible driving\n",
    "            'Rights-Based': 8,  # High: Protects passenger rights\n",
    "            'Care Ethics': 7  # Medium-high: Considers passenger safety\n",
    "        },\n",
    "        'Healthcare AI': {  # Scenario 2: Medical AI systems\n",
    "            'Utilitarianism': 8,  # High: Benefits many patients\n",
    "            'Deontology': 9,  # Very high: Follows medical ethics rules\n",
    "            'Virtue Ethics': 8,  # High: Reflects medical virtues (care, compassion)\n",
    "            'Rights-Based': 9,  # Very high: Protects patient rights\n",
    "            'Care Ethics': 9  # Very high: Emphasizes patient care\n",
    "        },\n",
    "        'Facial Recognition': {  # Scenario 3: Face recognition systems\n",
    "            'Utilitarianism': 5,  # Medium-low: May benefit security but harm privacy\n",
    "            'Deontology': 6,  # Medium: May violate privacy rules\n",
    "            'Virtue Ethics': 4,  # Low: Doesn't reflect trustworthiness\n",
    "            'Rights-Based': 3,  # Very low: Violates privacy rights\n",
    "            'Care Ethics': 5  # Medium-low: Doesn't consider individual relationships\n",
    "        },\n",
    "        'Hiring Algorithms': {  # Scenario 4: AI hiring systems\n",
    "            'Utilitarianism': 6,  # Medium: May benefit companies but harm fairness\n",
    "            'Deontology': 7,  # Medium-high: Should follow fairness rules\n",
    "            'Virtue Ethics': 7,  # Medium-high: Should reflect fairness virtue\n",
    "            'Rights-Based': 8,  # High: Must protect equal opportunity rights\n",
    "            'Care Ethics': 6  # Medium: Should consider candidate relationships\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Prepare data: Convert scenario dictionary to matrix for visualization\n",
    "    scenario_names = list(scenarios.keys())  # Get scenario names: Extract keys for y-axis labels\n",
    "    framework_names = list(frameworks.keys())  # Get framework names: Extract keys for x-axis labels\n",
    "    data_matrix = np.array([[scenarios[s][f] for f in framework_names] \n",
    "                           for s in scenario_names])  # Create matrix: Convert nested dict to 2D array (scenarios x frameworks)\n",
    "    \n",
    "    # Create heatmap: Visualize framework-scenario applicability\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))  # Create figure: 12x8 inches for readable heatmap\n",
    "    im = ax.imshow(data_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=10)  # Create heatmap: Red-Yellow-Green colormap, 0-10 scale\n",
    "    \n",
    "    # Set axis labels: Make heatmap readable\n",
    "    ax.set_xticks(np.arange(len(framework_names)))  # X tick positions: One tick per framework\n",
    "    ax.set_yticks(np.arange(len(scenario_names)))  # Y tick positions: One tick per scenario\n",
    "    ax.set_xticklabels(framework_names, rotation=15, ha='right')  # X labels: Framework names, rotated for readability\n",
    "    ax.set_yticklabels(scenario_names)  # Y labels: Scenario names\n",
    "    \n",
    "    # Add score annotations: Show exact values in each cell\n",
    "    for i in range(len(scenario_names)):  # Loop through scenarios: Process each row\n",
    "        for j in range(len(framework_names)):  # Loop through frameworks: Process each column\n",
    "            text = ax.text(j, i, data_matrix[i, j],  # Add text: Place score value in cell center\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')  # Text style: Centered, bold, black\n",
    "    \n",
    "    # Add title: Describe what the heatmap shows\n",
    "    ax.set_title('Ethical Framework Applicability to AI Scenarios', \n",
    "                 fontsize=14, fontweight='bold', pad=20)  # Title: Main heading\n",
    "    \n",
    "    # Add colorbar: Explain color coding\n",
    "    cbar = plt.colorbar(im, ax=ax)  # Create colorbar: Show color-to-value mapping\n",
    "    cbar.set_label('Applicability Score (1-10)', \n",
    "                   fontsize=10)  # Colorbar label: Explain what colors mean\n",
    "    \n",
    "    # Save visualization: Export as image\n",
    "    plt.tight_layout()  # Adjust layout: Prevent label cutoff\n",
    "    # In Jupyter notebooks, __file__ is not available, so we save to current directory\n",
    "    output_path = 'ai_scenario_framework_analysis.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')  # Save image: High resolution, tight bounds\n",
    "    print(\" Saved: ai_scenario_framework_analysis.png\")  # Success message: Confirm save\n",
    "    plt.close()  # Close figure: Free memory\n",
    "\n",
    "# Run the scenario analysis\n",
    "print(\"Analyzing framework applicability to AI scenarios...\")\n",
    "create_ai_scenario_analysis()\n",
    "print(\" Scenario analysis complete!\")\n",
    "# ============================================================================\n",
    "# FRAMEWORK DESCRIPTION TABLE\n",
    "# ============================================================================\n",
    "def print_framework_descriptions():\n",
    "    \"\"\"Print detailed framework descriptions\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ETHICAL FRAMEWORKS FOR AI\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    for key, framework in frameworks.items():\n",
    "        print(f\"\\n{framework[\"name_en']}'name_ar']}')\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Focus\"focus']}'focus_ar']}')\n",
    "        print(f\"AI Application\")\n",
    "        print(f\"  {framework[\"ai_application']}')\n",
    "        print(f\"  {framework[\"ai_application_ar']}')\n",
    "        print(f\"Strengths Score\"strength']}')\n",
    "        print(f\"Weaknesses Score\"weakness']}')\n",
    "        print(f\"Practicality Score\"practicality']}')\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 1 - Example 1: Ethical Frameworks Comparison\")\n",
    "    print(\"\")\n",
    "    print(\"=\"*80)\n",
    "    # Print framework descriptions\n",
    "    print_framework_descriptions()\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations\")\n",
    "    print(\"=\"*80)\n",
    "    create_framework_comparison()\n",
    "    create_ai_scenario_analysis()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" Example completed successfully!\")\n",
    "    print(\"\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways\")\n",
    "    print(\"1. Different ethical frameworks offer different perspectives\")\n",
    "    print(\"\")\n",
    "    print(\"2. No single framework is perfect for all AI scenarios\")\n",
    "    print(\"\")\n",
    "    print(\"3. Combining frameworks provides more comprehensive ethical analysis\")\n",
    "    print(\"\")\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
