{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Rnn Lstm Nlp\n",
    "\n",
    "## ğŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the key concepts of this topic\n",
    "- Apply the topic using Python code examples\n",
    "- Practice with small, realistic datasets or scenarios\n",
    "\n",
    "## ğŸ”— Prerequisites\n",
    "\n",
    "- âœ… Basic Python\n",
    "- âœ… Basic NumPy/Pandas (when applicable)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook supports **Course 07, Unit 4** requirements from `DETAILED_UNIT_DESCRIPTIONS.md`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Rnn Lstm Nlp\n",
    "\n",
    "## ğŸ“š Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "\n",
    "This notebook demonstrates key concepts through hands-on examples.\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Understand the core concepts\n",
    "- See practical implementations\n",
    "- Be ready for exercises\n",
    "\n",
    "## ğŸ”— Prerequisites | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "- âœ… Python 3.8+ installed\n",
    "- âœ… Required libraries (see `requirements.txt`)\n",
    "- âœ… Basic Python knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Code Example | Ù…Ø«Ø§Ù„ Ø§Ù„ÙƒÙˆØ¯\n",
    "\n",
    "Run the code below to see the demonstration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:59:40.419216Z",
     "iopub.status.busy": "2026-01-16T23:59:40.418984Z",
     "iopub.status.idle": "2026-01-16T23:59:40.464038Z",
     "shell.execute_reply": "2026-01-16T23:59:40.463785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Example 1: RNNs and LSTMs for NLP\n",
      "Ù…Ø«Ø§Ù„ 1: RNNs Ùˆ LSTMs Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\n",
      "============================================================\n",
      "\n",
      "1. Recurrent Neural Networks (RNNs)\n",
      "Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (RNNs)\n",
      "------------------------------------------------------------\n",
      "\n",
      "RNN Structure:\n",
      "- Processes sequences one element at a time\n",
      "- Maintains hidden state across time steps\n",
      "- Can remember previous context\n",
      "- Useful for sequential data like text\n",
      "\n",
      "Ù‡ÙŠÙƒÙ„ RNN:\n",
      "- ÙŠØ¹Ø§Ù„Ø¬ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø¹Ù†ØµØ±Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©\n",
      "- ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø®ÙÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n",
      "- ÙŠÙ…ÙƒÙ†Ù‡ ØªØ°ÙƒØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚\n",
      "- Ù…ÙÙŠØ¯ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø© Ù…Ø«Ù„ Ø§Ù„Ù†Øµ\n",
      "\n",
      "\n",
      "============================================================\n",
      "2. Long Short-Term Memory (LSTM)\n",
      "Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù‚ØµÙŠØ±Ø© ÙˆØ·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰ (LSTM)\n",
      "============================================================\n",
      "\n",
      "LSTM Advantages over RNN:\n",
      "- Can remember information for longer periods\n",
      "- Solves vanishing gradient problem\n",
      "- Better for long sequences\n",
      "- Three gates: Forget, Input, Output\n",
      "\n",
      "Ù…Ø²Ø§ÙŠØ§ LSTM Ø¹Ù„Ù‰ RNN:\n",
      "- ÙŠÙ…ÙƒÙ†Ù‡ ØªØ°ÙƒØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„ÙØªØ±Ø§Øª Ø£Ø·ÙˆÙ„\n",
      "- ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ø®ØªÙØ§Ø¡ Ø§Ù„ØªØ¯Ø±Ø¬\n",
      "- Ø£ÙØ¶Ù„ Ù„Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©\n",
      "- Ø«Ù„Ø§Ø« Ø¨ÙˆØ§Ø¨Ø§Øª: Ø§Ù„Ù†Ø³ÙŠØ§Ù†ØŒ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ØŒ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬\n",
      "\n",
      "\n",
      "============================================================\n",
      "3. Sequence Modeling Example\n",
      "Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„ØªØ³Ù„Ø³Ù„\n",
      "============================================================\n",
      "\n",
      "Text sequence: hello\n",
      "Character mapping: {'e': 0, 'h': 1, 'o': 2, 'l': 3}\n",
      "Integer sequence: [1, 0, 3, 3, 2]\n",
      "\n",
      "Simulating RNN processing:\n",
      "Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© RNN:\n",
      "  Step 1: Input='h' (1), Hidden state=0.50\n",
      "  Step 2: Input='e' (0), Hidden state=0.25\n",
      "  Step 3: Input='l' (3), Hidden state=1.62\n",
      "  Step 4: Input='l' (3), Hidden state=2.31\n",
      "  Step 5: Input='o' (2), Hidden state=2.16\n",
      "\n",
      "============================================================\n",
      "4. NLP Applications\n",
      "ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\n",
      "============================================================\n",
      "\n",
      "Common Applications:\n",
      "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©:\n",
      "\n",
      "Text Generation:\n",
      "  Generate next word/character in sequence\n",
      "\n",
      "Sentiment Analysis:\n",
      "  Classify sentiment of text sequences\n",
      "\n",
      "Machine Translation:\n",
      "  Translate sequences from one language to another\n",
      "\n",
      "Named Entity Recognition:\n",
      "  Identify entities in text sequences\n",
      "\n",
      "============================================================\n",
      "Example completed successfully!\n",
      "ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­!\n",
      "============================================================\n",
      "\n",
      "Note: For actual implementation, use TensorFlow/Keras or PyTorch\n",
      "Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ÙØ¹Ù„ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… TensorFlow/Keras Ø£Ùˆ PyTorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4 - Example 1: RNNs and LSTMs for NLP\n",
    "Ø§Ù„ÙˆØ­Ø¯Ø© 4 - Ù…Ø«Ø§Ù„ 1: RNNs Ùˆ LSTMs Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\n",
    "\n",
    "This example demonstrates:\n",
    "1. RNN architecture for sequences\n",
    "2. LSTM for long-term dependencies\n",
    "3. Text sequence modeling\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: RNNs and LSTMs for NLP\")\n",
    "print(\"Ù…Ø«Ø§Ù„ 1: RNNs Ùˆ LSTMs Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Understanding RNNs\n",
    "# ÙÙ‡Ù… RNNs\n",
    "print(\"\\n1. Recurrent Neural Networks (RNNs)\")\n",
    "print(\"Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (RNNs)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rnn_explanation = \"\"\"\n",
    "RNN Structure:\n",
    "- Processes sequences one element at a time\n",
    "- Maintains hidden state across time steps\n",
    "- Can remember previous context\n",
    "- Useful for sequential data like text\n",
    "\n",
    "Ù‡ÙŠÙƒÙ„ RNN:\n",
    "- ÙŠØ¹Ø§Ù„Ø¬ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø¹Ù†ØµØ±Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©\n",
    "- ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø®ÙÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n",
    "- ÙŠÙ…ÙƒÙ†Ù‡ ØªØ°ÙƒØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚\n",
    "- Ù…ÙÙŠØ¯ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø© Ù…Ø«Ù„ Ø§Ù„Ù†Øµ\n",
    "\"\"\"\n",
    "\n",
    "print(rnn_explanation)\n",
    "\n",
    "# 2. LSTM for Long-term Dependencies\n",
    "# LSTM Ù„Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. Long Short-Term Memory (LSTM)\")\n",
    "print(\"Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù‚ØµÙŠØ±Ø© ÙˆØ·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰ (LSTM)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lstm_explanation = \"\"\"\n",
    "LSTM Advantages over RNN:\n",
    "- Can remember information for longer periods\n",
    "- Solves vanishing gradient problem\n",
    "- Better for long sequences\n",
    "- Three gates: Forget, Input, Output\n",
    "\n",
    "Ù…Ø²Ø§ÙŠØ§ LSTM Ø¹Ù„Ù‰ RNN:\n",
    "- ÙŠÙ…ÙƒÙ†Ù‡ ØªØ°ÙƒØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„ÙØªØ±Ø§Øª Ø£Ø·ÙˆÙ„\n",
    "- ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ø®ØªÙØ§Ø¡ Ø§Ù„ØªØ¯Ø±Ø¬\n",
    "- Ø£ÙØ¶Ù„ Ù„Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©\n",
    "- Ø«Ù„Ø§Ø« Ø¨ÙˆØ§Ø¨Ø§Øª: Ø§Ù„Ù†Ø³ÙŠØ§Ù†ØŒ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ØŒ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬\n",
    "\"\"\"\n",
    "\n",
    "print(lstm_explanation)\n",
    "\n",
    "# 3. Simple Sequence Example\n",
    "# Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ· Ø¹Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. Sequence Modeling Example\")\n",
    "print(\"Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„ØªØ³Ù„Ø³Ù„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simple character-level sequence\n",
    "# ØªØ³Ù„Ø³Ù„ Ø¨Ø³ÙŠØ· Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø­Ø±Ù\n",
    "text_sequence = \"hello\"\n",
    "char_to_int = {char: i for i, char in enumerate(set(text_sequence))}\n",
    "int_to_char = {i: char for char, i in char_to_int.items()}\n",
    "\n",
    "print(f\"\\nText sequence: {text_sequence}\")\n",
    "print(f\"Character mapping: {char_to_int}\")\n",
    "\n",
    "# Convert to sequence of integers\n",
    "# ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ù…Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµØ­ÙŠØ­Ø©\n",
    "sequence = [char_to_int[char] for char in text_sequence]\n",
    "print(f\"Integer sequence: {sequence}\")\n",
    "\n",
    "# Simulate RNN processing\n",
    "# Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© RNN\n",
    "print(\"\\nSimulating RNN processing:\")\n",
    "print(\"Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© RNN:\")\n",
    "hidden_state = 0\n",
    "for i, char_int in enumerate(sequence):\n",
    "    char = int_to_char[char_int]\n",
    "    # Simple update (in real RNN, this would be a neural network)\n",
    "    hidden_state = hidden_state * 0.5 + char_int * 0.5\n",
    "    print(f\"  Step {i+1}: Input='{char}' ({char_int}), Hidden state={hidden_state:.2f}\")\n",
    "\n",
    "# 4. Applications\n",
    "# Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. NLP Applications\")\n",
    "print(\"ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "applications = {\n",
    "    \"Text Generation\": \"Generate next word/character in sequence\", \"Sentiment Analysis\": \"Classify sentiment of text sequences\",\n",
    "    \"Machine Translation\": \"Translate sequences from one language to another\",\n",
    "    \"Named Entity Recognition\": \"Identify entities in text sequences\"\n",
    "}\n",
    "\n",
    "print(\"\\nCommon Applications:\")\n",
    "print(\"Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©:\")\n",
    "for app, description in applications.items():\n",
    "    print(f\"\\n{app}:\")\n",
    "    print(f\"  {description}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example completed successfully!\")\n",
    "print(\"ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\n",
    "print(\"Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ÙØ¹Ù„ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… TensorFlow/Keras Ø£Ùˆ PyTorch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Summary | Ø§Ù„Ù…Ù„Ø®Øµ\n",
    "\n",
    "Great job completing this example!\n",
    "\n",
    "**What you learned:**\n",
    "- Core concepts demonstrated in the code\n",
    "- Practical implementation details\n",
    "\n",
    "**Next steps:**\n",
    "- Complete the exercises in `exercises/` folder\n",
    "- Review the quiz materials\n",
    "- Proceed to the next example\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ Tip:** If you see errors, make sure:\n",
    "- All libraries are installed: `pip install -r requirements.txt`\n",
    "- You're using Python 3.8+\n",
    "- Cells are executed in order\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
