{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) and POS Tagging with spaCy\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Implement NER using spaCy\n",
    "- Perform POS tagging using spaCy\n",
    "- Extract named entities from text\n",
    "- Analyze and visualize NER results\n",
    "\n",
    "## üîó Prerequisites\n",
    "\n",
    "- ‚úÖ Unit 2: Text representation completed\n",
    "- ‚úÖ Understanding of NLP fundamentals\n",
    "- ‚úÖ Python, spaCy knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 07, Unit 3**:\n",
    "- Implementing NER and POS tagging using spaCy\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 3 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Named Entity Recognition (NER)** identifies and classifies named entities (persons, organizations, locations, etc.) in text. **POS Tagging** assigns part-of-speech tags (noun, verb, adjective, etc.) to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:59:33.122793Z",
     "iopub.status.busy": "2026-01-16T23:59:33.122665Z",
     "iopub.status.idle": "2026-01-16T23:59:34.338501Z",
     "shell.execute_reply": "2026-01-16T23:59:34.338306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  spaCy model not found. Download with: python -m spacy download en_core_web_sm\n",
      "   Using basic spaCy without model...\n",
      "\n",
      "‚úÖ Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Try importing spaCy\n",
    "try:\n",
    "    import spacy\n",
    "    HAS_SPACY = True\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        print(\"‚úÖ spaCy English model loaded!\")\n",
    "    except OSError:\n",
    "        print(\"‚ö†Ô∏è  spaCy model not found. Download with: python -m spacy download en_core_web_sm\")\n",
    "        print(\"   Using basic spaCy without model...\")\n",
    "        nlp = None\n",
    "except ImportError:\n",
    "    HAS_SPACY = False\n",
    "    nlp = None\n",
    "    print(\"‚ö†Ô∏è  spaCy not available. Install with: pip install spacy\")\n",
    "\n",
    "print(\"\\n‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Named Entity Recognition (NER) with spaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:59:34.339557Z",
     "iopub.status.busy": "2026-01-16T23:59:34.339450Z",
     "iopub.status.idle": "2026-01-16T23:59:34.341946Z",
     "shell.execute_reply": "2026-01-16T23:59:34.341718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NER with spaCy (Installation Required)\n",
      "============================================================\n",
      "\n",
      "    To use spaCy for NER:\n",
      "    \n",
      "    1. Install spaCy:\n",
      "       pip install spacy\n",
      "    \n",
      "    2. Download English model:\n",
      "       python -m spacy download en_core_web_sm\n",
      "    \n",
      "    3. Use spaCy:\n",
      "       import spacy\n",
      "       nlp = spacy.load(\"en_core_web_sm\")\n",
      "       doc = nlp(text)\n",
      "       for ent in doc.ents:\n",
      "           print(ent.text, ent.label_)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if HAS_SPACY and nlp is not None:\n",
    "    # Sample text for NER\n",
    "    text = \"\"\"\n",
    "    Apple Inc. is an American multinational technology company headquartered in \n",
    "    Cupertino, California. Tim Cook is the CEO of Apple. The company was founded \n",
    "    by Steve Jobs in 1976. Microsoft Corporation, founded by Bill Gates, is \n",
    "    another major technology company based in Redmond, Washington.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Named Entity Recognition (NER)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nInput text:\\n{text.strip()}\\n\")\n",
    "    \n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract named entities\n",
    "    print(\"Named Entities Found:\")\n",
    "    print(\"-\" * 60)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append({\n",
    "            'Text': ent.text, 'Label': ent.label_,\n",
    "            'Description': spacy.explain(ent.label_)\n",
    "        })\n",
    "        print(f\"{ent.text:20s} | {ent.label_:15s} | {spacy.explain(ent.label_)}\")\n",
    "    \n",
    "    print(f\"\\nTotal entities found: {len(entities)}\")\n",
    "    \n",
    "    # Count by entity type\n",
    "    entity_counts = Counter([ent['Label'] for ent in entities])\n",
    "    print(\"\\nEntity type distribution:\")\n",
    "    for label, count in entity_counts.items():\n",
    "        print(f\"  {label}: {count}\")\n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"NER with spaCy (Installation Required)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\"\"\n",
    "    To use spaCy for NER:\n",
    "    \n",
    "    1. Install spaCy:\n",
    "       pip install spacy\n",
    "    \n",
    "    2. Download English model:\n",
    "       python -m spacy download en_core_web_sm\n",
    "    \n",
    "    3. Use spaCy:\n",
    "       import spacy\n",
    "       nlp = spacy.load(\"en_core_web_sm\")\n",
    "       doc = nlp(text)\n",
    "       for ent in doc.ents:\n",
    "           print(ent.text, ent.label_)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Part-of-Speech (POS) Tagging with spaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:59:34.342769Z",
     "iopub.status.busy": "2026-01-16T23:59:34.342702Z",
     "iopub.status.idle": "2026-01-16T23:59:34.344757Z",
     "shell.execute_reply": "2026-01-16T23:59:34.344582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Install spaCy and download model for POS tagging\n"
     ]
    }
   ],
   "source": [
    "if HAS_SPACY and nlp is not None:\n",
    "    # Sample sentence for POS tagging\n",
    "    sentence = \"Natural language processing helps computers understand human language.\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Part-of-Speech (POS) Tagging\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nInput sentence: {sentence}\\n\")\n",
    "    \n",
    "    # Process sentence\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Extract POS tags\n",
    "    print(\"POS Tags:\")\n",
    "    print(\"-\" * 60)\n",
    "    pos_data = []\n",
    "    for token in doc:\n",
    "        pos_data.append({\n",
    "            'Word': token.text, 'POS': token.pos_,\n",
    "            'POS_Description': spacy.explain(token.pos_),\n",
    "            'Tag': token.tag_,\n",
    "            'Tag_Description': spacy.explain(token.tag_)\n",
    "        })\n",
    "        print(f\"{token.text:15s} | {token.pos_:10s} | {token.tag_:10s} | {spacy.explain(token.pos_)}\")\n",
    "    \n",
    "    # Count POS tags\n",
    "    pos_counts = Counter([token.pos_ for token in doc])\n",
    "    print(\"\\nPOS distribution:\")\n",
    "    for pos, count in pos_counts.items():\n",
    "        print(f\"  {pos}: {count}\")\n",
    "else:\n",
    "    print(\"Note: Install spaCy and download model for POS tagging\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Named Entity Recognition (NER)**: Identifies and classifies entities\n",
    "   - Common types: PERSON, ORGANIZATION, GPE (location), DATE, MONEY, etc.\n",
    "   - Useful for information extraction, question answering, knowledge graphs\n",
    "\n",
    "2. **Part-of-Speech (POS) Tagging**: Assigns grammatical tags to words\n",
    "   - Common tags: NOUN, VERB, ADJ, ADV, PRON, DET, etc.\n",
    "   - Useful for parsing, text understanding, feature engineering\n",
    "\n",
    "3. **spaCy**: Modern NLP library with pre-trained models\n",
    "   - Fast and efficient\n",
    "   - Built-in NER and POS tagging\n",
    "   - Supports multiple languages\n",
    "\n",
    "### Applications:\n",
    "- **NER**: Information extraction, knowledge graph construction, search\n",
    "- **POS Tagging**: Text preprocessing, feature engineering, parsing\n",
    "\n",
    "**Reference:** Course 07, Unit 3: \"Machine Learning for NLP\" - NER and POS tagging practical content\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
