{
  "timestamp": "2026-01-20T14:35:33.329857",
  "total_notebooks": 817,
  "execution_method": "nbclient",
  "timeout_per_notebook": 300,
  "results": [
    {
      "path": "Course 01/unit1-ai-foundations/examples/01_ai_introduction.ipynb",
      "status": "failed",
      "execution_time": 0.893190860748291,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Progress Chart\n# \u062a\u0635\u0648\u0631: \u0645\u062e\u0637\u0637 \u0627\u0644\u062a\u0642\u062f\u0645\ntry:\n    import matplotlib.pyplot as plt\n    \n    # Example progress visualization\n    steps = ['Step 1', 'Step 2', 'Step 3', 'Step 4']\n    progress = [25, 50, 75, 100]\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(steps, progress, color='green', alpha=0.7)\n    plt.xlabel('Progress % | \u0627\u0644\u0646\u0633\u0628\u0629 \u0627\u0644\u0645\u0626\u0648\u064a\u0629 \u0644\u0644\u062a\u0642\u062f\u0645', fontsize=12)\n    plt.title('Learning Progress | \u062a\u0642\u062f\u0645 \u0627\u0644\u062a\u0639\u0644\u0645', fontsize=14, pad=20)\n    plt.xlim(0, 100)\n    for i, v in enumerate(progress):\n        plt.text(v + 2, i, f'{v}%', va='center', fontsize=11)\n    plt.tight_layout()\n    plt.show()\n    print(\"\u2705 Progress visualization displayed\")\nexcept ImportError:\n    print(\"Note: Install matplotlib for visualizations\")\n    print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Introduction to Artificial Intelligence\n\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0645\u0642\u062f\u0645\u0629 \u0641\u064a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n\nThis example demonstrates:\n1. Basic AI concepts and definitions\n2. Types of AI systems\n3. Real-world AI applications\n4. Simple AI decision-making example\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Introduction to Artificial Intelligence\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0645\u0642\u062f\u0645\u0629 \u0641\u064a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"=\" * 60)\n\n# 1. What is AI?\n# \u0645\u0627 \u0647\u0648 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\u061f\nprint(\"\\n1. What is Artificial Intelligence?\")\nprint(\"\u0645\u0627 \u0647\u0648 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\u061f\")\nprint(\"-\" * 60)\n\nai_definition = \"\"\"\nArtificial Intelligence (AI) is the simulation of human intelligence \nin machines that are programmed to think and learn like humans.\n\n\u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0647\u0648 \u0645\u062d\u0627\u0643\u0627\u0629 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0628\u0634\u0631\u064a \u0641\u064a \u0627\u0644\u0622\u0644\u0627\u062a \u0627\u0644\u0645\u0628\u0631\u0645\u062c\u0629 \n\u0644\u0644\u062a\u0641\u0643\u064a\u0631 \u0648\u0627\u0644\u062a\u0639\u0644\u0645 \u0645\u062b\u0644 \u0627\u0644\u0628\u0634\u0631.\n\"\"\"\n\nprint(ai_definition)\n\n# 2. Types of AI Systems\n# \u0623\u0646\u0648\u0627\u0639 \u0623\u0646\u0638\u0645\u0629 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\n2. Types of AI Systems\")\nprint(\"\u0623\u0646\u0648\u0627\u0639 \u0623\u0646\u0638\u0645\u0629 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\nai_types = {\n    \"Narrow AI (Weak AI)\": {\n        \"description\": \"AI designed for specific tasks\", \"examples\": [\"Siri\", \"Google Translate\", \"Image Recognition\"],\n        \"arabic\": \"\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0636\u064a\u0642 (\u0636\u0639\u064a\u0641) - \u0645\u0635\u0645\u0645 \u0644\u0645\u0647\u0627\u0645 \u0645\u062d\u062f\u062f\u0629\"\n    },\n    \"General AI (Strong AI)\": {\n        \"description\": \"AI with human-level intelligence across all domains\",\n        \"examples\": [\"Not yet achieved\", \"Theoretical\"],\n        \"arabic\": \"\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0639\u0627\u0645 (\u0642\u0648\u064a) - \u0630\u0643\u0627\u0621 \u0639\u0644\u0649 \u0645\u0633\u062a\u0648\u0649 \u0627\u0644\u0628\u0634\u0631\"\n    },\n    \"Superintelligent AI\": {\n        \"description\": \"AI that surpasses human intelligence\",\n        \"examples\": [\"Future concept\", \"Theoretical\"],\n        \"arabic\": \"\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u0627\u0626\u0642 - \u064a\u062a\u062c\u0627\u0648\u0632 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0628\u0634\u0631\u064a\"\n    }\n}\n\nfor ai_type, info in ai_types.items():\n    print(f\"\\n{ai_type}:\")\n    print(f\"  {info['arabic']}\")\n    print(f\"  Description: {info['description']}\")\n    print(f\"  Examples: {', '.join(info['examples'])}\")\n\n# 3. Simple AI Decision-Making Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631 \u0628\u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\n\" + \"=\" * 60)\nprint(\"3. Simple AI Decision-Making Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631 \u0628\u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"=\" * 60)\n\ndef simple_ai_decision(temperature, humidity, time_of_day):\n    \"\"\"\n    Simple rule-based AI system for weather-based activity recommendation.\n    \u0646\u0638\u0627\u0645 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f \u0644\u062a\u0648\u0635\u064a\u0629 \u0646\u0634\u0627\u0637 \u0628\u0646\u0627\u0621\u064b \u0639\u0644\u0649 \u0627\u0644\u0637\u0642\u0633.\n    \n    Args:\n        temperature: Temperature in Celsius\n        humidity: Humidity percentage (0-100)\n        time_of_day: 'morning', 'afternoon', or 'evening'\n    \n    Returns:\n        Recommended activity\n    \"\"\"\n    # Decision rules\n\u0642\u0648\u0627\u0639\u062f \u0627\u0644\u0642\u0631\u0627\u0631\n    if temperature > 25 and humidity < 60:\n        if time_of_day == 'morning':\n            return \"Go for a jog in the park | \u0627\u0630\u0647\u0628 \u0644\u0644\u062c\u0631\u064a \u0641\u064a \u0627\u0644\u062d\u062f\u064a\u0642\u0629\"\n        elif time_of_day == 'afternoon':\n            return \"Go swimming | \u0627\u0630\u0647\u0628 \u0644\u0644\u0633\u0628\u0627\u062d\u0629\"\n        else:\n            return \"Take an evening walk | \u0627\u0630\u0647\u0628 \u0644\u0646\u0632\u0647\u0629 \u0645\u0633\u0627\u0626\u064a\u0629\"\n    \n    elif temperature < 15:\n        return \"Stay indoors, read a book | \u0627\u0628\u0642 \u0641\u064a \u0627\u0644\u062f\u0627\u062e\u0644 \u0648\u0627\u0642\u0631\u0623 \u0643\u062a\u0627\u0628\u0627\u064b\"\n    \n    elif humidity > 80:\n        return \"Stay indoors, watch a movie | \u0627\u0628\u0642 \u0641\u064a \u0627\u0644\u062f\u0627\u062e\u0644 \u0648\u0634\u0627\u0647\u062f \u0641\u064a\u0644\u0645\u0627\u064b\"\n    \n    else:\n        return \"Moderate weather, any outdoor activity is fine | \u0637\u0642\u0633 \u0645\u0639\u062a\u062f\u0644\u060c \u0623\u064a \u0646\u0634\u0627\u0637 \u062e\u0627\u0631\u062c\u064a \u0645\u0646\u0627\u0633\u0628\"\n\n# Test the AI system\n# \u0627\u062e\u062a\u0628\u0627\u0631 \u0646\u0638\u0627\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\nTesting AI Decision System:\")\nprint(\"\u0627\u062e\u062a\u0628\u0627\u0631 \u0646\u0638\u0627\u0645 \u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631:\")\n\ntest_cases = [\n    (28, 50, 'morning'),\n    (30, 45, 'afternoon'),\n    (12, 70, 'evening'),\n    (20, 85, 'afternoon')\n]\n\nfor temp, hum, time in test_cases:\n    decision = simple_ai_decision(temp, hum, time)\n    print(f\"\\nTemperature: {temp}\u00b0C, Humidity: {hum}%, Time: {time}\")\n    print(f\"Recommendation: {decision}\")\n\n# 4. AI Applications in Real World\n# \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0627\u0644\u0639\u0627\u0644\u0645 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\nprint(\"\\n\" + \"=\" * 60)\nprint(\"4. AI Applications in Real World\")\nprint(\"\u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0627\u0644\u0639\u0627\u0644\u0645 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\")\nprint(\"=\" * 60)\n\napplications = {\n    \"Healthcare\": [\n        \"Medical image analysis\", \"Drug discovery\",\n        \"Personalized treatment plans\"\n    ],\n    \"Transportation\": [\n        \"Autonomous vehicles\",\n        \"Traffic optimization\",\n        \"Route planning\"\n    ],\n    \"Finance\": [\n        \"Fraud detection\",\n        \"Algorithmic trading\",\n        \"Credit scoring\"\n    ],\n    \"Education\": [\n        \"Personalized learning\",\n        \"Automated grading\",\n        \"Intelligent tutoring systems\"\n    ]\n}\n\nfor domain, apps in applications.items():\n    print(f\"\\n{domain}:\")\n    for app in apps:\n        print(f\"  - {app}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 106\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u0642\u0648\u0627\u0639\u062f \u0627\u0644\u0642\u0631\u0627\u0631\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Progress Chart\n# \u062a\u0635\u0648\u0631: \u0645\u062e\u0637\u0637 \u0627\u0644\u062a\u0642\u062f\u0645\ntry:\n    import matplotlib.pyplot as plt\n    \n    # Example progress visualization\n    steps = ['Step 1', 'Step 2', 'Step 3', 'Step 4']\n    progress = [25, 50, 75, 100]\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(steps, progress, color='green', alpha=0.7)\n    plt.xlabel('Progress % | \u0627\u0644\u0646\u0633\u0628\u0629 \u0627\u0644\u0645\u0626\u0648\u064a\u0629 \u0644\u0644\u062a\u0642\u062f\u0645', fontsize=12)\n    plt.title('Learning Progress | \u062a\u0642\u062f\u0645 \u0627\u0644\u062a\u0639\u0644\u0645', fontsize=14, pad=20)\n    plt.xlim(0, 100)\n    for i, v in enumerate(progress):\n        plt.text(v + 2, i, f'{v}%', va='center', fontsize=11)\n    plt.tight_layout()\n    plt.show()\n    print(\"\u2705 Progress visualization displayed\")\nexcept ImportError:\n    print(\"Note: Install matplotlib for visualizations\")\n    print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Introduction to Artificial Intelligence\n\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0645\u0642\u062f\u0645\u0629 \u0641\u064a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n\nThis example demonstrates:\n1. Basic AI concepts and definitions\n2. Types of AI systems\n3. Real-world AI applications\n4. Simple AI decision-making example\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Introduction to Artificial Intelligence\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0645\u0642\u062f\u0645\u0629 \u0641\u064a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"=\" * 60)\n\n# 1. What is AI?\n# \u0645\u0627 \u0647\u0648 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\u061f\nprint(\"\\n1. What is Artificial Intelligence?\")\nprint(\"\u0645\u0627 \u0647\u0648 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\u061f\")\nprint(\"-\" * 60)\n\nai_definition = \"\"\"\nArtificial Intelligence (AI) is the simulation of human intelligence \nin machines that are programmed to think and learn like humans.\n\n\u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0647\u0648 \u0645\u062d\u0627\u0643\u0627\u0629 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0628\u0634\u0631\u064a \u0641\u064a \u0627\u0644\u0622\u0644\u0627\u062a \u0627\u0644\u0645\u0628\u0631\u0645\u062c\u0629 \n\u0644\u0644\u062a\u0641\u0643\u064a\u0631 \u0648\u0627\u0644\u062a\u0639\u0644\u0645 \u0645\u062b\u0644 \u0627\u0644\u0628\u0634\u0631.\n\"\"\"\n\nprint(ai_definition)\n\n# 2. Types of AI Systems\n# \u0623\u0646\u0648\u0627\u0639 \u0623\u0646\u0638\u0645\u0629 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\n2. Types of AI Systems\")\nprint(\"\u0623\u0646\u0648\u0627\u0639 \u0623\u0646\u0638\u0645\u0629 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\nai_types = {\n    \"Narrow AI (Weak AI)\": {\n        \"description\": \"AI designed for specific tasks\", \"examples\": [\"Siri\", \"Google Translate\", \"Image Recognition\"],\n        \"arabic\": \"\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0636\u064a\u0642 (\u0636\u0639\u064a\u0641) - \u0645\u0635\u0645\u0645 \u0644\u0645\u0647\u0627\u0645 \u0645\u062d\u062f\u062f\u0629\"\n    },\n    \"General AI (Strong AI)\": {\n        \"description\": \"AI with human-level intelligence across all domains\",\n        \"examples\": [\"Not yet achieved\", \"Theoretical\"],\n        \"arabic\": \"\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0639\u0627\u0645 (\u0642\u0648\u064a) - \u0630\u0643\u0627\u0621 \u0639\u0644\u0649 \u0645\u0633\u062a\u0648\u0649 \u0627\u0644\u0628\u0634\u0631\"\n    },\n    \"Superintelligent AI\": {\n        \"description\": \"AI that surpasses human intelligence\",\n        \"examples\": [\"Future concept\", \"Theoretical\"],\n        \"arabic\": \"\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u0627\u0626\u0642 - \u064a\u062a\u062c\u0627\u0648\u0632 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0628\u0634\u0631\u064a\"\n    }\n}\n\nfor ai_type, info in ai_types.items():\n    print(f\"\\n{ai_type}:\")\n    print(f\"  {info['arabic']}\")\n    print(f\"  Description: {info['description']}\")\n    print(f\"  Examples: {', '.join(info['examples'])}\")\n\n# 3. Simple AI Decision-Making Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631 \u0628\u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\n\" + \"=\" * 60)\nprint(\"3. Simple AI Decision-Making Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631 \u0628\u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"=\" * 60)\n\ndef simple_ai_decision(temperature, humidity, time_of_day):\n    \"\"\"\n    Simple rule-based AI system for weather-based activity recommendation.\n    \u0646\u0638\u0627\u0645 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f \u0644\u062a\u0648\u0635\u064a\u0629 \u0646\u0634\u0627\u0637 \u0628\u0646\u0627\u0621\u064b \u0639\u0644\u0649 \u0627\u0644\u0637\u0642\u0633.\n    \n    Args:\n        temperature: Temperature in Celsius\n        humidity: Humidity percentage (0-100)\n        time_of_day: 'morning', 'afternoon', or 'evening'\n    \n    Returns:\n        Recommended activity\n    \"\"\"\n    # Decision rules\n\u0642\u0648\u0627\u0639\u062f \u0627\u0644\u0642\u0631\u0627\u0631\n    if temperature > 25 and humidity < 60:\n        if time_of_day == 'morning':\n            return \"Go for a jog in the park | \u0627\u0630\u0647\u0628 \u0644\u0644\u062c\u0631\u064a \u0641\u064a \u0627\u0644\u062d\u062f\u064a\u0642\u0629\"\n        elif time_of_day == 'afternoon':\n            return \"Go swimming | \u0627\u0630\u0647\u0628 \u0644\u0644\u0633\u0628\u0627\u062d\u0629\"\n        else:\n            return \"Take an evening walk | \u0627\u0630\u0647\u0628 \u0644\u0646\u0632\u0647\u0629 \u0645\u0633\u0627\u0626\u064a\u0629\"\n    \n    elif temperature < 15:\n        return \"Stay indoors, read a book | \u0627\u0628\u0642 \u0641\u064a \u0627\u0644\u062f\u0627\u062e\u0644 \u0648\u0627\u0642\u0631\u0623 \u0643\u062a\u0627\u0628\u0627\u064b\"\n    \n    elif humidity > 80:\n        return \"Stay indoors, watch a movie | \u0627\u0628\u0642 \u0641\u064a \u0627\u0644\u062f\u0627\u062e\u0644 \u0648\u0634\u0627\u0647\u062f \u0641\u064a\u0644\u0645\u0627\u064b\"\n    \n    else:\n        return \"Moderate weather, any outdoor activity is fine | \u0637\u0642\u0633 \u0645\u0639\u062a\u062f\u0644\u060c \u0623\u064a \u0646\u0634\u0627\u0637 \u062e\u0627\u0631\u062c\u064a \u0645\u0646\u0627\u0633\u0628\"\n\n# Test the AI system\n# \u0627\u062e\u062a\u0628\u0627\u0631 \u0646\u0638\u0627\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\nTesting AI Decision System:\")\nprint(\"\u0627\u062e\u062a\u0628\u0627\u0631 \u0646\u0638\u0627\u0645 \u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631:\")\n\ntest_cases = [\n    (28, 50, 'morning'),\n    (30, 45, 'afternoon'),\n    (12, 70, 'evening'),\n    (20, 85, 'afternoon')\n]\n\nfor temp, hum, time in test_cases:\n    decision = simple_ai_decision(temp, hum, time)\n    print(f\"\\nTemperature: {temp}\u00b0C, Humidity: {hum}%, Time: {time}\")\n    print(f\"Recommendation: {decision}\")\n\n# 4. AI Applications in Real World\n# \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0627\u0644\u0639\u0627\u0644\u0645 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\nprint(\"\\n\" + \"=\" * 60)\nprint(\"4. AI Applications in Real World\")\nprint(\"\u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0627\u0644\u0639\u0627\u0644\u0645 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\")\nprint(\"=\" * 60)\n\napplications = {\n    \"Healthcare\": [\n        \"Medical image analysis\", \"Drug discovery\",\n        \"Personalized treatment plans\"\n    ],\n    \"Transportation\": [\n        \"Autonomous vehicles\",\n        \"Traffic optimization\",\n        \"Route planning\"\n    ],\n    \"Finance\": [\n        \"Fraud detection\",\n        \"Algorithmic trading\",\n        \"Credit scoring\"\n    ],\n    \"Education\": [\n        \"Personalized learning\",\n        \"Automated grading\",\n        \"Intelligent tutoring systems\"\n    ]\n}\n\nfor domain, apps in applications.items():\n    print(f\"\\n{domain}:\")\n    for app in apps:\n        print(f\"  - {app}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 106\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u0642\u0648\u0627\u0639\u062f \u0627\u0644\u0642\u0631\u0627\u0631\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/02_ai_history.ipynb",
      "status": "passed",
      "execution_time": 1.179358959197998,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/03_intelligent_agents_rationality.ipynb",
      "status": "failed",
      "execution_time": 0.7300119400024414,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\nimport numpy as np\nfrom typing import List, Dict, Any\n\nprint('\u2705 Setup complete!')\n\n# Define agent components\nclass IntelligentAgent:\n    \"\"\"\n    Simple intelligent agent structure\n    \"\"\"\n    def__init__(self, sensors, actuators, knowledge_base):\n        self.sensors = sensors\n        self.actuators = actuators\n        self.knowledge_base = knowledge_base\n        \n    def perceive(self, environment):\n        \"\"\"Agent perceives environment through sensors\"\"\"\n        # TODO: Implement perception\n        pass\n        \n    def think(self, perception):\n        \"\"\"Agent processes information and makes decisions\"\"\"\n        # TODO: Implement reasoning\n        pass\n        \n    def act(self, action):\n        \"\"\"Agent acts on environment through actuators\"\"\"\n        # TODO: Implement action\n        pass\n\nprint('Agent structure defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, sensors, actuators, knowledge_base):\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\nimport numpy as np\nfrom typing import List, Dict, Any\n\nprint('\u2705 Setup complete!')\n\n# Define agent components\nclass IntelligentAgent:\n    \"\"\"\n    Simple intelligent agent structure\n    \"\"\"\n    def__init__(self, sensors, actuators, knowledge_base):\n        self.sensors = sensors\n        self.actuators = actuators\n        self.knowledge_base = knowledge_base\n        \n    def perceive(self, environment):\n        \"\"\"Agent perceives environment through sensors\"\"\"\n        # TODO: Implement perception\n        pass\n        \n    def think(self, perception):\n        \"\"\"Agent processes information and makes decisions\"\"\"\n        # TODO: Implement reasoning\n        pass\n        \n    def act(self, action):\n        \"\"\"Agent acts on environment through actuators\"\"\"\n        # TODO: Implement action\n        pass\n\nprint('Agent structure defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, sensors, actuators, knowledge_base):\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/04_philosophy_turing_test.ipynb",
      "status": "failed",
      "execution_time": 0.5418901443481445,
      "error": "An error occurred while executing the following cell:\n------------------\n# Simple Turing Test Simulation\nclass SimpleChatbot:\n    \"\"\"Simple chatbot for Turing Test demonstration\"\"\"\n    def__init__(self):\n        self.responses = {\n            'hello': ['Hello!', 'Hi there!', 'Greetings!'],\n            'how are you': ['I am doing well, thank you!', 'Great, thanks for asking!'],\n            'what is ai': ['AI is the simulation of human intelligence by machines.', \n                          'AI involves creating systems that can perform tasks requiring intelligence.'],\n            'goodbye': ['Goodbye!', 'See you later!', 'Farewell!']\n        }\n    \n    def respond(self, user_input):\n        \"\"\"Generate response based on user input\"\"\"\n        user_input_lower = user_input.lower().strip()\n        \n        # Simple keyword matching\n        for key, responses in self.responses.items():\n            if key in user_input_lower:\n                return random.choice(responses)\n        \n        # Default response\n        return \"That's interesting. Can you tell me more?\"\n\n# Test the chatbot\nbot = SimpleChatbot()\nprint(\"Chatbot: Hello! I'm a simple chatbot. Ask me something!\")\nprint(\"\\nExample interactions:\")\nprint(f\"User: Hello\\nBot: {bot.respond('Hello')}\")\nprint(f\"User: What is AI?\\nBot: {bot.respond('What is AI?')}\")\nprint(f\"User: How are you?\\nBot: {bot.respond('How are you?')}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Turing Test Concept:\")\nprint(\"If you couldn't tell this was a machine, it might pass!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Simple Turing Test Simulation\nclass SimpleChatbot:\n    \"\"\"Simple chatbot for Turing Test demonstration\"\"\"\n    def__init__(self):\n        self.responses = {\n            'hello': ['Hello!', 'Hi there!', 'Greetings!'],\n            'how are you': ['I am doing well, thank you!', 'Great, thanks for asking!'],\n            'what is ai': ['AI is the simulation of human intelligence by machines.', \n                          'AI involves creating systems that can perform tasks requiring intelligence.'],\n            'goodbye': ['Goodbye!', 'See you later!', 'Farewell!']\n        }\n    \n    def respond(self, user_input):\n        \"\"\"Generate response based on user input\"\"\"\n        user_input_lower = user_input.lower().strip()\n        \n        # Simple keyword matching\n        for key, responses in self.responses.items():\n            if key in user_input_lower:\n                return random.choice(responses)\n        \n        # Default response\n        return \"That's interesting. Can you tell me more?\"\n\n# Test the chatbot\nbot = SimpleChatbot()\nprint(\"Chatbot: Hello! I'm a simple chatbot. Ask me something!\")\nprint(\"\\nExample interactions:\")\nprint(f\"User: Hello\\nBot: {bot.respond('Hello')}\")\nprint(f\"User: What is AI?\\nBot: {bot.respond('What is AI?')}\")\nprint(f\"User: How are you?\\nBot: {bot.respond('How are you?')}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Turing Test Concept:\")\nprint(\"If you couldn't tell this was a machine, it might pass!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/05_adversarial_search_minimax.ipynb",
      "status": "failed",
      "execution_time": 0.8095300197601318,
      "error": "An error occurred while executing the following cell:\n------------------\n# Simple Tic-Tac-Toe Game State\nclass TicTacToe:\n    \"\"\"Simple Tic-Tac-Toe game for MiniMax demonstration\"\"\"\n    def__init__(self):\n        self.board = [[' ' for _ in range(3)] for _ in range(3)]\n        self.current_player = 'X'\n    \n    def print_board(self):\n        \"\"\"Print the current board state\"\"\"\n        for row in self.board:\n            print('|'.join(row))\n            print('-' * 5)\n    \n    def is_terminal(self):\n        \"\"\"Check if game is over\"\"\"\n        # Check rows, columns, diagonals for winner\n        # Check for draw\n        # TODO: Implement terminal state check\n        return False\n    \n    def get_score(self):\n        \"\"\"Evaluate board state\"\"\"\n        # TODO: Return score (+1 for X win, -1 for O win, 0 for draw)\n        return 0\n    \n    def get_moves(self):\n        \"\"\"Get all possible moves\"\"\"\n        moves = []\n        for i in range(3):\n            for j in range(3):\n                if self.board[i][j] == ' ':\n                    moves.append((i, j))\n        return moves\n\n# Example game state\ngame = TicTacToe()\nprint(\"Initial Tic-Tac-Toe board:\")\ngame.print_board()\nprint(f\"\\nPossible moves: {game.get_moves()}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Simple Tic-Tac-Toe Game State\nclass TicTacToe:\n    \"\"\"Simple Tic-Tac-Toe game for MiniMax demonstration\"\"\"\n    def__init__(self):\n        self.board = [[' ' for _ in range(3)] for _ in range(3)]\n        self.current_player = 'X'\n    \n    def print_board(self):\n        \"\"\"Print the current board state\"\"\"\n        for row in self.board:\n            print('|'.join(row))\n            print('-' * 5)\n    \n    def is_terminal(self):\n        \"\"\"Check if game is over\"\"\"\n        # Check rows, columns, diagonals for winner\n        # Check for draw\n        # TODO: Implement terminal state check\n        return False\n    \n    def get_score(self):\n        \"\"\"Evaluate board state\"\"\"\n        # TODO: Return score (+1 for X win, -1 for O win, 0 for draw)\n        return 0\n    \n    def get_moves(self):\n        \"\"\"Get all possible moves\"\"\"\n        moves = []\n        for i in range(3):\n            for j in range(3):\n                if self.board[i][j] == ' ':\n                    moves.append((i, j))\n        return moves\n\n# Example game state\ngame = TicTacToe()\nprint(\"Initial Tic-Tac-Toe board:\")\ngame.print_board()\nprint(f\"\\nPossible moves: {game.get_moves()}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/06_knowledge_representation.ipynb",
      "status": "failed",
      "execution_time": 0.5748457908630371,
      "error": "An error occurred while executing the following cell:\n------------------\n# Knowledge Representation Concepts\n\n# Knowledge is information that enables an agent to act intelligently\n# Knowledge representation is about how to encode this information\n\nclass KnowledgeBase:\n    \"\"\"\n    Simple knowledge base structure\n    \"\"\"\n    def__init__(self):\n        self.facts = []  # Simple facts storage\n        self.rules = []  # If-then rules\n        \n    def add_fact(self, fact):\n        \"\"\"Add a fact to the knowledge base\"\"\"\n        self.facts.append(fact)\n        \n    def add_rule(self, condition, conclusion):\n        \"\"\"Add a rule: if condition then conclusion\"\"\"\n        self.rules.append({'if': condition, 'then': conclusion})\n        \n    def query(self, question):\n        \"\"\"Query the knowledge base\"\"\"\n        # Check if answer exists in facts\n        for fact in self.facts:\n            if question in fact:\n                return fact\n        return None\n\n# Create a simple knowledge base\nkb = KnowledgeBase()\n\n# Add some facts\nkb.add_fact(\"Python is a programming language\")\nkb.add_fact(\"AI uses Python for machine learning\")\nkb.add_fact(\"Knowledge representation is important in AI\")\n\nprint(\"\u2705 Knowledge base created\")\nprint(f\"Facts stored: {len(kb.facts)}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Knowledge Representation Concepts\n\n# Knowledge is information that enables an agent to act intelligently\n# Knowledge representation is about how to encode this information\n\nclass KnowledgeBase:\n    \"\"\"\n    Simple knowledge base structure\n    \"\"\"\n    def__init__(self):\n        self.facts = []  # Simple facts storage\n        self.rules = []  # If-then rules\n        \n    def add_fact(self, fact):\n        \"\"\"Add a fact to the knowledge base\"\"\"\n        self.facts.append(fact)\n        \n    def add_rule(self, condition, conclusion):\n        \"\"\"Add a rule: if condition then conclusion\"\"\"\n        self.rules.append({'if': condition, 'then': conclusion})\n        \n    def query(self, question):\n        \"\"\"Query the knowledge base\"\"\"\n        # Check if answer exists in facts\n        for fact in self.facts:\n            if question in fact:\n                return fact\n        return None\n\n# Create a simple knowledge base\nkb = KnowledgeBase()\n\n# Add some facts\nkb.add_fact(\"Python is a programming language\")\nkb.add_fact(\"AI uses Python for machine learning\")\nkb.add_fact(\"Knowledge representation is important in AI\")\n\nprint(\"\u2705 Knowledge base created\")\nprint(f\"Facts stored: {len(kb.facts)}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/07_python_basics_for_ai.ipynb",
      "status": "failed",
      "execution_time": 0.6048069000244141,
      "error": "An error occurred while executing the following cell:\n------------------\n# Lists - Essential for data manipulation\ndata_points = [1, 2, 3, 4, 5]\nprint(f\"Data points: {data_points}\")\nprint(f\"Sum: {sum(data_points)}\")\nprint(f\"Average: {sum(data_points)\nlen(data_points)}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Average: {sum(data_points)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Lists - Essential for data manipulation\ndata_points = [1, 2, 3, 4, 5]\nprint(f\"Data points: {data_points}\")\nprint(f\"Sum: {sum(data_points)}\")\nprint(f\"Average: {sum(data_points)\nlen(data_points)}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Average: {sum(data_points)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/08_generative_ai_intro.ipynb",
      "status": "passed",
      "execution_time": 0.6378171443939209,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/09_case_studies_intelligent_agents.ipynb",
      "status": "failed",
      "execution_time": 0.7387959957122803,
      "error": "An error occurred while executing the following cell:\n------------------\n# Simple Reflex Vacuum Agent Implementation\nclass SimpleVacuumAgent:\n    \"\"\"Simple reflex-based vacuum cleaner agent\"\"\"\n    def__init__(self):\n        self.location = (0, 0)\n        self.battery = 100\n        self.cleaned = set()\n    \n    def sense(self, environment):\n        \"\"\"Sense the environment\"\"\"\n        x, y = self.location\n        return {\n            'dirt': environment.get((x, y), False),\n            'battery': self.battery,\n            'location': (x, y)\n        }\n    \n    def act(self, perception):\n        \"\"\"Simple reflex: if dirty, clean; else move\"\"\"\n        if perception['battery'] <= 10:\n            return 'return_to_charger'\n        elif perception['dirt']:\n            self.cleaned.add(self.location)\n            self.battery -= 1\n            return 'clean'\n        else:\n            self.battery -= 1\n            return 'move_forward'\n\n# Example usage\nagent = SimpleVacuumAgent()\nenvironment = {(0, 0): True, (1, 0): False, (2, 0): True}\n\nprint(\"=== Simple Vacuum Agent Decision-Making ===\")\nfor step in range(5):\n    perception = agent.sense(environment)\n    action = agent.act(perception)\n    print(f\"Step {step + 1}: Location {perception['location']}, Dirt: {perception['dirt']}, Action: {action}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Simple Reflex Vacuum Agent Implementation\nclass SimpleVacuumAgent:\n    \"\"\"Simple reflex-based vacuum cleaner agent\"\"\"\n    def__init__(self):\n        self.location = (0, 0)\n        self.battery = 100\n        self.cleaned = set()\n    \n    def sense(self, environment):\n        \"\"\"Sense the environment\"\"\"\n        x, y = self.location\n        return {\n            'dirt': environment.get((x, y), False),\n            'battery': self.battery,\n            'location': (x, y)\n        }\n    \n    def act(self, perception):\n        \"\"\"Simple reflex: if dirty, clean; else move\"\"\"\n        if perception['battery'] <= 10:\n            return 'return_to_charger'\n        elif perception['dirt']:\n            self.cleaned.add(self.location)\n            self.battery -= 1\n            return 'clean'\n        else:\n            self.battery -= 1\n            return 'move_forward'\n\n# Example usage\nagent = SimpleVacuumAgent()\nenvironment = {(0, 0): True, (1, 0): False, (2, 0): True}\n\nprint(\"=== Simple Vacuum Agent Decision-Making ===\")\nfor step in range(5):\n    perception = agent.sense(environment)\n    action = agent.act(perception)\n    print(f\"Step {step + 1}: Location {perception['location']}, Dirt: {perception['dirt']}, Action: {action}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/implementing_search_algorithms_uninformed_heuristic_greedy.ipynb",
      "status": "passed",
      "execution_time": 2.5316450595855713,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/working_with_numpy_for_data_processing_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.2838997840881348,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7635879516601562,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 1: AI Fundamentals and Python Basics\n\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0628\u0627\u064a\u062b\u0648\u0646\n\nComplete the following exercises to practice AI fundamentals and Python for AI.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0628\u0627\u064a\u062b\u0648\u0646 \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a.\n\nRequired Practical Activities (from official structure):\n- Applied workshops on Python basics for AI\n- Working with NumPy for data processing in AI applications\n- Exercises on knowledge representation and rule-based systems\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Define AI\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"Exercise 1: Define AI\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\n# TODO: Write your own definition of AI in 2-3 sentences\n# TODO: \u0627\u0643\u062a\u0628 \u062a\u0639\u0631\u064a\u0641\u0643 \u0627\u0644\u062e\u0627\u0635 \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a 2-3 \u062c\u0645\u0644\nai_definition = \"\"\"\nYour definition here\n\u062a\u0639\u0631\u064a\u0641\u0643 \u0647\u0646\u0627:\n\"\"\"\n\nprint(ai_definition)\n\n# Exercise 2: Identify AI Types\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\nExercise 2: Identify AI Types\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\n# TODO: Classify each system as Narrow AI, General AI, or Superintelligent AI\n# TODO: \u0635\u0646\u0641 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0643\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0636\u064a\u0642\u060c \u0639\u0627\u0645\u060c \u0623\u0648 \u0641\u0627\u0626\u0642\nsystems = [\n    \"Siri voice assistant\",\n    \"Self-driving car\",\n    \"Chess-playing computer\",\n    \"Human-like robot that can do any task\",\n    \"AI that is smarter than all humans combined\"\n]\n\n# TODO: Create a dictionary mapping each system to its AI type\n# TODO: \u0623\u0646\u0634\u0626 \u0642\u0627\u0645\u0648\u0633 \u064a\u0631\u0628\u0637 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0628\u0646\u0648\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nsystem_types = {}\n\nfor system in systems:\n    # TODO: Classify the system\n    # system_types[system] = \"Your classification here\"\n    pass\n\n# Exercise 3: AI Application Research\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\nExercise 3: AI Application Research\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\n# TODO: Research and list 3 AI applications in a field of your choice\n# TODO: \u0627\u0628\u062d\u062b \u0648\u0627\u0630\u0643\u0631 3 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0645\u062c\u0627\u0644 \u0645\u0646 \u0627\u062e\u062a\u064a\u0627\u0631\u0643\nchosen_field = \"Your field here\n\u0627\u0644\u0645\u062c\u0627\u0644 \u0627\u0644\u0630\u064a \u0627\u062e\u062a\u0631\u062a\u0647:\"\napplications = [\n    \"Application 1\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 1:\", \"Application 2\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 2:\",\n    \"Application 3\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 3:\"\n]\n\nprint(f\"\\nField: {chosen_field}\")\nfor app in applications:\n    print(f\"  - {app}\")\n\n# Exercise 4: Simple Rule-Based System\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\nprint(\"\\nExercise 4: Simple Rule-Based System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\")\nprint(\"-\" * 60)\n\ndef recommend_movie(age, genre_preference, mood):\n    \"\"\"\n    TODO: Create a rule-based system that recommends a movie\n    based on age, genre preference, and mood.\n    \n    TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645\u0627\u064b \u0642\u0627\u0626\u0645\u0627\u064b \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f \u064a\u0648\u0635\u064a \u0628\u0641\u064a\u0644\u0645\n    \u0628\u0646\u0627\u0621\u064b \u0639\u0644\u0649 \u0627\u0644\u0639\u0645\u0631\u060c \u062a\u0641\u0636\u064a\u0644 \u0627\u0644\u0646\u0648\u0639\u060c \u0648\u0627\u0644\u0645\u0632\u0627\u062c.\n    \n    Args:\n        age: Person's age\n        genre_preference: 'action', 'comedy', 'drama', 'horror'\n        mood: 'happy', 'sad', 'excited', 'relaxed'\n    \n    Returns:\n        Movie recommendation\n    \"\"\"\n    # TODO: Implement your recommendation logic\n    # TODO: \u0646\u0641\u0630 \u0645\u0646\u0637\u0642 \u0627\u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u062e\u0627\u0635 \u0628\u0643\n    pass\n\n# Test your function\n# \u0627\u062e\u062a\u0628\u0631 \u062f\u0627\u0644\u062a\u0643\nprint(\"\\nTesting movie recommendation system:\")\ntest_cases = [\n    (25, 'action', 'excited'),\n    (15, 'comedy', 'happy'),\n    (30, 'drama', 'sad')\n]\n\nfor age, genre, mood in test_cases:\n    recommendation = recommend_movie(age, genre, mood)\n    print(f\"Age: {age}, Genre: {genre}, Mood: {mood}\")\n    print(f\"Recommendation: {recommendation}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 64\u001b[0;36m\u001b[0m\n\u001b[0;31m    chosen_field = \"Your field here\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 64)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 1: AI Fundamentals and Python Basics\n\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0628\u0627\u064a\u062b\u0648\u0646\n\nComplete the following exercises to practice AI fundamentals and Python for AI.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0628\u0627\u064a\u062b\u0648\u0646 \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a.\n\nRequired Practical Activities (from official structure):\n- Applied workshops on Python basics for AI\n- Working with NumPy for data processing in AI applications\n- Exercises on knowledge representation and rule-based systems\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Define AI\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"Exercise 1: Define AI\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\n# TODO: Write your own definition of AI in 2-3 sentences\n# TODO: \u0627\u0643\u062a\u0628 \u062a\u0639\u0631\u064a\u0641\u0643 \u0627\u0644\u062e\u0627\u0635 \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a 2-3 \u062c\u0645\u0644\nai_definition = \"\"\"\nYour definition here\n\u062a\u0639\u0631\u064a\u0641\u0643 \u0647\u0646\u0627:\n\"\"\"\n\nprint(ai_definition)\n\n# Exercise 2: Identify AI Types\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\nExercise 2: Identify AI Types\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\n# TODO: Classify each system as Narrow AI, General AI, or Superintelligent AI\n# TODO: \u0635\u0646\u0641 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0643\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0636\u064a\u0642\u060c \u0639\u0627\u0645\u060c \u0623\u0648 \u0641\u0627\u0626\u0642\nsystems = [\n    \"Siri voice assistant\",\n    \"Self-driving car\",\n    \"Chess-playing computer\",\n    \"Human-like robot that can do any task\",\n    \"AI that is smarter than all humans combined\"\n]\n\n# TODO: Create a dictionary mapping each system to its AI type\n# TODO: \u0623\u0646\u0634\u0626 \u0642\u0627\u0645\u0648\u0633 \u064a\u0631\u0628\u0637 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0628\u0646\u0648\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nsystem_types = {}\n\nfor system in systems:\n    # TODO: Classify the system\n    # system_types[system] = \"Your classification here\"\n    pass\n\n# Exercise 3: AI Application Research\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\nprint(\"\\nExercise 3: AI Application Research\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\nprint(\"-\" * 60)\n\n# TODO: Research and list 3 AI applications in a field of your choice\n# TODO: \u0627\u0628\u062d\u062b \u0648\u0627\u0630\u0643\u0631 3 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0645\u062c\u0627\u0644 \u0645\u0646 \u0627\u062e\u062a\u064a\u0627\u0631\u0643\nchosen_field = \"Your field here\n\u0627\u0644\u0645\u062c\u0627\u0644 \u0627\u0644\u0630\u064a \u0627\u062e\u062a\u0631\u062a\u0647:\"\napplications = [\n    \"Application 1\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 1:\", \"Application 2\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 2:\",\n    \"Application 3\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 3:\"\n]\n\nprint(f\"\\nField: {chosen_field}\")\nfor app in applications:\n    print(f\"  - {app}\")\n\n# Exercise 4: Simple Rule-Based System\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\nprint(\"\\nExercise 4: Simple Rule-Based System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\")\nprint(\"-\" * 60)\n\ndef recommend_movie(age, genre_preference, mood):\n    \"\"\"\n    TODO: Create a rule-based system that recommends a movie\n    based on age, genre preference, and mood.\n    \n    TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645\u0627\u064b \u0642\u0627\u0626\u0645\u0627\u064b \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f \u064a\u0648\u0635\u064a \u0628\u0641\u064a\u0644\u0645\n    \u0628\u0646\u0627\u0621\u064b \u0639\u0644\u0649 \u0627\u0644\u0639\u0645\u0631\u060c \u062a\u0641\u0636\u064a\u0644 \u0627\u0644\u0646\u0648\u0639\u060c \u0648\u0627\u0644\u0645\u0632\u0627\u062c.\n    \n    Args:\n        age: Person's age\n        genre_preference: 'action', 'comedy', 'drama', 'horror'\n        mood: 'happy', 'sad', 'excited', 'relaxed'\n    \n    Returns:\n        Movie recommendation\n    \"\"\"\n    # TODO: Implement your recommendation logic\n    # TODO: \u0646\u0641\u0630 \u0645\u0646\u0637\u0642 \u0627\u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u062e\u0627\u0635 \u0628\u0643\n    pass\n\n# Test your function\n# \u0627\u062e\u062a\u0628\u0631 \u062f\u0627\u0644\u062a\u0643\nprint(\"\\nTesting movie recommendation system:\")\ntest_cases = [\n    (25, 'action', 'excited'),\n    (15, 'comedy', 'happy'),\n    (30, 'drama', 'sad')\n]\n\nfor age, genre, mood in test_cases:\n    recommendation = recommend_movie(age, genre, mood)\n    print(f\"Age: {age}, Genre: {genre}, Mood: {mood}\")\n    print(f\"Recommendation: {recommendation}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 64\u001b[0;36m\u001b[0m\n\u001b[0;31m    chosen_field = \"Your field here\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 64)\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit1-ai-foundations/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5504171848297119,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"\n# Unit 1 - Exercise 1: AI Fundamentals\n# \u0627\u0644\u0648\u062d\u062f\u0629 1 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# \n# Complete the following exercises to practice AI fundamentals.\n# \u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a.\n# \"\"\"\n# \n# # Exercise 1: Define AI\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# print(\"Exercise 1: Define AI\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\n# print(\"-\" * 60)\n# \n# # # SOLUTION: Write your own definition of AI in 2-3 sentences\n# # # SOLUTION: \u0627\u0643\u062a\u0628 \u062a\u0639\u0631\u064a\u0641\u0643 \u0627\u0644\u062e\u0627\u0635 \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a 2-3 \u062c\u0645\u0644\n# ai_definition = \"\"\"\n# Your definition here\n\u062a\u0639\u0631\u064a\u0641\u0643 \u0647\u0646\u0627:\n# \"\"\"\n# \n# print(ai_definition)\n# \n# # Exercise 2: Identify AI Types\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# print(\"\\nExercise 2: Identify AI Types\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\n# print(\"-\" * 60)\n# \n# # # SOLUTION: Classify each system as Narrow AI, General AI, or Superintelligent AI\n# # # SOLUTION: \u0635\u0646\u0641 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0643\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0636\u064a\u0642\u060c \u0639\u0627\u0645\u060c \u0623\u0648 \u0641\u0627\u0626\u0642\n# systems = [\n#     \"Siri voice assistant\",\n#     \"Self-driving car\",\n#     \"Chess-playing computer\",\n#     \"Human-like robot that can do any task\",\n#     \"AI that is smarter than all humans combined\"\n# ]\n# \n# # # SOLUTION: Create a dictionary mapping each system to its AI type\n# # # SOLUTION: \u0623\u0646\u0634\u0626 \u0642\u0627\u0645\u0648\u0633 \u064a\u0631\u0628\u0637 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0628\u0646\u0648\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# system_types = {}\n# \n# for system in systems:\n#     # # SOLUTION: Classify the system\n#     # system_types[system] = \"Your classification here\"\n#     pass\n# \n# # Exercise 3: AI Application Research\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# print(\"\\nExercise 3: AI Application Research\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\n# print(\"-\" * 60)\n# \n# # # SOLUTION: Research and list 3 AI applications in a field of your choice\n# # # SOLUTION: \u0627\u0628\u062d\u062b \u0648\u0627\u0630\u0643\u0631 3 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0645\u062c\u0627\u0644 \u0645\u0646 \u0627\u062e\u062a\u064a\u0627\u0631\u0643\n# chosen_field = \"Your field here\n\u0627\u0644\u0645\u062c\u0627\u0644 \u0627\u0644\u0630\u064a \u0627\u062e\u062a\u0631\u062a\u0647:\"\n# applications = [\n#     \"Application 1\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 1:\", #     \"Application 2\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 2:\",\n#     \"Application 3\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 3:\"\n# ]\n# \n# print(f\"\\nField: {chosen_field}\")\n# for app in applications:\n#     print(f\"  - {app}\")\n# \n# # Exercise 4: Simple Rule-Based System\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\n# print(\"\\nExercise 4: Simple Rule-Based System\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\")\n# print(\"-\" * 60)\n# \n# def recommend_movie(age, genre_preference, mood):\n#     \"\"\"\n#     # SOLUTION: Create a rule-based system that recommends a movie\n#     based on age, genre preference, and mood.\n#     \n#     # SOLUTION: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645\u0627\u064b \u0642\u0627\u0626\u0645\u0627\u064b \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f \u064a\u0648\u0635\u064a \u0628\u0641\u064a\u0644\u0645\n#     \u0628\u0646\u0627\u0621\u064b \u0639\u0644\u0649 \u0627\u0644\u0639\u0645\u0631\u060c \u062a\u0641\u0636\u064a\u0644 \u0627\u0644\u0646\u0648\u0639\u060c \u0648\u0627\u0644\u0645\u0632\u0627\u062c.\n#     \n#     Args:\n#         age: Person's age\n#         genre_preference: 'action', 'comedy', 'drama', 'horror'\n#         mood: 'happy', 'sad', 'excited', 'relaxed'\n#     \n#     Returns:\n#         Movie recommendation\n#     \"\"\"\n#     # # SOLUTION: Implement your recommendation logic\n#     # # SOLUTION: \u0646\u0641\u0630 \u0645\u0646\u0637\u0642 \u0627\u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u062e\u0627\u0635 \u0628\u0643\n#     pass\n# \n# # Test your function\n# # \u0627\u062e\u062a\u0628\u0631 \u062f\u0627\u0644\u062a\u0643\n# print(\"\\nTesting movie recommendation system:\")\n# test_cases = [\n#     (25, 'action', 'excited'),\n#     (15, 'comedy', 'happy'),\n#     (30, 'drama', 'sad')\n# ]\n# \n# for age, genre, mood in test_cases:\n#     recommendation = recommend_movie(age, genre, mood)\n#     print(f\"Age: {age}, Genre: {genre}, Mood: {mood}\")\n#     print(f\"Recommendation: {recommendation}\")\n# \n# print(\"\\n\" + \"=\" * 60)\n# print(\"Exercises completed! Check solutions/ folder for answers.\")\n# print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\n# print(\"=\" * 60)\n# \n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u0627\u0644\u0645\u062c\u0627\u0644 \u0627\u0644\u0630\u064a \u0627\u062e\u062a\u0631\u062a\u0647:\"\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 59)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"\n# Unit 1 - Exercise 1: AI Fundamentals\n# \u0627\u0644\u0648\u062d\u062f\u0629 1 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# \n# Complete the following exercises to practice AI fundamentals.\n# \u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a.\n# \"\"\"\n# \n# # Exercise 1: Define AI\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# print(\"Exercise 1: Define AI\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0639\u0631\u064a\u0641 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\n# print(\"-\" * 60)\n# \n# # # SOLUTION: Write your own definition of AI in 2-3 sentences\n# # # SOLUTION: \u0627\u0643\u062a\u0628 \u062a\u0639\u0631\u064a\u0641\u0643 \u0627\u0644\u062e\u0627\u0635 \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a 2-3 \u062c\u0645\u0644\n# ai_definition = \"\"\"\n# Your definition here\n\u062a\u0639\u0631\u064a\u0641\u0643 \u0647\u0646\u0627:\n# \"\"\"\n# \n# print(ai_definition)\n# \n# # Exercise 2: Identify AI Types\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# print(\"\\nExercise 2: Identify AI Types\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u062a\u062d\u062f\u064a\u062f \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\n# print(\"-\" * 60)\n# \n# # # SOLUTION: Classify each system as Narrow AI, General AI, or Superintelligent AI\n# # # SOLUTION: \u0635\u0646\u0641 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0643\u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0636\u064a\u0642\u060c \u0639\u0627\u0645\u060c \u0623\u0648 \u0641\u0627\u0626\u0642\n# systems = [\n#     \"Siri voice assistant\",\n#     \"Self-driving car\",\n#     \"Chess-playing computer\",\n#     \"Human-like robot that can do any task\",\n#     \"AI that is smarter than all humans combined\"\n# ]\n# \n# # # SOLUTION: Create a dictionary mapping each system to its AI type\n# # # SOLUTION: \u0623\u0646\u0634\u0626 \u0642\u0627\u0645\u0648\u0633 \u064a\u0631\u0628\u0637 \u0643\u0644 \u0646\u0638\u0627\u0645 \u0628\u0646\u0648\u0639 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# system_types = {}\n# \n# for system in systems:\n#     # # SOLUTION: Classify the system\n#     # system_types[system] = \"Your classification here\"\n#     pass\n# \n# # Exercise 3: AI Application Research\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\n# print(\"\\nExercise 3: AI Application Research\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u0628\u062d\u062b \u0639\u0646 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\")\n# print(\"-\" * 60)\n# \n# # # SOLUTION: Research and list 3 AI applications in a field of your choice\n# # # SOLUTION: \u0627\u0628\u062d\u062b \u0648\u0627\u0630\u0643\u0631 3 \u062a\u0637\u0628\u064a\u0642\u0627\u062a \u0644\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0641\u064a \u0645\u062c\u0627\u0644 \u0645\u0646 \u0627\u062e\u062a\u064a\u0627\u0631\u0643\n# chosen_field = \"Your field here\n\u0627\u0644\u0645\u062c\u0627\u0644 \u0627\u0644\u0630\u064a \u0627\u062e\u062a\u0631\u062a\u0647:\"\n# applications = [\n#     \"Application 1\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 1:\", #     \"Application 2\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 2:\",\n#     \"Application 3\n\u0627\u0644\u062a\u0637\u0628\u064a\u0642 3:\"\n# ]\n# \n# print(f\"\\nField: {chosen_field}\")\n# for app in applications:\n#     print(f\"  - {app}\")\n# \n# # Exercise 4: Simple Rule-Based System\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\n# print(\"\\nExercise 4: Simple Rule-Based System\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 4: \u0646\u0638\u0627\u0645 \u0628\u0633\u064a\u0637 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\")\n# print(\"-\" * 60)\n# \n# def recommend_movie(age, genre_preference, mood):\n#     \"\"\"\n#     # SOLUTION: Create a rule-based system that recommends a movie\n#     based on age, genre preference, and mood.\n#     \n#     # SOLUTION: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645\u0627\u064b \u0642\u0627\u0626\u0645\u0627\u064b \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f \u064a\u0648\u0635\u064a \u0628\u0641\u064a\u0644\u0645\n#     \u0628\u0646\u0627\u0621\u064b \u0639\u0644\u0649 \u0627\u0644\u0639\u0645\u0631\u060c \u062a\u0641\u0636\u064a\u0644 \u0627\u0644\u0646\u0648\u0639\u060c \u0648\u0627\u0644\u0645\u0632\u0627\u062c.\n#     \n#     Args:\n#         age: Person's age\n#         genre_preference: 'action', 'comedy', 'drama', 'horror'\n#         mood: 'happy', 'sad', 'excited', 'relaxed'\n#     \n#     Returns:\n#         Movie recommendation\n#     \"\"\"\n#     # # SOLUTION: Implement your recommendation logic\n#     # # SOLUTION: \u0646\u0641\u0630 \u0645\u0646\u0637\u0642 \u0627\u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u062e\u0627\u0635 \u0628\u0643\n#     pass\n# \n# # Test your function\n# # \u0627\u062e\u062a\u0628\u0631 \u062f\u0627\u0644\u062a\u0643\n# print(\"\\nTesting movie recommendation system:\")\n# test_cases = [\n#     (25, 'action', 'excited'),\n#     (15, 'comedy', 'happy'),\n#     (30, 'drama', 'sad')\n# ]\n# \n# for age, genre, mood in test_cases:\n#     recommendation = recommend_movie(age, genre, mood)\n#     print(f\"Age: {age}, Genre: {genre}, Mood: {mood}\")\n#     print(f\"Recommendation: {recommendation}\")\n# \n# print(\"\\n\" + \"=\" * 60)\n# print(\"Exercises completed! Check solutions/ folder for answers.\")\n# print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\n# print(\"=\" * 60)\n# \n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u0627\u0644\u0645\u062c\u0627\u0644 \u0627\u0644\u0630\u064a \u0627\u062e\u062a\u0631\u062a\u0647:\"\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 59)\n\n\n",
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "other"
    },
    {
      "path": "Course 01/unit1-introduction/examples/10_implementing_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.7358648777008057,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/10_search_algorithms_uninformed_heuristic.ipynb",
      "status": "passed",
      "execution_time": 0.7303168773651123,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/11_numpy_data_processing.ipynb",
      "status": "passed",
      "execution_time": 0.74239182472229,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/11_working_with_numpy_data_processing.ipynb",
      "status": "passed",
      "execution_time": 0.6202690601348877,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/01_applied_python_review.ipynb",
      "status": "passed",
      "execution_time": 0.6685359477996826,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/02_encoding_categorical_features.ipynb",
      "status": "passed",
      "execution_time": 1.548792839050293,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/03_supervised_unsupervised_models.ipynb",
      "status": "passed",
      "execution_time": 1.7302401065826416,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_applied_python_review.ipynb",
      "status": "passed",
      "execution_time": 0.8299789428710938,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_data_generation_process.ipynb",
      "status": "passed",
      "execution_time": 0.8843789100646973,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_implementing_expert_system.ipynb",
      "status": "passed",
      "execution_time": 0.6427791118621826,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/05_implementing_simple_expert_system.ipynb",
      "status": "passed",
      "execution_time": 0.5238709449768066,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/05_working_with_rdf_sparql.ipynb",
      "status": "passed",
      "execution_time": 0.8218288421630859,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_applying_bayes_theorem.ipynb",
      "status": "failed",
      "execution_time": 0.7287390232086182,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Bayes' Theorem\")\nprint(\"=\" * 60)\n\nprint(\"\\nBayes' Theorem:\")\nprint(\"  P(A|B) = P(B|A) * P(A)\nP(B)\")\nprint(\"  - Prior probability: P(A)\")\nprint(\"  - Likelihood: P(B|A)\")\nprint(\"  - Posterior probability: P(A|B)\")\n\nprint(\"\\nApplications:\")\nprint(\"  - Medical diagnosis\")\nprint(\"  - Spam filtering\")\nprint(\"  - Machine learning\")\nprint(\"  - Decision making\")\n\nprint(\"\\nImplementation:\")\nprint(\"  - Calculate conditional probabilities\")\nprint(\"  - Update beliefs with evidence\")\nprint(\"  - Solve real-world problems\")\n\nprint(\"\\n\u2705 Bayes' theorem concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  P(A|B) = P(B|A) * P(A)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Bayes' Theorem\")\nprint(\"=\" * 60)\n\nprint(\"\\nBayes' Theorem:\")\nprint(\"  P(A|B) = P(B|A) * P(A)\nP(B)\")\nprint(\"  - Prior probability: P(A)\")\nprint(\"  - Likelihood: P(B|A)\")\nprint(\"  - Posterior probability: P(A|B)\")\n\nprint(\"\\nApplications:\")\nprint(\"  - Medical diagnosis\")\nprint(\"  - Spam filtering\")\nprint(\"  - Machine learning\")\nprint(\"  - Decision making\")\n\nprint(\"\\nImplementation:\")\nprint(\"  - Calculate conditional probabilities\")\nprint(\"  - Update beliefs with evidence\")\nprint(\"  - Solve real-world problems\")\n\nprint(\"\\n\u2705 Bayes' theorem concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  P(A|B) = P(B|A) * P(A)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n\n\n",
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_expert_system_python.ipynb",
      "status": "passed",
      "execution_time": 0.7365419864654541,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_working_with_rdf_sparql.ipynb",
      "status": "passed",
      "execution_time": 0.7801730632781982,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/07_applying_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.5863540172576904,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/07_bayes_theorem_applications.ipynb",
      "status": "failed",
      "execution_time": 0.5406148433685303,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Bayes' Theorem to Real-World Problems\")\nprint(\"=\" * 60)\n\nprint(\"\\nBayes' Theorem:\")\nprint(\"  P(A|B) = P(B|A) * P(A)\nP(B)\")\nprint(\"  - P(A|B): Posterior probability\")\nprint(\"  - P(B|A): Likelihood\")\nprint(\"  - P(A): Prior probability\")\nprint(\"  - P(B): Evidence\")\n\nprint(\"\\nApplications:\")\nprint(\"  - Medical diagnosis\")\nprint(\"  - Spam filtering\")\nprint(\"  - Machine learning\")\nprint(\"  - Decision making\")\n\nprint(\"\\n\u2705 Bayes' theorem concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  P(A|B) = P(B|A) * P(A)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Bayes' Theorem to Real-World Problems\")\nprint(\"=\" * 60)\n\nprint(\"\\nBayes' Theorem:\")\nprint(\"  P(A|B) = P(B|A) * P(A)\nP(B)\")\nprint(\"  - P(A|B): Posterior probability\")\nprint(\"  - P(B|A): Likelihood\")\nprint(\"  - P(A): Prior probability\")\nprint(\"  - P(B): Evidence\")\n\nprint(\"\\nApplications:\")\nprint(\"  - Medical diagnosis\")\nprint(\"  - Spam filtering\")\nprint(\"  - Machine learning\")\nprint(\"  - Decision making\")\n\nprint(\"\\n\u2705 Bayes' theorem concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  P(A|B) = P(B|A) * P(A)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n\n\n",
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/08_encoding_categorical_features.ipynb",
      "status": "passed",
      "execution_time": 1.3309640884399414,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/09_supervised_unsupervised_models.ipynb",
      "status": "passed",
      "execution_time": 1.5775189399719238,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/10_data_generation_process.ipynb",
      "status": "passed",
      "execution_time": 0.9349620342254639,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/01_bfs_algorithm.ipynb",
      "status": "passed",
      "execution_time": 1.0251259803771973,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/02_dfs_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.7823688983917236,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/03_astar_algorithm.ipynb",
      "status": "passed",
      "execution_time": 1.0657243728637695,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/04_expert_systems.ipynb",
      "status": "failed",
      "execution_time": 0.6648268699645996,
      "error": "An error occurred while executing the following cell:\n------------------\n# Simple Expert System: Medical Diagnosis Assistant\n# \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637: \u0645\u0633\u0627\u0639\u062f \u0627\u0644\u062a\u0634\u062e\u064a\u0635 \u0627\u0644\u0637\u0628\u064a\n\nclass ExpertSystem:\n    \"\"\"Simple rule-based expert system\"\"\"\n    \n    def__init__(self):\n        # Knowledge Base: Rules for medical diagnosis\n        self.knowledge_base = {\n            'fever': {\n                'high': ['flu', 'infection'],\n                'low': ['cold', 'allergy']\n            },\n            'cough': {\n                'dry': ['flu', 'allergy'],\n                'wet': ['cold', 'infection']\n            },\n            'headache': {\n                'severe': ['flu', 'infection'],\n                'mild': ['cold', 'allergy']\n            }\n        }\n        \n        # Rules for diagnosis\n        self.rules = [\n            {'conditions': {'fever': 'high', 'cough': 'dry', 'headache': 'severe'}, \n             'diagnosis': 'flu', 'confidence': 0.9},\n            {'conditions': {'fever': 'high', 'cough': 'wet'}, \n             'diagnosis': 'infection', 'confidence': 0.85},\n            {'conditions': {'fever': 'low', 'cough': 'dry'}, \n             'diagnosis': 'allergy', 'confidence': 0.75},\n            {'conditions': {'fever': 'low', 'cough': 'wet'}, \n             'diagnosis': 'cold', 'confidence': 0.8}\n        ]\n    \n    def forward_reasoning(self, symptoms):\n        \"\"\"\n        Forward reasoning: Start with facts (symptoms) and derive conclusions (diagnosis)\n        \u0627\u0644\u0627\u0633\u062a\u062f\u0644\u0627\u0644 \u0627\u0644\u0623\u0645\u0627\u0645\u064a: \u0627\u0628\u062f\u0623 \u0628\u0627\u0644\u062d\u0642\u0627\u0626\u0642 (\u0627\u0644\u0623\u0639\u0631\u0627\u0636) \u0648\u0627\u0633\u062a\u0646\u062a\u062c \u0627\u0644\u0627\u0633\u062a\u0646\u062a\u0627\u062c\u0627\u062a (\u0627\u0644\u062a\u0634\u062e\u064a\u0635)\n        \"\"\"\n        matching_rules = []\n        \n        for rule in self.rules:\n            # Check if all conditions in rule match symptoms\n            if all(symptoms.get(key) == value \n                   for key, value in rule['conditions'].items() \n                   if key in symptoms):\n                matching_rules.append(rule)\n        \n        if matching_rules:\n            # Return best match (highest confidence)\n            best_match = max(matching_rules, key=lambda x: x['confidence'])\n            return {\n                'diagnosis': best_match['diagnosis'],\n                'confidence': best_match['confidence'],\n                'matched_rules': len(matching_rules)\n            }\n        return {'diagnosis': 'unknown', 'confidence': 0.0}\n    \n    def backward_reasoning(self, target_diagnosis):\n        \"\"\"\n        Backward reasoning: Start with goal (diagnosis) and find required conditions\n        \u0627\u0644\u0627\u0633\u062a\u062f\u0644\u0627\u0644 \u0627\u0644\u062e\u0644\u0641\u064a: \u0627\u0628\u062f\u0623 \u0628\u0627\u0644\u0647\u062f\u0641 (\u0627\u0644\u062a\u0634\u062e\u064a\u0635) \u0648\u0627\u0628\u062d\u062b \u0639\u0646 \u0627\u0644\u0634\u0631\u0648\u0637 \u0627\u0644\u0645\u0637\u0644\u0648\u0628\u0629\n        \"\"\"\n        required_symptoms = []\n        \n        for rule in self.rules:\n            if rule['diagnosis'] == target_diagnosis:\n                required_symptoms.append(rule['conditions'])\n        \n        return required_symptoms\n\n# Example usage\nexpert = ExpertSystem()\n\nprint(\"=== Forward Reasoning Example ===\")\nsymptoms = {'fever': 'high', 'cough': 'dry', 'headache': 'severe'}\nresult = expert.forward_reasoning(symptoms)\nprint(f\"Symptoms: {symptoms}\")\nprint(f\"Diagnosis: {result['diagnosis']}\")\nprint(f\"Confidence: {result['confidence']:.2%}\")\n\nprint(\"\\n=== Backward Reasoning Example ===\")\ntarget = 'flu'\nrequired = expert.backward_reasoning(target)\nprint(f\"To diagnose '{target}', you need:\")\nfor i, conditions in enumerate(required, 1):\n    print(f\"  Option {i}: {conditions}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Simple Expert System: Medical Diagnosis Assistant\n# \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637: \u0645\u0633\u0627\u0639\u062f \u0627\u0644\u062a\u0634\u062e\u064a\u0635 \u0627\u0644\u0637\u0628\u064a\n\nclass ExpertSystem:\n    \"\"\"Simple rule-based expert system\"\"\"\n    \n    def__init__(self):\n        # Knowledge Base: Rules for medical diagnosis\n        self.knowledge_base = {\n            'fever': {\n                'high': ['flu', 'infection'],\n                'low': ['cold', 'allergy']\n            },\n            'cough': {\n                'dry': ['flu', 'allergy'],\n                'wet': ['cold', 'infection']\n            },\n            'headache': {\n                'severe': ['flu', 'infection'],\n                'mild': ['cold', 'allergy']\n            }\n        }\n        \n        # Rules for diagnosis\n        self.rules = [\n            {'conditions': {'fever': 'high', 'cough': 'dry', 'headache': 'severe'}, \n             'diagnosis': 'flu', 'confidence': 0.9},\n            {'conditions': {'fever': 'high', 'cough': 'wet'}, \n             'diagnosis': 'infection', 'confidence': 0.85},\n            {'conditions': {'fever': 'low', 'cough': 'dry'}, \n             'diagnosis': 'allergy', 'confidence': 0.75},\n            {'conditions': {'fever': 'low', 'cough': 'wet'}, \n             'diagnosis': 'cold', 'confidence': 0.8}\n        ]\n    \n    def forward_reasoning(self, symptoms):\n        \"\"\"\n        Forward reasoning: Start with facts (symptoms) and derive conclusions (diagnosis)\n        \u0627\u0644\u0627\u0633\u062a\u062f\u0644\u0627\u0644 \u0627\u0644\u0623\u0645\u0627\u0645\u064a: \u0627\u0628\u062f\u0623 \u0628\u0627\u0644\u062d\u0642\u0627\u0626\u0642 (\u0627\u0644\u0623\u0639\u0631\u0627\u0636) \u0648\u0627\u0633\u062a\u0646\u062a\u062c \u0627\u0644\u0627\u0633\u062a\u0646\u062a\u0627\u062c\u0627\u062a (\u0627\u0644\u062a\u0634\u062e\u064a\u0635)\n        \"\"\"\n        matching_rules = []\n        \n        for rule in self.rules:\n            # Check if all conditions in rule match symptoms\n            if all(symptoms.get(key) == value \n                   for key, value in rule['conditions'].items() \n                   if key in symptoms):\n                matching_rules.append(rule)\n        \n        if matching_rules:\n            # Return best match (highest confidence)\n            best_match = max(matching_rules, key=lambda x: x['confidence'])\n            return {\n                'diagnosis': best_match['diagnosis'],\n                'confidence': best_match['confidence'],\n                'matched_rules': len(matching_rules)\n            }\n        return {'diagnosis': 'unknown', 'confidence': 0.0}\n    \n    def backward_reasoning(self, target_diagnosis):\n        \"\"\"\n        Backward reasoning: Start with goal (diagnosis) and find required conditions\n        \u0627\u0644\u0627\u0633\u062a\u062f\u0644\u0627\u0644 \u0627\u0644\u062e\u0644\u0641\u064a: \u0627\u0628\u062f\u0623 \u0628\u0627\u0644\u0647\u062f\u0641 (\u0627\u0644\u062a\u0634\u062e\u064a\u0635) \u0648\u0627\u0628\u062d\u062b \u0639\u0646 \u0627\u0644\u0634\u0631\u0648\u0637 \u0627\u0644\u0645\u0637\u0644\u0648\u0628\u0629\n        \"\"\"\n        required_symptoms = []\n        \n        for rule in self.rules:\n            if rule['diagnosis'] == target_diagnosis:\n                required_symptoms.append(rule['conditions'])\n        \n        return required_symptoms\n\n# Example usage\nexpert = ExpertSystem()\n\nprint(\"=== Forward Reasoning Example ===\")\nsymptoms = {'fever': 'high', 'cough': 'dry', 'headache': 'severe'}\nresult = expert.forward_reasoning(symptoms)\nprint(f\"Symptoms: {symptoms}\")\nprint(f\"Diagnosis: {result['diagnosis']}\")\nprint(f\"Confidence: {result['confidence']:.2%}\")\n\nprint(\"\\n=== Backward Reasoning Example ===\")\ntarget = 'flu'\nrequired = expert.backward_reasoning(target)\nprint(f\"To diagnose '{target}', you need:\")\nfor i, conditions in enumerate(required, 1):\n    print(f\"  Option {i}: {conditions}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/05_bayes_theorem.ipynb",
      "status": "failed",
      "execution_time": 0.7323520183563232,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 1: Medical Diagnosis with Bayes' Theorem\n# \u0645\u062b\u0627\u0644 1: \u0627\u0644\u062a\u0634\u062e\u064a\u0635 \u0627\u0644\u0637\u0628\u064a \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0638\u0631\u064a\u0629 \u0628\u0627\u064a\u0632\n\ndef bayes_theorem(prior, likelihood, evidence):\n    \"\"\"\n    Calculate posterior probability using Bayes' theorem\n    \u0627\u062d\u0633\u0628 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0644\u0627\u062d\u0642 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0638\u0631\u064a\u0629 \u0628\u0627\u064a\u0632\n    \n    Args:\n        prior: P(A) - prior probability\n        likelihood: P(B|A) - likelihood\n        evidence: P(B) - evidence probability\n    \n    Returns:\n        P(A|B) - posterior probability\n    \"\"\"\n    posterior = (likelihood * prior)\nevidence\n    return posterior\n\n# Medical test example\n# Suppose:\n# - Disease prevalence (prior): 1% of population\n# - Test sensitivity (likelihood): 95% (P(positive|disease))\n# - Test specificity: 90% (P(negative|no_disease))\n# - What is P(disease|positive_test)?\n\nprior_disease = 0.01  # 1% have the disease\nsensitivity = 0.95    # 95% true positive rate\nspecificity = 0.90    # 90% true negative rate\n\n# Calculate P(positive_test)\n# P(positive) = P(positive|disease) * P(disease) + P(positive|no_disease) * P(no_disease)\np_positive_given_disease = sensitivity\np_positive_given_no_disease = 1 - specificity  # False positive rate\np_no_disease = 1 - prior_disease\n\np_positive = (p_positive_given_disease * prior_disease) + \\\n             (p_positive_given_no_disease * p_no_disease)\n\n# Calculate posterior: P(disease|positive_test)\np_disease_given_positive = bayes_theorem(\n    prior=prior_disease, likelihood=p_positive_given_disease,\n    evidence=p_positive\n)\n\nprint(\"=== Medical Diagnosis Example ===\")\nprint(f\"Prior probability of disease: {prior_disease:.2%}\")\nprint(f\"Test sensitivity: {sensitivity:.2%}\")\nprint(f\"Test specificity: {specificity:.2%}\")\nprint(f\"\\nProbability of positive test: {p_positive:.2%}\")\nprint(f\"\\nPosterior probability (disease given positive test): {p_disease_given_positive:.2%}\")\nprint(f\"\\nEven with a positive test, probability is only {p_disease_given_positive:.2%}!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    return posterior\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 1: Medical Diagnosis with Bayes' Theorem\n# \u0645\u062b\u0627\u0644 1: \u0627\u0644\u062a\u0634\u062e\u064a\u0635 \u0627\u0644\u0637\u0628\u064a \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0638\u0631\u064a\u0629 \u0628\u0627\u064a\u0632\n\ndef bayes_theorem(prior, likelihood, evidence):\n    \"\"\"\n    Calculate posterior probability using Bayes' theorem\n    \u0627\u062d\u0633\u0628 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0644\u0627\u062d\u0642 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0638\u0631\u064a\u0629 \u0628\u0627\u064a\u0632\n    \n    Args:\n        prior: P(A) - prior probability\n        likelihood: P(B|A) - likelihood\n        evidence: P(B) - evidence probability\n    \n    Returns:\n        P(A|B) - posterior probability\n    \"\"\"\n    posterior = (likelihood * prior)\nevidence\n    return posterior\n\n# Medical test example\n# Suppose:\n# - Disease prevalence (prior): 1% of population\n# - Test sensitivity (likelihood): 95% (P(positive|disease))\n# - Test specificity: 90% (P(negative|no_disease))\n# - What is P(disease|positive_test)?\n\nprior_disease = 0.01  # 1% have the disease\nsensitivity = 0.95    # 95% true positive rate\nspecificity = 0.90    # 90% true negative rate\n\n# Calculate P(positive_test)\n# P(positive) = P(positive|disease) * P(disease) + P(positive|no_disease) * P(no_disease)\np_positive_given_disease = sensitivity\np_positive_given_no_disease = 1 - specificity  # False positive rate\np_no_disease = 1 - prior_disease\n\np_positive = (p_positive_given_disease * prior_disease) + \\\n             (p_positive_given_no_disease * p_no_disease)\n\n# Calculate posterior: P(disease|positive_test)\np_disease_given_positive = bayes_theorem(\n    prior=prior_disease, likelihood=p_positive_given_disease,\n    evidence=p_positive\n)\n\nprint(\"=== Medical Diagnosis Example ===\")\nprint(f\"Prior probability of disease: {prior_disease:.2%}\")\nprint(f\"Test sensitivity: {sensitivity:.2%}\")\nprint(f\"Test specificity: {specificity:.2%}\")\nprint(f\"\\nProbability of positive test: {p_positive:.2%}\")\nprint(f\"\\nPosterior probability (disease given positive test): {p_disease_given_positive:.2%}\")\nprint(f\"\\nEven with a positive test, probability is only {p_disease_given_positive:.2%}!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    return posterior\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/06_machine_learning_intro.ipynb",
      "status": "failed",
      "execution_time": 1.4701008796691895,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom sklearn.preprocessing import LabelEncoder\n# Method 1: Label Encoding (for ordinal data)\nlabel_encoder = LabelEncoder()\ndf['location_encoded'] = label_encoder.fit_transform(df['location'])\n\nprint(\"=== Label Encoding ===\")\nprint(df[['location', 'location_encoded']])\n\n# Method 2: One-Hot Encoding (for nominal data)\nonehot_encoder = OneHotEncoder(sparse=False)\nlocation_onehot = onehot_encoder.fit_transform(df[['location']])\nlocation_df = pd.DataFrame(\n location_onehot, columns=[f'location_{cat}' for cat in label_encoder.classes_]\n)\n\nprint(\"\\n=== One-Hot Encoding ===\")\nprint(location_df)\n\n# Combine with original features\nX_encoded = pd.concat([X, location_df], axis=1)\nprint(\"\\n=== Combined Features ===\")\nprint(X_encoded)\n\n------------------\n\n----- stdout -----\n=== Label Encoding ===\n  location  location_encoded\n0        A                 0\n1        B                 1\n2        A                 0\n3        C                 2\n4        B                 1\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 2: One-Hot Encoding (for nominal data)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m location_onehot \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m location_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     13\u001b[0m  location_onehot, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_]\n\u001b[1;32m     14\u001b[0m )\n\n\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom sklearn.preprocessing import LabelEncoder\n# Method 1: Label Encoding (for ordinal data)\nlabel_encoder = LabelEncoder()\ndf['location_encoded'] = label_encoder.fit_transform(df['location'])\n\nprint(\"=== Label Encoding ===\")\nprint(df[['location', 'location_encoded']])\n\n# Method 2: One-Hot Encoding (for nominal data)\nonehot_encoder = OneHotEncoder(sparse=False)\nlocation_onehot = onehot_encoder.fit_transform(df[['location']])\nlocation_df = pd.DataFrame(\n location_onehot, columns=[f'location_{cat}' for cat in label_encoder.classes_]\n)\n\nprint(\"\\n=== One-Hot Encoding ===\")\nprint(location_df)\n\n# Combine with original features\nX_encoded = pd.concat([X, location_df], axis=1)\nprint(\"\\n=== Combined Features ===\")\nprint(X_encoded)\n\n------------------\n\n----- stdout -----\n=== Label Encoding ===\n  location  location_encoded\n0        A                 0\n1        B                 1\n2        A                 0\n3        C                 2\n4        B                 1\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 2: One-Hot Encoding (for nominal data)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m location_onehot \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m location_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     13\u001b[0m  location_onehot, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_]\n\u001b[1;32m     14\u001b[0m )\n\n\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/07_rdf_sparql_knowledge_graph.ipynb",
      "status": "failed",
      "execution_time": 0.5921599864959717,
      "error": "An error occurred while executing the following cell:\n------------------\n# Serialize the graph in different formats\nprint(\"=\" * 60)\nprint(\"RDF/XML Format:\")\nprint(\"=\" * 60)\nprint(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\u001b[0m\n\u001b[0m                                                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Serialize the graph in different formats\nprint(\"=\" * 60)\nprint(\"RDF/XML Format:\")\nprint(\"=\" * 60)\nprint(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\u001b[0m\n\u001b[0m                                                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.734503984451294,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 1: AI Concepts and Applications\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0627\u0644\u062a\u0637\u0628\u064a\u0642\u0627\u062a\n\nComplete the following exercises to practice Unit 2 concepts.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0648\u062d\u062f\u0629 2.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n\n# Exercise 1: Expert System Implementation\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631p\nrint(\"Exercise 1: Expert System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631\")\nprint(\"-\" * 60)\n\n# TODO: Create a simple expert system for product recommendation\n# The system should recommend products based on:\n# - Budget (low, medium, high)\n# - Interest (tech, fashion, sports)\n# - Age group (young, adult, senior)\n# TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637 \u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u0645\u0646\u062a\u062c\u0627\u062a\n\ndef bfs_complete(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Complete the BFS implementation.\n TODO: \u0623\u0643\u0645\u0644 \u062a\u0646\u0641\u064a\u0630 BFS.\n \n Args:\n graph: Dictionary representing the graph\n start: Starting nodegoal: Target node\n \n Returns:\n Shortest path from start to goal\n \"\"\"\n # TODO: Initialize queue with start node\n # TODO: Initialize visited se\nt\n # TODO: Implement BFS algorith\nm\n # TODO: Return path when goal is foun\nd\n pass\n\n# Test your implementation\nprint(\"\\nTesting BFS:\")\nresult = bfs_complete(graph, '1', '6')\nprint(f\"Path from 1 to 6: {result}\")\n\n# Exercise 2: DFS Path Findin\ng\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DF\nSp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: DFS Path Finding\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DFS\")\nprint(\"=\" * 60)\n\ndef dfs_path(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Implement DFS to find any path from start to goal.\n TODO: \u0646\u0641\u0630 DFS \u0644\u0625\u064a\u062c\u0627\u062f \u0623\u064a \u0645\u0633\u0627\u0631 \u0645\u0646 \u0627\u0644\u0628\u062f\u0627\u064a\u0629 \u0625\u0644\u0649 \u0627\u0644\u0647\u062f\u0641.\n \"\"\"\n # TODO: Implement DFS (recursive or iterativ\ne)\n pass\n\n# Test your implementation\nresult = dfs_path(graph, '4', '3')\nprint(f\"Path from 4 to 3: {result}\")\n\n# Exercise 3: Maze Solver\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 3: Maze Solver\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629\")\nprint(\"=\" * 60)\n\n# Simple maze representation (0 = wall, 1 = path)\n# \u062a\u0645\u062b\u064a\u0644 \u0645\u062a\u0627\u0647\u0629 \u0628\u0633\u064a\u0637\u0629 (0 = \u062c\u062f\u0627\u0631\u060c 1 = \u0645\u0633\u0627\u0631)\nmaze = [\n [1, 1, 0, 1],\n [0, 1, 1, 1],\n [1, 0, 1, 0],\n [1, 1, 1, 1]\n]\n\ndef solve_maze(maze, start, end):\n \n    \n    \"\"\"\n TODO: Use BFS or DFS to solve the maze.\n TODO: \u0627\u0633\u062a\u062e\u062f\u0645 BFS \u0623\u0648 DFS \u0644\u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629.\n \n Args:\n maze: 2D list representing the mazestart: (row, col) starting position\n end: (row, col) ending position\n \n Returns:\n List of (row, col) positions forming the path\n \"\"\"\n # TODO: Implement maze solving algorith\nm\n pass\n\n# Test maze solver\nstart_pos = (0, 0)\nend_pos = (3, 3)\npath = solve_maze(maze, start_pos, end_pos)\nprint(f\"Path from {start_pos} to {end_pos}: {path}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 1: AI Concepts and Applications\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0627\u0644\u062a\u0637\u0628\u064a\u0642\u0627\u062a\n\nComplete the following exercises to practice Unit 2 concepts.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0648\u062d\u062f\u0629 2.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n\n# Exercise 1: Expert System Implementation\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631p\nrint(\"Exercise 1: Expert System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631\")\nprint(\"-\" * 60)\n\n# TODO: Create a simple expert system for product recommendation\n# The system should recommend products based on:\n# - Budget (low, medium, high)\n# - Interest (tech, fashion, sports)\n# - Age group (young, adult, senior)\n# TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637 \u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u0645\u0646\u062a\u062c\u0627\u062a\n\ndef bfs_complete(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Complete the BFS implementation.\n TODO: \u0623\u0643\u0645\u0644 \u062a\u0646\u0641\u064a\u0630 BFS.\n \n Args:\n graph: Dictionary representing the graph\n start: Starting nodegoal: Target node\n \n Returns:\n Shortest path from start to goal\n \"\"\"\n # TODO: Initialize queue with start node\n # TODO: Initialize visited se\nt\n # TODO: Implement BFS algorith\nm\n # TODO: Return path when goal is foun\nd\n pass\n\n# Test your implementation\nprint(\"\\nTesting BFS:\")\nresult = bfs_complete(graph, '1', '6')\nprint(f\"Path from 1 to 6: {result}\")\n\n# Exercise 2: DFS Path Findin\ng\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DF\nSp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: DFS Path Finding\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DFS\")\nprint(\"=\" * 60)\n\ndef dfs_path(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Implement DFS to find any path from start to goal.\n TODO: \u0646\u0641\u0630 DFS \u0644\u0625\u064a\u062c\u0627\u062f \u0623\u064a \u0645\u0633\u0627\u0631 \u0645\u0646 \u0627\u0644\u0628\u062f\u0627\u064a\u0629 \u0625\u0644\u0649 \u0627\u0644\u0647\u062f\u0641.\n \"\"\"\n # TODO: Implement DFS (recursive or iterativ\ne)\n pass\n\n# Test your implementation\nresult = dfs_path(graph, '4', '3')\nprint(f\"Path from 4 to 3: {result}\")\n\n# Exercise 3: Maze Solver\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 3: Maze Solver\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629\")\nprint(\"=\" * 60)\n\n# Simple maze representation (0 = wall, 1 = path)\n# \u062a\u0645\u062b\u064a\u0644 \u0645\u062a\u0627\u0647\u0629 \u0628\u0633\u064a\u0637\u0629 (0 = \u062c\u062f\u0627\u0631\u060c 1 = \u0645\u0633\u0627\u0631)\nmaze = [\n [1, 1, 0, 1],\n [0, 1, 1, 1],\n [1, 0, 1, 0],\n [1, 1, 1, 1]\n]\n\ndef solve_maze(maze, start, end):\n \n    \n    \"\"\"\n TODO: Use BFS or DFS to solve the maze.\n TODO: \u0627\u0633\u062a\u062e\u062f\u0645 BFS \u0623\u0648 DFS \u0644\u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629.\n \n Args:\n maze: 2D list representing the mazestart: (row, col) starting position\n end: (row, col) ending position\n \n Returns:\n List of (row, col) positions forming the path\n \"\"\"\n # TODO: Implement maze solving algorith\nm\n pass\n\n# Test maze solver\nstart_pos = (0, 0)\nend_pos = (3, 3)\npath = solve_maze(maze, start_pos, end_pos)\nprint(f\"Path from {start_pos} to {end_pos}: {path}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit2-search-algorithms/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.5279359817504883,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "other"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/01_knowledge_graph.ipynb",
      "status": "failed",
      "execution_time": 0.5197687149047852,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Example 1: Knowledge Graph Representation\n\u0627\u0644\u0648\u062d\u062f\u0629 3 - \u0645\u062b\u0627\u0644 1: \u062a\u0645\u062b\u064a\u0644 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629\n\nThis example demonstrates:\n1. Creating a knowledge graph\n2. Representing relationships\n3. Querying the knowledge graph\n4. Visualizing knowledge structure\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Knowledge Graph Representation\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u062a\u0645\u062b\u064a\u0644 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629\")\nprint(\"=\" * 60)\n\n# Knowledge Graph: Family Relationships\n# \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629: \u0639\u0644\u0627\u0642\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u0629\nknowledge_graph = {\n    'Ahmed': {\n        'is_parent_of': ['Sara', 'Omar'],\n        'is_married_to': ['Fatima'],\n        'age': 45,\n        'profession': 'Engineer'\n    },\n    'Fatima': {\n        'is_parent_of': ['Sara', 'Omar'],\n        'is_married_to': ['Ahmed'],\n        'age': 42,\n        'profession': 'Doctor'\n    },\n    'Sara': {\n        'is_child_of': ['Ahmed', 'Fatima'],\n        'is_sibling_of': ['Omar'],\n        'age': 18,\n        'profession': 'Student'\n    },\n    'Omar': {\n        'is_child_of': ['Ahmed', 'Fatima'],\n        'is_sibling_of': ['Sara'],\n        'age': 15,\n        'profession': 'Student'\n    }\n}\n\ndef query_knowledge_graph(graph, person, relationship):\n    \"\"\"\n    Query the knowledge graph for relationships.\n    \u0627\u0633\u062a\u0639\u0644\u0627\u0645 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629 \u0639\u0646 \u0627\u0644\u0639\u0644\u0627\u0642\u0627\u062a.\n    \n    Args:\n        graph: Knowledge graph dictionary\n        person: Person to query about\n        relationship: Type of relationship to find\n    \n    Returns:\n        List of related people\n    \"\"\"\n    if person not in graph:\n        return []\n    \n    return graph[person].get(relationship, [])\n\ndef find_all_relationships(graph, person):\n    \"\"\"\n    Find all relationships for a person.\n    \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 \u062c\u0645\u064a\u0639 \u0627\u0644\u0639\u0644\u0627\u0642\u0627\u062a \u0644\u0634\u062e\u0635 \u0645\u0627.\n    \"\"\"\n    if person not in graph:\n        return {}\n    \n    return graph[person]\n\n# Example queries\nprint(\"\\n1. Querying Knowledge Graph\")\nprint(\"\u0627\u0633\u062a\u0639\u0644\u0627\u0645 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629\")\nprint(\"-\" * 60)\n\n# Who are Ahmed's children?\nprint(\"\\nWho are Ahmed's children?\n\u0645\u0646 \u0647\u0645 \u0623\u0637\u0641\u0627\u0644 \u0623\u062d\u0645\u062f\u061f\")\nchildren = query_knowledge_graph(knowledge_graph, 'Ahmed', 'is_parent_of')\nprint(f\"  Answer: {children}\")\n\n# Who is Sara's sibling?\nprint(\"\\nWho is Sara's sibling?\n\u0645\u0646 \u0647\u0648 \u0634\u0642\u064a\u0642 \u0633\u0627\u0631\u0629\u061f\")\nsiblings = query_knowledge_graph(knowledge_graph, 'Sara', 'is_sibling_of')\nprint(f\"  Answer: {siblings}\")\n\n# All relationships for Fatima\nprint(\"\\nAll relationships for Fatima\n\u062c\u0645\u064a\u0639 \u0639\u0644\u0627\u0642\u0627\u062a \u0641\u0627\u0637\u0645\u0629:\")\nrelationships = find_all_relationships(knowledge_graph, 'Fatima')\nfor rel_type, rel_value in relationships.items():\n    print(f\"  {rel_type}: {rel_value}\")\n\n# Rule-Based System Example\nprint(\"\\n\" + \"=\" * 60)\nprint(\"2. Rule-Based System\")\nprint(\"\u0646\u0638\u0627\u0645 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\")\nprint(\"=\" * 60)\n\n# Rules for determining if someone can drive\n# \u0642\u0648\u0627\u0639\u062f \u0644\u062a\u062d\u062f\u064a\u062f \u0645\u0627 \u0625\u0630\u0627 \u0643\u0627\u0646 \u0634\u062e\u0635 \u0645\u0627 \u064a\u0645\u0643\u0646\u0647 \u0627\u0644\u0642\u064a\u0627\u062f\u0629\ndef can_drive(person, graph):\n    \"\"\"\n    Rule-based system: Can person drive?\n    \u0646\u0638\u0627\u0645 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f: \u0647\u0644 \u064a\u0645\u0643\u0646 \u0644\u0644\u0634\u062e\u0635 \u0627\u0644\u0642\u064a\u0627\u062f\u0629\u061f\n    \"\"\"\n    if person not in graph:\n        return False, \"Person not found\"\n    \n    age = graph[person].get('age', 0)\n    profession = graph[person].get('profession', '')\n    \n    # Rule 1: Must be 18 or older\n    if age < 18:\n        return False, \"Too young to drive (must be 18+)\"\n    \n    # Rule 2: Must not be a student (simplified rule)\n    if profession == 'Student':\n        return False, \"Students need special permit\"\n    \n    # Rule 3: If 18+ and not student, can drive\n    return True, \"Can drive\"\n\n# Test rules\nprint(\"\\nTesting driving rules:\")\nfor person in knowledge_graph.keys():\n    can_drive_result, reason = can_drive(person, knowledge_graph)\n    status = \"\u2713 Can drive\" if can_drive_result else \"\u2717 Cannot drive\"\n    print(f\"\\n{person} (age {knowledge_graph[person]['age']}):\")\n    print(f\"  {status} - {reason}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 80\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\nWho are Ahmed's children?\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 80)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Example 1: Knowledge Graph Representation\n\u0627\u0644\u0648\u062d\u062f\u0629 3 - \u0645\u062b\u0627\u0644 1: \u062a\u0645\u062b\u064a\u0644 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629\n\nThis example demonstrates:\n1. Creating a knowledge graph\n2. Representing relationships\n3. Querying the knowledge graph\n4. Visualizing knowledge structure\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Knowledge Graph Representation\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u062a\u0645\u062b\u064a\u0644 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629\")\nprint(\"=\" * 60)\n\n# Knowledge Graph: Family Relationships\n# \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629: \u0639\u0644\u0627\u0642\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u0629\nknowledge_graph = {\n    'Ahmed': {\n        'is_parent_of': ['Sara', 'Omar'],\n        'is_married_to': ['Fatima'],\n        'age': 45,\n        'profession': 'Engineer'\n    },\n    'Fatima': {\n        'is_parent_of': ['Sara', 'Omar'],\n        'is_married_to': ['Ahmed'],\n        'age': 42,\n        'profession': 'Doctor'\n    },\n    'Sara': {\n        'is_child_of': ['Ahmed', 'Fatima'],\n        'is_sibling_of': ['Omar'],\n        'age': 18,\n        'profession': 'Student'\n    },\n    'Omar': {\n        'is_child_of': ['Ahmed', 'Fatima'],\n        'is_sibling_of': ['Sara'],\n        'age': 15,\n        'profession': 'Student'\n    }\n}\n\ndef query_knowledge_graph(graph, person, relationship):\n    \"\"\"\n    Query the knowledge graph for relationships.\n    \u0627\u0633\u062a\u0639\u0644\u0627\u0645 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629 \u0639\u0646 \u0627\u0644\u0639\u0644\u0627\u0642\u0627\u062a.\n    \n    Args:\n        graph: Knowledge graph dictionary\n        person: Person to query about\n        relationship: Type of relationship to find\n    \n    Returns:\n        List of related people\n    \"\"\"\n    if person not in graph:\n        return []\n    \n    return graph[person].get(relationship, [])\n\ndef find_all_relationships(graph, person):\n    \"\"\"\n    Find all relationships for a person.\n    \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 \u062c\u0645\u064a\u0639 \u0627\u0644\u0639\u0644\u0627\u0642\u0627\u062a \u0644\u0634\u062e\u0635 \u0645\u0627.\n    \"\"\"\n    if person not in graph:\n        return {}\n    \n    return graph[person]\n\n# Example queries\nprint(\"\\n1. Querying Knowledge Graph\")\nprint(\"\u0627\u0633\u062a\u0639\u0644\u0627\u0645 \u0627\u0644\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a \u0644\u0644\u0645\u0639\u0631\u0641\u0629\")\nprint(\"-\" * 60)\n\n# Who are Ahmed's children?\nprint(\"\\nWho are Ahmed's children?\n\u0645\u0646 \u0647\u0645 \u0623\u0637\u0641\u0627\u0644 \u0623\u062d\u0645\u062f\u061f\")\nchildren = query_knowledge_graph(knowledge_graph, 'Ahmed', 'is_parent_of')\nprint(f\"  Answer: {children}\")\n\n# Who is Sara's sibling?\nprint(\"\\nWho is Sara's sibling?\n\u0645\u0646 \u0647\u0648 \u0634\u0642\u064a\u0642 \u0633\u0627\u0631\u0629\u061f\")\nsiblings = query_knowledge_graph(knowledge_graph, 'Sara', 'is_sibling_of')\nprint(f\"  Answer: {siblings}\")\n\n# All relationships for Fatima\nprint(\"\\nAll relationships for Fatima\n\u062c\u0645\u064a\u0639 \u0639\u0644\u0627\u0642\u0627\u062a \u0641\u0627\u0637\u0645\u0629:\")\nrelationships = find_all_relationships(knowledge_graph, 'Fatima')\nfor rel_type, rel_value in relationships.items():\n    print(f\"  {rel_type}: {rel_value}\")\n\n# Rule-Based System Example\nprint(\"\\n\" + \"=\" * 60)\nprint(\"2. Rule-Based System\")\nprint(\"\u0646\u0638\u0627\u0645 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\")\nprint(\"=\" * 60)\n\n# Rules for determining if someone can drive\n# \u0642\u0648\u0627\u0639\u062f \u0644\u062a\u062d\u062f\u064a\u062f \u0645\u0627 \u0625\u0630\u0627 \u0643\u0627\u0646 \u0634\u062e\u0635 \u0645\u0627 \u064a\u0645\u0643\u0646\u0647 \u0627\u0644\u0642\u064a\u0627\u062f\u0629\ndef can_drive(person, graph):\n    \"\"\"\n    Rule-based system: Can person drive?\n    \u0646\u0638\u0627\u0645 \u0642\u0627\u0626\u0645 \u0639\u0644\u0649 \u0627\u0644\u0642\u0648\u0627\u0639\u062f: \u0647\u0644 \u064a\u0645\u0643\u0646 \u0644\u0644\u0634\u062e\u0635 \u0627\u0644\u0642\u064a\u0627\u062f\u0629\u061f\n    \"\"\"\n    if person not in graph:\n        return False, \"Person not found\"\n    \n    age = graph[person].get('age', 0)\n    profession = graph[person].get('profession', '')\n    \n    # Rule 1: Must be 18 or older\n    if age < 18:\n        return False, \"Too young to drive (must be 18+)\"\n    \n    # Rule 2: Must not be a student (simplified rule)\n    if profession == 'Student':\n        return False, \"Students need special permit\"\n    \n    # Rule 3: If 18+ and not student, can drive\n    return True, \"Can drive\"\n\n# Test rules\nprint(\"\\nTesting driving rules:\")\nfor person in knowledge_graph.keys():\n    can_drive_result, reason = can_drive(person, knowledge_graph)\n    status = \"\u2713 Can drive\" if can_drive_result else \"\u2717 Cannot drive\"\n    print(f\"\\n{person} (age {knowledge_graph[person]['age']}):\")\n    print(f\"  {status} - {reason}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 80\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\nWho are Ahmed's children?\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 80)\n\n\n",
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/02_rule_based_systems.ipynb",
      "status": "failed",
      "execution_time": 0.6021640300750732,
      "error": "An error occurred while executing the following cell:\n------------------\n# Rule-based system structure\nclass Rule:\n    def__init__(self, condition, conclusion):\n        self.condition = condition\n        self.conclusion = conclusion\n    \n    def matches(self, facts):\n        # TODO: Check if condition matches facts\n        pass\n\n# Example rules\nrules = [\n    Rule('fever AND cough', 'flu'),\n    Rule('fever AND rash', 'measles'),\n]\n\nprint('Rules defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, condition, conclusion):\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Rule-based system structure\nclass Rule:\n    def__init__(self, condition, conclusion):\n        self.condition = condition\n        self.conclusion = conclusion\n    \n    def matches(self, facts):\n        # TODO: Check if condition matches facts\n        pass\n\n# Example rules\nrules = [\n    Rule('fever AND cough', 'flu'),\n    Rule('fever AND rash', 'measles'),\n]\n\nprint('Rules defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, condition, conclusion):\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/03_expert_systems.ipynb",
      "status": "failed",
      "execution_time": 0.61794114112854,
      "error": "An error occurred while executing the following cell:\n------------------\n# Expert system structure\nclass ExpertSystem:\n    def__init__(self, knowledge_base, inference_engine):\n        self.knowledge_base = knowledge_base\n        self.inference_engine = inference_engine\n    \n    def query(self, question):\n        # TODO: Process query using inference engine\n        pass\n\nprint('Expert system structure defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, knowledge_base, inference_engine):\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Expert system structure\nclass ExpertSystem:\n    def__init__(self, knowledge_base, inference_engine):\n        self.knowledge_base = knowledge_base\n        self.inference_engine = inference_engine\n    \n    def query(self, question):\n        # TODO: Process query using inference engine\n        pass\n\nprint('Expert system structure defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, knowledge_base, inference_engine):\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/04_regression_classification.ipynb",
      "status": "passed",
      "execution_time": 1.5568556785583496,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/05_perceptron_xor.ipynb",
      "status": "failed",
      "execution_time": 2.554097890853882,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\n\nprint(\"=== The Neuron and Perceptron ===\")\nprint(\"\\nNeuron Structure:\")\nprint(\"  - Inputs (x\u2081, x\u2082, ..., x\u2099)\")\nprint(\"  - Weights (w\u2081, w\u2082, ..., w\u2099)\")\nprint(\"  - Bias (b)\")\nprint(\"  - Activation function (\u03c3)\")\nprint(\"  - Output: \u03c3(\u03a3(w\u1d62\u00b7x\u1d62) + b)\")\n\nprint(\"\\nActivation Functions:\")\nprint(\"  - Sigmoid: \u03c3(x) = 1/(1+e\u207b\u02e3)\")\nprint(\"  - ReLU: f(x) = max(0, x)\")\nprint(\"  - Tanh: tanh(x)\")\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\n\nprint(\"=== The Neuron and Perceptron ===\")\nprint(\"\\nNeuron Structure:\")\nprint(\"  - Inputs (x\u2081, x\u2082, ..., x\u2099)\")\nprint(\"  - Weights (w\u2081, w\u2082, ..., w\u2099)\")\nprint(\"  - Bias (b)\")\nprint(\"  - Activation function (\u03c3)\")\nprint(\"  - Output: \u03c3(\u03a3(w\u1d62\u00b7x\u1d62) + b)\")\n\nprint(\"\\nActivation Functions:\")\nprint(\"  - Sigmoid: \u03c3(x) = 1/(1+e\u207b\u02e3)\")\nprint(\"  - ReLU: f(x) = max(0, x)\")\nprint(\"  - Tanh: tanh(x)\")\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.6799228191375732,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6076130867004395,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "other"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/04_implementing_regression_classification.ipynb",
      "status": "passed",
      "execution_time": 1.5163559913635254,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/04_xor_problem_neural_network.ipynb",
      "status": "passed",
      "execution_time": 0.7693634033203125,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/05_solving_xor_keras.ipynb",
      "status": "failed",
      "execution_time": 1.858454942703247,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSolving XOR Problem with Keras\")\nprint(\"=\" * 60)\n\n# XOR truth table\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([[0], [1], [1], [0]])\n\nprint(\"\\nXOR Truth Table:\")\nprint(\"Input | Output\")\nprint(\"------|-------\")\nfor i in range(len(X)):\n    print(f\"{X[i]} | {y[i][0]}\")\n\nprint(\"\\n\u2705 XOR data prepared!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSolving XOR Problem with Keras\")\nprint(\"=\" * 60)\n\n# XOR truth table\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([[0], [1], [1], [0]])\n\nprint(\"\\nXOR Truth Table:\")\nprint(\"Input | Output\")\nprint(\"------|-------\")\nfor i in range(len(X)):\n    print(f\"{X[i]} | {y[i][0]}\")\n\nprint(\"\\n\u2705 XOR data prepared!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/05_single_neuron_activation_functions.ipynb",
      "status": "passed",
      "execution_time": 0.778965950012207,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/06_multiclass_classification_keras.ipynb",
      "status": "passed",
      "execution_time": 0.7401127815246582,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/07_cnn_image_classification.ipynb",
      "status": "passed",
      "execution_time": 0.6940610408782959,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/08_rnn_lstm_gru_sequential.ipynb",
      "status": "passed",
      "execution_time": 0.667917013168335,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/09_early_stopping_regularization.ipynb",
      "status": "passed",
      "execution_time": 0.8046040534973145,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/01_simple_perceptron.ipynb",
      "status": "failed",
      "execution_time": 0.7342660427093506,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Example 1: Simple Perceptron\n\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0627\u0644\u0628\u0633\u064a\u0637\n\nThis example demonstrates:\n1. Perceptron implementation\n2. Training a perceptron\n3. Binary classification\n4. Decision boundary visualization\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"Example 1: Simple Perceptron\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0627\u0644\u0628\u0633\u064a\u0637\")\nprint(\"=\" * 60)\n\nclass SimplePerceptron:\n    \"\"\"\n    Simple Perceptron for binary classification.\n    \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u062b\u0646\u0627\u0626\u064a.\n    \"\"\"\n    \n    def__init__(self, learning_rate=0.1, epochs=100):\n        \"\"\"\n        Initialize perceptron.\n        \u062a\u0647\u064a\u0626\u0629 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646.\n        \n        Args:\n            learning_rate: Learning rate (default: 0.1)\n            epochs: Number of training iterations (default: 100)\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.weights = None\n        self.bias = None\n    \n    def activation(self, x):\n        \"\"\"\n        Step activation function.\n        \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u062e\u0637\u0648\u0629.\n        \n        Returns 1 if x >= 0, else 0\n        \"\"\"\n        return 1 if x >= 0 else 0\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the perceptron.\n        \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646.\n        \n        Args:\n            X: Input features (n_samples, n_features)\n            y: Target labels (0 or 1)\n        \"\"\"\n        n_samples, n_features = X.shape\n        \n        # Initialize weights and bias\n        # \u062a\u0647\u064a\u0626\u0629 \u0627\u0644\u0623\u0648\u0632\u0627\u0646 \u0648\u0627\u0644\u0627\u0646\u062d\u064a\u0627\u0632\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        \n        print(\"\\nTraining Perceptron...\")\n        print(\"\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646...\")\n        \n        for epoch in range(self.epochs):\n            errors = 0\n            for i in range(n_samples):\n                # Forward pass\n                # \u0627\u0644\u0645\u0631\u0648\u0631 \u0627\u0644\u0623\u0645\u0627\u0645\u064a\n                linear_output = np.dot(X[i], self.weights) + self.bias\n                prediction = self.activation(linear_output)\n                \n                # Update weights if prediction is wrong\n                # \u062a\u062d\u062f\u064a\u062b \u0627\u0644\u0623\u0648\u0632\u0627\u0646 \u0625\u0630\u0627 \u0643\u0627\u0646\u062a \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u062e\u0627\u0637\u0626\u0629\n                error = y[i] - prediction\n                if error != 0:\n                    errors += 1\n                    self.weights += self.learning_rate * error * X[i]\n                    self.bias += self.learning_rate * error\n            \n            if errors == 0:\n                print(f\"  Converged at epoch {epoch + 1}\")\n                print(f\"  \u062a\u0642\u0627\u0631\u0628 \u0641\u064a \u0627\u0644\u0639\u0635\u0631 {epoch + 1}\")\n                break\n            \n            if (epoch + 1) % 10 == 0:\n                print(f\"  Epoch {epoch + 1}: {errors} errors\")\n        \n        print(f\"\\nTraining complete!\")\n        print(f\"\u062a\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628!\")\n        print(f\"Final weights: {self.weights}\")\n        print(f\"Final bias: {self.bias}\")\n    \n    def predict(self, X):\n        \"\"\"\n        Make predictions.\n        \u0639\u0645\u0644 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a.\n        \"\"\"\n        predictions = []\n        for i in range(len(X)):\n            linear_output = np.dot(X[i], self.weights) + self.bias\n            predictions.append(self.activation(linear_output))\n        return np.array(predictions)\n\n# Example: AND Gate\n# \u0645\u062b\u0627\u0644: \u0628\u0648\u0627\u0628\u0629 AND\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example: AND Gate Classification\")\nprint(\"\u0645\u062b\u0627\u0644: \u062a\u0635\u0646\u064a\u0641 \u0628\u0648\u0627\u0628\u0629 AND\")\nprint(\"=\" * 60)\n\n# Training data for AND gate\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 AND\nX = np.array([\n    [0, 0],\n    [0, 1],\n    [1, 0],\n    [1, 1]\n])\n\ny = np.array([0, 0, 0, 1])  # AND gate output\n\nprint(\"\\nTraining Data:\")\nprint(\"\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628:\")\nprint(\"Input | Output\")\nprint(\"------|-------\")\nfor i in range(len(X)):\n    print(f\"{X[i]}  |   {y[i]}\")\n\n# Create and train perceptron\n# \u0625\u0646\u0634\u0627\u0621 \u0648\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646\nperceptron = SimplePerceptron(learning_rate=0.1, epochs=100)\nperceptron.fit(X, y)\n\n# Test the perceptron\n# \u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Testing Perceptron\")\nprint(\"\u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646\")\nprint(\"=\" * 60)\n\npredictions = perceptron.predict(X)\nprint(\"\\nPredictions:\")\nprint(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a:\")\nprint(\"Input | Expected | Predicted | Correct\")\nprint(\"------|----------|-----------|--------\")\nfor i in range(len(X)):\n    correct = \"\u2713\" if predictions[i] == y[i] else \"\u2717\"\n    print(f\"{X[i]}  |    {y[i]}     |     {predictions[i]}     |   {correct}\")\n\naccuracy = np.mean(predictions == y) * 100\nprint(f\"\\nAccuracy: {accuracy}%\")\nprint(f\"\u0627\u0644\u062f\u0642\u0629: {accuracy}%\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.1, epochs=100):\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Example 1: Simple Perceptron\n\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0627\u0644\u0628\u0633\u064a\u0637\n\nThis example demonstrates:\n1. Perceptron implementation\n2. Training a perceptron\n3. Binary classification\n4. Decision boundary visualization\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"Example 1: Simple Perceptron\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0627\u0644\u0628\u0633\u064a\u0637\")\nprint(\"=\" * 60)\n\nclass SimplePerceptron:\n    \"\"\"\n    Simple Perceptron for binary classification.\n    \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u062b\u0646\u0627\u0626\u064a.\n    \"\"\"\n    \n    def__init__(self, learning_rate=0.1, epochs=100):\n        \"\"\"\n        Initialize perceptron.\n        \u062a\u0647\u064a\u0626\u0629 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646.\n        \n        Args:\n            learning_rate: Learning rate (default: 0.1)\n            epochs: Number of training iterations (default: 100)\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.weights = None\n        self.bias = None\n    \n    def activation(self, x):\n        \"\"\"\n        Step activation function.\n        \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u062e\u0637\u0648\u0629.\n        \n        Returns 1 if x >= 0, else 0\n        \"\"\"\n        return 1 if x >= 0 else 0\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the perceptron.\n        \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646.\n        \n        Args:\n            X: Input features (n_samples, n_features)\n            y: Target labels (0 or 1)\n        \"\"\"\n        n_samples, n_features = X.shape\n        \n        # Initialize weights and bias\n        # \u062a\u0647\u064a\u0626\u0629 \u0627\u0644\u0623\u0648\u0632\u0627\u0646 \u0648\u0627\u0644\u0627\u0646\u062d\u064a\u0627\u0632\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        \n        print(\"\\nTraining Perceptron...\")\n        print(\"\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646...\")\n        \n        for epoch in range(self.epochs):\n            errors = 0\n            for i in range(n_samples):\n                # Forward pass\n                # \u0627\u0644\u0645\u0631\u0648\u0631 \u0627\u0644\u0623\u0645\u0627\u0645\u064a\n                linear_output = np.dot(X[i], self.weights) + self.bias\n                prediction = self.activation(linear_output)\n                \n                # Update weights if prediction is wrong\n                # \u062a\u062d\u062f\u064a\u062b \u0627\u0644\u0623\u0648\u0632\u0627\u0646 \u0625\u0630\u0627 \u0643\u0627\u0646\u062a \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u062e\u0627\u0637\u0626\u0629\n                error = y[i] - prediction\n                if error != 0:\n                    errors += 1\n                    self.weights += self.learning_rate * error * X[i]\n                    self.bias += self.learning_rate * error\n            \n            if errors == 0:\n                print(f\"  Converged at epoch {epoch + 1}\")\n                print(f\"  \u062a\u0642\u0627\u0631\u0628 \u0641\u064a \u0627\u0644\u0639\u0635\u0631 {epoch + 1}\")\n                break\n            \n            if (epoch + 1) % 10 == 0:\n                print(f\"  Epoch {epoch + 1}: {errors} errors\")\n        \n        print(f\"\\nTraining complete!\")\n        print(f\"\u062a\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628!\")\n        print(f\"Final weights: {self.weights}\")\n        print(f\"Final bias: {self.bias}\")\n    \n    def predict(self, X):\n        \"\"\"\n        Make predictions.\n        \u0639\u0645\u0644 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a.\n        \"\"\"\n        predictions = []\n        for i in range(len(X)):\n            linear_output = np.dot(X[i], self.weights) + self.bias\n            predictions.append(self.activation(linear_output))\n        return np.array(predictions)\n\n# Example: AND Gate\n# \u0645\u062b\u0627\u0644: \u0628\u0648\u0627\u0628\u0629 AND\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example: AND Gate Classification\")\nprint(\"\u0645\u062b\u0627\u0644: \u062a\u0635\u0646\u064a\u0641 \u0628\u0648\u0627\u0628\u0629 AND\")\nprint(\"=\" * 60)\n\n# Training data for AND gate\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 AND\nX = np.array([\n    [0, 0],\n    [0, 1],\n    [1, 0],\n    [1, 1]\n])\n\ny = np.array([0, 0, 0, 1])  # AND gate output\n\nprint(\"\\nTraining Data:\")\nprint(\"\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628:\")\nprint(\"Input | Output\")\nprint(\"------|-------\")\nfor i in range(len(X)):\n    print(f\"{X[i]}  |   {y[i]}\")\n\n# Create and train perceptron\n# \u0625\u0646\u0634\u0627\u0621 \u0648\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646\nperceptron = SimplePerceptron(learning_rate=0.1, epochs=100)\nperceptron.fit(X, y)\n\n# Test the perceptron\n# \u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Testing Perceptron\")\nprint(\"\u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646\")\nprint(\"=\" * 60)\n\npredictions = perceptron.predict(X)\nprint(\"\\nPredictions:\")\nprint(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a:\")\nprint(\"Input | Expected | Predicted | Correct\")\nprint(\"------|----------|-----------|--------\")\nfor i in range(len(X)):\n    correct = \"\u2713\" if predictions[i] == y[i] else \"\u2717\"\n    print(f\"{X[i]}  |    {y[i]}     |     {predictions[i]}     |   {correct}\")\n\naccuracy = np.mean(predictions == y) * 100\nprint(f\"\\nAccuracy: {accuracy}%\")\nprint(f\"\u0627\u0644\u062f\u0642\u0629: {accuracy}%\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.1, epochs=100):\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/02_generative_ai_intro.ipynb",
      "status": "passed",
      "execution_time": 0.8207120895385742,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/03_cnn_rnn_architectures.ipynb",
      "status": "failed",
      "execution_time": 1.6753592491149902,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, GRU, SimpleRNN\nfrom tensorflow.keras.datasets import mnist\n\nprint(\"=== Deep Learning Architectures ===\")\nprint(\"\\n1. CNN (Convolutional Neural Network):\")\nprint(\"   - Best for: Images, spatial data\")\nprint(\"   - Components: Convolution, Pooling, Fully Connected\")\nprint(\"   - Applications: Image classification, object detection\")\n\nprint(\"\\n2. RNN (Recurrent Neural Network):\")\nprint(\"   - Best for: Sequential data, time series\")\nprint(\"   - Components: Recurrent layers, memory\")\nprint(\"   - Applications: Text, speech, time series\")\n\nprint(\"\\n3. LSTM (Long Short-Term Memory):\")\nprint(\"   - Advanced RNN with long-term memory\")\nprint(\"   - Solves vanishing gradient problem\")\n\nprint(\"\\n4. GRU (Gated Recurrent Unit):\")\nprint(\"   - Simpler than LSTM, similar performance\")\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, LSTM, GRU, SimpleRNN\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, GRU, SimpleRNN\nfrom tensorflow.keras.datasets import mnist\n\nprint(\"=== Deep Learning Architectures ===\")\nprint(\"\\n1. CNN (Convolutional Neural Network):\")\nprint(\"   - Best for: Images, spatial data\")\nprint(\"   - Components: Convolution, Pooling, Fully Connected\")\nprint(\"   - Applications: Image classification, object detection\")\n\nprint(\"\\n2. RNN (Recurrent Neural Network):\")\nprint(\"   - Best for: Sequential data, time series\")\nprint(\"   - Components: Recurrent layers, memory\")\nprint(\"   - Applications: Text, speech, time series\")\n\nprint(\"\\n3. LSTM (Long Short-Term Memory):\")\nprint(\"   - Advanced RNN with long-term memory\")\nprint(\"   - Solves vanishing gradient problem\")\n\nprint(\"\\n4. GRU (Gated Recurrent Unit):\")\nprint(\"   - Simpler than LSTM, similar performance\")\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, LSTM, GRU, SimpleRNN\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/applying_early_stopping_and_regularization_to_prevent_overfitting.ipynb",
      "status": "passed",
      "execution_time": 1.295206069946289,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/building_a_multi_class_classification_model_with_keras.ipynb",
      "status": "passed",
      "execution_time": 1.5096900463104248,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/experimenting_with_rnn_lstm_gru_for_sequential_data.ipynb",
      "status": "passed",
      "execution_time": 1.4044511318206787,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/implementing_a_cnn_for_image_classification_using_tensorflowkeras.ipynb",
      "status": "passed",
      "execution_time": 1.3348908424377441,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/implementing_a_single_neuron_with_different_activation_functions_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.7031540870666504,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5292642116546631,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 1: Neural Networks Basics\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\nComplete the following exercises.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Implement Activation Function\ns\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637p\nrint(\"Exercise 1: Activation Functions\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\nprint(\"-\" * 60)\n\ndef sigmoid(x):\n \n    \n    \"\"\"\n TODO: Implement sigmoid activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n \n Formula: 1\n(1 + e^(-x))\n \"\"\"\n # TODO: Implement sigmoi\nd\n pass\n\ndef relu(x):\n \n    \n    \"\"\"\n TODO: Implement ReLU activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n \n Formula: max(0, x)\n \"\"\"\n # TODO: Implement ReLU\n pass\n\n# Test activation function\nst\nest_values = [-2, -1, 0, 1, 2]\nprint(\"\\nTesting activation functions:\")\nfor x in test_values:\n sig_result = sigmoid(x)\n relu_result = relu(x)\n print(f\"x={x:3d}: sigmoid={sig_result:.3f}, ReLU={relu_result:.3f}\")\n\n# Exercise 2: Simple Perceptron for OR Gate\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: OR Gate Perceptron\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\nprint(\"=\" * 60)\n\n# TODO: Create training data for OR gate\n# TODO: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nX_or = np.array([\n # TODO: Add OR gate inputs\n])\n\ny_or = np.array([\n # TODO: Add OR gate output\ns\n])\n\n# TODO: Train a perceptron to learn OR gate\n# TODO: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:41\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 1: Neural Networks Basics\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\nComplete the following exercises.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Implement Activation Function\ns\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637p\nrint(\"Exercise 1: Activation Functions\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\nprint(\"-\" * 60)\n\ndef sigmoid(x):\n \n    \n    \"\"\"\n TODO: Implement sigmoid activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n \n Formula: 1\n(1 + e^(-x))\n \"\"\"\n # TODO: Implement sigmoi\nd\n pass\n\ndef relu(x):\n \n    \n    \"\"\"\n TODO: Implement ReLU activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n \n Formula: max(0, x)\n \"\"\"\n # TODO: Implement ReLU\n pass\n\n# Test activation function\nst\nest_values = [-2, -1, 0, 1, 2]\nprint(\"\\nTesting activation functions:\")\nfor x in test_values:\n sig_result = sigmoid(x)\n relu_result = relu(x)\n print(f\"x={x:3d}: sigmoid={sig_result:.3f}, ReLU={relu_result:.3f}\")\n\n# Exercise 2: Simple Perceptron for OR Gate\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: OR Gate Perceptron\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\nprint(\"=\" * 60)\n\n# TODO: Create training data for OR gate\n# TODO: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nX_or = np.array([\n # TODO: Add OR gate inputs\n])\n\ny_or = np.array([\n # TODO: Add OR gate output\ns\n])\n\n# TODO: Train a perceptron to learn OR gate\n# TODO: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:41\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7587790489196777,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"\n# Unit 4 - Exercise 1: Neural Networks Basics\n# \u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n# \n# Complete the following exercises.\n# \u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n# \"\"\"\n# \n# import numpy as np\n# \n# # Exercise 1: Implement Activation Functions\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\n# print(\"Exercise 1: Activation Functions\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\n# print(\"-\" * 60)\n# \n# def sigmoid(x):\n#     \"\"\"\n#     # SOLUTION: Implement sigmoid activation function.\n#     # SOLUTION: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n#     \n#     Formula: 1\n(1 + e^(-x))\n#     \"\"\"\n#     # # SOLUTION: Implement sigmoid\n#     pass\n# \n# def relu(x):\n#     \"\"\"\n#     # SOLUTION: Implement ReLU activation function.\n#     # SOLUTION: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n#     \n#     Formula: max(0, x)\n#     \"\"\"\n#     # # SOLUTION: Implement ReLU\n#     pass\n# \n# # Test activation functions\n# test_values = [-2, -1, 0, 1, 2]\n# print(\"\\nTesting activation functions:\")\n# for x in test_values:\n#     sig_result = sigmoid(x)\n#     relu_result = relu(x)\n#     print(f\"x={x:3d}: sigmoid={sig_result:.3f}, ReLU={relu_result:.3f}\")\n# \n# # Exercise 2: Simple Perceptron for OR Gate\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\n# print(\"\\n\" + \"=\" * 60)\n# print(\"Exercise 2: OR Gate Perceptron\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\n# print(\"=\" * 60)\n# \n# # # SOLUTION: Create training data for OR gate\n# # # SOLUTION: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\n# X_or = np.array([\n#     # # SOLUTION: Add OR gate inputs\n# ])\n# \n# y_or = np.array([\n#     # # SOLUTION: Add OR gate outputs\n# ])\n# \n# # # SOLUTION: Train a perceptron to learn OR gate\n# # # SOLUTION: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n# \n# print(\"\\n\" + \"=\" * 60)\n# print(\"Exercises completed! Check solutions/ folder.\")\n# print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\n# print(\"=\" * 60)\n# \n# \n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Complete solution:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Unit 4 - Exercise 1: Neural Networks Basics\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     Formula: 1\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m e\u001b[38;5;241m^\u001b[39m(\u001b[38;5;241m-\u001b[39mx))\n\n\u001b[0;31mNameError\u001b[0m: name 'e' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"\n# Unit 4 - Exercise 1: Neural Networks Basics\n# \u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n# \n# Complete the following exercises.\n# \u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n# \"\"\"\n# \n# import numpy as np\n# \n# # Exercise 1: Implement Activation Functions\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\n# print(\"Exercise 1: Activation Functions\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\n# print(\"-\" * 60)\n# \n# def sigmoid(x):\n#     \"\"\"\n#     # SOLUTION: Implement sigmoid activation function.\n#     # SOLUTION: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n#     \n#     Formula: 1\n(1 + e^(-x))\n#     \"\"\"\n#     # # SOLUTION: Implement sigmoid\n#     pass\n# \n# def relu(x):\n#     \"\"\"\n#     # SOLUTION: Implement ReLU activation function.\n#     # SOLUTION: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n#     \n#     Formula: max(0, x)\n#     \"\"\"\n#     # # SOLUTION: Implement ReLU\n#     pass\n# \n# # Test activation functions\n# test_values = [-2, -1, 0, 1, 2]\n# print(\"\\nTesting activation functions:\")\n# for x in test_values:\n#     sig_result = sigmoid(x)\n#     relu_result = relu(x)\n#     print(f\"x={x:3d}: sigmoid={sig_result:.3f}, ReLU={relu_result:.3f}\")\n# \n# # Exercise 2: Simple Perceptron for OR Gate\n# # \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\n# print(\"\\n\" + \"=\" * 60)\n# print(\"Exercise 2: OR Gate Perceptron\")\n# print(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\n# print(\"=\" * 60)\n# \n# # # SOLUTION: Create training data for OR gate\n# # # SOLUTION: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\n# X_or = np.array([\n#     # # SOLUTION: Add OR gate inputs\n# ])\n# \n# y_or = np.array([\n#     # # SOLUTION: Add OR gate outputs\n# ])\n# \n# # # SOLUTION: Train a perceptron to learn OR gate\n# # # SOLUTION: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n# \n# print(\"\\n\" + \"=\" * 60)\n# print(\"Exercises completed! Check solutions/ folder.\")\n# print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\n# print(\"=\" * 60)\n# \n# \n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Complete solution:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Unit 4 - Exercise 1: Neural Networks Basics\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     Formula: 1\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m e\u001b[38;5;241m^\u001b[39m(\u001b[38;5;241m-\u001b[39mx))\n\n\u001b[0;31mNameError\u001b[0m: name 'e' is not defined\n\n",
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "other"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/04_gan_transformer_generative.ipynb",
      "status": "passed",
      "execution_time": 0.6500532627105713,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/05_eda_data_preprocessing_medical.ipynb",
      "status": "passed",
      "execution_time": 1.5768020153045654,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/06_feature_scaling_encoding_missing_data.ipynb",
      "status": "passed",
      "execution_time": 1.5660090446472168,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/01_generative_ai_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.7746596336364746,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/02_generative_vs_discriminative.ipynb",
      "status": "passed",
      "execution_time": 1.8830668926239014,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/03_course_summary.ipynb",
      "status": "passed",
      "execution_time": 0.6395251750946045,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/04_diabetes_classification_ffnn.ipynb",
      "status": "failed",
      "execution_time": 0.7339661121368408,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nprint(\"=== Binary Classification Metrics ===\")\nprint(\"\\nMetrics for evaluating binary classification:\")\nprint(\" - Accuracy: (TP + TN)\n(TP + TN + FP + FN)\")\nprint(\" - Precision: TP\n(TP + FP) - How many predicted positives are actually positive?\")\nprint(\" - Recall: TP\n(TP + FN) - How many actual positives did we catch?\")\nprint(\" - F1-score: 2 * (Precision * Recall)\n(Precision + Recall) - Harmonic mean\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" - Accuracy: (TP + TN)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 13)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nprint(\"=== Binary Classification Metrics ===\")\nprint(\"\\nMetrics for evaluating binary classification:\")\nprint(\" - Accuracy: (TP + TN)\n(TP + TN + FP + FN)\")\nprint(\" - Precision: TP\n(TP + FP) - How many predicted positives are actually positive?\")\nprint(\" - Recall: TP\n(TP + FN) - How many actual positives did we catch?\")\nprint(\" - F1-score: 2 * (Precision * Recall)\n(Precision + Recall) - Harmonic mean\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" - Accuracy: (TP + TN)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 13)\n\n\n",
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/developing_simple_supervised_and_unsupervised_learning_models.ipynb",
      "status": "passed",
      "execution_time": 1.5287871360778809,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/eda_and_data_preprocessing_for_medical_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.6586439609527588,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/encoding_categorical_features_for_ml_models.ipynb",
      "status": "passed",
      "execution_time": 1.4191088676452637,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/exploring_the_data_generation_process_using_python_and_pandas.ipynb",
      "status": "passed",
      "execution_time": 1.564004898071289,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/implementing_a_simple_expert_system_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.5545389652252197,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/implementing_feature_scaling_encoding_and_handling_missing_data_in_a_medical_dat.ipynb",
      "status": "passed",
      "execution_time": 1.6404170989990234,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/solving_the_xor_problem_using_a_neural_network_in_keras.ipynb",
      "status": "passed",
      "execution_time": 1.4011991024017334,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/exercises/01_generative_ai_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.8844089508056641,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/solutions/01_generative_ai_solution.ipynb",
      "status": "failed",
      "execution_time": 1.1055119037628174,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Solution 1: Generative AI Concepts\n\u0627\u0644\u0648\u062d\u062f\u0629 5 - \u062d\u0644 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\n\nComplete solutions to Exercise 1.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt_\nprint(\"=\" * 70)\nprint(\"Solution 1: Generative AI Concepts\")\nprint(\"=\" * 70)\n\n# Solution 1: Identify Model Types_\nprint(\"\\nSolution 1: Identify Model Types\")\nprint(\"-\" * 70)\n\nmodels = {\n    \"Logistic Regression\": \"D\",  # Discriminative - learns P(Y|X)\n    \"GAN (Generative Adversarial Network)\": \"G\",  # Generative - creates new data\n    \"Support Vector Machine\": \"D\",  # Discriminative - learns decision boundary\n    \"VAE (Variational Autoencoder)\": \"G\",  # Generative - learns data distribution\n    \"Neural Network Classifier\": \"D\",  # Discriminative - learns P(Y|X)\n    \"Naive Bayes\": \"G\"  # Generative - learns P(X|Y) and P(Y)\n}\n\nfor model, answer in models.items():\n    print(f\"{model}: {answer}\")\n\n# Solution 2: Generate Synthetic Data_\nprint(\"\\nSolution 2: Generate Synthetic Data\")\nprint(\"-\" * 70)\n\ndef generate_square_pattern(n_points=100):\n    \n    \n    \n    \"\"\"\n    Generate synthetic data points forming a square pattern.\n    \"\"\"\n    # Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\n    \n    # Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\n    y_top = np.full(points_per_side, side_length/2)\n    \n    # Right side_x_right = np.full(points_per_side, side_length/2)\n    y_right = np.linspace(side_length/2, -side_length/2, points_per_side)\n    \n    # Bottom side_x_bottom = np.linspace(side_length/2, -side_length/2, points_per_side)\n    y_bottom = np.full(points_per_side, -side_length/2)\n    \n    # Left side_x_left = np.full(points_per_side, -side_length/2)\n    y_left = np.linspace(-side_length/2, side_length/2, points_per_side)\n    \n    # Combine and add noise_x = np.concatenate([x_top, x_right, x_bottom, x_left])\n    y = np.concatenate([y_top, y_right, y_bottom, y_left])\n    \n    # Add noise to make it more realistic\n    x += np.random.normal(0, 0.1, len(x))\n    y += np.random.normal(0, 0.1, len(y))\n    \n    return x, y\n\n# Test and visualize\nx_square, y_square = generate_square_pattern(200)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_square, y_square, alpha=0.6, s=30)\nplt.title('Generated Square Pattern\\n(Solution)', fontsize=12)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.show()\n\nprint(\"\u2705 Square pattern generated successfully!\")\n\n# Solution 3: Compare Approaches_\nprint(\"\\nSolution 3: Compare Generative vs Discriminative\")\nprint(\"-\" * 70)\n\ncomparison = {\n    \"What does it learn?\": {\n        \"Generative\": \"P(X|Y) and P(Y) - Joint probability distribution\", \"Discriminative\": \"P(Y|X) - Conditional probability\"\n    },\n    \"Can it generate new data?\": {\n        \"Generative\": True,\n        \"Discriminative\": False\n    },\n    \"Best use case\": {\n        \"Generative\": \"Image generation, data augmentation, anomaly detection\",\n        \"Discriminative\": \"Classification, prediction, spam detection\"\n    }\n}\n\nfor question, answers in comparison.items():\n    print(f\"\\n{question}\")\n    for model_type, answer in answers.items():\n        print(f\"  {model_type}: {answer}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\u2705 All exercises completed!\")\nprint(\"=\" * 70)\n\n------------------\n\n----- stdout -----\n======================================================================\nSolution 1: Generative AI Concepts\n======================================================================\n\nSolution 1: Identify Model Types\n----------------------------------------------------------------------\nLogistic Regression: D\nGAN (Generative Adversarial Network): G\nSupport Vector Machine: D\nVAE (Variational Autoencoder): G\nNeural Network Classifier: D\nNaive Bayes: G\n\nSolution 2: Generate Synthetic Data\n----------------------------------------------------------------------\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Test and visualize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m x_square, y_square \u001b[38;5;241m=\u001b[39m generate_square_pattern(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_square, y_square, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mgenerate_square_pattern\u001b[0;34m(n_points)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mGenerate synthetic data points forming a square pattern.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m y_top \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(points_per_side, side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Right side_x_right = np.full(points_per_side, side_length/2)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39mside_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, points_per_side)\n\n\u001b[0;31mNameError\u001b[0m: name 'points_per_side' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Solution 1: Generative AI Concepts\n\u0627\u0644\u0648\u062d\u062f\u0629 5 - \u062d\u0644 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\n\nComplete solutions to Exercise 1.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt_\nprint(\"=\" * 70)\nprint(\"Solution 1: Generative AI Concepts\")\nprint(\"=\" * 70)\n\n# Solution 1: Identify Model Types_\nprint(\"\\nSolution 1: Identify Model Types\")\nprint(\"-\" * 70)\n\nmodels = {\n    \"Logistic Regression\": \"D\",  # Discriminative - learns P(Y|X)\n    \"GAN (Generative Adversarial Network)\": \"G\",  # Generative - creates new data\n    \"Support Vector Machine\": \"D\",  # Discriminative - learns decision boundary\n    \"VAE (Variational Autoencoder)\": \"G\",  # Generative - learns data distribution\n    \"Neural Network Classifier\": \"D\",  # Discriminative - learns P(Y|X)\n    \"Naive Bayes\": \"G\"  # Generative - learns P(X|Y) and P(Y)\n}\n\nfor model, answer in models.items():\n    print(f\"{model}: {answer}\")\n\n# Solution 2: Generate Synthetic Data_\nprint(\"\\nSolution 2: Generate Synthetic Data\")\nprint(\"-\" * 70)\n\ndef generate_square_pattern(n_points=100):\n    \n    \n    \n    \"\"\"\n    Generate synthetic data points forming a square pattern.\n    \"\"\"\n    # Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\n    \n    # Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\n    y_top = np.full(points_per_side, side_length/2)\n    \n    # Right side_x_right = np.full(points_per_side, side_length/2)\n    y_right = np.linspace(side_length/2, -side_length/2, points_per_side)\n    \n    # Bottom side_x_bottom = np.linspace(side_length/2, -side_length/2, points_per_side)\n    y_bottom = np.full(points_per_side, -side_length/2)\n    \n    # Left side_x_left = np.full(points_per_side, -side_length/2)\n    y_left = np.linspace(-side_length/2, side_length/2, points_per_side)\n    \n    # Combine and add noise_x = np.concatenate([x_top, x_right, x_bottom, x_left])\n    y = np.concatenate([y_top, y_right, y_bottom, y_left])\n    \n    # Add noise to make it more realistic\n    x += np.random.normal(0, 0.1, len(x))\n    y += np.random.normal(0, 0.1, len(y))\n    \n    return x, y\n\n# Test and visualize\nx_square, y_square = generate_square_pattern(200)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_square, y_square, alpha=0.6, s=30)\nplt.title('Generated Square Pattern\\n(Solution)', fontsize=12)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.show()\n\nprint(\"\u2705 Square pattern generated successfully!\")\n\n# Solution 3: Compare Approaches_\nprint(\"\\nSolution 3: Compare Generative vs Discriminative\")\nprint(\"-\" * 70)\n\ncomparison = {\n    \"What does it learn?\": {\n        \"Generative\": \"P(X|Y) and P(Y) - Joint probability distribution\", \"Discriminative\": \"P(Y|X) - Conditional probability\"\n    },\n    \"Can it generate new data?\": {\n        \"Generative\": True,\n        \"Discriminative\": False\n    },\n    \"Best use case\": {\n        \"Generative\": \"Image generation, data augmentation, anomaly detection\",\n        \"Discriminative\": \"Classification, prediction, spam detection\"\n    }\n}\n\nfor question, answers in comparison.items():\n    print(f\"\\n{question}\")\n    for model_type, answer in answers.items():\n        print(f\"  {model_type}: {answer}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\u2705 All exercises completed!\")\nprint(\"=\" * 70)\n\n------------------\n\n----- stdout -----\n======================================================================\nSolution 1: Generative AI Concepts\n======================================================================\n\nSolution 1: Identify Model Types\n----------------------------------------------------------------------\nLogistic Regression: D\nGAN (Generative Adversarial Network): G\nSupport Vector Machine: D\nVAE (Variational Autoencoder): G\nNeural Network Classifier: D\nNaive Bayes: G\n\nSolution 2: Generate Synthetic Data\n----------------------------------------------------------------------\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Test and visualize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m x_square, y_square \u001b[38;5;241m=\u001b[39m generate_square_pattern(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_square, y_square, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mgenerate_square_pattern\u001b[0;34m(n_points)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mGenerate synthetic data points forming a square pattern.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m y_top \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(points_per_side, side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Right side_x_right = np.full(points_per_side, side_length/2)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39mside_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, points_per_side)\n\n\u001b[0;31mNameError\u001b[0m: name 'points_per_side' is not defined\n\n",
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "other"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_01_search_algorithms_solution.ipynb",
      "status": "passed",
      "execution_time": 0.8346292972564697,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_02_knowledge_representation_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5717897415161133,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_03_probability_and_uncertainty_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5268821716308594,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_04_optimization_techniques_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6300392150878906,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_05_machine_learning_models_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6720361709594727,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_01_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.5247478485107422,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_02_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.7450911998748779,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_03_probability_and_uncertainty.ipynb",
      "status": "passed",
      "execution_time": 0.640099048614502,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_04_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.737097978591919,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_05_machine_learning_models.ipynb",
      "status": "passed",
      "execution_time": 0.5295612812042236,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/NOTEBOOKS/00_Python_Libraries_for_AI.ipynb",
      "status": "failed",
      "execution_time": 5.277387857437134,
      "error": "An error occurred while executing the following cell:\n------------------\n# \ud83d\udcda QUICK REFERENCE: NumPy Most Commonly Used Functions\n# Complete cheat sheet of functions you'll use in AI projects\n\nimport numpy as np\n\nprint(\"=\" * 70)\nprint(\"\ud83d\udcda NUMPY FUNCTION REFERENCE - Most Commonly Used Functions\")\nprint(\"=\" * 70)\nprint()\n\nprint(\"\ud83d\udd39 ARRAY CREATION:\")\nprint(\"   np.array([1, 2, 3])                    # Create from list\")\nprint(\"   np.zeros(5)                            # Array of zeros: [0, 0, 0, 0, 0]\")\nprint(\"   np.ones(5)                             # Array of ones: [1, 1, 1, 1, 1]\")\nprint(\"   np.arange(0, 10, 2)                    # Like range(): [0, 2, 4, 6, 8]\")\nprint(\"   np.linspace(0, 1, 5)                   # Evenly spaced: [0, 0.25, 0.5, 0.75, 1]\")\nprint(\"   np.empty((3, 3))                       # Uninitialized array (fast)\")\nprint(\"   np.full((2, 3), 7)                     # Array filled with value: all 7s\")\nprint(\"   np.eye(3)                              # Identity matrix (3x3)\")\nprint(\"   np.random.rand(5)                      # Random [0,1): 5 numbers\")\nprint(\"   np.random.randn(5)                     # Random normal: mean=0, std=1\")\nprint(\"   np.random.randint(0, 10, 5)            # Random integers: 5 numbers from [0,10)\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY PROPERTIES:\")\nprint(\"   arr.shape                              # Dimensions: (3, 4)\")\nprint(\"   arr.size                               # Total elements: 12\")\nprint(\"   arr.dtype                              # Data type: int64, float64\")\nprint(\"   arr.ndim                               # Number of dimensions: 2\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY OPERATIONS (Element-wise):\")\nprint(\"   arr1 + arr2                            # Addition\")\nprint(\"   arr1 - arr2                            # Subtraction\")\nprint(\"   arr1 * arr2                            # Multiplication\")\nprint(\"   arr1\narr2                            # Division\")\nprint(\"   arr ** 2                               # Power\")\nprint(\"   arr % 2                                # Modulo\")\nprint()\n\nprint(\"\ud83d\udd39 STATISTICAL FUNCTIONS:\")\nprint(\"   np.mean(arr)                           # Average value\")\nprint(\"   np.median(arr)                         # Median value\")\nprint(\"   np.std(arr)                            # Standard deviation\")\nprint(\"   np.var(arr)                            # Variance\")\nprint(\"   np.min(arr)                            # Minimum value\")\nprint(\"   np.max(arr)                            # Maximum value\")\nprint(\"   np.sum(arr)                            # Sum of all elements\")\nprint(\"   np.prod(arr)                           # Product of all elements\")\nprint(\"   np.percentile(arr, 75)                 # 75th percentile\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY MANIPULATION:\")\nprint(\"   arr.reshape(3, 4)                      # Reshape to 3x4\")\nprint(\"   arr.flatten()                          # Flatten to 1D\")\nprint(\"   np.concatenate([arr1, arr2])           # Join arrays\")\nprint(\"   np.split(arr, 3)                       # Split array into 3 parts\")\nprint(\"   arr.T                                  # Transpose\")\nprint(\"   np.sort(arr)                           # Sort array\")\nprint(\"   np.argsort(arr)                        # Indices that would sort\")\nprint()\n\nprint(\"\ud83d\udd39 INDEXING & SLICING:\")\nprint(\"   arr[0]                                 # First element\")\nprint(\"   arr[1:4]                               # Slice: elements 1,2,3\")\nprint(\"   arr[-1]                                # Last element\")\nprint(\"   arr[arr > 5]                           # Boolean indexing: elements > 5\")\nprint(\"   arr[[0, 2, 4]]                         # Fancy indexing: select indices\")\nprint()\n\nprint(\"\ud83d\udd39 MATRIX OPERATIONS:\")\nprint(\"   np.dot(A, B)                           # Matrix multiplication\")\nprint(\"   A @ B                                  # Matrix multiplication (Python 3.5+)\")\nprint(\"   np.linalg.inv(A)                       # Matrix inverse\")\nprint(\"   np.linalg.det(A)                       # Determinant\")\nprint(\"   np.linalg.eig(A)                       # Eigenvalues & eigenvectors\")\nprint()\n\nprint(\"\ud83d\udd39 MATH FUNCTIONS:\")\nprint(\"   np.sqrt(arr)                           # Square root\")\nprint(\"   np.exp(arr)                            # Exponential\")\nprint(\"   np.log(arr)                            # Natural logarithm\")\nprint(\"   np.sin(arr), np.cos(arr)               # Trigonometric\")\nprint(\"   np.abs(arr)                            # Absolute value\")\nprint()\n\nprint(\"\ud83d\udca1 TIP: These functions work on entire arrays at once - very fast!\")\nprint(\"\ud83d\udca1 TIP: Most functions can work with axis parameter: axis=0 (rows), axis=1 (columns)\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   arr1\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 36)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# \ud83d\udcda QUICK REFERENCE: NumPy Most Commonly Used Functions\n# Complete cheat sheet of functions you'll use in AI projects\n\nimport numpy as np\n\nprint(\"=\" * 70)\nprint(\"\ud83d\udcda NUMPY FUNCTION REFERENCE - Most Commonly Used Functions\")\nprint(\"=\" * 70)\nprint()\n\nprint(\"\ud83d\udd39 ARRAY CREATION:\")\nprint(\"   np.array([1, 2, 3])                    # Create from list\")\nprint(\"   np.zeros(5)                            # Array of zeros: [0, 0, 0, 0, 0]\")\nprint(\"   np.ones(5)                             # Array of ones: [1, 1, 1, 1, 1]\")\nprint(\"   np.arange(0, 10, 2)                    # Like range(): [0, 2, 4, 6, 8]\")\nprint(\"   np.linspace(0, 1, 5)                   # Evenly spaced: [0, 0.25, 0.5, 0.75, 1]\")\nprint(\"   np.empty((3, 3))                       # Uninitialized array (fast)\")\nprint(\"   np.full((2, 3), 7)                     # Array filled with value: all 7s\")\nprint(\"   np.eye(3)                              # Identity matrix (3x3)\")\nprint(\"   np.random.rand(5)                      # Random [0,1): 5 numbers\")\nprint(\"   np.random.randn(5)                     # Random normal: mean=0, std=1\")\nprint(\"   np.random.randint(0, 10, 5)            # Random integers: 5 numbers from [0,10)\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY PROPERTIES:\")\nprint(\"   arr.shape                              # Dimensions: (3, 4)\")\nprint(\"   arr.size                               # Total elements: 12\")\nprint(\"   arr.dtype                              # Data type: int64, float64\")\nprint(\"   arr.ndim                               # Number of dimensions: 2\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY OPERATIONS (Element-wise):\")\nprint(\"   arr1 + arr2                            # Addition\")\nprint(\"   arr1 - arr2                            # Subtraction\")\nprint(\"   arr1 * arr2                            # Multiplication\")\nprint(\"   arr1\narr2                            # Division\")\nprint(\"   arr ** 2                               # Power\")\nprint(\"   arr % 2                                # Modulo\")\nprint()\n\nprint(\"\ud83d\udd39 STATISTICAL FUNCTIONS:\")\nprint(\"   np.mean(arr)                           # Average value\")\nprint(\"   np.median(arr)                         # Median value\")\nprint(\"   np.std(arr)                            # Standard deviation\")\nprint(\"   np.var(arr)                            # Variance\")\nprint(\"   np.min(arr)                            # Minimum value\")\nprint(\"   np.max(arr)                            # Maximum value\")\nprint(\"   np.sum(arr)                            # Sum of all elements\")\nprint(\"   np.prod(arr)                           # Product of all elements\")\nprint(\"   np.percentile(arr, 75)                 # 75th percentile\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY MANIPULATION:\")\nprint(\"   arr.reshape(3, 4)                      # Reshape to 3x4\")\nprint(\"   arr.flatten()                          # Flatten to 1D\")\nprint(\"   np.concatenate([arr1, arr2])           # Join arrays\")\nprint(\"   np.split(arr, 3)                       # Split array into 3 parts\")\nprint(\"   arr.T                                  # Transpose\")\nprint(\"   np.sort(arr)                           # Sort array\")\nprint(\"   np.argsort(arr)                        # Indices that would sort\")\nprint()\n\nprint(\"\ud83d\udd39 INDEXING & SLICING:\")\nprint(\"   arr[0]                                 # First element\")\nprint(\"   arr[1:4]                               # Slice: elements 1,2,3\")\nprint(\"   arr[-1]                                # Last element\")\nprint(\"   arr[arr > 5]                           # Boolean indexing: elements > 5\")\nprint(\"   arr[[0, 2, 4]]                         # Fancy indexing: select indices\")\nprint()\n\nprint(\"\ud83d\udd39 MATRIX OPERATIONS:\")\nprint(\"   np.dot(A, B)                           # Matrix multiplication\")\nprint(\"   A @ B                                  # Matrix multiplication (Python 3.5+)\")\nprint(\"   np.linalg.inv(A)                       # Matrix inverse\")\nprint(\"   np.linalg.det(A)                       # Determinant\")\nprint(\"   np.linalg.eig(A)                       # Eigenvalues & eigenvectors\")\nprint()\n\nprint(\"\ud83d\udd39 MATH FUNCTIONS:\")\nprint(\"   np.sqrt(arr)                           # Square root\")\nprint(\"   np.exp(arr)                            # Exponential\")\nprint(\"   np.log(arr)                            # Natural logarithm\")\nprint(\"   np.sin(arr), np.cos(arr)               # Trigonometric\")\nprint(\"   np.abs(arr)                            # Absolute value\")\nprint()\n\nprint(\"\ud83d\udca1 TIP: These functions work on entire arrays at once - very fast!\")\nprint(\"\ud83d\udca1 TIP: Most functions can work with axis parameter: axis=0 (rows), axis=1 (columns)\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   arr1\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 36)\n\n\n",
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/01_Introduction_Search_Algorithms.ipynb",
      "status": "failed",
      "execution_time": 1.0502300262451172,
      "error": "An error occurred while executing the following cell:\n------------------\n# Visualize Dijkstra's path found\ndef visualize_dijkstra_path(graph, path, exploration_order, edge_costs, title=\"Dijkstra's Algorithm Result\"):\n    \"\"\"\n    Visualize the path found by Dijkstra's algorithm.\n    \n    \u23f0 WHEN to use: After Dijkstra completes - see the optimal path found\n    \ud83d\udca1 WHY use: Visual understanding helps verify algorithm works correctly, see path with costs!\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))  # Create figure: Set size to 12 inches wide, 8 inches tall\n    \n    positions = {  # Define node positions: Fixed coordinates for each node (for consistent visualization)\n        'A': (3, 3), 'B': (1.5, 2), 'C': (4.5, 2),  # Top row: A at center, B left, C right\n        'D': (0.5, 1), 'E': (2.5, 1), 'F': (4, 1), 'G': (3, 0)  # Bottom rows: D, E, F, G at different levels\n    }\n    \n    # Draw all edges with costs (weights)\n    for node, neighbors in graph.items():  # Loop through all nodes: Iterate over every node in graph\n        x1, y1 = positions[node]  # Get node position: Get (x, y) coordinates for current node\n        for neighbor in neighbors:  # Loop through neighbors: Iterate over each neighbor of current node\n            x2, y2 = positions[neighbor]  # Get neighbor position: Get (x, y) coordinates for neighbor node\n            edge_key = (node, neighbor)  # Create edge key: Tuple for dictionary lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost, default to 1\n            \n            # Draw edge (arrow)\n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw edge: Draw arrow from node to neighbor\n                       arrowprops=dict(arrowstyle='->', color='gray', lw=1.5, alpha=0.4))  # Edge style: Gray arrow, thin, semi-transparent\n            \n            # Add cost label on edge\n            mid_x, mid_y = (x1 + x2)\n2, (y1 + y2)\n2  # Calculate midpoint: Center of edge for label placement\n            ax.text(mid_x, mid_y, str(cost), fontsize=10, ha='center', va='center',  # Add cost label: Display edge cost\n                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))  # Label style: White box with border\n    \n    # Highlight the path found by Dijkstra in RED\n    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\n        for i in range(len(path) - 1):  # Loop through path: Iterate over consecutive pairs in path\n            x1, y1 = positions[path[i]]  # Get start position: Get coordinates of current node in path\n            x2, y2 = positions[path[i+1]]  # Get end position: Get coordinates of next node in path\n            edge_key = (path[i], path[i+1])  # Get edge key: Tuple for cost lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost for this path edge\n            \n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw path edge: Draw arrow showing path\n                       arrowprops=dict(arrowstyle='->', color='red', lw=4, alpha=0.9))  # Path style: Red arrow, thick, opaque (stands out!)\n    \n    # Color nodes based on their status\n    for node, (x, y) in positions.items():  # Loop through all nodes: Iterate over every node to color them appropriately\n        if node in path:  # Check if on path: This node is part of the solution path\n            # Nodes on the path: green to red gradient\n            idx = path.index(node)  # Get position in path: Find where this node appears in path (0 = start, last = goal)\n            color = plt.cm.Greens(0.7) if idx == 0 else (plt.cm.Reds(0.7) if idx == len(path)-1 else 'yellow')  # Choose color: Green for start, red for goal, yellow for intermediate\n        elif node in exploration_order:  # Check if explored: This node was visited but not on path\n            # Explored but not on path: light blue\n            color = 'lightblue'  # Color: Light blue (explored but not solution)\n        else:\n            # Unexplored: white\n            color = 'white'  # Color: White (not visited at all)\n        \n        circle = plt.Circle((x, y), 0.3, color=color, edgecolor='black', lw=2, zorder=5)  # Draw node: Create circle at (x, y), radius 0.3, colored, black border\n        ax.add_patch(circle)  # Add to plot: Add circle to the visualization\n        ax.text(x, y, node, ha='center', va='center', fontsize=14, fontweight='bold')  # Add label: Place node name in center of circle, bold text\n    \n    ax.set_xlim(-0.5, 5.5)  # Set x-axis limits: Define horizontal range of plot\n    ax.set_ylim(-0.5, 4)  # Set y-axis limits: Define vertical range of plot\n    ax.set_aspect('equal')  # Equal aspect ratio: Make circles look circular (not oval)\n    ax.axis('off')  # Hide axes: Remove axis lines and labels (cleaner look)\n    ax.set_title(title, fontsize=16, fontweight='bold')  # Add title: Bold text, large font\n    \n    # Add legend\n    legend_elements = [  # Legend items: List of colored patches to explain node colors\n        mpatches.Patch(facecolor='lightgreen', label='Start'),\n        mpatches.Patch(facecolor='yellow', label='Path Nodes'),\n        mpatches.Patch(facecolor='lightcoral', label='Goal'),\n        mpatches.Patch(facecolor='lightblue', label='Explored (not on path)'),\n        mpatches.Patch(facecolor='white', edgecolor='black', label='Unexplored')\n    ]\n    ax.legend(handles=legend_elements, loc='upper right')  # Show legend: Display legend in upper right corner\n    \n    plt.tight_layout()  # Adjust spacing: Prevent labels from overlapping or being cut off\n    plt.show()  # Display plot: Show the visualization (MUST call this to see plot!)\n\n# Visualize Dijkstra result\nprint(\"\\n\ud83d\udcca Visualizing Dijkstra's result...\")\nif dijkstra_path:\n    visualize_dijkstra_path(weighted_graph, dijkstra_path, dijkstra_order, edge_costs, \n                           \"Dijkstra's Algorithm: Optimal Path Found (Red Arrows)\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:36\u001b[0;36m\u001b[0m\n\u001b[0;31m    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Visualize Dijkstra's path found\ndef visualize_dijkstra_path(graph, path, exploration_order, edge_costs, title=\"Dijkstra's Algorithm Result\"):\n    \"\"\"\n    Visualize the path found by Dijkstra's algorithm.\n    \n    \u23f0 WHEN to use: After Dijkstra completes - see the optimal path found\n    \ud83d\udca1 WHY use: Visual understanding helps verify algorithm works correctly, see path with costs!\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))  # Create figure: Set size to 12 inches wide, 8 inches tall\n    \n    positions = {  # Define node positions: Fixed coordinates for each node (for consistent visualization)\n        'A': (3, 3), 'B': (1.5, 2), 'C': (4.5, 2),  # Top row: A at center, B left, C right\n        'D': (0.5, 1), 'E': (2.5, 1), 'F': (4, 1), 'G': (3, 0)  # Bottom rows: D, E, F, G at different levels\n    }\n    \n    # Draw all edges with costs (weights)\n    for node, neighbors in graph.items():  # Loop through all nodes: Iterate over every node in graph\n        x1, y1 = positions[node]  # Get node position: Get (x, y) coordinates for current node\n        for neighbor in neighbors:  # Loop through neighbors: Iterate over each neighbor of current node\n            x2, y2 = positions[neighbor]  # Get neighbor position: Get (x, y) coordinates for neighbor node\n            edge_key = (node, neighbor)  # Create edge key: Tuple for dictionary lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost, default to 1\n            \n            # Draw edge (arrow)\n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw edge: Draw arrow from node to neighbor\n                       arrowprops=dict(arrowstyle='->', color='gray', lw=1.5, alpha=0.4))  # Edge style: Gray arrow, thin, semi-transparent\n            \n            # Add cost label on edge\n            mid_x, mid_y = (x1 + x2)\n2, (y1 + y2)\n2  # Calculate midpoint: Center of edge for label placement\n            ax.text(mid_x, mid_y, str(cost), fontsize=10, ha='center', va='center',  # Add cost label: Display edge cost\n                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))  # Label style: White box with border\n    \n    # Highlight the path found by Dijkstra in RED\n    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\n        for i in range(len(path) - 1):  # Loop through path: Iterate over consecutive pairs in path\n            x1, y1 = positions[path[i]]  # Get start position: Get coordinates of current node in path\n            x2, y2 = positions[path[i+1]]  # Get end position: Get coordinates of next node in path\n            edge_key = (path[i], path[i+1])  # Get edge key: Tuple for cost lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost for this path edge\n            \n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw path edge: Draw arrow showing path\n                       arrowprops=dict(arrowstyle='->', color='red', lw=4, alpha=0.9))  # Path style: Red arrow, thick, opaque (stands out!)\n    \n    # Color nodes based on their status\n    for node, (x, y) in positions.items():  # Loop through all nodes: Iterate over every node to color them appropriately\n        if node in path:  # Check if on path: This node is part of the solution path\n            # Nodes on the path: green to red gradient\n            idx = path.index(node)  # Get position in path: Find where this node appears in path (0 = start, last = goal)\n            color = plt.cm.Greens(0.7) if idx == 0 else (plt.cm.Reds(0.7) if idx == len(path)-1 else 'yellow')  # Choose color: Green for start, red for goal, yellow for intermediate\n        elif node in exploration_order:  # Check if explored: This node was visited but not on path\n            # Explored but not on path: light blue\n            color = 'lightblue'  # Color: Light blue (explored but not solution)\n        else:\n            # Unexplored: white\n            color = 'white'  # Color: White (not visited at all)\n        \n        circle = plt.Circle((x, y), 0.3, color=color, edgecolor='black', lw=2, zorder=5)  # Draw node: Create circle at (x, y), radius 0.3, colored, black border\n        ax.add_patch(circle)  # Add to plot: Add circle to the visualization\n        ax.text(x, y, node, ha='center', va='center', fontsize=14, fontweight='bold')  # Add label: Place node name in center of circle, bold text\n    \n    ax.set_xlim(-0.5, 5.5)  # Set x-axis limits: Define horizontal range of plot\n    ax.set_ylim(-0.5, 4)  # Set y-axis limits: Define vertical range of plot\n    ax.set_aspect('equal')  # Equal aspect ratio: Make circles look circular (not oval)\n    ax.axis('off')  # Hide axes: Remove axis lines and labels (cleaner look)\n    ax.set_title(title, fontsize=16, fontweight='bold')  # Add title: Bold text, large font\n    \n    # Add legend\n    legend_elements = [  # Legend items: List of colored patches to explain node colors\n        mpatches.Patch(facecolor='lightgreen', label='Start'),\n        mpatches.Patch(facecolor='yellow', label='Path Nodes'),\n        mpatches.Patch(facecolor='lightcoral', label='Goal'),\n        mpatches.Patch(facecolor='lightblue', label='Explored (not on path)'),\n        mpatches.Patch(facecolor='white', edgecolor='black', label='Unexplored')\n    ]\n    ax.legend(handles=legend_elements, loc='upper right')  # Show legend: Display legend in upper right corner\n    \n    plt.tight_layout()  # Adjust spacing: Prevent labels from overlapping or being cut off\n    plt.show()  # Display plot: Show the visualization (MUST call this to see plot!)\n\n# Visualize Dijkstra result\nprint(\"\\n\ud83d\udcca Visualizing Dijkstra's result...\")\nif dijkstra_path:\n    visualize_dijkstra_path(weighted_graph, dijkstra_path, dijkstra_order, edge_costs, \n                           \"Dijkstra's Algorithm: Optimal Path Found (Red Arrows)\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:36\u001b[0;36m\u001b[0m\n\u001b[0;31m    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/02_Knowledge_Representation.ipynb",
      "status": "failed",
      "execution_time": 0.8060400485992432,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Define a Fact class\n# This represents a single piece of knowledge: Subject-Predicate-Object\n# Example: \"Socrates\" (subject) \"is_a\" (predicate) \"Human\" (object)\n\nclass Fact:\n    \"\"\"\n    Represents a single fact in knowledge base.\n    \n    Structure: Subject -> Predicate -> Object\n    Example: \"Socrates\" -> \"is_a\" -> \"Human\"\n    \n    Why use a class? Because we can:\n    - Store structured data\n    - Add methods to work with facts\n    - Compare facts easily\n    \"\"\"\n    def__init__(self, subject, predicate, object_val):\n        \"\"\"\n        Initialize a fact with three components:\n        - subject: Who/what (e.g., \"Socrates\")\n        - predicate: Relationship (e.g., \"is_a\", \"studied_under\")\n        - object_val: What it relates to (e.g., \"Human\", \"Plato\")\n        \"\"\"\n        self.subject = subject      # Store subject\n        self.predicate = predicate  # Store predicate (relationship type)\n        self.object = object_val    # Store object\n    \n    def__repr__(self):\n        \"\"\"\n        Pretty print the fact.\n        When we print a Fact object, it shows: Fact(Socrates, is_a, Human)\n        \"\"\"\n        return f\"Fact({self.subject}, {self.predicate}, {self.object})\"\n\n# Step 2: Create a Knowledge Base class\n# This is our \"memory\" - it stores facts and allows us to query them\n\nclass KnowledgeBase:\n    \"\"\"\n    A simple knowledge base using Python structures.\n    \n    This is our \"memory\" - it stores facts and allows us to:\n    1. Add new facts\n    2. Query facts (find facts matching criteria)\n    3. Get statistics about what we know\n    \n    BEFORE: We had scattered strings\n    AFTER: We have structured storage with query capabilities!\n    \"\"\"\n    def__init__(self):\n        \"\"\"\n        Initialize an empty knowledge base.\n        We start with no facts and no rules.\n        \"\"\"\n        self.facts = []  # List to store all facts (our memory!)\n        self.rules = []  # List to store rules (we'll use this later)\n        print(\"\u2705 Created new Knowledge Base (empty - ready to learn!)\")\n    \n    def add_fact(self, subject, predicate, object_val):\n        \"\"\"\n        Add a fact to the knowledge base.\n        \n        Process:\n        1. Create a Fact object from the components\n        2. Add it to our facts list (store it in memory)\n        3. Return the fact (in case we want to use it later)\n        \"\"\"\n        fact = Fact(subject, predicate, object_val)  # Create fact object\n        self.facts.append(fact)  # Add to our knowledge base (store in memory)\n        print(f\"  \u2795 Added: {fact}\")  # Show what we added (for learning!)\n        return fact  # Return it (useful for chaining operations)\n    \n    def query(self, subject=None, predicate=None, object_val=None):\n        \"\"\"\n        Query facts matching given criteria.\n        \n        This is powerful! We can ask:\n        - \"What do we know about Socrates?\" (subject='Socrates')\n        - \"What relationships involve 'is_a'?\" (predicate='is_a')\n        - \"Who/what is a Human?\" (object_val='Human')\n        - Or any combination!\n        \n        Parameters:\n        - subject: Filter by subject (who/what)\n        - predicate: Filter by predicate (relationship type)\n        - object_val: Filter by object (what it relates to)\n        \n        Returns: List of matching Fact objects\n        \"\"\"\n        results = []  # List to store matching facts\n        \n        # Go through each fact in our knowledge base\n        for fact in self.facts:\n            # Check if this fact matches all our criteria\n            # (If a criteria is None, we don't filter on it - means \"match anything\")\n            matches_subject = (subject is None or fact.subject == subject)\n            matches_predicate = (predicate is None or fact.predicate == predicate)\n            matches_object = (object_val is None or fact.object == object_val)\n            \n            # If all specified criteria match, include this fact\n            if matches_subject and matches_predicate and matches_object:\n                results.append(fact)  # Add to results\n        \n        return results  # Return all matching facts\n    \n    def__repr__(self):\n        \"\"\"\n        Show summary of knowledge base.\n        When we print the knowledge base, it shows: KnowledgeBase(5 facts, 0 rules)\n        \"\"\"\n        return f\"KnowledgeBase({len(self.facts)} facts, {len(self.rules)} rules)\"\n\n# Step 3: Create a knowledge base and add facts\n# NOW we can see the difference!\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 AFTER: Structured Knowledge Base\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udcdd Creating knowledge base and adding facts...\\n\")\n\nkb = KnowledgeBase()  # Create empty knowledge base\n\nprint(\"\\n\u2795 Adding facts:\")\nkb.add_fact(\"Socrates\", \"is_a\", \"Human\")       # Socrates is a Human\nkb.add_fact(\"Humans\", \"are\", \"Mortal\")          # Humans are Mortal\nkb.add_fact(\"Socrates\", \"is_a\", \"Philosopher\")  # Socrates is a Philosopher\nkb.add_fact(\"Plato\", \"is_a\", \"Human\")           # Plato is a Human\nkb.add_fact(\"Plato\", \"studied_under\", \"Socrates\")  # Plato studied under Socrates\n\nprint(f\"\\n\ud83d\udcca Knowledge Base Status: {kb}\")\nprint(f\"\u2705 Now we have {len(kb.facts)} structured facts (instead of scattered strings)!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, subject, predicate, object_val):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Define a Fact class\n# This represents a single piece of knowledge: Subject-Predicate-Object\n# Example: \"Socrates\" (subject) \"is_a\" (predicate) \"Human\" (object)\n\nclass Fact:\n    \"\"\"\n    Represents a single fact in knowledge base.\n    \n    Structure: Subject -> Predicate -> Object\n    Example: \"Socrates\" -> \"is_a\" -> \"Human\"\n    \n    Why use a class? Because we can:\n    - Store structured data\n    - Add methods to work with facts\n    - Compare facts easily\n    \"\"\"\n    def__init__(self, subject, predicate, object_val):\n        \"\"\"\n        Initialize a fact with three components:\n        - subject: Who/what (e.g., \"Socrates\")\n        - predicate: Relationship (e.g., \"is_a\", \"studied_under\")\n        - object_val: What it relates to (e.g., \"Human\", \"Plato\")\n        \"\"\"\n        self.subject = subject      # Store subject\n        self.predicate = predicate  # Store predicate (relationship type)\n        self.object = object_val    # Store object\n    \n    def__repr__(self):\n        \"\"\"\n        Pretty print the fact.\n        When we print a Fact object, it shows: Fact(Socrates, is_a, Human)\n        \"\"\"\n        return f\"Fact({self.subject}, {self.predicate}, {self.object})\"\n\n# Step 2: Create a Knowledge Base class\n# This is our \"memory\" - it stores facts and allows us to query them\n\nclass KnowledgeBase:\n    \"\"\"\n    A simple knowledge base using Python structures.\n    \n    This is our \"memory\" - it stores facts and allows us to:\n    1. Add new facts\n    2. Query facts (find facts matching criteria)\n    3. Get statistics about what we know\n    \n    BEFORE: We had scattered strings\n    AFTER: We have structured storage with query capabilities!\n    \"\"\"\n    def__init__(self):\n        \"\"\"\n        Initialize an empty knowledge base.\n        We start with no facts and no rules.\n        \"\"\"\n        self.facts = []  # List to store all facts (our memory!)\n        self.rules = []  # List to store rules (we'll use this later)\n        print(\"\u2705 Created new Knowledge Base (empty - ready to learn!)\")\n    \n    def add_fact(self, subject, predicate, object_val):\n        \"\"\"\n        Add a fact to the knowledge base.\n        \n        Process:\n        1. Create a Fact object from the components\n        2. Add it to our facts list (store it in memory)\n        3. Return the fact (in case we want to use it later)\n        \"\"\"\n        fact = Fact(subject, predicate, object_val)  # Create fact object\n        self.facts.append(fact)  # Add to our knowledge base (store in memory)\n        print(f\"  \u2795 Added: {fact}\")  # Show what we added (for learning!)\n        return fact  # Return it (useful for chaining operations)\n    \n    def query(self, subject=None, predicate=None, object_val=None):\n        \"\"\"\n        Query facts matching given criteria.\n        \n        This is powerful! We can ask:\n        - \"What do we know about Socrates?\" (subject='Socrates')\n        - \"What relationships involve 'is_a'?\" (predicate='is_a')\n        - \"Who/what is a Human?\" (object_val='Human')\n        - Or any combination!\n        \n        Parameters:\n        - subject: Filter by subject (who/what)\n        - predicate: Filter by predicate (relationship type)\n        - object_val: Filter by object (what it relates to)\n        \n        Returns: List of matching Fact objects\n        \"\"\"\n        results = []  # List to store matching facts\n        \n        # Go through each fact in our knowledge base\n        for fact in self.facts:\n            # Check if this fact matches all our criteria\n            # (If a criteria is None, we don't filter on it - means \"match anything\")\n            matches_subject = (subject is None or fact.subject == subject)\n            matches_predicate = (predicate is None or fact.predicate == predicate)\n            matches_object = (object_val is None or fact.object == object_val)\n            \n            # If all specified criteria match, include this fact\n            if matches_subject and matches_predicate and matches_object:\n                results.append(fact)  # Add to results\n        \n        return results  # Return all matching facts\n    \n    def__repr__(self):\n        \"\"\"\n        Show summary of knowledge base.\n        When we print the knowledge base, it shows: KnowledgeBase(5 facts, 0 rules)\n        \"\"\"\n        return f\"KnowledgeBase({len(self.facts)} facts, {len(self.rules)} rules)\"\n\n# Step 3: Create a knowledge base and add facts\n# NOW we can see the difference!\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 AFTER: Structured Knowledge Base\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udcdd Creating knowledge base and adding facts...\\n\")\n\nkb = KnowledgeBase()  # Create empty knowledge base\n\nprint(\"\\n\u2795 Adding facts:\")\nkb.add_fact(\"Socrates\", \"is_a\", \"Human\")       # Socrates is a Human\nkb.add_fact(\"Humans\", \"are\", \"Mortal\")          # Humans are Mortal\nkb.add_fact(\"Socrates\", \"is_a\", \"Philosopher\")  # Socrates is a Philosopher\nkb.add_fact(\"Plato\", \"is_a\", \"Human\")           # Plato is a Human\nkb.add_fact(\"Plato\", \"studied_under\", \"Socrates\")  # Plato studied under Socrates\n\nprint(f\"\\n\ud83d\udcca Knowledge Base Status: {kb}\")\nprint(f\"\u2705 Now we have {len(kb.facts)} structured facts (instead of scattered strings)!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, subject, predicate, object_val):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/03_Learning_Under_Uncertainty.ipynb",
      "status": "failed",
      "execution_time": 0.9043700695037842,
      "error": "An error occurred while executing the following cell:\n------------------\n# \ud83d\udd17 HOW THE SOLUTION SOLVES THE PROBLEM\n# Medical diagnosis example: The problem we identified earlier\n\nclass BayesianInference:\n    \"\"\"\n    Bayesian inference: The SOLUTION to the problem of uncertainty.\n    \n    THE PROBLEM: We get test results but don't know what they mean.\n    THE SOLUTION: Use Bayes' theorem to update our beliefs with evidence.\n    \n    How it works:\n    1. Start with PRIOR belief (what we believe before test)\n    2. Get EVIDENCE (test result)\n    3. Use Bayes' theorem to calculate POSTERIOR (updated belief)\n    \"\"\"\n    def__init__(self, prior_prob):\n        \"\"\"\n        Initialize with prior probability P(H).\n        This is what we believe BEFORE getting evidence.\n        \"\"\"\n        self.prior = prior_prob  # Our initial belief\n        self.posterior = prior_prob  # Updated belief (starts same as prior)\n    \n    def update(self, likelihood, evidence_prob):\n        \"\"\"\n        Update belief using Bayes' theorem.\n        \n        Formula: P(H|E) = P(E|H) * P(H)\nP(E)\n        \n        Where:\n        - P(H|E): Probability of hypothesis given evidence (what we want)\n        - P(E|H): Probability of evidence given hypothesis (likelihood)\n        - P(H): Prior probability of hypothesis\n        - P(E): Probability of evidence\n        \n        This is THE SOLUTION - it tells us how to update beliefs!\n        \"\"\"\n        # Bayes' theorem: Update belief based on evidence\n        self.posterior = (likelihood * self.prior)\nevidence_prob\n        self.prior = self.posterior  # Update for next iteration\n        return self.posterior\n    \n    def get_belief(self):\n        \"\"\"Get current belief (posterior probability)\"\"\"\n        return self.posterior\n\n# Example: Medical diagnosis\n# THE PROBLEM we identified: Test is positive - what does it mean?\nprint(\"=\" * 70)\nprint(\"\ud83d\udd17 PROBLEM \u2192 SOLUTION: Medical Diagnosis Example\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u274c THE PROBLEM (from earlier):\")\nprint(\"   \u2022 Medical test comes back POSITIVE\")\nprint(\"   \u2022 Without probability: 'I definitely have the disease!' (panic)\")\nprint(\"   \u2022 Or: 'Test might be wrong, I'll ignore it' (dangerous)\")\nprint()\nprint(\"\u2705 THE SOLUTION: Use Bayesian inference to calculate actual probability\")\nprint()\n\n# Given information:\nprint(\"\ud83d\udcca Given Information:\")\nprint(\"   \u2022 Prior P(Disease) = 0.01 (1% of population has disease)\")\nprint(\"   \u2022 Test accuracy: P(Positive|Disease) = 0.99 (99% accurate if diseased)\")\nprint(\"   \u2022 Test false positive: P(Positive|No Disease) = 0.05 (5% false positive)\")\nprint()\n\n# Calculate using probability (THE SOLUTION)\nP_disease = 0.01  # Prior: 1% have disease\nP_no_disease = 0.99  # 99% don't have disease\nP_positive_given_disease = 0.99  # Test is 99% accurate if diseased\nP_positive_given_no_disease = 0.05  # 5% false positive rate\n\n# Calculate P(Positive) - overall probability of positive test\n# \u23f0 WHEN to use: BEFORE applying Bayes' theorem - need P(Evidence) for denominator\n# \ud83d\udca1 WHY use: Bayes' theorem needs P(Evidence) in denominator - calculate total probability of positive test\nP_positive = (P_positive_given_disease * P_disease + \n              P_positive_given_no_disease * P_no_disease)  # Total probability: Calculate P(Positive) using law of total probability (sum of conditional probabilities weighted by prior)\n\nprint(f\"\ud83d\udcca Calculation:\")\nprint(f\"   P(Positive) = P(Pos|Disease) \u00d7 P(Disease) + P(Pos|No Disease) \u00d7 P(No Disease)\")  # Show formula: Display the law of total probability formula\nprint(f\"   P(Positive) = {P_positive_given_disease} \u00d7 {P_disease} + {P_positive_given_no_disease} \u00d7 {P_no_disease}\")  # Show values: Display actual numbers plugged into formula\nprint(f\"   P(Positive) = {P_positive:.4f}\")  # Show result: Display calculated probability of positive test (should be around 0.05-0.06!)\nprint()\n\n# Use Bayesian inference (THE SOLUTION)\nprint(\"   \u23f0 WHEN to use: After getting test result - update belief based on evidence\")\nprint(\"   \ud83d\udca1 WHY use: Bayes' theorem updates prior belief with evidence - gives accurate posterior probability!\")\n\nbayesian = BayesianInference(P_disease)  # Create Bayesian object: Initialize with prior probability P(Disease) = 0.01 (what we believe BEFORE test)\nP_disease_given_positive = bayesian.update(P_positive_given_disease, P_positive)  # Update belief: Apply Bayes' theorem to calculate P(Disease|Positive) using likelihood and evidence probability\n\nprint(f\"\u2705 THE SOLUTION (Bayesian Inference):\")\nprint(f\"   P(Disease|Positive) = {P_disease_given_positive:.4f} = {P_disease_given_positive*100:.2f}%\")\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(f\"   \u274c WITHOUT probability: 'I definitely have it!' (wrong!)\")\nprint(f\"   \u2705 WITH probability: 'I have {P_disease_given_positive*100:.1f}% chance' (accurate!)\")\nprint(f\"   \u2022 Instead of panic, we have accurate assessment\")\nprint(f\"   \u2022 Instead of ignoring, we know it's worth investigating\")\nprint(f\"   \u2022 We can make informed medical decisions!\")\nprint()\nprint(\"\ud83d\udcca BEFORE vs AFTER Comparison:\")\nprint(\"   BEFORE: Test positive \u2192 Panic or Ignore (both wrong!)\")\nprint(f\"   AFTER: Test positive \u2192 {P_disease_given_positive*100:.1f}% probability \u2192 Informed decision!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:45\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_belief(self):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# \ud83d\udd17 HOW THE SOLUTION SOLVES THE PROBLEM\n# Medical diagnosis example: The problem we identified earlier\n\nclass BayesianInference:\n    \"\"\"\n    Bayesian inference: The SOLUTION to the problem of uncertainty.\n    \n    THE PROBLEM: We get test results but don't know what they mean.\n    THE SOLUTION: Use Bayes' theorem to update our beliefs with evidence.\n    \n    How it works:\n    1. Start with PRIOR belief (what we believe before test)\n    2. Get EVIDENCE (test result)\n    3. Use Bayes' theorem to calculate POSTERIOR (updated belief)\n    \"\"\"\n    def__init__(self, prior_prob):\n        \"\"\"\n        Initialize with prior probability P(H).\n        This is what we believe BEFORE getting evidence.\n        \"\"\"\n        self.prior = prior_prob  # Our initial belief\n        self.posterior = prior_prob  # Updated belief (starts same as prior)\n    \n    def update(self, likelihood, evidence_prob):\n        \"\"\"\n        Update belief using Bayes' theorem.\n        \n        Formula: P(H|E) = P(E|H) * P(H)\nP(E)\n        \n        Where:\n        - P(H|E): Probability of hypothesis given evidence (what we want)\n        - P(E|H): Probability of evidence given hypothesis (likelihood)\n        - P(H): Prior probability of hypothesis\n        - P(E): Probability of evidence\n        \n        This is THE SOLUTION - it tells us how to update beliefs!\n        \"\"\"\n        # Bayes' theorem: Update belief based on evidence\n        self.posterior = (likelihood * self.prior)\nevidence_prob\n        self.prior = self.posterior  # Update for next iteration\n        return self.posterior\n    \n    def get_belief(self):\n        \"\"\"Get current belief (posterior probability)\"\"\"\n        return self.posterior\n\n# Example: Medical diagnosis\n# THE PROBLEM we identified: Test is positive - what does it mean?\nprint(\"=\" * 70)\nprint(\"\ud83d\udd17 PROBLEM \u2192 SOLUTION: Medical Diagnosis Example\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u274c THE PROBLEM (from earlier):\")\nprint(\"   \u2022 Medical test comes back POSITIVE\")\nprint(\"   \u2022 Without probability: 'I definitely have the disease!' (panic)\")\nprint(\"   \u2022 Or: 'Test might be wrong, I'll ignore it' (dangerous)\")\nprint()\nprint(\"\u2705 THE SOLUTION: Use Bayesian inference to calculate actual probability\")\nprint()\n\n# Given information:\nprint(\"\ud83d\udcca Given Information:\")\nprint(\"   \u2022 Prior P(Disease) = 0.01 (1% of population has disease)\")\nprint(\"   \u2022 Test accuracy: P(Positive|Disease) = 0.99 (99% accurate if diseased)\")\nprint(\"   \u2022 Test false positive: P(Positive|No Disease) = 0.05 (5% false positive)\")\nprint()\n\n# Calculate using probability (THE SOLUTION)\nP_disease = 0.01  # Prior: 1% have disease\nP_no_disease = 0.99  # 99% don't have disease\nP_positive_given_disease = 0.99  # Test is 99% accurate if diseased\nP_positive_given_no_disease = 0.05  # 5% false positive rate\n\n# Calculate P(Positive) - overall probability of positive test\n# \u23f0 WHEN to use: BEFORE applying Bayes' theorem - need P(Evidence) for denominator\n# \ud83d\udca1 WHY use: Bayes' theorem needs P(Evidence) in denominator - calculate total probability of positive test\nP_positive = (P_positive_given_disease * P_disease + \n              P_positive_given_no_disease * P_no_disease)  # Total probability: Calculate P(Positive) using law of total probability (sum of conditional probabilities weighted by prior)\n\nprint(f\"\ud83d\udcca Calculation:\")\nprint(f\"   P(Positive) = P(Pos|Disease) \u00d7 P(Disease) + P(Pos|No Disease) \u00d7 P(No Disease)\")  # Show formula: Display the law of total probability formula\nprint(f\"   P(Positive) = {P_positive_given_disease} \u00d7 {P_disease} + {P_positive_given_no_disease} \u00d7 {P_no_disease}\")  # Show values: Display actual numbers plugged into formula\nprint(f\"   P(Positive) = {P_positive:.4f}\")  # Show result: Display calculated probability of positive test (should be around 0.05-0.06!)\nprint()\n\n# Use Bayesian inference (THE SOLUTION)\nprint(\"   \u23f0 WHEN to use: After getting test result - update belief based on evidence\")\nprint(\"   \ud83d\udca1 WHY use: Bayes' theorem updates prior belief with evidence - gives accurate posterior probability!\")\n\nbayesian = BayesianInference(P_disease)  # Create Bayesian object: Initialize with prior probability P(Disease) = 0.01 (what we believe BEFORE test)\nP_disease_given_positive = bayesian.update(P_positive_given_disease, P_positive)  # Update belief: Apply Bayes' theorem to calculate P(Disease|Positive) using likelihood and evidence probability\n\nprint(f\"\u2705 THE SOLUTION (Bayesian Inference):\")\nprint(f\"   P(Disease|Positive) = {P_disease_given_positive:.4f} = {P_disease_given_positive*100:.2f}%\")\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(f\"   \u274c WITHOUT probability: 'I definitely have it!' (wrong!)\")\nprint(f\"   \u2705 WITH probability: 'I have {P_disease_given_positive*100:.1f}% chance' (accurate!)\")\nprint(f\"   \u2022 Instead of panic, we have accurate assessment\")\nprint(f\"   \u2022 Instead of ignoring, we know it's worth investigating\")\nprint(f\"   \u2022 We can make informed medical decisions!\")\nprint()\nprint(\"\ud83d\udcca BEFORE vs AFTER Comparison:\")\nprint(\"   BEFORE: Test positive \u2192 Panic or Ignore (both wrong!)\")\nprint(f\"   AFTER: Test positive \u2192 {P_disease_given_positive*100:.1f}% probability \u2192 Informed decision!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:45\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_belief(self):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/04_Optimization_Techniques.ipynb",
      "status": "failed",
      "execution_time": 0.9521899223327637,
      "error": "An error occurred while executing the following cell:\n------------------\n# \u2705 THE SOLUTION: Gradient Descent\n# This algorithm solves the problem by following the gradient (slope) downhill\n\nclass GradientDescent:\n    \"\"\"\n    Gradient Descent: The SOLUTION to the optimization problem.\n    \n    THE PROBLEM: We don't know where the minimum is.\n    THE SOLUTION: Follow the gradient (slope) downhill - it always leads to minimum!\n    \n    How it works:\n    1. Start at random point\n    2. Calculate gradient (which way is downhill?)\n    3. Move in that direction (downhill)\n    4. Repeat until we reach the bottom (minimum)\n    \"\"\"\n    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n        \"\"\"\n        Initialize optimizer.\n        - learning_rate: How big steps to take (too big = overshoot, too small = slow)\n        - max_iterations: Maximum number of steps\n        - tolerance: Stop when change is smaller than this\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.max_iterations = max_iterations\n        self.tolerance = tolerance\n        self.history = []  # Track our path (for visualization)\n    \n    def optimize(self, f, grad_f, x0):\n        \"\"\"\n        Optimize function f starting from x0.\n        \n        THIS IS THE SOLUTION:\n        Instead of random search, we systematically follow the gradient downhill!\n        \"\"\"\n        x = np.array(x0, dtype=float)  # Starting point\n        self.history = [x.copy()]  # Remember where we started\n        \n        print(f\"\ud83d\ude80 Starting gradient descent from x = {x[0]:.2f}\")\n        print(f\"   Learning rate: {self.learning_rate}\")\n        print()\n        \n        for i in range(self.max_iterations):  # Iteration loop: Repeat up to max_iterations times (stop early if converged)\n            # Calculate gradient at current point\n            # Gradient tells us: which way is downhill?\n            gradient = grad_f(x)  # Calculate gradient: Compute gradient (slope) at current position x (gradient points uphill, we want to go downhill!)\n            \n            # Move downhill: x_new = x - learning_rate * gradient\n            # (Minus because gradient points uphill, we want to go downhill)\n            x_new = x - self.learning_rate * gradient  # Update position: Move in opposite direction of gradient (downhill) by learning_rate amount (subtract because gradient points uphill)\n            \n            self.history.append(x_new.copy())  # Remember our path: Store new position in history (copy() to avoid reference issues - we want a copy, not reference)\n            \n            # Check if we've converged (found minimum)\n            if np.linalg.norm(x_new - x) < self.tolerance:  # Check convergence: If change in position is smaller than tolerance, we've found minimum (np.linalg.norm computes distance/change)\n                print(f\"\u2705 Converged after {i+1} iterations!\")  # Success message: Algorithm found minimum!\n                print(f\"   Found minimum at x = {x_new[0]:.6f}\")  # Show solution: Display x coordinate where minimum was found\n                print(f\"   Function value: f({x_new[0]:.6f}) = {f(x_new):.6f}\")  # Show function value: Display minimum function value (should be smallest value!)\n                break  # Exit loop: Stop iterating - we've found the minimum!\n            \n            if i < 5 or i % 50 == 0:  # Show first few and periodic updates: Display progress for first 5 iterations, then every 50 iterations (avoid spam)\n                print(f\"   Step {i+1}: x = {x_new[0]:.4f}, gradient = {gradient[0]:.4f}, f(x) = {f(x_new):.4f}\")  # Progress update: Show updated position, gradient value, and function value (helps debug/understand algorithm)\n            \n            x = x_new  # Move to new position: Update current position to new position (prepare for next iteration)\n        \n        # Return both solution and cost for consistency with other optimization methods\n        return x, f(x)  # Return result: Return final position and function value (should be near minimum!)\n\n# Define function and its gradient\ndef f1(x):\n    \"\"\"Function to minimize: f(x) = x\u00b2\n    \n    Expects x as a numpy array (even for 1D).\n    For 1D arrays, returns x[0]**2; for multi-element arrays, squares all elements.\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    if x.ndim == 0:  # Scalar\n        return float(x)**2\n    elif len(x) == 1:  # Single-element array (optimization use case)\n        return x[0]**2\n    else:  # Multi-element array\n        return x**2\n\ndef grad_f1(x):\n    \"\"\"Gradient of f(x) = x\u00b2 is 2x\n    \n    Expects x as a numpy array (even for 1D).\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    return np.array([2 * x[0]])\n\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: The Solution - Gradient Descent\")\nprint(\"=\" * 70)\nprint()\n\n# Use gradient descent (THE SOLUTION)\noptimizer = GradientDescent(learning_rate=0.1, max_iterations=100)\nx_optimal, _ = optimizer.optimize(f1, grad_f1, [5.0])  # Start at x = 5\n\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Random search \u2192 Try x = 5, x = -3, x = 2.7... (slow!)\")\nprint(f\"   \u2705 AFTER: Gradient descent \u2192 Systematically move from 5 to 0 (fast!)\")\nprint(\"   \u2022 Instead of random \u2192 Systematic\")\nprint(\"   \u2022 Instead of slow \u2192 Fast convergence\")\nprint(\"   \u2022 Instead of guessing \u2192 Finds minimum efficiently!\")\nprint(\"   (Note: For smooth convex functions like x\u00b2, gradient descent finds the global minimum)\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# \u2705 THE SOLUTION: Gradient Descent\n# This algorithm solves the problem by following the gradient (slope) downhill\n\nclass GradientDescent:\n    \"\"\"\n    Gradient Descent: The SOLUTION to the optimization problem.\n    \n    THE PROBLEM: We don't know where the minimum is.\n    THE SOLUTION: Follow the gradient (slope) downhill - it always leads to minimum!\n    \n    How it works:\n    1. Start at random point\n    2. Calculate gradient (which way is downhill?)\n    3. Move in that direction (downhill)\n    4. Repeat until we reach the bottom (minimum)\n    \"\"\"\n    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n        \"\"\"\n        Initialize optimizer.\n        - learning_rate: How big steps to take (too big = overshoot, too small = slow)\n        - max_iterations: Maximum number of steps\n        - tolerance: Stop when change is smaller than this\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.max_iterations = max_iterations\n        self.tolerance = tolerance\n        self.history = []  # Track our path (for visualization)\n    \n    def optimize(self, f, grad_f, x0):\n        \"\"\"\n        Optimize function f starting from x0.\n        \n        THIS IS THE SOLUTION:\n        Instead of random search, we systematically follow the gradient downhill!\n        \"\"\"\n        x = np.array(x0, dtype=float)  # Starting point\n        self.history = [x.copy()]  # Remember where we started\n        \n        print(f\"\ud83d\ude80 Starting gradient descent from x = {x[0]:.2f}\")\n        print(f\"   Learning rate: {self.learning_rate}\")\n        print()\n        \n        for i in range(self.max_iterations):  # Iteration loop: Repeat up to max_iterations times (stop early if converged)\n            # Calculate gradient at current point\n            # Gradient tells us: which way is downhill?\n            gradient = grad_f(x)  # Calculate gradient: Compute gradient (slope) at current position x (gradient points uphill, we want to go downhill!)\n            \n            # Move downhill: x_new = x - learning_rate * gradient\n            # (Minus because gradient points uphill, we want to go downhill)\n            x_new = x - self.learning_rate * gradient  # Update position: Move in opposite direction of gradient (downhill) by learning_rate amount (subtract because gradient points uphill)\n            \n            self.history.append(x_new.copy())  # Remember our path: Store new position in history (copy() to avoid reference issues - we want a copy, not reference)\n            \n            # Check if we've converged (found minimum)\n            if np.linalg.norm(x_new - x) < self.tolerance:  # Check convergence: If change in position is smaller than tolerance, we've found minimum (np.linalg.norm computes distance/change)\n                print(f\"\u2705 Converged after {i+1} iterations!\")  # Success message: Algorithm found minimum!\n                print(f\"   Found minimum at x = {x_new[0]:.6f}\")  # Show solution: Display x coordinate where minimum was found\n                print(f\"   Function value: f({x_new[0]:.6f}) = {f(x_new):.6f}\")  # Show function value: Display minimum function value (should be smallest value!)\n                break  # Exit loop: Stop iterating - we've found the minimum!\n            \n            if i < 5 or i % 50 == 0:  # Show first few and periodic updates: Display progress for first 5 iterations, then every 50 iterations (avoid spam)\n                print(f\"   Step {i+1}: x = {x_new[0]:.4f}, gradient = {gradient[0]:.4f}, f(x) = {f(x_new):.4f}\")  # Progress update: Show updated position, gradient value, and function value (helps debug/understand algorithm)\n            \n            x = x_new  # Move to new position: Update current position to new position (prepare for next iteration)\n        \n        # Return both solution and cost for consistency with other optimization methods\n        return x, f(x)  # Return result: Return final position and function value (should be near minimum!)\n\n# Define function and its gradient\ndef f1(x):\n    \"\"\"Function to minimize: f(x) = x\u00b2\n    \n    Expects x as a numpy array (even for 1D).\n    For 1D arrays, returns x[0]**2; for multi-element arrays, squares all elements.\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    if x.ndim == 0:  # Scalar\n        return float(x)**2\n    elif len(x) == 1:  # Single-element array (optimization use case)\n        return x[0]**2\n    else:  # Multi-element array\n        return x**2\n\ndef grad_f1(x):\n    \"\"\"Gradient of f(x) = x\u00b2 is 2x\n    \n    Expects x as a numpy array (even for 1D).\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    return np.array([2 * x[0]])\n\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: The Solution - Gradient Descent\")\nprint(\"=\" * 70)\nprint()\n\n# Use gradient descent (THE SOLUTION)\noptimizer = GradientDescent(learning_rate=0.1, max_iterations=100)\nx_optimal, _ = optimizer.optimize(f1, grad_f1, [5.0])  # Start at x = 5\n\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Random search \u2192 Try x = 5, x = -3, x = 2.7... (slow!)\")\nprint(f\"   \u2705 AFTER: Gradient descent \u2192 Systematically move from 5 to 0 (fast!)\")\nprint(\"   \u2022 Instead of random \u2192 Systematic\")\nprint(\"   \u2022 Instead of slow \u2192 Fast convergence\")\nprint(\"   \u2022 Instead of guessing \u2192 Finds minimum efficiently!\")\nprint(\"   (Note: For smooth convex functions like x\u00b2, gradient descent finds the global minimum)\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/05_AI_Learning_Models.ipynb",
      "status": "failed",
      "execution_time": 1.6409556865692139,
      "error": "An error occurred while executing the following cell:\n------------------\n# K-Nearest Neighbors (KNN) Algorithm\n# BEFORE: Complex patterns are hard to model with formulas\n# AFTER: KNN uses simple idea - \"similar things are close\" - to predict!\n\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nclass KNN:\n    \"\"\"\n    K-Nearest Neighbors: Simple but powerful classification algorithm.\n    \n    THE PROBLEM: Complex patterns can't be captured by simple formulas.\n    THE SOLUTION: Use the simple idea - \"similar things are close together\"!\n    \n    How it works:\n    1. Store all training examples\n    2. For new example, find K nearest neighbors\n    3. Predict based on majority class of neighbors\n    \"\"\"\n    def__init__(self, k=3):\n        \"\"\"\n        Initialize KNN classifier.\n        \n        Parameters:\n        - k: Number of neighbors to consider (usually odd: 3, 5, 7)\n        \"\"\"\n        self.k = k\n        self.X_train = None  # Training features\n        self.y_train = None  # Training labels\n        print(f\"\u2705 Created KNN classifier (k={k})\")\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the model (just store the data - KNN is \"lazy\" learning!).\n        \n        Unlike other algorithms, KNN doesn't \"learn\" a formula.\n        It just remembers all examples - that's why it's called \"lazy\"!\n        \"\"\"\n        self.X_train = np.array(X)  # Store training features\n        self.y_train = np.array(y)  # Store training labels\n        print(f\"  \u2705 Stored {len(X)} training examples\")\n    \n    def predict(self, X):\n        \"\"\"\n        Predict class for new examples.\n        \n        THE SOLUTION:\n        1. For each new example, find K nearest neighbors\n        2. Look at their classes\n        3. Predict the majority class\n        \"\"\"\n        X = np.array(X)  # Convert to numpy array\n        predictions = []  # Store predictions\n        \n        for x in X:\n            # Calculate distances to all training examples\n            # Distance = how \"far\" is this example from each training example?\n            distances = np.sqrt(np.sum((self.X_train - x)**2, axis=1))\n            \n            # Find K nearest neighbors (smallest distances)\n            k_indices = np.argsort(distances)[:self.k]  # Indices of K nearest\n            k_nearest_labels = self.y_train[k_indices]  # Classes of K nearest\n            \n            # Predict majority class (most common class among neighbors)\n            majority_class = Counter(k_nearest_labels).most_common(1)[0][0]\n            predictions.append(majority_class)\n        \n        return np.array(predictions)\n\n# Example: Classifying fruits by size and sweetness\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: K-Nearest Neighbors (KNN)\")\nprint(\"=\" * 70)\nprint()\n\n# Generate example data\nnp.random.seed(42)\n# Apples: small size, medium sweetness\napples = np.random.randn(20, 2) * [0.5, 0.3] + [2, 5]\n# Oranges: medium size, high sweetness\noranges = np.random.randn(20, 2) * [0.5, 0.3] + [5, 7]\n\nX = np.vstack([apples, oranges])  # All features\ny = np.array([0]*20 + [1]*20)  # Labels: 0=Apple, 1=Orange\n\nprint(\"\ud83d\udcca Training data:\")\nprint(f\"   \u2022 {len(apples)} apples (class 0)\")\nprint(f\"   \u2022 {len(oranges)} oranges (class 1)\")\nprint(\"   Features: [size, sweetness]\")\nprint()\n\n# Train KNN\nknn = KNN(k=3)\nknn.fit(X, y)\n\n# Test on new examples\ntest_points = np.array([[2.5, 5.5], [5.5, 7.5], [3.5, 6.0]])\npredictions = knn.predict(test_points)\n\nprint(\"\ud83d\udcca Predictions on new examples:\")\nfor i, (point, pred) in enumerate(zip(test_points, predictions)):\n    fruit = \"Apple\" if pred == 0 else \"Orange\"\n    print(f\"   Point {i+1}: {point} \u2192 Predicted: {fruit}\")\n\nprint(\"\\n\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Need complex formula for pattern\")\nprint(\"   \u2705 AFTER: KNN uses simple idea - 'similar things are close'!\")\nprint(\"   \u2022 No formula needed - just find nearest neighbors\")\nprint(\"   \u2022 Works for complex, non-linear patterns\")\nprint(\"   \u2022 Simple but powerful!\")\n\n# Visualize\nplt.figure(figsize=(10, 6))\nplt.scatter(apples[:, 0], apples[:, 1], c='red', label='Apples (training)', s=100, alpha=0.6)\nplt.scatter(oranges[:, 0], oranges[:, 1], c='orange', label='Oranges (training)', s=100, alpha=0.6)\nplt.scatter(test_points[:, 0], test_points[:, 1], c=['red' if p==0 else 'orange' for p in predictions], \n            marker='*', s=300, label='Predictions', edgecolors='black', linewidths=2)\nplt.xlabel('Size')\nplt.ylabel('Sweetness')\nplt.title('\u2705 AFTER: KNN Classification\\n(Similar things are close together!)', fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, k=3):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# K-Nearest Neighbors (KNN) Algorithm\n# BEFORE: Complex patterns are hard to model with formulas\n# AFTER: KNN uses simple idea - \"similar things are close\" - to predict!\n\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nclass KNN:\n    \"\"\"\n    K-Nearest Neighbors: Simple but powerful classification algorithm.\n    \n    THE PROBLEM: Complex patterns can't be captured by simple formulas.\n    THE SOLUTION: Use the simple idea - \"similar things are close together\"!\n    \n    How it works:\n    1. Store all training examples\n    2. For new example, find K nearest neighbors\n    3. Predict based on majority class of neighbors\n    \"\"\"\n    def__init__(self, k=3):\n        \"\"\"\n        Initialize KNN classifier.\n        \n        Parameters:\n        - k: Number of neighbors to consider (usually odd: 3, 5, 7)\n        \"\"\"\n        self.k = k\n        self.X_train = None  # Training features\n        self.y_train = None  # Training labels\n        print(f\"\u2705 Created KNN classifier (k={k})\")\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the model (just store the data - KNN is \"lazy\" learning!).\n        \n        Unlike other algorithms, KNN doesn't \"learn\" a formula.\n        It just remembers all examples - that's why it's called \"lazy\"!\n        \"\"\"\n        self.X_train = np.array(X)  # Store training features\n        self.y_train = np.array(y)  # Store training labels\n        print(f\"  \u2705 Stored {len(X)} training examples\")\n    \n    def predict(self, X):\n        \"\"\"\n        Predict class for new examples.\n        \n        THE SOLUTION:\n        1. For each new example, find K nearest neighbors\n        2. Look at their classes\n        3. Predict the majority class\n        \"\"\"\n        X = np.array(X)  # Convert to numpy array\n        predictions = []  # Store predictions\n        \n        for x in X:\n            # Calculate distances to all training examples\n            # Distance = how \"far\" is this example from each training example?\n            distances = np.sqrt(np.sum((self.X_train - x)**2, axis=1))\n            \n            # Find K nearest neighbors (smallest distances)\n            k_indices = np.argsort(distances)[:self.k]  # Indices of K nearest\n            k_nearest_labels = self.y_train[k_indices]  # Classes of K nearest\n            \n            # Predict majority class (most common class among neighbors)\n            majority_class = Counter(k_nearest_labels).most_common(1)[0][0]\n            predictions.append(majority_class)\n        \n        return np.array(predictions)\n\n# Example: Classifying fruits by size and sweetness\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: K-Nearest Neighbors (KNN)\")\nprint(\"=\" * 70)\nprint()\n\n# Generate example data\nnp.random.seed(42)\n# Apples: small size, medium sweetness\napples = np.random.randn(20, 2) * [0.5, 0.3] + [2, 5]\n# Oranges: medium size, high sweetness\noranges = np.random.randn(20, 2) * [0.5, 0.3] + [5, 7]\n\nX = np.vstack([apples, oranges])  # All features\ny = np.array([0]*20 + [1]*20)  # Labels: 0=Apple, 1=Orange\n\nprint(\"\ud83d\udcca Training data:\")\nprint(f\"   \u2022 {len(apples)} apples (class 0)\")\nprint(f\"   \u2022 {len(oranges)} oranges (class 1)\")\nprint(\"   Features: [size, sweetness]\")\nprint()\n\n# Train KNN\nknn = KNN(k=3)\nknn.fit(X, y)\n\n# Test on new examples\ntest_points = np.array([[2.5, 5.5], [5.5, 7.5], [3.5, 6.0]])\npredictions = knn.predict(test_points)\n\nprint(\"\ud83d\udcca Predictions on new examples:\")\nfor i, (point, pred) in enumerate(zip(test_points, predictions)):\n    fruit = \"Apple\" if pred == 0 else \"Orange\"\n    print(f\"   Point {i+1}: {point} \u2192 Predicted: {fruit}\")\n\nprint(\"\\n\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Need complex formula for pattern\")\nprint(\"   \u2705 AFTER: KNN uses simple idea - 'similar things are close'!\")\nprint(\"   \u2022 No formula needed - just find nearest neighbors\")\nprint(\"   \u2022 Works for complex, non-linear patterns\")\nprint(\"   \u2022 Simple but powerful!\")\n\n# Visualize\nplt.figure(figsize=(10, 6))\nplt.scatter(apples[:, 0], apples[:, 1], c='red', label='Apples (training)', s=100, alpha=0.6)\nplt.scatter(oranges[:, 0], oranges[:, 1], c='orange', label='Oranges (training)', s=100, alpha=0.6)\nplt.scatter(test_points[:, 0], test_points[:, 1], c=['red' if p==0 else 'orange' for p in predictions], \n            marker='*', s=300, label='Predictions', edgecolors='black', linewidths=2)\nplt.xlabel('Size')\nplt.ylabel('Sweetness')\nplt.title('\u2705 AFTER: KNN Classification\\n(Similar things are close together!)', fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, k=3):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/00_Python_Libraries_for_AI.ipynb",
      "status": "failed",
      "execution_time": 3.845499277114868,
      "error": "An error occurred while executing the following cell:\n------------------\n# \ud83d\udcda QUICK REFERENCE: NumPy Most Commonly Used Functions\n# Complete cheat sheet of functions you'll use in AI projects\n\nimport numpy as np\n\nprint(\"=\" * 70)\nprint(\"\ud83d\udcda NUMPY FUNCTION REFERENCE - Most Commonly Used Functions\")\nprint(\"=\" * 70)\nprint()\n\nprint(\"\ud83d\udd39 ARRAY CREATION:\")\nprint(\"   np.array([1, 2, 3])                    # Create from list\")\nprint(\"   np.zeros(5)                            # Array of zeros: [0, 0, 0, 0, 0]\")\nprint(\"   np.ones(5)                             # Array of ones: [1, 1, 1, 1, 1]\")\nprint(\"   np.arange(0, 10, 2)                    # Like range(): [0, 2, 4, 6, 8]\")\nprint(\"   np.linspace(0, 1, 5)                   # Evenly spaced: [0, 0.25, 0.5, 0.75, 1]\")\nprint(\"   np.empty((3, 3))                       # Uninitialized array (fast)\")\nprint(\"   np.full((2, 3), 7)                     # Array filled with value: all 7s\")\nprint(\"   np.eye(3)                              # Identity matrix (3x3)\")\nprint(\"   np.random.rand(5)                      # Random [0,1): 5 numbers\")\nprint(\"   np.random.randn(5)                     # Random normal: mean=0, std=1\")\nprint(\"   np.random.randint(0, 10, 5)            # Random integers: 5 numbers from [0,10)\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY PROPERTIES:\")\nprint(\"   arr.shape                              # Dimensions: (3, 4)\")\nprint(\"   arr.size                               # Total elements: 12\")\nprint(\"   arr.dtype                              # Data type: int64, float64\")\nprint(\"   arr.ndim                               # Number of dimensions: 2\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY OPERATIONS (Element-wise):\")\nprint(\"   arr1 + arr2                            # Addition\")\nprint(\"   arr1 - arr2                            # Subtraction\")\nprint(\"   arr1 * arr2                            # Multiplication\")\nprint(\"   arr1\narr2                            # Division\")\nprint(\"   arr ** 2                               # Power\")\nprint(\"   arr % 2                                # Modulo\")\nprint()\n\nprint(\"\ud83d\udd39 STATISTICAL FUNCTIONS:\")\nprint(\"   np.mean(arr)                           # Average value\")\nprint(\"   np.median(arr)                         # Median value\")\nprint(\"   np.std(arr)                            # Standard deviation\")\nprint(\"   np.var(arr)                            # Variance\")\nprint(\"   np.min(arr)                            # Minimum value\")\nprint(\"   np.max(arr)                            # Maximum value\")\nprint(\"   np.sum(arr)                            # Sum of all elements\")\nprint(\"   np.prod(arr)                           # Product of all elements\")\nprint(\"   np.percentile(arr, 75)                 # 75th percentile\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY MANIPULATION:\")\nprint(\"   arr.reshape(3, 4)                      # Reshape to 3x4\")\nprint(\"   arr.flatten()                          # Flatten to 1D\")\nprint(\"   np.concatenate([arr1, arr2])           # Join arrays\")\nprint(\"   np.split(arr, 3)                       # Split array into 3 parts\")\nprint(\"   arr.T                                  # Transpose\")\nprint(\"   np.sort(arr)                           # Sort array\")\nprint(\"   np.argsort(arr)                        # Indices that would sort\")\nprint()\n\nprint(\"\ud83d\udd39 INDEXING & SLICING:\")\nprint(\"   arr[0]                                 # First element\")\nprint(\"   arr[1:4]                               # Slice: elements 1,2,3\")\nprint(\"   arr[-1]                                # Last element\")\nprint(\"   arr[arr > 5]                           # Boolean indexing: elements > 5\")\nprint(\"   arr[[0, 2, 4]]                         # Fancy indexing: select indices\")\nprint()\n\nprint(\"\ud83d\udd39 MATRIX OPERATIONS:\")\nprint(\"   np.dot(A, B)                           # Matrix multiplication\")\nprint(\"   A @ B                                  # Matrix multiplication (Python 3.5+)\")\nprint(\"   np.linalg.inv(A)                       # Matrix inverse\")\nprint(\"   np.linalg.det(A)                       # Determinant\")\nprint(\"   np.linalg.eig(A)                       # Eigenvalues & eigenvectors\")\nprint()\n\nprint(\"\ud83d\udd39 MATH FUNCTIONS:\")\nprint(\"   np.sqrt(arr)                           # Square root\")\nprint(\"   np.exp(arr)                            # Exponential\")\nprint(\"   np.log(arr)                            # Natural logarithm\")\nprint(\"   np.sin(arr), np.cos(arr)               # Trigonometric\")\nprint(\"   np.abs(arr)                            # Absolute value\")\nprint()\n\nprint(\"\ud83d\udca1 TIP: These functions work on entire arrays at once - very fast!\")\nprint(\"\ud83d\udca1 TIP: Most functions can work with axis parameter: axis=0 (rows), axis=1 (columns)\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   arr1\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 36)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# \ud83d\udcda QUICK REFERENCE: NumPy Most Commonly Used Functions\n# Complete cheat sheet of functions you'll use in AI projects\n\nimport numpy as np\n\nprint(\"=\" * 70)\nprint(\"\ud83d\udcda NUMPY FUNCTION REFERENCE - Most Commonly Used Functions\")\nprint(\"=\" * 70)\nprint()\n\nprint(\"\ud83d\udd39 ARRAY CREATION:\")\nprint(\"   np.array([1, 2, 3])                    # Create from list\")\nprint(\"   np.zeros(5)                            # Array of zeros: [0, 0, 0, 0, 0]\")\nprint(\"   np.ones(5)                             # Array of ones: [1, 1, 1, 1, 1]\")\nprint(\"   np.arange(0, 10, 2)                    # Like range(): [0, 2, 4, 6, 8]\")\nprint(\"   np.linspace(0, 1, 5)                   # Evenly spaced: [0, 0.25, 0.5, 0.75, 1]\")\nprint(\"   np.empty((3, 3))                       # Uninitialized array (fast)\")\nprint(\"   np.full((2, 3), 7)                     # Array filled with value: all 7s\")\nprint(\"   np.eye(3)                              # Identity matrix (3x3)\")\nprint(\"   np.random.rand(5)                      # Random [0,1): 5 numbers\")\nprint(\"   np.random.randn(5)                     # Random normal: mean=0, std=1\")\nprint(\"   np.random.randint(0, 10, 5)            # Random integers: 5 numbers from [0,10)\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY PROPERTIES:\")\nprint(\"   arr.shape                              # Dimensions: (3, 4)\")\nprint(\"   arr.size                               # Total elements: 12\")\nprint(\"   arr.dtype                              # Data type: int64, float64\")\nprint(\"   arr.ndim                               # Number of dimensions: 2\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY OPERATIONS (Element-wise):\")\nprint(\"   arr1 + arr2                            # Addition\")\nprint(\"   arr1 - arr2                            # Subtraction\")\nprint(\"   arr1 * arr2                            # Multiplication\")\nprint(\"   arr1\narr2                            # Division\")\nprint(\"   arr ** 2                               # Power\")\nprint(\"   arr % 2                                # Modulo\")\nprint()\n\nprint(\"\ud83d\udd39 STATISTICAL FUNCTIONS:\")\nprint(\"   np.mean(arr)                           # Average value\")\nprint(\"   np.median(arr)                         # Median value\")\nprint(\"   np.std(arr)                            # Standard deviation\")\nprint(\"   np.var(arr)                            # Variance\")\nprint(\"   np.min(arr)                            # Minimum value\")\nprint(\"   np.max(arr)                            # Maximum value\")\nprint(\"   np.sum(arr)                            # Sum of all elements\")\nprint(\"   np.prod(arr)                           # Product of all elements\")\nprint(\"   np.percentile(arr, 75)                 # 75th percentile\")\nprint()\n\nprint(\"\ud83d\udd39 ARRAY MANIPULATION:\")\nprint(\"   arr.reshape(3, 4)                      # Reshape to 3x4\")\nprint(\"   arr.flatten()                          # Flatten to 1D\")\nprint(\"   np.concatenate([arr1, arr2])           # Join arrays\")\nprint(\"   np.split(arr, 3)                       # Split array into 3 parts\")\nprint(\"   arr.T                                  # Transpose\")\nprint(\"   np.sort(arr)                           # Sort array\")\nprint(\"   np.argsort(arr)                        # Indices that would sort\")\nprint()\n\nprint(\"\ud83d\udd39 INDEXING & SLICING:\")\nprint(\"   arr[0]                                 # First element\")\nprint(\"   arr[1:4]                               # Slice: elements 1,2,3\")\nprint(\"   arr[-1]                                # Last element\")\nprint(\"   arr[arr > 5]                           # Boolean indexing: elements > 5\")\nprint(\"   arr[[0, 2, 4]]                         # Fancy indexing: select indices\")\nprint()\n\nprint(\"\ud83d\udd39 MATRIX OPERATIONS:\")\nprint(\"   np.dot(A, B)                           # Matrix multiplication\")\nprint(\"   A @ B                                  # Matrix multiplication (Python 3.5+)\")\nprint(\"   np.linalg.inv(A)                       # Matrix inverse\")\nprint(\"   np.linalg.det(A)                       # Determinant\")\nprint(\"   np.linalg.eig(A)                       # Eigenvalues & eigenvectors\")\nprint()\n\nprint(\"\ud83d\udd39 MATH FUNCTIONS:\")\nprint(\"   np.sqrt(arr)                           # Square root\")\nprint(\"   np.exp(arr)                            # Exponential\")\nprint(\"   np.log(arr)                            # Natural logarithm\")\nprint(\"   np.sin(arr), np.cos(arr)               # Trigonometric\")\nprint(\"   np.abs(arr)                            # Absolute value\")\nprint()\n\nprint(\"\ud83d\udca1 TIP: These functions work on entire arrays at once - very fast!\")\nprint(\"\ud83d\udca1 TIP: Most functions can work with axis parameter: axis=0 (rows), axis=1 (columns)\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   arr1\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 36)\n\n\n",
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/01_Introduction_Search_Algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.8070027828216553,
      "error": "An error occurred while executing the following cell:\n------------------\n# Visualize Dijkstra's path found\ndef visualize_dijkstra_path(graph, path, exploration_order, edge_costs, title=\"Dijkstra's Algorithm Result\"):\n    \"\"\"\n    Visualize the path found by Dijkstra's algorithm.\n    \n    \u23f0 WHEN to use: After Dijkstra completes - see the optimal path found\n    \ud83d\udca1 WHY use: Visual understanding helps verify algorithm works correctly, see path with costs!\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))  # Create figure: Set size to 12 inches wide, 8 inches tall\n    \n    positions = {  # Define node positions: Fixed coordinates for each node (for consistent visualization)\n        'A': (3, 3), 'B': (1.5, 2), 'C': (4.5, 2),  # Top row: A at center, B left, C right\n        'D': (0.5, 1), 'E': (2.5, 1), 'F': (4, 1), 'G': (3, 0)  # Bottom rows: D, E, F, G at different levels\n    }\n    \n    # Draw all edges with costs (weights)\n    for node, neighbors in graph.items():  # Loop through all nodes: Iterate over every node in graph\n        x1, y1 = positions[node]  # Get node position: Get (x, y) coordinates for current node\n        for neighbor in neighbors:  # Loop through neighbors: Iterate over each neighbor of current node\n            x2, y2 = positions[neighbor]  # Get neighbor position: Get (x, y) coordinates for neighbor node\n            edge_key = (node, neighbor)  # Create edge key: Tuple for dictionary lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost, default to 1\n            \n            # Draw edge (arrow)\n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw edge: Draw arrow from node to neighbor\n                       arrowprops=dict(arrowstyle='->', color='gray', lw=1.5, alpha=0.4))  # Edge style: Gray arrow, thin, semi-transparent\n            \n            # Add cost label on edge\n            mid_x, mid_y = (x1 + x2)\n2, (y1 + y2)\n2  # Calculate midpoint: Center of edge for label placement\n            ax.text(mid_x, mid_y, str(cost), fontsize=10, ha='center', va='center',  # Add cost label: Display edge cost\n                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))  # Label style: White box with border\n    \n    # Highlight the path found by Dijkstra in RED\n    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\n        for i in range(len(path) - 1):  # Loop through path: Iterate over consecutive pairs in path\n            x1, y1 = positions[path[i]]  # Get start position: Get coordinates of current node in path\n            x2, y2 = positions[path[i+1]]  # Get end position: Get coordinates of next node in path\n            edge_key = (path[i], path[i+1])  # Get edge key: Tuple for cost lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost for this path edge\n            \n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw path edge: Draw arrow showing path\n                       arrowprops=dict(arrowstyle='->', color='red', lw=4, alpha=0.9))  # Path style: Red arrow, thick, opaque (stands out!)\n    \n    # Color nodes based on their status\n    for node, (x, y) in positions.items():  # Loop through all nodes: Iterate over every node to color them appropriately\n        if node in path:  # Check if on path: This node is part of the solution path\n            # Nodes on the path: green to red gradient\n            idx = path.index(node)  # Get position in path: Find where this node appears in path (0 = start, last = goal)\n            color = plt.cm.Greens(0.7) if idx == 0 else (plt.cm.Reds(0.7) if idx == len(path)-1 else 'yellow')  # Choose color: Green for start, red for goal, yellow for intermediate\n        elif node in exploration_order:  # Check if explored: This node was visited but not on path\n            # Explored but not on path: light blue\n            color = 'lightblue'  # Color: Light blue (explored but not solution)\n        else:\n            # Unexplored: white\n            color = 'white'  # Color: White (not visited at all)\n        \n        circle = plt.Circle((x, y), 0.3, color=color, edgecolor='black', lw=2, zorder=5)  # Draw node: Create circle at (x, y), radius 0.3, colored, black border\n        ax.add_patch(circle)  # Add to plot: Add circle to the visualization\n        ax.text(x, y, node, ha='center', va='center', fontsize=14, fontweight='bold')  # Add label: Place node name in center of circle, bold text\n    \n    ax.set_xlim(-0.5, 5.5)  # Set x-axis limits: Define horizontal range of plot\n    ax.set_ylim(-0.5, 4)  # Set y-axis limits: Define vertical range of plot\n    ax.set_aspect('equal')  # Equal aspect ratio: Make circles look circular (not oval)\n    ax.axis('off')  # Hide axes: Remove axis lines and labels (cleaner look)\n    ax.set_title(title, fontsize=16, fontweight='bold')  # Add title: Bold text, large font\n    \n    # Add legend\n    legend_elements = [  # Legend items: List of colored patches to explain node colors\n        mpatches.Patch(facecolor='lightgreen', label='Start'),\n        mpatches.Patch(facecolor='yellow', label='Path Nodes'),\n        mpatches.Patch(facecolor='lightcoral', label='Goal'),\n        mpatches.Patch(facecolor='lightblue', label='Explored (not on path)'),\n        mpatches.Patch(facecolor='white', edgecolor='black', label='Unexplored')\n    ]\n    ax.legend(handles=legend_elements, loc='upper right')  # Show legend: Display legend in upper right corner\n    \n    plt.tight_layout()  # Adjust spacing: Prevent labels from overlapping or being cut off\n    plt.show()  # Display plot: Show the visualization (MUST call this to see plot!)\n\n# Visualize Dijkstra result\nprint(\"\\n\ud83d\udcca Visualizing Dijkstra's result...\")\nif dijkstra_path:\n    visualize_dijkstra_path(weighted_graph, dijkstra_path, dijkstra_order, edge_costs, \n                           \"Dijkstra's Algorithm: Optimal Path Found (Red Arrows)\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:36\u001b[0;36m\u001b[0m\n\u001b[0;31m    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Visualize Dijkstra's path found\ndef visualize_dijkstra_path(graph, path, exploration_order, edge_costs, title=\"Dijkstra's Algorithm Result\"):\n    \"\"\"\n    Visualize the path found by Dijkstra's algorithm.\n    \n    \u23f0 WHEN to use: After Dijkstra completes - see the optimal path found\n    \ud83d\udca1 WHY use: Visual understanding helps verify algorithm works correctly, see path with costs!\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))  # Create figure: Set size to 12 inches wide, 8 inches tall\n    \n    positions = {  # Define node positions: Fixed coordinates for each node (for consistent visualization)\n        'A': (3, 3), 'B': (1.5, 2), 'C': (4.5, 2),  # Top row: A at center, B left, C right\n        'D': (0.5, 1), 'E': (2.5, 1), 'F': (4, 1), 'G': (3, 0)  # Bottom rows: D, E, F, G at different levels\n    }\n    \n    # Draw all edges with costs (weights)\n    for node, neighbors in graph.items():  # Loop through all nodes: Iterate over every node in graph\n        x1, y1 = positions[node]  # Get node position: Get (x, y) coordinates for current node\n        for neighbor in neighbors:  # Loop through neighbors: Iterate over each neighbor of current node\n            x2, y2 = positions[neighbor]  # Get neighbor position: Get (x, y) coordinates for neighbor node\n            edge_key = (node, neighbor)  # Create edge key: Tuple for dictionary lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost, default to 1\n            \n            # Draw edge (arrow)\n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw edge: Draw arrow from node to neighbor\n                       arrowprops=dict(arrowstyle='->', color='gray', lw=1.5, alpha=0.4))  # Edge style: Gray arrow, thin, semi-transparent\n            \n            # Add cost label on edge\n            mid_x, mid_y = (x1 + x2)\n2, (y1 + y2)\n2  # Calculate midpoint: Center of edge for label placement\n            ax.text(mid_x, mid_y, str(cost), fontsize=10, ha='center', va='center',  # Add cost label: Display edge cost\n                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))  # Label style: White box with border\n    \n    # Highlight the path found by Dijkstra in RED\n    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\n        for i in range(len(path) - 1):  # Loop through path: Iterate over consecutive pairs in path\n            x1, y1 = positions[path[i]]  # Get start position: Get coordinates of current node in path\n            x2, y2 = positions[path[i+1]]  # Get end position: Get coordinates of next node in path\n            edge_key = (path[i], path[i+1])  # Get edge key: Tuple for cost lookup\n            cost = edge_costs.get(edge_key, 1)  # Get edge cost: Look up cost for this path edge\n            \n            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),  # Draw path edge: Draw arrow showing path\n                       arrowprops=dict(arrowstyle='->', color='red', lw=4, alpha=0.9))  # Path style: Red arrow, thick, opaque (stands out!)\n    \n    # Color nodes based on their status\n    for node, (x, y) in positions.items():  # Loop through all nodes: Iterate over every node to color them appropriately\n        if node in path:  # Check if on path: This node is part of the solution path\n            # Nodes on the path: green to red gradient\n            idx = path.index(node)  # Get position in path: Find where this node appears in path (0 = start, last = goal)\n            color = plt.cm.Greens(0.7) if idx == 0 else (plt.cm.Reds(0.7) if idx == len(path)-1 else 'yellow')  # Choose color: Green for start, red for goal, yellow for intermediate\n        elif node in exploration_order:  # Check if explored: This node was visited but not on path\n            # Explored but not on path: light blue\n            color = 'lightblue'  # Color: Light blue (explored but not solution)\n        else:\n            # Unexplored: white\n            color = 'white'  # Color: White (not visited at all)\n        \n        circle = plt.Circle((x, y), 0.3, color=color, edgecolor='black', lw=2, zorder=5)  # Draw node: Create circle at (x, y), radius 0.3, colored, black border\n        ax.add_patch(circle)  # Add to plot: Add circle to the visualization\n        ax.text(x, y, node, ha='center', va='center', fontsize=14, fontweight='bold')  # Add label: Place node name in center of circle, bold text\n    \n    ax.set_xlim(-0.5, 5.5)  # Set x-axis limits: Define horizontal range of plot\n    ax.set_ylim(-0.5, 4)  # Set y-axis limits: Define vertical range of plot\n    ax.set_aspect('equal')  # Equal aspect ratio: Make circles look circular (not oval)\n    ax.axis('off')  # Hide axes: Remove axis lines and labels (cleaner look)\n    ax.set_title(title, fontsize=16, fontweight='bold')  # Add title: Bold text, large font\n    \n    # Add legend\n    legend_elements = [  # Legend items: List of colored patches to explain node colors\n        mpatches.Patch(facecolor='lightgreen', label='Start'),\n        mpatches.Patch(facecolor='yellow', label='Path Nodes'),\n        mpatches.Patch(facecolor='lightcoral', label='Goal'),\n        mpatches.Patch(facecolor='lightblue', label='Explored (not on path)'),\n        mpatches.Patch(facecolor='white', edgecolor='black', label='Unexplored')\n    ]\n    ax.legend(handles=legend_elements, loc='upper right')  # Show legend: Display legend in upper right corner\n    \n    plt.tight_layout()  # Adjust spacing: Prevent labels from overlapping or being cut off\n    plt.show()  # Display plot: Show the visualization (MUST call this to see plot!)\n\n# Visualize Dijkstra result\nprint(\"\\n\ud83d\udcca Visualizing Dijkstra's result...\")\nif dijkstra_path:\n    visualize_dijkstra_path(weighted_graph, dijkstra_path, dijkstra_order, edge_costs, \n                           \"Dijkstra's Algorithm: Optimal Path Found (Red Arrows)\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:36\u001b[0;36m\u001b[0m\n\u001b[0;31m    if path:  # Check if path exists: Only draw path if Dijkstra found a solution\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/02_real_world_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 0.7576062679290771,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/03_implementing_ai_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.6659719944000244,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/04_implementing_adversarial_search.ipynb",
      "status": "passed",
      "execution_time": 0.7697908878326416,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/05_ai_learning_methods_research.ipynb",
      "status": "passed",
      "execution_time": 0.6114199161529541,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/ai_learning_methods_and_research.ipynb",
      "status": "passed",
      "execution_time": 1.5582151412963867,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/evaluating_ai_models.ipynb",
      "status": "passed",
      "execution_time": 1.6120529174804688,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/implementing_adversarial_search.ipynb",
      "status": "passed",
      "execution_time": 1.4005670547485352,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/implementing_ai_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.5240519046783447,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/real_world_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.3905742168426514,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/exercises/exercise_01_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.5472261905670166,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/02_Knowledge_Representation.ipynb",
      "status": "failed",
      "execution_time": 0.527108907699585,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Define a Fact class\n# This represents a single piece of knowledge: Subject-Predicate-Object\n# Example: \"Socrates\" (subject) \"is_a\" (predicate) \"Human\" (object)\n\nclass Fact:\n    \"\"\"\n    Represents a single fact in knowledge base.\n    \n    Structure: Subject -> Predicate -> Object\n    Example: \"Socrates\" -> \"is_a\" -> \"Human\"\n    \n    Why use a class? Because we can:\n    - Store structured data\n    - Add methods to work with facts\n    - Compare facts easily\n    \"\"\"\n    def__init__(self, subject, predicate, object_val):\n        \"\"\"\n        Initialize a fact with three components:\n        - subject: Who/what (e.g., \"Socrates\")\n        - predicate: Relationship (e.g., \"is_a\", \"studied_under\")\n        - object_val: What it relates to (e.g., \"Human\", \"Plato\")\n        \"\"\"\n        self.subject = subject      # Store subject\n        self.predicate = predicate  # Store predicate (relationship type)\n        self.object = object_val    # Store object\n    \n    def__repr__(self):\n        \"\"\"\n        Pretty print the fact.\n        When we print a Fact object, it shows: Fact(Socrates, is_a, Human)\n        \"\"\"\n        return f\"Fact({self.subject}, {self.predicate}, {self.object})\"\n\n# Step 2: Create a Knowledge Base class\n# This is our \"memory\" - it stores facts and allows us to query them\n\nclass KnowledgeBase:\n    \"\"\"\n    A simple knowledge base using Python structures.\n    \n    This is our \"memory\" - it stores facts and allows us to:\n    1. Add new facts\n    2. Query facts (find facts matching criteria)\n    3. Get statistics about what we know\n    \n    BEFORE: We had scattered strings\n    AFTER: We have structured storage with query capabilities!\n    \"\"\"\n    def__init__(self):\n        \"\"\"\n        Initialize an empty knowledge base.\n        We start with no facts and no rules.\n        \"\"\"\n        self.facts = []  # List to store all facts (our memory!)\n        self.rules = []  # List to store rules (we'll use this later)\n        print(\"\u2705 Created new Knowledge Base (empty - ready to learn!)\")\n    \n    def add_fact(self, subject, predicate, object_val):\n        \"\"\"\n        Add a fact to the knowledge base.\n        \n        Process:\n        1. Create a Fact object from the components\n        2. Add it to our facts list (store it in memory)\n        3. Return the fact (in case we want to use it later)\n        \"\"\"\n        fact = Fact(subject, predicate, object_val)  # Create fact object\n        self.facts.append(fact)  # Add to our knowledge base (store in memory)\n        print(f\"  \u2795 Added: {fact}\")  # Show what we added (for learning!)\n        return fact  # Return it (useful for chaining operations)\n    \n    def query(self, subject=None, predicate=None, object_val=None):\n        \"\"\"\n        Query facts matching given criteria.\n        \n        This is powerful! We can ask:\n        - \"What do we know about Socrates?\" (subject='Socrates')\n        - \"What relationships involve 'is_a'?\" (predicate='is_a')\n        - \"Who/what is a Human?\" (object_val='Human')\n        - Or any combination!\n        \n        Parameters:\n        - subject: Filter by subject (who/what)\n        - predicate: Filter by predicate (relationship type)\n        - object_val: Filter by object (what it relates to)\n        \n        Returns: List of matching Fact objects\n        \"\"\"\n        results = []  # List to store matching facts\n        \n        # Go through each fact in our knowledge base\n        for fact in self.facts:\n            # Check if this fact matches all our criteria\n            # (If a criteria is None, we don't filter on it - means \"match anything\")\n            matches_subject = (subject is None or fact.subject == subject)\n            matches_predicate = (predicate is None or fact.predicate == predicate)\n            matches_object = (object_val is None or fact.object == object_val)\n            \n            # If all specified criteria match, include this fact\n            if matches_subject and matches_predicate and matches_object:\n                results.append(fact)  # Add to results\n        \n        return results  # Return all matching facts\n    \n    def__repr__(self):\n        \"\"\"\n        Show summary of knowledge base.\n        When we print the knowledge base, it shows: KnowledgeBase(5 facts, 0 rules)\n        \"\"\"\n        return f\"KnowledgeBase({len(self.facts)} facts, {len(self.rules)} rules)\"\n\n# Step 3: Create a knowledge base and add facts\n# NOW we can see the difference!\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 AFTER: Structured Knowledge Base\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udcdd Creating knowledge base and adding facts...\\n\")\n\nkb = KnowledgeBase()  # Create empty knowledge base\n\nprint(\"\\n\u2795 Adding facts:\")\nkb.add_fact(\"Socrates\", \"is_a\", \"Human\")       # Socrates is a Human\nkb.add_fact(\"Humans\", \"are\", \"Mortal\")          # Humans are Mortal\nkb.add_fact(\"Socrates\", \"is_a\", \"Philosopher\")  # Socrates is a Philosopher\nkb.add_fact(\"Plato\", \"is_a\", \"Human\")           # Plato is a Human\nkb.add_fact(\"Plato\", \"studied_under\", \"Socrates\")  # Plato studied under Socrates\n\nprint(f\"\\n\ud83d\udcca Knowledge Base Status: {kb}\")\nprint(f\"\u2705 Now we have {len(kb.facts)} structured facts (instead of scattered strings)!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, subject, predicate, object_val):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Define a Fact class\n# This represents a single piece of knowledge: Subject-Predicate-Object\n# Example: \"Socrates\" (subject) \"is_a\" (predicate) \"Human\" (object)\n\nclass Fact:\n    \"\"\"\n    Represents a single fact in knowledge base.\n    \n    Structure: Subject -> Predicate -> Object\n    Example: \"Socrates\" -> \"is_a\" -> \"Human\"\n    \n    Why use a class? Because we can:\n    - Store structured data\n    - Add methods to work with facts\n    - Compare facts easily\n    \"\"\"\n    def__init__(self, subject, predicate, object_val):\n        \"\"\"\n        Initialize a fact with three components:\n        - subject: Who/what (e.g., \"Socrates\")\n        - predicate: Relationship (e.g., \"is_a\", \"studied_under\")\n        - object_val: What it relates to (e.g., \"Human\", \"Plato\")\n        \"\"\"\n        self.subject = subject      # Store subject\n        self.predicate = predicate  # Store predicate (relationship type)\n        self.object = object_val    # Store object\n    \n    def__repr__(self):\n        \"\"\"\n        Pretty print the fact.\n        When we print a Fact object, it shows: Fact(Socrates, is_a, Human)\n        \"\"\"\n        return f\"Fact({self.subject}, {self.predicate}, {self.object})\"\n\n# Step 2: Create a Knowledge Base class\n# This is our \"memory\" - it stores facts and allows us to query them\n\nclass KnowledgeBase:\n    \"\"\"\n    A simple knowledge base using Python structures.\n    \n    This is our \"memory\" - it stores facts and allows us to:\n    1. Add new facts\n    2. Query facts (find facts matching criteria)\n    3. Get statistics about what we know\n    \n    BEFORE: We had scattered strings\n    AFTER: We have structured storage with query capabilities!\n    \"\"\"\n    def__init__(self):\n        \"\"\"\n        Initialize an empty knowledge base.\n        We start with no facts and no rules.\n        \"\"\"\n        self.facts = []  # List to store all facts (our memory!)\n        self.rules = []  # List to store rules (we'll use this later)\n        print(\"\u2705 Created new Knowledge Base (empty - ready to learn!)\")\n    \n    def add_fact(self, subject, predicate, object_val):\n        \"\"\"\n        Add a fact to the knowledge base.\n        \n        Process:\n        1. Create a Fact object from the components\n        2. Add it to our facts list (store it in memory)\n        3. Return the fact (in case we want to use it later)\n        \"\"\"\n        fact = Fact(subject, predicate, object_val)  # Create fact object\n        self.facts.append(fact)  # Add to our knowledge base (store in memory)\n        print(f\"  \u2795 Added: {fact}\")  # Show what we added (for learning!)\n        return fact  # Return it (useful for chaining operations)\n    \n    def query(self, subject=None, predicate=None, object_val=None):\n        \"\"\"\n        Query facts matching given criteria.\n        \n        This is powerful! We can ask:\n        - \"What do we know about Socrates?\" (subject='Socrates')\n        - \"What relationships involve 'is_a'?\" (predicate='is_a')\n        - \"Who/what is a Human?\" (object_val='Human')\n        - Or any combination!\n        \n        Parameters:\n        - subject: Filter by subject (who/what)\n        - predicate: Filter by predicate (relationship type)\n        - object_val: Filter by object (what it relates to)\n        \n        Returns: List of matching Fact objects\n        \"\"\"\n        results = []  # List to store matching facts\n        \n        # Go through each fact in our knowledge base\n        for fact in self.facts:\n            # Check if this fact matches all our criteria\n            # (If a criteria is None, we don't filter on it - means \"match anything\")\n            matches_subject = (subject is None or fact.subject == subject)\n            matches_predicate = (predicate is None or fact.predicate == predicate)\n            matches_object = (object_val is None or fact.object == object_val)\n            \n            # If all specified criteria match, include this fact\n            if matches_subject and matches_predicate and matches_object:\n                results.append(fact)  # Add to results\n        \n        return results  # Return all matching facts\n    \n    def__repr__(self):\n        \"\"\"\n        Show summary of knowledge base.\n        When we print the knowledge base, it shows: KnowledgeBase(5 facts, 0 rules)\n        \"\"\"\n        return f\"KnowledgeBase({len(self.facts)} facts, {len(self.rules)} rules)\"\n\n# Step 3: Create a knowledge base and add facts\n# NOW we can see the difference!\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 AFTER: Structured Knowledge Base\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udcdd Creating knowledge base and adding facts...\\n\")\n\nkb = KnowledgeBase()  # Create empty knowledge base\n\nprint(\"\\n\u2795 Adding facts:\")\nkb.add_fact(\"Socrates\", \"is_a\", \"Human\")       # Socrates is a Human\nkb.add_fact(\"Humans\", \"are\", \"Mortal\")          # Humans are Mortal\nkb.add_fact(\"Socrates\", \"is_a\", \"Philosopher\")  # Socrates is a Philosopher\nkb.add_fact(\"Plato\", \"is_a\", \"Human\")           # Plato is a Human\nkb.add_fact(\"Plato\", \"studied_under\", \"Socrates\")  # Plato studied under Socrates\n\nprint(f\"\\n\ud83d\udcca Knowledge Base Status: {kb}\")\nprint(f\"\u2705 Now we have {len(kb.facts)} structured facts (instead of scattered strings)!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, subject, predicate, object_val):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/03_propositional_logic_truth_tables.ipynb",
      "status": "passed",
      "execution_time": 1.0387468338012695,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/04_inference_rules_logical_reasoning.ipynb",
      "status": "failed",
      "execution_time": 0.5353562831878662,
      "error": "An error occurred while executing the following cell:\n------------------\nclass LogicalArgument:\n    \"\"\"Class to represent and validate logical arguments\"\"\"\n    \n    def__init__(self):\n        self.premises = []\n        self.conclusion = None\n        self.inference_rule = None\n    \n    def add_premise(self, premise):\n        \"\"\"Add a premise to the argument\"\"\"\n        self.premises.append(premise)\n    \n    def set_conclusion(self, conclusion):\n        \"\"\"Set the conclusion of the argument\"\"\"\n        self.conclusion = conclusion\n    \n    def validate(self):\n        \"\"\"Validate the argument using inference rules\"\"\"\n        if len(self.premises) < 2:\n            return False, \"Need at least 2 premises\"\n        \n        # Try to identify which inference rule applies\n        # This is a simplified version - in practice, you'd have more sophisticated pattern matching\n        \n        # Check for Modus Ponens pattern: P \u2192 Q, P, therefore Q\n        if len(self.premises) == 2:\n            # Simplified: assume first premise is P \u2192 Q, second is P\n            # In practice, you'd parse the logical structure\n            pass\n        \n        return True, \"Valid argument\"\n    \n    def__str__(self):\n        result = \"Premises:\\n\"\n        for i, p in enumerate(self.premises, 1):\n            result += f\"  {i}. {p}\\n\"\n        result += f\"Conclusion: {self.conclusion}\\n\"\n        return result\n\n# Example: Classic \"Socrates is mortal\" argument\nprint(\"=\" * 60)\nprint(\"Example: Validating 'Socrates is Mortal' Argument\")\nprint(\"=\" * 60)\n\nargument = LogicalArgument()\nargument.add_premise(\"All humans are mortal\")\nargument.add_premise(\"Socrates is a human\")\nargument.set_conclusion(\"Therefore, Socrates is mortal\")\n\nprint(argument)\nvalid, message = argument.validate()\nprint(f\"Validation: {'\u2705 VALID' if valid else '\u274c INVALID'}\")\nprint(f\"Message: {message}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass LogicalArgument:\n    \"\"\"Class to represent and validate logical arguments\"\"\"\n    \n    def__init__(self):\n        self.premises = []\n        self.conclusion = None\n        self.inference_rule = None\n    \n    def add_premise(self, premise):\n        \"\"\"Add a premise to the argument\"\"\"\n        self.premises.append(premise)\n    \n    def set_conclusion(self, conclusion):\n        \"\"\"Set the conclusion of the argument\"\"\"\n        self.conclusion = conclusion\n    \n    def validate(self):\n        \"\"\"Validate the argument using inference rules\"\"\"\n        if len(self.premises) < 2:\n            return False, \"Need at least 2 premises\"\n        \n        # Try to identify which inference rule applies\n        # This is a simplified version - in practice, you'd have more sophisticated pattern matching\n        \n        # Check for Modus Ponens pattern: P \u2192 Q, P, therefore Q\n        if len(self.premises) == 2:\n            # Simplified: assume first premise is P \u2192 Q, second is P\n            # In practice, you'd parse the logical structure\n            pass\n        \n        return True, \"Valid argument\"\n    \n    def__str__(self):\n        result = \"Premises:\\n\"\n        for i, p in enumerate(self.premises, 1):\n            result += f\"  {i}. {p}\\n\"\n        result += f\"Conclusion: {self.conclusion}\\n\"\n        return result\n\n# Example: Classic \"Socrates is mortal\" argument\nprint(\"=\" * 60)\nprint(\"Example: Validating 'Socrates is Mortal' Argument\")\nprint(\"=\" * 60)\n\nargument = LogicalArgument()\nargument.add_premise(\"All humans are mortal\")\nargument.add_premise(\"Socrates is a human\")\nargument.set_conclusion(\"Therefore, Socrates is mortal\")\n\nprint(argument)\nvalid, message = argument.validate()\nprint(f\"Validation: {'\u2705 VALID' if valid else '\u274c INVALID'}\")\nprint(f\"Message: {message}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/05_first_order_logic_fol.ipynb",
      "status": "failed",
      "execution_time": 0.5327310562133789,
      "error": "An error occurred while executing the following cell:\n------------------\nclass FOLPredicate:\n    \"\"\"Represents a FOL predicate (e.g., Human(x), Loves(x, y))\"\"\"\n    \n    def__init__(self, name: str, arguments: List[str]):\n        self.name = name\n        self.arguments = arguments  # List of variables or constants\n    \n    def__str__(self):\n        args_str = ', '.join(self.arguments)\n        return f\"{self.name}({args_str})\"\n    \n    def__repr__(self):\n        return str(self)\n    \n    def evaluate(self, interpretation: Dict[str, Any]) -> bool:\n        \"\"\"\n        Evaluate predicate with given interpretation (variable assignments).\n        In a real system, this would check against a knowledge base.\n        \"\"\"\n        # For demonstration: check if all arguments are in interpretation\n        # In practice, this would query a knowledge base\n        for arg in self.arguments:\n            if arg not in interpretation:\n                return False  # Cannot evaluate if variable not bound\n        return True  # Simplified: assume true if all variables bound\n\n# Example: Create predicates\nprint(\"=\" * 60)\nprint(\"FOL Predicate Examples:\")\nprint(\"=\" * 60)\n\n# Human(socrates)\nhuman_pred = FOLPredicate(\"Human\", [\"socrates\"])\nprint(f\"1. {human_pred}\")\n\n# Loves(romeo, juliet)\nloves_pred = FOLPredicate(\"Loves\", [\"romeo\", \"juliet\"])\nprint(f\"2. {loves_pred}\")\n\n# Mortal(x) - with variable\nmortal_pred = FOLPredicate(\"Mortal\", [\"x\"])\nprint(f\"3. {mortal_pred}\")\n\n# Greater(x, y) - binary predicate\ngreater_pred = FOLPredicate(\"Greater\", [\"x\", \"y\"])\nprint(f\"4. {greater_pred}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, name: str, arguments: List[str]):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass FOLPredicate:\n    \"\"\"Represents a FOL predicate (e.g., Human(x), Loves(x, y))\"\"\"\n    \n    def__init__(self, name: str, arguments: List[str]):\n        self.name = name\n        self.arguments = arguments  # List of variables or constants\n    \n    def__str__(self):\n        args_str = ', '.join(self.arguments)\n        return f\"{self.name}({args_str})\"\n    \n    def__repr__(self):\n        return str(self)\n    \n    def evaluate(self, interpretation: Dict[str, Any]) -> bool:\n        \"\"\"\n        Evaluate predicate with given interpretation (variable assignments).\n        In a real system, this would check against a knowledge base.\n        \"\"\"\n        # For demonstration: check if all arguments are in interpretation\n        # In practice, this would query a knowledge base\n        for arg in self.arguments:\n            if arg not in interpretation:\n                return False  # Cannot evaluate if variable not bound\n        return True  # Simplified: assume true if all variables bound\n\n# Example: Create predicates\nprint(\"=\" * 60)\nprint(\"FOL Predicate Examples:\")\nprint(\"=\" * 60)\n\n# Human(socrates)\nhuman_pred = FOLPredicate(\"Human\", [\"socrates\"])\nprint(f\"1. {human_pred}\")\n\n# Loves(romeo, juliet)\nloves_pred = FOLPredicate(\"Loves\", [\"romeo\", \"juliet\"])\nprint(f\"2. {loves_pred}\")\n\n# Mortal(x) - with variable\nmortal_pred = FOLPredicate(\"Mortal\", [\"x\"])\nprint(f\"3. {mortal_pred}\")\n\n# Greater(x, y) - binary predicate\ngreater_pred = FOLPredicate(\"Greater\", [\"x\", \"y\"])\nprint(f\"4. {greater_pred}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, name: str, arguments: List[str]):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/06_logical_operators_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.7880532741546631,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/07_logical_arguments_validation.ipynb",
      "status": "passed",
      "execution_time": 0.5257420539855957,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/08_model_checking_temporal_logic.ipynb",
      "status": "passed",
      "execution_time": 0.7439839839935303,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/09_fol_parsing_evaluation.ipynb",
      "status": "passed",
      "execution_time": 0.5954837799072266,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/building_logical_arguments_and_validating_them_programmatically.ipynb",
      "status": "passed",
      "execution_time": 1.4299860000610352,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/implementing_logical_operators_and_or_not_implies_biconditional.ipynb",
      "status": "passed",
      "execution_time": 1.4292290210723877,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/implementing_model_checking_algorithms_for_temporal_logic.ipynb",
      "status": "passed",
      "execution_time": 1.457448959350586,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/writing_code_to_parse_and_evaluate_fol_formulas.ipynb",
      "status": "passed",
      "execution_time": 1.5540380477905273,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/exercises/exercise_02_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.6067070960998535,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/02_bayesian_networks.ipynb",
      "status": "passed",
      "execution_time": 0.6692547798156738,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/03_Learning_Under_Uncertainty.ipynb",
      "status": "failed",
      "execution_time": 0.7887239456176758,
      "error": "An error occurred while executing the following cell:\n------------------\n# \ud83d\udd17 HOW THE SOLUTION SOLVES THE PROBLEM\n# Medical diagnosis example: The problem we identified earlier\n\nclass BayesianInference:\n    \"\"\"\n    Bayesian inference: The SOLUTION to the problem of uncertainty.\n    \n    THE PROBLEM: We get test results but don't know what they mean.\n    THE SOLUTION: Use Bayes' theorem to update our beliefs with evidence.\n    \n    How it works:\n    1. Start with PRIOR belief (what we believe before test)\n    2. Get EVIDENCE (test result)\n    3. Use Bayes' theorem to calculate POSTERIOR (updated belief)\n    \"\"\"\n    def__init__(self, prior_prob):\n        \"\"\"\n        Initialize with prior probability P(H).\n        This is what we believe BEFORE getting evidence.\n        \"\"\"\n        self.prior = prior_prob  # Our initial belief\n        self.posterior = prior_prob  # Updated belief (starts same as prior)\n    \n    def update(self, likelihood, evidence_prob):\n        \"\"\"\n        Update belief using Bayes' theorem.\n        \n        Formula: P(H|E) = P(E|H) * P(H)\nP(E)\n        \n        Where:\n        - P(H|E): Probability of hypothesis given evidence (what we want)\n        - P(E|H): Probability of evidence given hypothesis (likelihood)\n        - P(H): Prior probability of hypothesis\n        - P(E): Probability of evidence\n        \n        This is THE SOLUTION - it tells us how to update beliefs!\n        \"\"\"\n        # Bayes' theorem: Update belief based on evidence\n        self.posterior = (likelihood * self.prior)\nevidence_prob\n        self.prior = self.posterior  # Update for next iteration\n        return self.posterior\n    \n    def get_belief(self):\n        \"\"\"Get current belief (posterior probability)\"\"\"\n        return self.posterior\n\n# Example: Medical diagnosis\n# THE PROBLEM we identified: Test is positive - what does it mean?\nprint(\"=\" * 70)\nprint(\"\ud83d\udd17 PROBLEM \u2192 SOLUTION: Medical Diagnosis Example\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u274c THE PROBLEM (from earlier):\")\nprint(\"   \u2022 Medical test comes back POSITIVE\")\nprint(\"   \u2022 Without probability: 'I definitely have the disease!' (panic)\")\nprint(\"   \u2022 Or: 'Test might be wrong, I'll ignore it' (dangerous)\")\nprint()\nprint(\"\u2705 THE SOLUTION: Use Bayesian inference to calculate actual probability\")\nprint()\n\n# Given information:\nprint(\"\ud83d\udcca Given Information:\")\nprint(\"   \u2022 Prior P(Disease) = 0.01 (1% of population has disease)\")\nprint(\"   \u2022 Test accuracy: P(Positive|Disease) = 0.99 (99% accurate if diseased)\")\nprint(\"   \u2022 Test false positive: P(Positive|No Disease) = 0.05 (5% false positive)\")\nprint()\n\n# Calculate using probability (THE SOLUTION)\nP_disease = 0.01  # Prior: 1% have disease\nP_no_disease = 0.99  # 99% don't have disease\nP_positive_given_disease = 0.99  # Test is 99% accurate if diseased\nP_positive_given_no_disease = 0.05  # 5% false positive rate\n\n# Calculate P(Positive) - overall probability of positive test\n# \u23f0 WHEN to use: BEFORE applying Bayes' theorem - need P(Evidence) for denominator\n# \ud83d\udca1 WHY use: Bayes' theorem needs P(Evidence) in denominator - calculate total probability of positive test\nP_positive = (P_positive_given_disease * P_disease + \n              P_positive_given_no_disease * P_no_disease)  # Total probability: Calculate P(Positive) using law of total probability (sum of conditional probabilities weighted by prior)\n\nprint(f\"\ud83d\udcca Calculation:\")\nprint(f\"   P(Positive) = P(Pos|Disease) \u00d7 P(Disease) + P(Pos|No Disease) \u00d7 P(No Disease)\")  # Show formula: Display the law of total probability formula\nprint(f\"   P(Positive) = {P_positive_given_disease} \u00d7 {P_disease} + {P_positive_given_no_disease} \u00d7 {P_no_disease}\")  # Show values: Display actual numbers plugged into formula\nprint(f\"   P(Positive) = {P_positive:.4f}\")  # Show result: Display calculated probability of positive test (should be around 0.05-0.06!)\nprint()\n\n# Use Bayesian inference (THE SOLUTION)\nprint(\"   \u23f0 WHEN to use: After getting test result - update belief based on evidence\")\nprint(\"   \ud83d\udca1 WHY use: Bayes' theorem updates prior belief with evidence - gives accurate posterior probability!\")\n\nbayesian = BayesianInference(P_disease)  # Create Bayesian object: Initialize with prior probability P(Disease) = 0.01 (what we believe BEFORE test)\nP_disease_given_positive = bayesian.update(P_positive_given_disease, P_positive)  # Update belief: Apply Bayes' theorem to calculate P(Disease|Positive) using likelihood and evidence probability\n\nprint(f\"\u2705 THE SOLUTION (Bayesian Inference):\")\nprint(f\"   P(Disease|Positive) = {P_disease_given_positive:.4f} = {P_disease_given_positive*100:.2f}%\")\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(f\"   \u274c WITHOUT probability: 'I definitely have it!' (wrong!)\")\nprint(f\"   \u2705 WITH probability: 'I have {P_disease_given_positive*100:.1f}% chance' (accurate!)\")\nprint(f\"   \u2022 Instead of panic, we have accurate assessment\")\nprint(f\"   \u2022 Instead of ignoring, we know it's worth investigating\")\nprint(f\"   \u2022 We can make informed medical decisions!\")\nprint()\nprint(\"\ud83d\udcca BEFORE vs AFTER Comparison:\")\nprint(\"   BEFORE: Test positive \u2192 Panic or Ignore (both wrong!)\")\nprint(f\"   AFTER: Test positive \u2192 {P_disease_given_positive*100:.1f}% probability \u2192 Informed decision!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:45\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_belief(self):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# \ud83d\udd17 HOW THE SOLUTION SOLVES THE PROBLEM\n# Medical diagnosis example: The problem we identified earlier\n\nclass BayesianInference:\n    \"\"\"\n    Bayesian inference: The SOLUTION to the problem of uncertainty.\n    \n    THE PROBLEM: We get test results but don't know what they mean.\n    THE SOLUTION: Use Bayes' theorem to update our beliefs with evidence.\n    \n    How it works:\n    1. Start with PRIOR belief (what we believe before test)\n    2. Get EVIDENCE (test result)\n    3. Use Bayes' theorem to calculate POSTERIOR (updated belief)\n    \"\"\"\n    def__init__(self, prior_prob):\n        \"\"\"\n        Initialize with prior probability P(H).\n        This is what we believe BEFORE getting evidence.\n        \"\"\"\n        self.prior = prior_prob  # Our initial belief\n        self.posterior = prior_prob  # Updated belief (starts same as prior)\n    \n    def update(self, likelihood, evidence_prob):\n        \"\"\"\n        Update belief using Bayes' theorem.\n        \n        Formula: P(H|E) = P(E|H) * P(H)\nP(E)\n        \n        Where:\n        - P(H|E): Probability of hypothesis given evidence (what we want)\n        - P(E|H): Probability of evidence given hypothesis (likelihood)\n        - P(H): Prior probability of hypothesis\n        - P(E): Probability of evidence\n        \n        This is THE SOLUTION - it tells us how to update beliefs!\n        \"\"\"\n        # Bayes' theorem: Update belief based on evidence\n        self.posterior = (likelihood * self.prior)\nevidence_prob\n        self.prior = self.posterior  # Update for next iteration\n        return self.posterior\n    \n    def get_belief(self):\n        \"\"\"Get current belief (posterior probability)\"\"\"\n        return self.posterior\n\n# Example: Medical diagnosis\n# THE PROBLEM we identified: Test is positive - what does it mean?\nprint(\"=\" * 70)\nprint(\"\ud83d\udd17 PROBLEM \u2192 SOLUTION: Medical Diagnosis Example\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u274c THE PROBLEM (from earlier):\")\nprint(\"   \u2022 Medical test comes back POSITIVE\")\nprint(\"   \u2022 Without probability: 'I definitely have the disease!' (panic)\")\nprint(\"   \u2022 Or: 'Test might be wrong, I'll ignore it' (dangerous)\")\nprint()\nprint(\"\u2705 THE SOLUTION: Use Bayesian inference to calculate actual probability\")\nprint()\n\n# Given information:\nprint(\"\ud83d\udcca Given Information:\")\nprint(\"   \u2022 Prior P(Disease) = 0.01 (1% of population has disease)\")\nprint(\"   \u2022 Test accuracy: P(Positive|Disease) = 0.99 (99% accurate if diseased)\")\nprint(\"   \u2022 Test false positive: P(Positive|No Disease) = 0.05 (5% false positive)\")\nprint()\n\n# Calculate using probability (THE SOLUTION)\nP_disease = 0.01  # Prior: 1% have disease\nP_no_disease = 0.99  # 99% don't have disease\nP_positive_given_disease = 0.99  # Test is 99% accurate if diseased\nP_positive_given_no_disease = 0.05  # 5% false positive rate\n\n# Calculate P(Positive) - overall probability of positive test\n# \u23f0 WHEN to use: BEFORE applying Bayes' theorem - need P(Evidence) for denominator\n# \ud83d\udca1 WHY use: Bayes' theorem needs P(Evidence) in denominator - calculate total probability of positive test\nP_positive = (P_positive_given_disease * P_disease + \n              P_positive_given_no_disease * P_no_disease)  # Total probability: Calculate P(Positive) using law of total probability (sum of conditional probabilities weighted by prior)\n\nprint(f\"\ud83d\udcca Calculation:\")\nprint(f\"   P(Positive) = P(Pos|Disease) \u00d7 P(Disease) + P(Pos|No Disease) \u00d7 P(No Disease)\")  # Show formula: Display the law of total probability formula\nprint(f\"   P(Positive) = {P_positive_given_disease} \u00d7 {P_disease} + {P_positive_given_no_disease} \u00d7 {P_no_disease}\")  # Show values: Display actual numbers plugged into formula\nprint(f\"   P(Positive) = {P_positive:.4f}\")  # Show result: Display calculated probability of positive test (should be around 0.05-0.06!)\nprint()\n\n# Use Bayesian inference (THE SOLUTION)\nprint(\"   \u23f0 WHEN to use: After getting test result - update belief based on evidence\")\nprint(\"   \ud83d\udca1 WHY use: Bayes' theorem updates prior belief with evidence - gives accurate posterior probability!\")\n\nbayesian = BayesianInference(P_disease)  # Create Bayesian object: Initialize with prior probability P(Disease) = 0.01 (what we believe BEFORE test)\nP_disease_given_positive = bayesian.update(P_positive_given_disease, P_positive)  # Update belief: Apply Bayes' theorem to calculate P(Disease|Positive) using likelihood and evidence probability\n\nprint(f\"\u2705 THE SOLUTION (Bayesian Inference):\")\nprint(f\"   P(Disease|Positive) = {P_disease_given_positive:.4f} = {P_disease_given_positive*100:.2f}%\")\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(f\"   \u274c WITHOUT probability: 'I definitely have it!' (wrong!)\")\nprint(f\"   \u2705 WITH probability: 'I have {P_disease_given_positive*100:.1f}% chance' (accurate!)\")\nprint(f\"   \u2022 Instead of panic, we have accurate assessment\")\nprint(f\"   \u2022 Instead of ignoring, we know it's worth investigating\")\nprint(f\"   \u2022 We can make informed medical decisions!\")\nprint()\nprint(\"\ud83d\udcca BEFORE vs AFTER Comparison:\")\nprint(\"   BEFORE: Test positive \u2192 Panic or Ignore (both wrong!)\")\nprint(f\"   AFTER: Test positive \u2192 {P_disease_given_positive*100:.1f}% probability \u2192 Informed decision!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:45\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_belief(self):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/03_hmm_viterbi.ipynb",
      "status": "failed",
      "execution_time": 0.5804200172424316,
      "error": "An error occurred while executing the following cell:\n------------------\nclass SimpleHMM:\n    \"\"\"Simple Hidden Markov Model implementation\"\"\"\n    \n    def__init__(self, states, observations, transition_probs, emission_probs, initial_probs):\n        \"\"\"\n        Parameters:\n        - states: List of hidden states\n        - observations: List of possible observations\n        - transition_probs: Dict of transition probabilities P(state_i | state_j)\n        - emission_probs: Dict of emission probabilities P(obs | state)\n        - initial_probs: Initial state probabilities\n        \"\"\"\n        self.states = states\n        self.observations = observations\n        self.transition_probs = transition_probs\n        self.emission_probs = emission_probs\n        self.initial_probs = initial_probs\n    \n    def forward(self, obs_sequence):\n        \"\"\"Forward algorithm: Compute probability of observation sequence\"\"\"\n        T = len(obs_sequence)\n        N = len(self.states)\n        \n        # Initialize alpha (forward probabilities)\n        alpha = np.zeros((T, N))\n        \n        # Initialization\n        for i, state in enumerate(self.states):\n            alpha[0, i] = self.initial_probs[state] * self.emission_probs[state][obs_sequence[0]]\n        \n        # Recursion\n        for t in range(1, T):\n            for j, state_j in enumerate(self.states):\n                alpha[t, j] = sum(\n                    alpha[t-1, i] * self.transition_probs[state_j][self.states[i]] \n                    for i in range(N)\n                ) * self.emission_probs[state_j][obs_sequence[t]]\n        \n        # Termination\n        return alpha, sum(alpha[T-1, :])\n\n# Example: Weather HMM\nstates = ['Sunny', 'Rainy']\nobservations = ['Walk', 'Shop', 'Clean']\n\n# Transition probabilities: P(next_state | current_state)\ntransition_probs = {\n    'Sunny': {'Sunny': 0.7, 'Rainy': 0.3},\n    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n}\n\n# Emission probabilities: P(observation | state)\nemission_probs = {\n    'Sunny': {'Walk': 0.6, 'Shop': 0.3, 'Clean': 0.1},\n    'Rainy': {'Walk': 0.1, 'Shop': 0.4, 'Clean': 0.5}\n}\n\n# Initial probabilities\ninitial_probs = {'Sunny': 0.6, 'Rainy': 0.4}\n\n# Create HMM\nhmm = SimpleHMM(states, observations, transition_probs, emission_probs, initial_probs)\n\nprint(\"=\" * 60)\nprint(\"Hidden Markov Model: Weather Prediction\")\nprint(\"=\" * 60)\nprint(f\"States: {states}\")\nprint(f\"Observations: {observations}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, states, observations, transition_probs, emission_probs, initial_probs):\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass SimpleHMM:\n    \"\"\"Simple Hidden Markov Model implementation\"\"\"\n    \n    def__init__(self, states, observations, transition_probs, emission_probs, initial_probs):\n        \"\"\"\n        Parameters:\n        - states: List of hidden states\n        - observations: List of possible observations\n        - transition_probs: Dict of transition probabilities P(state_i | state_j)\n        - emission_probs: Dict of emission probabilities P(obs | state)\n        - initial_probs: Initial state probabilities\n        \"\"\"\n        self.states = states\n        self.observations = observations\n        self.transition_probs = transition_probs\n        self.emission_probs = emission_probs\n        self.initial_probs = initial_probs\n    \n    def forward(self, obs_sequence):\n        \"\"\"Forward algorithm: Compute probability of observation sequence\"\"\"\n        T = len(obs_sequence)\n        N = len(self.states)\n        \n        # Initialize alpha (forward probabilities)\n        alpha = np.zeros((T, N))\n        \n        # Initialization\n        for i, state in enumerate(self.states):\n            alpha[0, i] = self.initial_probs[state] * self.emission_probs[state][obs_sequence[0]]\n        \n        # Recursion\n        for t in range(1, T):\n            for j, state_j in enumerate(self.states):\n                alpha[t, j] = sum(\n                    alpha[t-1, i] * self.transition_probs[state_j][self.states[i]] \n                    for i in range(N)\n                ) * self.emission_probs[state_j][obs_sequence[t]]\n        \n        # Termination\n        return alpha, sum(alpha[T-1, :])\n\n# Example: Weather HMM\nstates = ['Sunny', 'Rainy']\nobservations = ['Walk', 'Shop', 'Clean']\n\n# Transition probabilities: P(next_state | current_state)\ntransition_probs = {\n    'Sunny': {'Sunny': 0.7, 'Rainy': 0.3},\n    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n}\n\n# Emission probabilities: P(observation | state)\nemission_probs = {\n    'Sunny': {'Walk': 0.6, 'Shop': 0.3, 'Clean': 0.1},\n    'Rainy': {'Walk': 0.1, 'Shop': 0.4, 'Clean': 0.5}\n}\n\n# Initial probabilities\ninitial_probs = {'Sunny': 0.6, 'Rainy': 0.4}\n\n# Create HMM\nhmm = SimpleHMM(states, observations, transition_probs, emission_probs, initial_probs)\n\nprint(\"=\" * 60)\nprint(\"Hidden Markov Model: Weather Prediction\")\nprint(\"=\" * 60)\nprint(f\"States: {states}\")\nprint(f\"Observations: {observations}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, states, observations, transition_probs, emission_probs, initial_probs):\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/04_mdp_value_iteration.ipynb",
      "status": "failed",
      "execution_time": 0.7776517868041992,
      "error": "An error occurred while executing the following cell:\n------------------\nclass SimpleMDP:\n    \"\"\"Simple Markov Decision Process implementation\"\"\"\n    \n    def__init__(self, states, actions, transitions, rewards, gamma=0.9):\n        \"\"\"\n        Parameters:\n        - states: List of states\n        - actions: List of actions\n        - transitions: Dict[state][action][next_state] = probability\n        - rewards: Dict[state][action] = reward\n        - gamma: Discount factor\n        \"\"\"\n        self.states = states\n        self.actions = actions\n        self.transitions = transitions\n        self.rewards = rewards\n        self.gamma = gamma\n    \n    def get_reward(self, state, action):\n        \"\"\"Get reward for state-action pair\"\"\"\n        return self.rewards.get(state, {}).get(action, 0.0)\n    \n    def get_transition_prob(self, state, action, next_state):\n        \"\"\"Get transition probability P(next_state | state, action)\"\"\"\n        return self.transitions.get(state, {}).get(action, {}).get(next_state, 0.0)\n\n# Example: Simple 3-state MDP\nstates = ['S0', 'S1', 'S2']\nactions = ['Left', 'Right']\n\n# Transition probabilities: P(next_state | current_state, action)\ntransitions = {\n    'S0': {\n        'Left': {'S0': 0.8, 'S1': 0.2},\n        'Right': {'S1': 0.9, 'S2': 0.1}\n    },\n    'S1': {\n        'Left': {'S0': 0.7, 'S1': 0.3},\n        'Right': {'S1': 0.5, 'S2': 0.5}\n    },\n    'S2': {\n        'Left': {'S1': 1.0},\n        'Right': {'S2': 1.0}  # Terminal state\n    }\n}\n\n# Rewards: R(state, action)\nrewards = {\n    'S0': {'Left': -1, 'Right': 0},\n    'S1': {'Left': 0, 'Right': 5},\n    'S2': {'Left': 0, 'Right': 10}  # Terminal state reward\n}\n\nmdp = SimpleMDP(states, actions, transitions, rewards)\n\nprint(\"=\" * 60)\nprint(\"Simple MDP: Grid World\")\nprint(\"=\" * 60)\nprint(f\"States: {states}\")\nprint(f\"Actions: {actions}\")\nprint(f\"Discount factor (gamma): {mdp.gamma}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, states, actions, transitions, rewards, gamma=0.9):\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass SimpleMDP:\n    \"\"\"Simple Markov Decision Process implementation\"\"\"\n    \n    def__init__(self, states, actions, transitions, rewards, gamma=0.9):\n        \"\"\"\n        Parameters:\n        - states: List of states\n        - actions: List of actions\n        - transitions: Dict[state][action][next_state] = probability\n        - rewards: Dict[state][action] = reward\n        - gamma: Discount factor\n        \"\"\"\n        self.states = states\n        self.actions = actions\n        self.transitions = transitions\n        self.rewards = rewards\n        self.gamma = gamma\n    \n    def get_reward(self, state, action):\n        \"\"\"Get reward for state-action pair\"\"\"\n        return self.rewards.get(state, {}).get(action, 0.0)\n    \n    def get_transition_prob(self, state, action, next_state):\n        \"\"\"Get transition probability P(next_state | state, action)\"\"\"\n        return self.transitions.get(state, {}).get(action, {}).get(next_state, 0.0)\n\n# Example: Simple 3-state MDP\nstates = ['S0', 'S1', 'S2']\nactions = ['Left', 'Right']\n\n# Transition probabilities: P(next_state | current_state, action)\ntransitions = {\n    'S0': {\n        'Left': {'S0': 0.8, 'S1': 0.2},\n        'Right': {'S1': 0.9, 'S2': 0.1}\n    },\n    'S1': {\n        'Left': {'S0': 0.7, 'S1': 0.3},\n        'Right': {'S1': 0.5, 'S2': 0.5}\n    },\n    'S2': {\n        'Left': {'S1': 1.0},\n        'Right': {'S2': 1.0}  # Terminal state\n    }\n}\n\n# Rewards: R(state, action)\nrewards = {\n    'S0': {'Left': -1, 'Right': 0},\n    'S1': {'Left': 0, 'Right': 5},\n    'S2': {'Left': 0, 'Right': 10}  # Terminal state reward\n}\n\nmdp = SimpleMDP(states, actions, transitions, rewards)\n\nprint(\"=\" * 60)\nprint(\"Simple MDP: Grid World\")\nprint(\"=\" * 60)\nprint(f\"States: {states}\")\nprint(f\"Actions: {actions}\")\nprint(f\"Discount factor (gamma): {mdp.gamma}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, states, actions, transitions, rewards, gamma=0.9):\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/exercises/exercise_03_probability_and_uncertainty.ipynb",
      "status": "passed",
      "execution_time": 0.8439643383026123,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/03_gradient_descent_variants.ipynb",
      "status": "passed",
      "execution_time": 0.5617842674255371,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/04_Optimization_Techniques.ipynb",
      "status": "failed",
      "execution_time": 0.8360772132873535,
      "error": "An error occurred while executing the following cell:\n------------------\n# \u2705 THE SOLUTION: Gradient Descent\n# This algorithm solves the problem by following the gradient (slope) downhill\n\nclass GradientDescent:\n    \"\"\"\n    Gradient Descent: The SOLUTION to the optimization problem.\n    \n    THE PROBLEM: We don't know where the minimum is.\n    THE SOLUTION: Follow the gradient (slope) downhill - it always leads to minimum!\n    \n    How it works:\n    1. Start at random point\n    2. Calculate gradient (which way is downhill?)\n    3. Move in that direction (downhill)\n    4. Repeat until we reach the bottom (minimum)\n    \"\"\"\n    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n        \"\"\"\n        Initialize optimizer.\n        - learning_rate: How big steps to take (too big = overshoot, too small = slow)\n        - max_iterations: Maximum number of steps\n        - tolerance: Stop when change is smaller than this\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.max_iterations = max_iterations\n        self.tolerance = tolerance\n        self.history = []  # Track our path (for visualization)\n    \n    def optimize(self, f, grad_f, x0):\n        \"\"\"\n        Optimize function f starting from x0.\n        \n        THIS IS THE SOLUTION:\n        Instead of random search, we systematically follow the gradient downhill!\n        \"\"\"\n        x = np.array(x0, dtype=float)  # Starting point\n        self.history = [x.copy()]  # Remember where we started\n        \n        print(f\"\ud83d\ude80 Starting gradient descent from x = {x[0]:.2f}\")\n        print(f\"   Learning rate: {self.learning_rate}\")\n        print()\n        \n        for i in range(self.max_iterations):  # Iteration loop: Repeat up to max_iterations times (stop early if converged)\n            # Calculate gradient at current point\n            # Gradient tells us: which way is downhill?\n            gradient = grad_f(x)  # Calculate gradient: Compute gradient (slope) at current position x (gradient points uphill, we want to go downhill!)\n            \n            # Move downhill: x_new = x - learning_rate * gradient\n            # (Minus because gradient points uphill, we want to go downhill)\n            x_new = x - self.learning_rate * gradient  # Update position: Move in opposite direction of gradient (downhill) by learning_rate amount (subtract because gradient points uphill)\n            \n            self.history.append(x_new.copy())  # Remember our path: Store new position in history (copy() to avoid reference issues - we want a copy, not reference)\n            \n            # Check if we've converged (found minimum)\n            if np.linalg.norm(x_new - x) < self.tolerance:  # Check convergence: If change in position is smaller than tolerance, we've found minimum (np.linalg.norm computes distance/change)\n                print(f\"\u2705 Converged after {i+1} iterations!\")  # Success message: Algorithm found minimum!\n                print(f\"   Found minimum at x = {x_new[0]:.6f}\")  # Show solution: Display x coordinate where minimum was found\n                print(f\"   Function value: f({x_new[0]:.6f}) = {f(x_new):.6f}\")  # Show function value: Display minimum function value (should be smallest value!)\n                break  # Exit loop: Stop iterating - we've found the minimum!\n            \n            if i < 5 or i % 50 == 0:  # Show first few and periodic updates: Display progress for first 5 iterations, then every 50 iterations (avoid spam)\n                print(f\"   Step {i+1}: x = {x_new[0]:.4f}, gradient = {gradient[0]:.4f}, f(x) = {f(x_new):.4f}\")  # Progress update: Show updated position, gradient value, and function value (helps debug/understand algorithm)\n            \n            x = x_new  # Move to new position: Update current position to new position (prepare for next iteration)\n        \n        # Return both solution and cost for consistency with other optimization methods\n        return x, f(x)  # Return result: Return final position and function value (should be near minimum!)\n\n# Define function and its gradient\ndef f1(x):\n    \"\"\"Function to minimize: f(x) = x\u00b2\n    \n    Expects x as a numpy array (even for 1D).\n    For 1D arrays, returns x[0]**2; for multi-element arrays, squares all elements.\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    if x.ndim == 0:  # Scalar\n        return float(x)**2\n    elif len(x) == 1:  # Single-element array (optimization use case)\n        return x[0]**2\n    else:  # Multi-element array\n        return x**2\n\ndef grad_f1(x):\n    \"\"\"Gradient of f(x) = x\u00b2 is 2x\n    \n    Expects x as a numpy array (even for 1D).\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    return np.array([2 * x[0]])\n\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: The Solution - Gradient Descent\")\nprint(\"=\" * 70)\nprint()\n\n# Use gradient descent (THE SOLUTION)\noptimizer = GradientDescent(learning_rate=0.1, max_iterations=100)\nx_optimal, _ = optimizer.optimize(f1, grad_f1, [5.0])  # Start at x = 5\n\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Random search \u2192 Try x = 5, x = -3, x = 2.7... (slow!)\")\nprint(f\"   \u2705 AFTER: Gradient descent \u2192 Systematically move from 5 to 0 (fast!)\")\nprint(\"   \u2022 Instead of random \u2192 Systematic\")\nprint(\"   \u2022 Instead of slow \u2192 Fast convergence\")\nprint(\"   \u2022 Instead of guessing \u2192 Finds minimum efficiently!\")\nprint(\"   (Note: For smooth convex functions like x\u00b2, gradient descent finds the global minimum)\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# \u2705 THE SOLUTION: Gradient Descent\n# This algorithm solves the problem by following the gradient (slope) downhill\n\nclass GradientDescent:\n    \"\"\"\n    Gradient Descent: The SOLUTION to the optimization problem.\n    \n    THE PROBLEM: We don't know where the minimum is.\n    THE SOLUTION: Follow the gradient (slope) downhill - it always leads to minimum!\n    \n    How it works:\n    1. Start at random point\n    2. Calculate gradient (which way is downhill?)\n    3. Move in that direction (downhill)\n    4. Repeat until we reach the bottom (minimum)\n    \"\"\"\n    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n        \"\"\"\n        Initialize optimizer.\n        - learning_rate: How big steps to take (too big = overshoot, too small = slow)\n        - max_iterations: Maximum number of steps\n        - tolerance: Stop when change is smaller than this\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.max_iterations = max_iterations\n        self.tolerance = tolerance\n        self.history = []  # Track our path (for visualization)\n    \n    def optimize(self, f, grad_f, x0):\n        \"\"\"\n        Optimize function f starting from x0.\n        \n        THIS IS THE SOLUTION:\n        Instead of random search, we systematically follow the gradient downhill!\n        \"\"\"\n        x = np.array(x0, dtype=float)  # Starting point\n        self.history = [x.copy()]  # Remember where we started\n        \n        print(f\"\ud83d\ude80 Starting gradient descent from x = {x[0]:.2f}\")\n        print(f\"   Learning rate: {self.learning_rate}\")\n        print()\n        \n        for i in range(self.max_iterations):  # Iteration loop: Repeat up to max_iterations times (stop early if converged)\n            # Calculate gradient at current point\n            # Gradient tells us: which way is downhill?\n            gradient = grad_f(x)  # Calculate gradient: Compute gradient (slope) at current position x (gradient points uphill, we want to go downhill!)\n            \n            # Move downhill: x_new = x - learning_rate * gradient\n            # (Minus because gradient points uphill, we want to go downhill)\n            x_new = x - self.learning_rate * gradient  # Update position: Move in opposite direction of gradient (downhill) by learning_rate amount (subtract because gradient points uphill)\n            \n            self.history.append(x_new.copy())  # Remember our path: Store new position in history (copy() to avoid reference issues - we want a copy, not reference)\n            \n            # Check if we've converged (found minimum)\n            if np.linalg.norm(x_new - x) < self.tolerance:  # Check convergence: If change in position is smaller than tolerance, we've found minimum (np.linalg.norm computes distance/change)\n                print(f\"\u2705 Converged after {i+1} iterations!\")  # Success message: Algorithm found minimum!\n                print(f\"   Found minimum at x = {x_new[0]:.6f}\")  # Show solution: Display x coordinate where minimum was found\n                print(f\"   Function value: f({x_new[0]:.6f}) = {f(x_new):.6f}\")  # Show function value: Display minimum function value (should be smallest value!)\n                break  # Exit loop: Stop iterating - we've found the minimum!\n            \n            if i < 5 or i % 50 == 0:  # Show first few and periodic updates: Display progress for first 5 iterations, then every 50 iterations (avoid spam)\n                print(f\"   Step {i+1}: x = {x_new[0]:.4f}, gradient = {gradient[0]:.4f}, f(x) = {f(x_new):.4f}\")  # Progress update: Show updated position, gradient value, and function value (helps debug/understand algorithm)\n            \n            x = x_new  # Move to new position: Update current position to new position (prepare for next iteration)\n        \n        # Return both solution and cost for consistency with other optimization methods\n        return x, f(x)  # Return result: Return final position and function value (should be near minimum!)\n\n# Define function and its gradient\ndef f1(x):\n    \"\"\"Function to minimize: f(x) = x\u00b2\n    \n    Expects x as a numpy array (even for 1D).\n    For 1D arrays, returns x[0]**2; for multi-element arrays, squares all elements.\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    if x.ndim == 0:  # Scalar\n        return float(x)**2\n    elif len(x) == 1:  # Single-element array (optimization use case)\n        return x[0]**2\n    else:  # Multi-element array\n        return x**2\n\ndef grad_f1(x):\n    \"\"\"Gradient of f(x) = x\u00b2 is 2x\n    \n    Expects x as a numpy array (even for 1D).\n    \"\"\"\n    x = np.asarray(x)  # Ensure it's an array\n    return np.array([2 * x[0]])\n\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: The Solution - Gradient Descent\")\nprint(\"=\" * 70)\nprint()\n\n# Use gradient descent (THE SOLUTION)\noptimizer = GradientDescent(learning_rate=0.1, max_iterations=100)\nx_optimal, _ = optimizer.optimize(f1, grad_f1, [5.0])  # Start at x = 5\n\nprint()\nprint(\"\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Random search \u2192 Try x = 5, x = -3, x = 2.7... (slow!)\")\nprint(f\"   \u2705 AFTER: Gradient descent \u2192 Systematically move from 5 to 0 (fast!)\")\nprint(\"   \u2022 Instead of random \u2192 Systematic\")\nprint(\"   \u2022 Instead of slow \u2192 Fast convergence\")\nprint(\"   \u2022 Instead of guessing \u2192 Finds minimum efficiently!\")\nprint(\"   (Note: For smooth convex functions like x\u00b2, gradient descent finds the global minimum)\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/04_advanced_optimizers_adam_rmsprop.ipynb",
      "status": "passed",
      "execution_time": 0.8636090755462646,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/applying_advanced_optimizers_adam_rmsprop_in_neural_networks.ipynb",
      "status": "passed",
      "execution_time": 1.6421897411346436,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/comparing_different_optimization_algorithms_on_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.592175006866455,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_bayesian_optimization_for_hyperparameter_search.ipynb",
      "status": "passed",
      "execution_time": 1.4124350547790527,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_gradient_descent_algorithms_batch_stochastic_mini_batch.ipynb",
      "status": "passed",
      "execution_time": 1.5101678371429443,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_regularization_techniques_l1_l2_dropout_early_stopping.ipynb",
      "status": "passed",
      "execution_time": 1.5486888885498047,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/performing_hyperparameter_tuning_using_grid_search_and_random_search.ipynb",
      "status": "passed",
      "execution_time": 1.5393450260162354,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/using_cross_validation_to_select_optimal_hyperparameters.ipynb",
      "status": "passed",
      "execution_time": 1.5190000534057617,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/exercises/exercise_04_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.6564559936523438,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/03_neural_network_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.7955701351165771,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/04_transfer_learning_pretrained.ipynb",
      "status": "passed",
      "execution_time": 0.6487407684326172,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/05_AI_Learning_Models.ipynb",
      "status": "failed",
      "execution_time": 1.8761909008026123,
      "error": "An error occurred while executing the following cell:\n------------------\n# K-Nearest Neighbors (KNN) Algorithm\n# BEFORE: Complex patterns are hard to model with formulas\n# AFTER: KNN uses simple idea - \"similar things are close\" - to predict!\n\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nclass KNN:\n    \"\"\"\n    K-Nearest Neighbors: Simple but powerful classification algorithm.\n    \n    THE PROBLEM: Complex patterns can't be captured by simple formulas.\n    THE SOLUTION: Use the simple idea - \"similar things are close together\"!\n    \n    How it works:\n    1. Store all training examples\n    2. For new example, find K nearest neighbors\n    3. Predict based on majority class of neighbors\n    \"\"\"\n    def__init__(self, k=3):\n        \"\"\"\n        Initialize KNN classifier.\n        \n        Parameters:\n        - k: Number of neighbors to consider (usually odd: 3, 5, 7)\n        \"\"\"\n        self.k = k\n        self.X_train = None  # Training features\n        self.y_train = None  # Training labels\n        print(f\"\u2705 Created KNN classifier (k={k})\")\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the model (just store the data - KNN is \"lazy\" learning!).\n        \n        Unlike other algorithms, KNN doesn't \"learn\" a formula.\n        It just remembers all examples - that's why it's called \"lazy\"!\n        \"\"\"\n        self.X_train = np.array(X)  # Store training features\n        self.y_train = np.array(y)  # Store training labels\n        print(f\"  \u2705 Stored {len(X)} training examples\")\n    \n    def predict(self, X):\n        \"\"\"\n        Predict class for new examples.\n        \n        THE SOLUTION:\n        1. For each new example, find K nearest neighbors\n        2. Look at their classes\n        3. Predict the majority class\n        \"\"\"\n        X = np.array(X)  # Convert to numpy array\n        predictions = []  # Store predictions\n        \n        for x in X:\n            # Calculate distances to all training examples\n            # Distance = how \"far\" is this example from each training example?\n            distances = np.sqrt(np.sum((self.X_train - x)**2, axis=1))\n            \n            # Find K nearest neighbors (smallest distances)\n            k_indices = np.argsort(distances)[:self.k]  # Indices of K nearest\n            k_nearest_labels = self.y_train[k_indices]  # Classes of K nearest\n            \n            # Predict majority class (most common class among neighbors)\n            majority_class = Counter(k_nearest_labels).most_common(1)[0][0]\n            predictions.append(majority_class)\n        \n        return np.array(predictions)\n\n# Example: Classifying fruits by size and sweetness\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: K-Nearest Neighbors (KNN)\")\nprint(\"=\" * 70)\nprint()\n\n# Generate example data\nnp.random.seed(42)\n# Apples: small size, medium sweetness\napples = np.random.randn(20, 2) * [0.5, 0.3] + [2, 5]\n# Oranges: medium size, high sweetness\noranges = np.random.randn(20, 2) * [0.5, 0.3] + [5, 7]\n\nX = np.vstack([apples, oranges])  # All features\ny = np.array([0]*20 + [1]*20)  # Labels: 0=Apple, 1=Orange\n\nprint(\"\ud83d\udcca Training data:\")\nprint(f\"   \u2022 {len(apples)} apples (class 0)\")\nprint(f\"   \u2022 {len(oranges)} oranges (class 1)\")\nprint(\"   Features: [size, sweetness]\")\nprint()\n\n# Train KNN\nknn = KNN(k=3)\nknn.fit(X, y)\n\n# Test on new examples\ntest_points = np.array([[2.5, 5.5], [5.5, 7.5], [3.5, 6.0]])\npredictions = knn.predict(test_points)\n\nprint(\"\ud83d\udcca Predictions on new examples:\")\nfor i, (point, pred) in enumerate(zip(test_points, predictions)):\n    fruit = \"Apple\" if pred == 0 else \"Orange\"\n    print(f\"   Point {i+1}: {point} \u2192 Predicted: {fruit}\")\n\nprint(\"\\n\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Need complex formula for pattern\")\nprint(\"   \u2705 AFTER: KNN uses simple idea - 'similar things are close'!\")\nprint(\"   \u2022 No formula needed - just find nearest neighbors\")\nprint(\"   \u2022 Works for complex, non-linear patterns\")\nprint(\"   \u2022 Simple but powerful!\")\n\n# Visualize\nplt.figure(figsize=(10, 6))\nplt.scatter(apples[:, 0], apples[:, 1], c='red', label='Apples (training)', s=100, alpha=0.6)\nplt.scatter(oranges[:, 0], oranges[:, 1], c='orange', label='Oranges (training)', s=100, alpha=0.6)\nplt.scatter(test_points[:, 0], test_points[:, 1], c=['red' if p==0 else 'orange' for p in predictions], \n            marker='*', s=300, label='Predictions', edgecolors='black', linewidths=2)\nplt.xlabel('Size')\nplt.ylabel('Sweetness')\nplt.title('\u2705 AFTER: KNN Classification\\n(Similar things are close together!)', fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, k=3):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# K-Nearest Neighbors (KNN) Algorithm\n# BEFORE: Complex patterns are hard to model with formulas\n# AFTER: KNN uses simple idea - \"similar things are close\" - to predict!\n\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nclass KNN:\n    \"\"\"\n    K-Nearest Neighbors: Simple but powerful classification algorithm.\n    \n    THE PROBLEM: Complex patterns can't be captured by simple formulas.\n    THE SOLUTION: Use the simple idea - \"similar things are close together\"!\n    \n    How it works:\n    1. Store all training examples\n    2. For new example, find K nearest neighbors\n    3. Predict based on majority class of neighbors\n    \"\"\"\n    def__init__(self, k=3):\n        \"\"\"\n        Initialize KNN classifier.\n        \n        Parameters:\n        - k: Number of neighbors to consider (usually odd: 3, 5, 7)\n        \"\"\"\n        self.k = k\n        self.X_train = None  # Training features\n        self.y_train = None  # Training labels\n        print(f\"\u2705 Created KNN classifier (k={k})\")\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the model (just store the data - KNN is \"lazy\" learning!).\n        \n        Unlike other algorithms, KNN doesn't \"learn\" a formula.\n        It just remembers all examples - that's why it's called \"lazy\"!\n        \"\"\"\n        self.X_train = np.array(X)  # Store training features\n        self.y_train = np.array(y)  # Store training labels\n        print(f\"  \u2705 Stored {len(X)} training examples\")\n    \n    def predict(self, X):\n        \"\"\"\n        Predict class for new examples.\n        \n        THE SOLUTION:\n        1. For each new example, find K nearest neighbors\n        2. Look at their classes\n        3. Predict the majority class\n        \"\"\"\n        X = np.array(X)  # Convert to numpy array\n        predictions = []  # Store predictions\n        \n        for x in X:\n            # Calculate distances to all training examples\n            # Distance = how \"far\" is this example from each training example?\n            distances = np.sqrt(np.sum((self.X_train - x)**2, axis=1))\n            \n            # Find K nearest neighbors (smallest distances)\n            k_indices = np.argsort(distances)[:self.k]  # Indices of K nearest\n            k_nearest_labels = self.y_train[k_indices]  # Classes of K nearest\n            \n            # Predict majority class (most common class among neighbors)\n            majority_class = Counter(k_nearest_labels).most_common(1)[0][0]\n            predictions.append(majority_class)\n        \n        return np.array(predictions)\n\n# Example: Classifying fruits by size and sweetness\nprint(\"=\" * 70)\nprint(\"\u2705 AFTER: K-Nearest Neighbors (KNN)\")\nprint(\"=\" * 70)\nprint()\n\n# Generate example data\nnp.random.seed(42)\n# Apples: small size, medium sweetness\napples = np.random.randn(20, 2) * [0.5, 0.3] + [2, 5]\n# Oranges: medium size, high sweetness\noranges = np.random.randn(20, 2) * [0.5, 0.3] + [5, 7]\n\nX = np.vstack([apples, oranges])  # All features\ny = np.array([0]*20 + [1]*20)  # Labels: 0=Apple, 1=Orange\n\nprint(\"\ud83d\udcca Training data:\")\nprint(f\"   \u2022 {len(apples)} apples (class 0)\")\nprint(f\"   \u2022 {len(oranges)} oranges (class 1)\")\nprint(\"   Features: [size, sweetness]\")\nprint()\n\n# Train KNN\nknn = KNN(k=3)\nknn.fit(X, y)\n\n# Test on new examples\ntest_points = np.array([[2.5, 5.5], [5.5, 7.5], [3.5, 6.0]])\npredictions = knn.predict(test_points)\n\nprint(\"\ud83d\udcca Predictions on new examples:\")\nfor i, (point, pred) in enumerate(zip(test_points, predictions)):\n    fruit = \"Apple\" if pred == 0 else \"Orange\"\n    print(f\"   Point {i+1}: {point} \u2192 Predicted: {fruit}\")\n\nprint(\"\\n\ud83d\udd17 HOW THIS SOLVES THE PROBLEM:\")\nprint(\"   \u274c BEFORE: Need complex formula for pattern\")\nprint(\"   \u2705 AFTER: KNN uses simple idea - 'similar things are close'!\")\nprint(\"   \u2022 No formula needed - just find nearest neighbors\")\nprint(\"   \u2022 Works for complex, non-linear patterns\")\nprint(\"   \u2022 Simple but powerful!\")\n\n# Visualize\nplt.figure(figsize=(10, 6))\nplt.scatter(apples[:, 0], apples[:, 1], c='red', label='Apples (training)', s=100, alpha=0.6)\nplt.scatter(oranges[:, 0], oranges[:, 1], c='orange', label='Oranges (training)', s=100, alpha=0.6)\nplt.scatter(test_points[:, 0], test_points[:, 1], c=['red' if p==0 else 'orange' for p in predictions], \n            marker='*', s=300, label='Predictions', edgecolors='black', linewidths=2)\nplt.xlabel('Size')\nplt.ylabel('Sweetness')\nplt.title('\u2705 AFTER: KNN Classification\\n(Similar things are close together!)', fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, k=3):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/05_model_evaluation_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.6418721675872803,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/applying_transfer_learning_with_pre_trained_models_vgg_resnet_bert.ipynb",
      "status": "passed",
      "execution_time": 1.6410348415374756,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/building_simple_apis_for_model_serving_flask_fastapi.ipynb",
      "status": "passed",
      "execution_time": 1.3132870197296143,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/fine_tuning_pre_trained_models_for_domain_specific_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.2944819927215576,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/implementing_different_neural_network_architectures_feedforward_cnn_rnn.ipynb",
      "status": "passed",
      "execution_time": 1.5072920322418213,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/implementing_model_selection_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.67706298828125,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/introduction_to_reinforcement_learning_setting_up_environments_and_agents.ipynb",
      "status": "passed",
      "execution_time": 1.3164401054382324,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/performing_model_evaluation_and_comparison_using_cross_validation.ipynb",
      "status": "passed",
      "execution_time": 1.4397292137145996,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/serializing_and_saving_models_for_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.6583259105682373,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/working_on_end_to_end_projects_integrating_multiple_ai_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.6387007236480713,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/exercises/exercise_05_machine_learning_models.ipynb",
      "status": "passed",
      "execution_time": 0.6360361576080322,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_01_search_algorithms_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7470619678497314,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_02_knowledge_representation_solution.ipynb",
      "status": "passed",
      "execution_time": 0.584630012512207,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_03_probability_and_uncertainty_solution.ipynb",
      "status": "passed",
      "execution_time": 0.648406982421875,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_04_optimization_techniques_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7311949729919434,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_05_machine_learning_models_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7387142181396484,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/examples/01_vectors_matrices_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8416721820831299,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/examples/02_matrix_operations.ipynb",
      "status": "passed",
      "execution_time": 0.9436078071594238,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/examples/03_eigenvalues_eigenvectors.ipynb",
      "status": "passed",
      "execution_time": 0.8976540565490723,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5778999328613281,
      "error": "An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 01: Vector and Matrix Operations\")\n print(\"=\" * 60)\n \n # Test 1: Create data matrix\n print(\"\\n1. Testing create_data\\n_matrix:\")\n data = create_data_matrix(5, 3)\n if data is None:\n print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.random.randn(samples, features)\")\n raise NotImplementedError(\"Please implement create_data_matrix() first!\")\n print(f\" Created matrix shape: {data.shape}\")\n print(f\" Expected: (5, 3)\")\n assert data.shape == (5, 3), \"Shape should be (5, 3)\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Dot product\n print(\"\\n2. Testing compute\\n_dot\\n_product:\")\n v1 = np.array([1, 2, 3])\n v2 = np.array([4, 5, 6])\n result = compute_dot_product(v1, v2)\n if result is None:\n print(\" \u274c ERROR: compute\\n_dot\\n_product() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(v1, v2)\")\n raise NotImplementedError(\"Please implement compute_dot_product() first!\")\n expected = 32 # 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n print(f\" Result: {result}\")\n print(f\" Expected: {expected}\")\n assert result == expected, f\"Expected {expected}, got {result}\"\n print(\" \u2705 Passed!\")\n \n # Test 3: Matrix multiplication\n print(\"\\n3. Testing matrix_multiplication:\")\n A = np.array([[1, 2], [3, 4]])\n B = np.array([[5, 6], [7, 8]])\n result = matrix_multiplication(A, B)\n if result is None:\n print(\" \u274c ERROR: matrix_multiplication() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(A, B)\")\n raise NotImplementedError(\"Please implement matrix_multiplication() first!\")\n expected = np.array([[19, 22], [43, 50]])\n print(f\" Result:\\n{result}\")\n print(f\" Expected:\\n{expected}\")\n assert np.allclose(result, expected), \"Matrix multiplication incorrect\"\n print(\" \u2705 Passed!\")\n \n # Test 4: Transpose\n print(\"\\n4. Testing compute\\n_transpose:\")\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\n result = compute_transpose(matrix)\n if result is None:\n print(\" \u274c ERROR: compute\\n_transpose() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return matrix.T\")\n raise NotImplementedError(\"Please implement compute_transpose() first!\")\n expected = np.array([[1, 4], [2, 5], [3, 6]])\n print(f\" Original shape: {matrix.shape}\")\n print(f\" Transposed shape: {result.shape}\")\n assert np.allclose(result, expected), \"Transpose incorrect\"\n print(\" \u2705 Passed!\")\n \n print(\"\\n\" + \"=\" * 60)\n print(\"\ud83c\udf89 All tests passed! Great job!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 01: Vector and Matrix Operations\")\n print(\"=\" * 60)\n \n # Test 1: Create data matrix\n print(\"\\n1. Testing create_data\\n_matrix:\")\n data = create_data_matrix(5, 3)\n if data is None:\n print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.random.randn(samples, features)\")\n raise NotImplementedError(\"Please implement create_data_matrix() first!\")\n print(f\" Created matrix shape: {data.shape}\")\n print(f\" Expected: (5, 3)\")\n assert data.shape == (5, 3), \"Shape should be (5, 3)\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Dot product\n print(\"\\n2. Testing compute\\n_dot\\n_product:\")\n v1 = np.array([1, 2, 3])\n v2 = np.array([4, 5, 6])\n result = compute_dot_product(v1, v2)\n if result is None:\n print(\" \u274c ERROR: compute\\n_dot\\n_product() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(v1, v2)\")\n raise NotImplementedError(\"Please implement compute_dot_product() first!\")\n expected = 32 # 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n print(f\" Result: {result}\")\n print(f\" Expected: {expected}\")\n assert result == expected, f\"Expected {expected}, got {result}\"\n print(\" \u2705 Passed!\")\n \n # Test 3: Matrix multiplication\n print(\"\\n3. Testing matrix_multiplication:\")\n A = np.array([[1, 2], [3, 4]])\n B = np.array([[5, 6], [7, 8]])\n result = matrix_multiplication(A, B)\n if result is None:\n print(\" \u274c ERROR: matrix_multiplication() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(A, B)\")\n raise NotImplementedError(\"Please implement matrix_multiplication() first!\")\n expected = np.array([[19, 22], [43, 50]])\n print(f\" Result:\\n{result}\")\n print(f\" Expected:\\n{expected}\")\n assert np.allclose(result, expected), \"Matrix multiplication incorrect\"\n print(\" \u2705 Passed!\")\n \n # Test 4: Transpose\n print(\"\\n4. Testing compute\\n_transpose:\")\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\n result = compute_transpose(matrix)\n if result is None:\n print(\" \u274c ERROR: compute\\n_transpose() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return matrix.T\")\n raise NotImplementedError(\"Please implement compute_transpose() first!\")\n expected = np.array([[1, 4], [2, 5], [3, 6]])\n print(f\" Original shape: {matrix.shape}\")\n print(f\" Transposed shape: {result.shape}\")\n assert np.allclose(result, expected), \"Transpose incorrect\"\n print(\" \u2705 Passed!\")\n \n print(\"\\n\" + \"=\" * 60)\n print(\"\ud83c\udf89 All tests passed! Great job!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_01/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.7344260215759277,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_determinant(matrix):\n \n # TODO: Compute determinant using np.linalg.de\nt()\n pass\n\n\ndef compute_matrix_inverse(matrix):\n \n # TODO: Compute inverse using np.linalg.in\nv()\n # Note: Matrix must be square and have non-zero determinan\ntpass\n\n\ndef compute_eigenvalues__eigenvectors(matrix):\n \n # TODO: Use np.linalg.eig() to compute eigenvalues and eigenvectors\n pass\n\n\ndef verify_inverse(matrix, inverse):\n \n # TODO: Multiply matrix by inverse and check if result is identity\n # Use np.allclose() for floating point comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_determinant(matrix):\n \n # TODO: Compute determinant using np.linalg.de\nt()\n pass\n\n\ndef compute_matrix_inverse(matrix):\n \n # TODO: Compute inverse using np.linalg.in\nv()\n # Note: Matrix must be square and have non-zero determinan\ntpass\n\n\ndef compute_eigenvalues__eigenvectors(matrix):\n \n # TODO: Use np.linalg.eig() to compute eigenvalues and eigenvectors\n pass\n\n\ndef verify_inverse(matrix, inverse):\n \n # TODO: Multiply matrix by inverse and check if result is identity\n # Use np.allclose() for floating point comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_01/notebook_01_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 0.7472269535064697,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.5233139991760254,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5294849872589111,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef create_data_matrix(samples, features):        # # SOLUTION: Create a matrix with the specified shape    # Use np.random.randn() to generate random values    pass\ndef compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\ndef matrix_multiplication(A, B):        # # SOLUTION: Perform matrix multiplication    # Remember: A @ B or np.dot(A, B)    pass\ndef compute_transpose(matrix):        # # SOLUTION: Compute transpose using .T or np.transpose()    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef create_data_matrix(samples, features):        # # SOLUTION: Create a matrix with the specified shape    # Use np.random.randn() to generate random values    pass\ndef compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\ndef matrix_multiplication(A, B):        # # SOLUTION: Perform matrix multiplication    # Remember: A @ B or np.dot(A, B)    pass\ndef compute_transpose(matrix):        # # SOLUTION: Compute transpose using .T or np.transpose()    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5270678997039795,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_determinant(matrix):        # # SOLUTION: Compute determinant using np.linalg.det()    pass\ndef compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\ndef compute_eigenvalues_eigenvectors(matrix):        # # SOLUTION: Use np.linalg.eig() to compute eigenvalues and eigenvectors    pass\ndef verify_inverse(matrix, inverse):        # # SOLUTION: Multiply matrix by inverse and check if result is identity    # Use np.allclose() for floating point comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_determinant(matrix):        # # SOLUTION: Compute determinant using np.linalg.det()    pass\ndef compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\ndef compute_eigenvalues_eigenvectors(matrix):        # # SOLUTION: Use np.linalg.eig() to compute eigenvalues and eigenvectors    pass\ndef verify_inverse(matrix, inverse):        # # SOLUTION: Multiply matrix by inverse and check if result is identity    # Use np.allclose() for floating point comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/examples/01_derivatives_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8126578330993652,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/examples/02_gradients_multivariable.ipynb",
      "status": "passed",
      "execution_time": 0.9161510467529297,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/examples/03_gradient_descent.ipynb",
      "status": "passed",
      "execution_time": 0.7491610050201416,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7222380638122559,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead def compute_derivative(func, x, h=1e-6):\n \n # TODO: Implement numerical derivative\n # Formula: (f(x+h) - f(x))  h pass\n\n\ndef compute_gradient(func, point):\n \n # TODO: Compute partial derivatives\n # Use compute_derivative for each variable h = 1e-6\n pass\n\n\ndef gradient_descent_step(func, x, learning_rate=0.1):\n \n # TODO: \n # 1. Compute gradient at current point\n # 2. Move in opposite direction: x_new = x - lr * gradient pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Test your solution\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead def compute_derivative(func, x, h=1e-6):\n \n # TODO: Implement numerical derivative\n # Formula: (f(x+h) - f(x))  h pass\n\n\ndef compute_gradient(func, point):\n \n # TODO: Compute partial derivatives\n # Use compute_derivative for each variable h = 1e-6\n pass\n\n\ndef gradient_descent_step(func, x, learning_rate=0.1):\n \n # TODO: \n # 1. Compute gradient at current point\n # 2. Move in opposite direction: x_new = x - lr * gradient pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Test your solution\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_02/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.5412399768829346,
      "error": "An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 02: Gradient Descent\")\nprint(\"=\" * 60)\n \n # Test 1: Gradient descent print(\"\\n1. Testing gradient_descent:\")\ndef f(x):\n return (x - 3)**2 # Minimum at x = 3 def grad_f(x):\n return 2 * (x - 3) # Gradient of (x-3)\u00b2\n \n initial_x = 5.0\n final_x, history = gradient_descent(f, grad_f, initial_x, learning_rate=0.1, iterations=20)\nprint(f\" Function: f(x) = (x - 3)\u00b2 (minimum at x = 3)\")\n print(f\" Starting at: {initial_x}\")\nprint(f\" Final value: {final_x:.4f}\")\nprint(f\" Expected: close to 3.0\")\nprint(f\" Converged: {abs(final_x - 3) < 0.1}\")\n assert abs(final_x - 3) < 0.5, \"Should converge close to minimum\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Learning rate analysis print(\"\\n2. Testing analyze\\n_learning_rate:\")\nlearning_rates = [0.01, 0.1, 0.5, 1.0]\n results = analyze_learning_rate(f, grad_f, initial_x, learning_rates, iterations=30)\nprint(f\" Learning Rate Analysis:\")\nfor lr, final_val in results.items():\n converged = abs(final_val - 3) < 0.5\n status = \"\u2705 Converged\" if converged else \"\u274c Diverged\"\n print(f\" LR = {lr:.2\nf}: Final x = {final_val:.4f} {status}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83c\udf89 All tests passed!\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 02: Gradient Descent\")\nprint(\"=\" * 60)\n \n # Test 1: Gradient descent print(\"\\n1. Testing gradient_descent:\")\ndef f(x):\n return (x - 3)**2 # Minimum at x = 3 def grad_f(x):\n return 2 * (x - 3) # Gradient of (x-3)\u00b2\n \n initial_x = 5.0\n final_x, history = gradient_descent(f, grad_f, initial_x, learning_rate=0.1, iterations=20)\nprint(f\" Function: f(x) = (x - 3)\u00b2 (minimum at x = 3)\")\n print(f\" Starting at: {initial_x}\")\nprint(f\" Final value: {final_x:.4f}\")\nprint(f\" Expected: close to 3.0\")\nprint(f\" Converged: {abs(final_x - 3) < 0.1}\")\n assert abs(final_x - 3) < 0.5, \"Should converge close to minimum\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Learning rate analysis print(\"\\n2. Testing analyze\\n_learning_rate:\")\nlearning_rates = [0.01, 0.1, 0.5, 1.0]\n results = analyze_learning_rate(f, grad_f, initial_x, learning_rates, iterations=30)\nprint(f\" Learning Rate Analysis:\")\nfor lr, final_val in results.items():\n converged = abs(final_val - 3) < 0.5\n status = \"\u2705 Converged\" if converged else \"\u274c Diverged\"\n print(f\" LR = {lr:.2\nf}: Final x = {final_val:.4f} {status}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83c\udf89 All tests passed!\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_02/notebook_02_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 0.632941722869873,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Why Calculus matters in ML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example: Understanding loss functions and optimization\n# In ML, we want to minimize a loss function\ndef simple_loss_function(x):\n \n    \n    \"\"\"A simple quadratic loss function\"\"\"\n return (x - 3)**2 + 2\n\n# The derivative tells us the direction to minimize\ndef loss_derivative(x):\n \n    \n    \"\"\"Derivative of the loss function\"\"\"\n return 2 * (x - 3)\n\n# Example: Finding the minimum\nx_values = np.linspace(0, 6, 100)\nloss_values = [simple_loss_function(x) for x in x_values]\n\nprint(\"Loss function example:\")\nprint(f\"At x=2, loss = {simple_loss_function(2):.2f}, derivative = {loss_derivative(2):.2f}\")\nprint(f\"At x=4, loss = {simple_loss_function(4):.2f}, derivative = {loss_derivative(4):.2f}\")\nprint(\"\\nThe derivative tells us which direction to move to minimize loss!\")\nprint(\"This is exactly how gradient descent works in ML!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (x - 3)**2 + 2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Why Calculus matters in ML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example: Understanding loss functions and optimization\n# In ML, we want to minimize a loss function\ndef simple_loss_function(x):\n \n    \n    \"\"\"A simple quadratic loss function\"\"\"\n return (x - 3)**2 + 2\n\n# The derivative tells us the direction to minimize\ndef loss_derivative(x):\n \n    \n    \"\"\"Derivative of the loss function\"\"\"\n return 2 * (x - 3)\n\n# Example: Finding the minimum\nx_values = np.linspace(0, 6, 100)\nloss_values = [simple_loss_function(x) for x in x_values]\n\nprint(\"Loss function example:\")\nprint(f\"At x=2, loss = {simple_loss_function(2):.2f}, derivative = {loss_derivative(2):.2f}\")\nprint(f\"At x=4, loss = {simple_loss_function(4):.2f}, derivative = {loss_derivative(4):.2f}\")\nprint(\"\\nThe derivative tells us which direction to move to minimize loss!\")\nprint(\"This is exactly how gradient descent works in ML!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (x - 3)**2 + 2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.6767051219940186,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7364201545715332,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy.misc import derivative\ndef compute_derivative(func, x, h=1e-6):        # # SOLUTION: Implement numerical derivative    # Formula: (f(x+h) - f(x))\nh    pass\ndef compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\ndef gradient_descent_step(func, x, learning_rate=0.1):        # # SOLUTION:     # 1. Compute gradient at current point    # 2. Move in opposite direction: x_new = x - lr * gradient    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    h    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy.misc import derivative\ndef compute_derivative(func, x, h=1e-6):        # # SOLUTION: Implement numerical derivative    # Formula: (f(x+h) - f(x))\nh    pass\ndef compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\ndef gradient_descent_step(func, x, learning_rate=0.1):        # # SOLUTION:     # 1. Compute gradient at current point    # 2. Move in opposite direction: x_new = x - lr * gradient    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    h    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.7405140399932861,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50):        results = {}        # # SOLUTION: For each learning rate, run gradient descent    # Store the final value in results dictionary       return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\u001b[0m\n\u001b[0m                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50):        results = {}        # # SOLUTION: For each learning rate, run gradient descent    # Store the final value in results dictionary       return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\u001b[0m\n\u001b[0m                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/examples/01_optimizers_comparison.ipynb",
      "status": "failed",
      "execution_time": 0.8897850513458252,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 2: Adam Optimizer\n# WHY: Adapts to each parameter, handles noise better\n# HOW: Tracks momentum + variance, adapts learning rate\n\nclass AdamOptimizer:\n    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1  # Momentum decay\n        self.beta2 = beta2  # Learning rate decay\n        self.m = 0  # First moment (mean of gradients)\n        self.v = 0  # Second moment (variance of gradients)\n        self.t = 0  # Time step\n    \n    def update(self, params, grads):\n        self.t += 1\n        self.m = self.beta1 * self.m + (1 - self.beta1) * grads  # Momentum\n        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2  # Variance\n        m_hat = self.m\n(1 - self.beta1**self.t)  # Bias correction\n        v_hat = self.v\n(1 - self.beta2**self.t)  # Bias correction\n        return params - self.lr * m_hat\n(np.sqrt(v_hat) + 1e-8)  # Adaptive step\n\n# Adam optimizer\nadam = AdamOptimizer(lr=0.1)\nx_adam = 0.0\nadam_path = [x_adam]\nadam_loss = [loss_function(x_adam)]\n\nfor i in range(30):\n    grad = loss_gradient(x_adam)\n    x_adam = adam.update(x_adam, grad)\n    adam_path.append(x_adam)\n    adam_loss.append(loss_function(x_adam))\n\nprint(\"\\nExample 2: Adam Optimizer\")\nprint(\"=\" * 60)\nprint(f\"Starting at x = 0.0\")\nprint(f\"After 30 iterations: x = {x_adam:.4f}, loss = {adam_loss[-1]:.4f}\")\nprint(f\"\\n\ud83d\udca1 WHY: Adapts to each parameter, handles noise better\")\nprint(f\"\ud83d\udca1 HOW: Tracks momentum + variance, adapts learning rate\")\nprint(f\"\ud83d\udca1 AFTER: Faster convergence, more stable!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 2: Adam Optimizer\n# WHY: Adapts to each parameter, handles noise better\n# HOW: Tracks momentum + variance, adapts learning rate\n\nclass AdamOptimizer:\n    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1  # Momentum decay\n        self.beta2 = beta2  # Learning rate decay\n        self.m = 0  # First moment (mean of gradients)\n        self.v = 0  # Second moment (variance of gradients)\n        self.t = 0  # Time step\n    \n    def update(self, params, grads):\n        self.t += 1\n        self.m = self.beta1 * self.m + (1 - self.beta1) * grads  # Momentum\n        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2  # Variance\n        m_hat = self.m\n(1 - self.beta1**self.t)  # Bias correction\n        v_hat = self.v\n(1 - self.beta2**self.t)  # Bias correction\n        return params - self.lr * m_hat\n(np.sqrt(v_hat) + 1e-8)  # Adaptive step\n\n# Adam optimizer\nadam = AdamOptimizer(lr=0.1)\nx_adam = 0.0\nadam_path = [x_adam]\nadam_loss = [loss_function(x_adam)]\n\nfor i in range(30):\n    grad = loss_gradient(x_adam)\n    x_adam = adam.update(x_adam, grad)\n    adam_path.append(x_adam)\n    adam_loss.append(loss_function(x_adam))\n\nprint(\"\\nExample 2: Adam Optimizer\")\nprint(\"=\" * 60)\nprint(f\"Starting at x = 0.0\")\nprint(f\"After 30 iterations: x = {x_adam:.4f}, loss = {adam_loss[-1]:.4f}\")\nprint(f\"\\n\ud83d\udca1 WHY: Adapts to each parameter, handles noise better\")\nprint(f\"\ud83d\udca1 HOW: Tracks momentum + variance, adapts learning rate\")\nprint(f\"\ud83d\udca1 AFTER: Faster convergence, more stable!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/examples/02_loss_functions.ipynb",
      "status": "passed",
      "execution_time": 0.8717207908630371,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/examples/03_statistical_measures.ipynb",
      "status": "failed",
      "execution_time": 0.6669938564300537,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 1: Statistical Measures\n# WHY: Need objective way to evaluate models\n# HOW: Compute error metrics\n\ndef calculate_statistics(predictions, targets):\n    \"\"\"Calculate statistical measures\"\"\"\n    errors = predictions - targets\n    mse = np.mean(errors**2)\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(errors))\n    r2 = 1 - np.sum(errors**2)\nnp.sum((targets - np.mean(targets))**2)\n    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\n\npredictions = np.array([2.1, 3.2, 4.0, 5.1])\ntargets = np.array([2.0, 3.0, 4.0, 5.0])\nstats = calculate_statistics(predictions, targets)\n\nprint(\"Example 1: Statistical Measures\")\nprint(\"=\" * 60)\nprint(f\"Predictions: {predictions}\")\nprint(f\"Targets:    {targets}\")\nprint(f\"\\nStatistical Measures:\")\nfor metric, value in stats.items():\n    print(f\"  - {metric}: {value:.4f}\")\n    if metric == 'R\u00b2':\n        print(f\"    \ud83d\udca1 WHY: Shows how much variance is explained\")\n        print(f\"    \ud83d\udca1 HOW: 1 - (error_variance\ntotal_variance)\")\n        print(f\"    \ud83d\udca1 AFTER: {value:.1%} of variance explained!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 1: Statistical Measures\n# WHY: Need objective way to evaluate models\n# HOW: Compute error metrics\n\ndef calculate_statistics(predictions, targets):\n    \"\"\"Calculate statistical measures\"\"\"\n    errors = predictions - targets\n    mse = np.mean(errors**2)\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(errors))\n    r2 = 1 - np.sum(errors**2)\nnp.sum((targets - np.mean(targets))**2)\n    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\n\npredictions = np.array([2.1, 3.2, 4.0, 5.1])\ntargets = np.array([2.0, 3.0, 4.0, 5.0])\nstats = calculate_statistics(predictions, targets)\n\nprint(\"Example 1: Statistical Measures\")\nprint(\"=\" * 60)\nprint(f\"Predictions: {predictions}\")\nprint(f\"Targets:    {targets}\")\nprint(f\"\\nStatistical Measures:\")\nfor metric, value in stats.items():\n    print(f\"  - {metric}: {value:.4f}\")\n    if metric == 'R\u00b2':\n        print(f\"    \ud83d\udca1 WHY: Shows how much variance is explained\")\n        print(f\"    \ud83d\udca1 HOW: 1 - (error_variance\ntotal_variance)\")\n        print(f\"    \ud83d\udca1 AFTER: {value:.1%} of variance explained!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7324490547180176,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\nclass SimpleGDOptimizer:\n \n \ndef__init__(self, lr=0.01):\n self.lr = lr\n \n def update(self, params, grads):\n \n # TODO: Implement simple gradient descent update\n pass\n\n\nclass MomentumOptimizer:\n \n \ndef__init__(self, lr=0.01, momentum=0.9):\n self.lr = lr\n self.momentum = momentum\n self.velocity = None\n \n def update(self, params, grads):\n \n # TODO: Initialize velocity if first call\n # TODO: Update velocity: v = momentum * v + lr * grad\ns\n # TODO: Update params: params = params - velocity\n pass\n\n\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):\n \n results = {}\n \n # TODO: For each optimize\nr:\n # 1. Start with initial_params\n # 2. Run for 'iterations' step\ns\n # 3. Store final parameters\n \n return results\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\nclass SimpleGDOptimizer:\n \n \ndef__init__(self, lr=0.01):\n self.lr = lr\n \n def update(self, params, grads):\n \n # TODO: Implement simple gradient descent update\n pass\n\n\nclass MomentumOptimizer:\n \n \ndef__init__(self, lr=0.01, momentum=0.9):\n self.lr = lr\n self.momentum = momentum\n self.velocity = None\n \n def update(self, params, grads):\n \n # TODO: Initialize velocity if first call\n # TODO: Update velocity: v = momentum * v + lr * grad\ns\n # TODO: Update params: params = params - velocity\n pass\n\n\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):\n \n results = {}\n \n # TODO: For each optimize\nr:\n # 1. Start with initial_params\n # 2. Run for 'iterations' step\ns\n # 3. Store final parameters\n \n return results\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_03/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.7318210601806641,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef calculate_mse(predictions, targets):\n \n # TODO: Calculate MS\nE\n # Formula: mean((predictions - targets)^2)\n pass\n\n\ndef calculate_rmse(predictions, targets):\n \n # TODO: Calculate RMSE\n # Formula: sqrt(MS\nE)\npass\n\n\ndef calculate_r2__score(predictions, targets):\n \n # TODO: Calculate R\u00b2\n # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(target\ns))^2)\n pass\n\n\ndef evaluate_model(predictions, targets):\n \n # TODO: Calculate all metrics and return as dictionary pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    E)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef calculate_mse(predictions, targets):\n \n # TODO: Calculate MS\nE\n # Formula: mean((predictions - targets)^2)\n pass\n\n\ndef calculate_rmse(predictions, targets):\n \n # TODO: Calculate RMSE\n # Formula: sqrt(MS\nE)\npass\n\n\ndef calculate_r2__score(predictions, targets):\n \n # TODO: Calculate R\u00b2\n # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(target\ns))^2)\n pass\n\n\ndef evaluate_model(predictions, targets):\n \n # TODO: Calculate all metrics and return as dictionary pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    E)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_03/notebook_03_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 0.5609500408172607,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Optimization and Statistics in Python for ML\n# This shows HOW optimizers work and WHY we use different ones\n\nimport numpy as np\nfrom scipy import stats\n\nprint(\"=\" * 60)\nprint(\"HOW Optimization and Statistics Work in ML\")\nprint(\"=\" * 60)\n\n# 1. Implementing different optimizers\n# WHY: Different optimizers work better for different problems\n# HOW: Each uses gradients (from Module 02) differently\n\nclass SimpleOptimizer:\n    \"\"\"Simple gradient descent optimizer\"\"\"\n    def__init__(self, lr=0.01):\n        self.lr = lr\n    \n    def update(self, params, grads):\n        # WHY: Simple and works for convex problems\n        # HOW: Just move opposite to gradient\n        return params - self.lr * grads\n\nclass AdamOptimizer:\n    \"\"\"Adam optimizer (adaptive moment estimation)\"\"\"\n    def__init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1  # Momentum decay\n        self.beta2 = beta2  # Learning rate decay\n        self.m = 0  # First moment (mean of gradients)\n        self.v = 0  # Second moment (variance of gradients)\n        self.t = 0  # Time step\n    \n    def update(self, params, grads):\n        # WHY: Adapts learning rate per parameter, handles noisy gradients\n        # HOW: \n        # 1. Track moving average of gradients (momentum)\n        # 2. Track moving average of squared gradients (variance)\n        # 3. Adapt learning rate based on variance\n        self.t += 1\n        self.m = self.beta1 * self.m + (1 - self.beta1) * grads  # Momentum\n        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2  # Variance\n        m_hat = self.m\n(1 - self.beta1**self.t)  # Bias correction\n        v_hat = self.v\n(1 - self.beta2**self.t)  # Bias correction\n        return params - self.lr * m_hat\n(np.sqrt(v_hat) + 1e-8)  # Adaptive step\n\nprint(\"\\n1. Optimizers (HOW Models Learn):\")\nprint(\"   Simple GD:\")\nprint(\"   - WHY: Simple, works for smooth functions\")\nprint(\"   - HOW: params = params - lr \u00d7 gradient\")\nprint(\"\\n   Adam:\")\nprint(\"   - WHY: Adapts to each parameter, handles noise better\")\nprint(\"   - HOW: Tracks momentum + variance, adapts learning rate\")\nprint(\"   - Result: Faster convergence, more stable\")\n\n# 2. Statistical measures for ML\n# WHY: Need objective way to evaluate models\n# HOW: Compute error metrics\ndef calculate_statistics(predictions, targets):\n    \"\"\"Calculate statistical measures for model evaluation\"\"\"\n    errors = predictions - targets\n    mse = np.mean(errors**2)  # Mean Squared Error\n    rmse = np.sqrt(mse)  # Root Mean Squared Error\n    mae = np.mean(np.abs(errors))  # Mean Absolute Error\n    r2 = 1 - np.sum(errors**2)\nnp.sum((targets - np.mean(targets))**2)  # R\u00b2\n    \n    return {\n        'MSE': mse, 'RMSE': rmse,\n        'MAE': mae,\n        'R\u00b2': r2\n    }\n\n# Example usage\npredictions = np.array([2.1, 3.2, 4.0, 5.1])\ntargets = np.array([2.0, 3.0, 4.0, 5.0])\nstats = calculate_statistics(predictions, targets)\n\nprint(\"\\n2. Statistical Measures (HOW We Evaluate Models):\")\nprint(\"   Predictions:\", predictions)\nprint(\"   Targets:    \", targets)\nprint(\"\\n   WHY: Need numbers to compare models objectively\")\nprint(\"   HOW: Compute different error metrics\")\nfor metric, value in stats.items():\n    print(f\"   - {metric}: {value:.4f}\")\n    if metric == 'MSE':\n        print(\"     WHY: Penalizes large errors more\")\n        print(\"     HOW: Square errors, then average\")\n    elif metric == 'R\u00b2':\n        print(\"     WHY: Shows how much variance is explained\")\n        print(\"     HOW: 1 - (error_variance\ntotal_variance)\")\n\n# Additional concepts you can explore:\n# - Regularization examples (with WHY and HOW)\n# - Cross-validation (step-by-step)\n# - Bias-variance analysis\n# - Confidence intervals\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 95\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"     HOW: 1 - (error_variance\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 95)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Optimization and Statistics in Python for ML\n# This shows HOW optimizers work and WHY we use different ones\n\nimport numpy as np\nfrom scipy import stats\n\nprint(\"=\" * 60)\nprint(\"HOW Optimization and Statistics Work in ML\")\nprint(\"=\" * 60)\n\n# 1. Implementing different optimizers\n# WHY: Different optimizers work better for different problems\n# HOW: Each uses gradients (from Module 02) differently\n\nclass SimpleOptimizer:\n    \"\"\"Simple gradient descent optimizer\"\"\"\n    def__init__(self, lr=0.01):\n        self.lr = lr\n    \n    def update(self, params, grads):\n        # WHY: Simple and works for convex problems\n        # HOW: Just move opposite to gradient\n        return params - self.lr * grads\n\nclass AdamOptimizer:\n    \"\"\"Adam optimizer (adaptive moment estimation)\"\"\"\n    def__init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1  # Momentum decay\n        self.beta2 = beta2  # Learning rate decay\n        self.m = 0  # First moment (mean of gradients)\n        self.v = 0  # Second moment (variance of gradients)\n        self.t = 0  # Time step\n    \n    def update(self, params, grads):\n        # WHY: Adapts learning rate per parameter, handles noisy gradients\n        # HOW: \n        # 1. Track moving average of gradients (momentum)\n        # 2. Track moving average of squared gradients (variance)\n        # 3. Adapt learning rate based on variance\n        self.t += 1\n        self.m = self.beta1 * self.m + (1 - self.beta1) * grads  # Momentum\n        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2  # Variance\n        m_hat = self.m\n(1 - self.beta1**self.t)  # Bias correction\n        v_hat = self.v\n(1 - self.beta2**self.t)  # Bias correction\n        return params - self.lr * m_hat\n(np.sqrt(v_hat) + 1e-8)  # Adaptive step\n\nprint(\"\\n1. Optimizers (HOW Models Learn):\")\nprint(\"   Simple GD:\")\nprint(\"   - WHY: Simple, works for smooth functions\")\nprint(\"   - HOW: params = params - lr \u00d7 gradient\")\nprint(\"\\n   Adam:\")\nprint(\"   - WHY: Adapts to each parameter, handles noise better\")\nprint(\"   - HOW: Tracks momentum + variance, adapts learning rate\")\nprint(\"   - Result: Faster convergence, more stable\")\n\n# 2. Statistical measures for ML\n# WHY: Need objective way to evaluate models\n# HOW: Compute error metrics\ndef calculate_statistics(predictions, targets):\n    \"\"\"Calculate statistical measures for model evaluation\"\"\"\n    errors = predictions - targets\n    mse = np.mean(errors**2)  # Mean Squared Error\n    rmse = np.sqrt(mse)  # Root Mean Squared Error\n    mae = np.mean(np.abs(errors))  # Mean Absolute Error\n    r2 = 1 - np.sum(errors**2)\nnp.sum((targets - np.mean(targets))**2)  # R\u00b2\n    \n    return {\n        'MSE': mse, 'RMSE': rmse,\n        'MAE': mae,\n        'R\u00b2': r2\n    }\n\n# Example usage\npredictions = np.array([2.1, 3.2, 4.0, 5.1])\ntargets = np.array([2.0, 3.0, 4.0, 5.0])\nstats = calculate_statistics(predictions, targets)\n\nprint(\"\\n2. Statistical Measures (HOW We Evaluate Models):\")\nprint(\"   Predictions:\", predictions)\nprint(\"   Targets:    \", targets)\nprint(\"\\n   WHY: Need numbers to compare models objectively\")\nprint(\"   HOW: Compute different error metrics\")\nfor metric, value in stats.items():\n    print(f\"   - {metric}: {value:.4f}\")\n    if metric == 'MSE':\n        print(\"     WHY: Penalizes large errors more\")\n        print(\"     HOW: Square errors, then average\")\n    elif metric == 'R\u00b2':\n        print(\"     WHY: Shows how much variance is explained\")\n        print(\"     HOW: 1 - (error_variance\ntotal_variance)\")\n\n# Additional concepts you can explore:\n# - Regularization examples (with WHY and HOW)\n# - Cross-validation (step-by-step)\n# - Bias-variance analysis\n# - Confidence intervals\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 95\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"     HOW: 1 - (error_variance\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 95)\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.6588940620422363,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5440020561218262,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nclass SimpleGDOptimizer:        \n\ndef__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\nclass MomentumOptimizer:        \n\ndef__init__(self, lr=0.01, momentum=0.9):        self.lr = lr        self.momentum = momentum        self.velocity = None        def update(self, params, grads):                # # SOLUTION: Initialize velocity if first call        # # SOLUTION: Update velocity: v = momentum * v + lr * grads        # # SOLUTION: Update params: params = params - velocity        pass\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):        results = {}        # # SOLUTION: For each optimizer:    #   1. Start with initial_params    #   2. Run for 'iterations' steps    #   3. Store final parameters        return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nclass SimpleGDOptimizer:        \n\ndef__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\nclass MomentumOptimizer:        \n\ndef__init__(self, lr=0.01, momentum=0.9):        self.lr = lr        self.momentum = momentum        self.velocity = None        def update(self, params, grads):                # # SOLUTION: Initialize velocity if first call        # # SOLUTION: Update velocity: v = momentum * v + lr * grads        # # SOLUTION: Update params: params = params - velocity        pass\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):        results = {}        # # SOLUTION: For each optimizer:    #   1. Start with initial_params    #   2. Run for 'iterations' steps    #   3. Store final parameters        return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.7306420803070068,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef calculate_mse(predictions, targets):        # # SOLUTION: Calculate MSE    # Formula: mean((predictions - targets)^2)    pass\ndef calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\ndef calculate_r2_score(predictions, targets):        # # SOLUTION: Calculate R\u00b2    # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(targets))^2)    pass\ndef evaluate_model(predictions, targets):        # # SOLUTION: Calculate all metrics and return as dictionary    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef calculate_mse(predictions, targets):        # # SOLUTION: Calculate MSE    # Formula: mean((predictions - targets)^2)    pass\ndef calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\ndef calculate_r2_score(predictions, targets):        # # SOLUTION: Calculate R\u00b2    # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(targets))^2)    pass\ndef evaluate_model(predictions, targets):        # # SOLUTION: Calculate all metrics and return as dictionary    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/examples/01_pca_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.7497999668121338,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/examples/02_curse_dimensionality.ipynb",
      "status": "failed",
      "execution_time": 0.9069440364837646,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 1: Curse of Dimensionality\n# WHY: High dimensions cause problems\n# HOW: Volume increases exponentially\n\ndef volume_ratio(dimensions):\n    \"\"\"Volume ratio in unit hypercube\"\"\"\n    # Volume of small cube\nVolume of unit cube\n    edge = 0.1\n    return edge ** dimensions\n\ndims = [1, 2, 5, 10, 20, 50]\nvolumes = [volume_ratio(d) for d in dims]\n\nprint(\"Example 1: Curse of Dimensionality\")\nprint(\"=\" * 60)\nprint(\"Volume ratio (0.1 edge cube\nunit cube) by dimension:\")\nfor d, v in zip(dims, volumes):\n    print(f\"  {d}D: {v:.2e}\")\nprint(f\"\\n\ud83d\udca1 WHY: Volume becomes tiny in high dimensions\")\nprint(f\"\ud83d\udca1 HOW: Volume = edge^dimensions (exponential decrease)\")\nprint(f\"\ud83d\udca1 AFTER: Data becomes extremely sparse!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Volume ratio (0.1 edge cube\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 17)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 1: Curse of Dimensionality\n# WHY: High dimensions cause problems\n# HOW: Volume increases exponentially\n\ndef volume_ratio(dimensions):\n    \"\"\"Volume ratio in unit hypercube\"\"\"\n    # Volume of small cube\nVolume of unit cube\n    edge = 0.1\n    return edge ** dimensions\n\ndims = [1, 2, 5, 10, 20, 50]\nvolumes = [volume_ratio(d) for d in dims]\n\nprint(\"Example 1: Curse of Dimensionality\")\nprint(\"=\" * 60)\nprint(\"Volume ratio (0.1 edge cube\nunit cube) by dimension:\")\nfor d, v in zip(dims, volumes):\n    print(f\"  {d}D: {v:.2e}\")\nprint(f\"\\n\ud83d\udca1 WHY: Volume becomes tiny in high dimensions\")\nprint(f\"\ud83d\udca1 HOW: Volume = edge^dimensions (exponential decrease)\")\nprint(f\"\ud83d\udca1 AFTER: Data becomes extremely sparse!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Volume ratio (0.1 edge cube\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 17)\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/examples/03_feature_selection.ipynb",
      "status": "passed",
      "execution_time": 0.9457521438598633,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6260697841644287,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_covariance_matrix(data):\n \n # TODO: Compute covariance matrix\n # Hint: Center data first (subtract mean), then compute covariance\n pass\n\n\ndef pca_from_scratch(data, n_components=2):\n \n # TODO: Implement PC\nA\n # Step\ns:\n # 1. Center the data (subtract mean)\n # 2. Compute covariance matrix\n # 3. Find eigenvalues and eigenvectors\n # 4. Sort by eigenvalues (descending)\n # 5. Select top n_components\n # 6. Project data: reduced = data @ eigenvectors\n # 7. Calculate explained variance rati\no\n pass\n\n\ndef calculate_variance_explained(eigenvalues, n_components):\n \n # TODO: Calculate variance explaine\nd\n # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    A\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 11\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_covariance_matrix(data):\n \n # TODO: Compute covariance matrix\n # Hint: Center data first (subtract mean), then compute covariance\n pass\n\n\ndef pca_from_scratch(data, n_components=2):\n \n # TODO: Implement PC\nA\n # Step\ns:\n # 1. Center the data (subtract mean)\n # 2. Compute covariance matrix\n # 3. Find eigenvalues and eigenvectors\n # 4. Sort by eigenvalues (descending)\n # 5. Select top n_components\n # 6. Project data: reduced = data @ eigenvectors\n # 7. Calculate explained variance rati\no\n pass\n\n\ndef calculate_variance_explained(eigenvalues, n_components):\n \n # TODO: Calculate variance explaine\nd\n # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    A\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 11\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_04/notebook_04_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 1.746093988418579,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.7731912136077881,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5915052890777588,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_covariance_matrix(data):        # # SOLUTION: Compute covariance matrix    # Hint: Center data first (subtract mean), then compute covariance    pass\ndef pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\ndef calculate_variance_explained(eigenvalues, n_components):        # # SOLUTION: Calculate variance explained    # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_covariance_matrix(data):        # # SOLUTION: Compute covariance matrix    # Hint: Center data first (subtract mean), then compute covariance    pass\ndef pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\ndef calculate_variance_explained(eigenvalues, n_components):        # # SOLUTION: Calculate variance explained    # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/examples/01_probability_distributions.ipynb",
      "status": "passed",
      "execution_time": 0.8948540687561035,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/examples/02_statistical_inference.ipynb",
      "status": "passed",
      "execution_time": 0.9529950618743896,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/examples/03_bayesian_inference.ipynb",
      "status": "passed",
      "execution_time": 1.282520055770874,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7584037780761719,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\n\n\ndef compute_confidence_interval(data, confidence=0.95):\n \n # TODO: Compute confidence interval\n # Step\ns:\n # 1. Calculate sample mean and standard erro\nr\n # 2. Get t-critical value for confidence leve\nl\n # 3. CI = mean \u00b1 t_critical * standard_error\n pass\n\n\ndef t_test_two_samples(sample1, sample2):\n \n # TODO: Perform two-sample t-test\n # Use scipy.stats.ttest_in\nd()\n pass\n\n\ndef interpret_p__value(p_value, alpha=0.05):\n \n # TODO: Interpret p-valu\ne\n # If p < alpha: significant difference\n # If p >= alpha: no significant difference\n pass\n\n\ndef compare_models(model1_scores, model2_scores, alpha=0.05):\n \n # TODO: \n # 1. Compute means and confidence interval\ns\n # 2. Perform t-test\n # 3. Interpret result\ns\n # 4. Return comprehensive comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    s:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\n\n\ndef compute_confidence_interval(data, confidence=0.95):\n \n # TODO: Compute confidence interval\n # Step\ns:\n # 1. Calculate sample mean and standard erro\nr\n # 2. Get t-critical value for confidence leve\nl\n # 3. CI = mean \u00b1 t_critical * standard_error\n pass\n\n\ndef t_test_two_samples(sample1, sample2):\n \n # TODO: Perform two-sample t-test\n # Use scipy.stats.ttest_in\nd()\n pass\n\n\ndef interpret_p__value(p_value, alpha=0.05):\n \n # TODO: Interpret p-valu\ne\n # If p < alpha: significant difference\n # If p >= alpha: no significant difference\n pass\n\n\ndef compare_models(model1_scores, model2_scores, alpha=0.05):\n \n # TODO: \n # 1. Compute means and confidence interval\ns\n # 2. Perform t-test\n # 3. Interpret result\ns\n # 4. Return comprehensive comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    s:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_05/notebook_05_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 1.4510409832000732,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Basic Probability and Statistical Inference Operations in Python\n# This shows HOW each concept works and WHY it's used in ML\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"HOW Probabilities and Statistical Inference Work in ML\")\nprint(\"=\" * 60)\n\n# 1. Working with probability distributions\n# WHY: ML models need to understand data distributions\n# HOW: Use probability distributions to model uncertainty\nprint(\"\\n1. Probability Distributions (Modeling Uncertainty):\")\nprint(\" WHY: Need to understand and model data distributions\")\nprint(\" HOW: Use probability distributions to describe data patterns\")\n\n# Normal distribution example\nmu, sigma = 0, 1\nsamples = np.random.normal(mu, sigma, 1000)\nprint(f\" Normal distribution: mean={np.mean(samples):.4f}, std={np.std(samples):.4f}\")\nprint(\" HOW: This distribution models continuous data (e.g., prediction errors)\")\n\n# Binomial distribution example\nn, p = 10, 0.5\nbinomial_samples = np.random.binomial(n, p, 1000)\nprint(f\" Binomial distribution: mean={np.mean(binomial_samples):.4f}, std={np.std(binomial_samples):.4f}\")\nprint(\" HOW: This distribution models binary outcomes (e.g., classification)\")\n\n# 2. Statistical hypothesis testing\n# WHY: Determine if differences between models are statistically significant\n# HOW: Compute test statistic and p-value\nprint(\"\\n2. Statistical Hypothesis Testing (Model Comparison):\")\nprint(\" WHY: Need to know if model improvements are real or by chance\")\nprint(\" HOW: Use statistical tests to compare models\")\n\n# Example: Comparing two models\nmodel_a_scores = np.random.normal(0.85, 0.02, 100)\nmodel_b_scores = np.random.normal(0.87, 0.02, 100)\n\nt_stat, p_value = stats.ttest_ind(model_a_scores, model_b_scores)\nprint(f\" Model A mean: {np.mean(model_a_scores):.4f}\")\nprint(f\" Model B mean: {np.mean(model_b_scores):.4f}\")\nprint(f\" t-statistic: {t_stat:.4f}\")\nprint(f\" p-value: {p_value:.4f}\")\nif p_value < 0.05:\n print(\" \u2705 Significant difference! (p < 0.05)\")\n print(\" HOW: p-value < 0.05 means < 5% chance this difference is by chance\")\nelse:\n print(\" \u274c No significant difference (p >= 0.05)\")\n\n# 3. Confidence intervals\n# WHY: Point estimates don't show uncertainty\n# HOW: Compute range of likely values\nprint(\"\\n3. Confidence Intervals (Uncertainty Quantification):\")\nprint(\" WHY: Need to know the range of likely values, not just a point estimate\")\nprint(\" HOW: Compute confidence interval using standard error\")\n\n# Example: Confidence interval for mean\nmean_score = np.mean(model_a_scores)\nstd_error = stats.sem(model_a_scores)\nci_95 = stats.t.interval(0.95, len(model_a_scores)-1, loc=mean_score, scale=std_error)\nprint(f\" Mean score: {mean_score:.4f}\")\nprint(f\" 95% Confidence Interval: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\nprint(\" HOW: 95% CI means we're 95% confident the true mean is in this range\")\n\n# 4. Sampling methods\n# WHY: Need representative samples for training/testing\n# HOW: Use proper sampling techniques\nprint(\"\\n4. Sampling Methods (Data Splitting):\")\nprint(\" WHY: Can't use all data - need representative train/test splits\")\nprint(\" HOW: Use random sampling to ensure representativeness\")\n\n# Example: Train/test split\ndata = np.random.normal(0, 1, 1000)\ntrain_size = int(0.8 * len(data))\ntrain_data = data[:train_size]\ntest_data = data[train_size:]\nprint(f\" Total data: {len(data)} samples\")\nprint(f\" Training set: {len(train_data)} samples ({len(train_data)/len(data)*100:.1f}%)\")\nprint(f\" Test set: {len(test_data)} samples ({len(test_data)/len(data)*100:.1f}%)\")\nprint(\" HOW: Random split ensures both sets are representative\")\n\n# 5. Bayesian inference basics\n# WHY: Incorporate prior knowledge into models\n# HOW: Update prior beliefs with observed data\nprint(\"\\n5. Bayesian Inference (Prior Knowledge Integration):\")\nprint(\" WHY: Want to incorporate what we know before seeing data\")\nprint(\" HOW: Start with prior, update with data to get posterior\")\n\n# Simple Bayesian example\nprior_belief = 0.5 # 50% chance before seeing data\nlikelihood = 0.8 # Data suggests 80% chance\n# Simplified: posterior = (prior * likelihood)\nnormalization\n# In practice, use Bayes' theorem properly\nprint(f\" Prior belief: {prior_belief:.1%}\")\nprint(f\" Likelihood from data: {likelihood:.1%}\")\nprint(\" HOW: Bayes' theorem combines prior knowledge with observed data\")\nprint(\" Result: Updated belief (posterior) that balances both\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Key Takeaway:\")\nprint(\" Probabilities quantify uncertainty\")\nprint(\" Statistical inference helps make data-driven decisions\")\nprint(\" Both are essential for evaluating and improving ML models!\")\nprint(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nHOW Probabilities and Statistical Inference Work in ML\n============================================================\n\n1. Probability Distributions (Modeling Uncertainty):\n WHY: Need to understand and model data distributions\n HOW: Use probability distributions to describe data patterns\n Normal distribution: mean=0.0277, std=1.0224\n HOW: This distribution models continuous data (e.g., prediction errors)\n Binomial distribution: mean=5.0560, std=1.5971\n HOW: This distribution models binary outcomes (e.g., classification)\n\n2. Statistical Hypothesis Testing (Model Comparison):\n WHY: Need to know if model improvements are real or by chance\n HOW: Use statistical tests to compare models\n Model A mean: 0.8489\n Model B mean: 0.8693\n t-statistic: -7.3680\n p-value: 0.0000\n \u2705 Significant difference! (p < 0.05)\n HOW: p-value < 0.05 means < 5% chance this difference is by chance\n\n3. Confidence Intervals (Uncertainty Quantification):\n WHY: Need to know the range of likely values, not just a point estimate\n HOW: Compute confidence interval using standard error\n Mean score: 0.8489\n 95% Confidence Interval: [0.8449, 0.8529]\n HOW: 95% CI means we're 95% confident the true mean is in this range\n\n4. Sampling Methods (Data Splitting):\n WHY: Can't use all data - need representative train/test splits\n HOW: Use random sampling to ensure representativeness\n Total data: 1000 samples\n Training set: 800 samples (80.0%)\n Test set: 200 samples (20.0%)\n HOW: Random split ensures both sets are representative\n\n5. Bayesian Inference (Prior Knowledge Integration):\n WHY: Want to incorporate what we know before seeing data\n HOW: Start with prior, update with data to get posterior\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;66;03m# Data suggests 80% chance\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Simplified: posterior = (prior * likelihood)\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m normalization\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# In practice, use Bayes' theorem properly\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Prior belief: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprior_belief\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'normalization' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Basic Probability and Statistical Inference Operations in Python\n# This shows HOW each concept works and WHY it's used in ML\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"HOW Probabilities and Statistical Inference Work in ML\")\nprint(\"=\" * 60)\n\n# 1. Working with probability distributions\n# WHY: ML models need to understand data distributions\n# HOW: Use probability distributions to model uncertainty\nprint(\"\\n1. Probability Distributions (Modeling Uncertainty):\")\nprint(\" WHY: Need to understand and model data distributions\")\nprint(\" HOW: Use probability distributions to describe data patterns\")\n\n# Normal distribution example\nmu, sigma = 0, 1\nsamples = np.random.normal(mu, sigma, 1000)\nprint(f\" Normal distribution: mean={np.mean(samples):.4f}, std={np.std(samples):.4f}\")\nprint(\" HOW: This distribution models continuous data (e.g., prediction errors)\")\n\n# Binomial distribution example\nn, p = 10, 0.5\nbinomial_samples = np.random.binomial(n, p, 1000)\nprint(f\" Binomial distribution: mean={np.mean(binomial_samples):.4f}, std={np.std(binomial_samples):.4f}\")\nprint(\" HOW: This distribution models binary outcomes (e.g., classification)\")\n\n# 2. Statistical hypothesis testing\n# WHY: Determine if differences between models are statistically significant\n# HOW: Compute test statistic and p-value\nprint(\"\\n2. Statistical Hypothesis Testing (Model Comparison):\")\nprint(\" WHY: Need to know if model improvements are real or by chance\")\nprint(\" HOW: Use statistical tests to compare models\")\n\n# Example: Comparing two models\nmodel_a_scores = np.random.normal(0.85, 0.02, 100)\nmodel_b_scores = np.random.normal(0.87, 0.02, 100)\n\nt_stat, p_value = stats.ttest_ind(model_a_scores, model_b_scores)\nprint(f\" Model A mean: {np.mean(model_a_scores):.4f}\")\nprint(f\" Model B mean: {np.mean(model_b_scores):.4f}\")\nprint(f\" t-statistic: {t_stat:.4f}\")\nprint(f\" p-value: {p_value:.4f}\")\nif p_value < 0.05:\n print(\" \u2705 Significant difference! (p < 0.05)\")\n print(\" HOW: p-value < 0.05 means < 5% chance this difference is by chance\")\nelse:\n print(\" \u274c No significant difference (p >= 0.05)\")\n\n# 3. Confidence intervals\n# WHY: Point estimates don't show uncertainty\n# HOW: Compute range of likely values\nprint(\"\\n3. Confidence Intervals (Uncertainty Quantification):\")\nprint(\" WHY: Need to know the range of likely values, not just a point estimate\")\nprint(\" HOW: Compute confidence interval using standard error\")\n\n# Example: Confidence interval for mean\nmean_score = np.mean(model_a_scores)\nstd_error = stats.sem(model_a_scores)\nci_95 = stats.t.interval(0.95, len(model_a_scores)-1, loc=mean_score, scale=std_error)\nprint(f\" Mean score: {mean_score:.4f}\")\nprint(f\" 95% Confidence Interval: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\nprint(\" HOW: 95% CI means we're 95% confident the true mean is in this range\")\n\n# 4. Sampling methods\n# WHY: Need representative samples for training/testing\n# HOW: Use proper sampling techniques\nprint(\"\\n4. Sampling Methods (Data Splitting):\")\nprint(\" WHY: Can't use all data - need representative train/test splits\")\nprint(\" HOW: Use random sampling to ensure representativeness\")\n\n# Example: Train/test split\ndata = np.random.normal(0, 1, 1000)\ntrain_size = int(0.8 * len(data))\ntrain_data = data[:train_size]\ntest_data = data[train_size:]\nprint(f\" Total data: {len(data)} samples\")\nprint(f\" Training set: {len(train_data)} samples ({len(train_data)/len(data)*100:.1f}%)\")\nprint(f\" Test set: {len(test_data)} samples ({len(test_data)/len(data)*100:.1f}%)\")\nprint(\" HOW: Random split ensures both sets are representative\")\n\n# 5. Bayesian inference basics\n# WHY: Incorporate prior knowledge into models\n# HOW: Update prior beliefs with observed data\nprint(\"\\n5. Bayesian Inference (Prior Knowledge Integration):\")\nprint(\" WHY: Want to incorporate what we know before seeing data\")\nprint(\" HOW: Start with prior, update with data to get posterior\")\n\n# Simple Bayesian example\nprior_belief = 0.5 # 50% chance before seeing data\nlikelihood = 0.8 # Data suggests 80% chance\n# Simplified: posterior = (prior * likelihood)\nnormalization\n# In practice, use Bayes' theorem properly\nprint(f\" Prior belief: {prior_belief:.1%}\")\nprint(f\" Likelihood from data: {likelihood:.1%}\")\nprint(\" HOW: Bayes' theorem combines prior knowledge with observed data\")\nprint(\" Result: Updated belief (posterior) that balances both\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Key Takeaway:\")\nprint(\" Probabilities quantify uncertainty\")\nprint(\" Statistical inference helps make data-driven decisions\")\nprint(\" Both are essential for evaluating and improving ML models!\")\nprint(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nHOW Probabilities and Statistical Inference Work in ML\n============================================================\n\n1. Probability Distributions (Modeling Uncertainty):\n WHY: Need to understand and model data distributions\n HOW: Use probability distributions to describe data patterns\n Normal distribution: mean=0.0277, std=1.0224\n HOW: This distribution models continuous data (e.g., prediction errors)\n Binomial distribution: mean=5.0560, std=1.5971\n HOW: This distribution models binary outcomes (e.g., classification)\n\n2. Statistical Hypothesis Testing (Model Comparison):\n WHY: Need to know if model improvements are real or by chance\n HOW: Use statistical tests to compare models\n Model A mean: 0.8489\n Model B mean: 0.8693\n t-statistic: -7.3680\n p-value: 0.0000\n \u2705 Significant difference! (p < 0.05)\n HOW: p-value < 0.05 means < 5% chance this difference is by chance\n\n3. Confidence Intervals (Uncertainty Quantification):\n WHY: Need to know the range of likely values, not just a point estimate\n HOW: Compute confidence interval using standard error\n Mean score: 0.8489\n 95% Confidence Interval: [0.8449, 0.8529]\n HOW: 95% CI means we're 95% confident the true mean is in this range\n\n4. Sampling Methods (Data Splitting):\n WHY: Can't use all data - need representative train/test splits\n HOW: Use random sampling to ensure representativeness\n Total data: 1000 samples\n Training set: 800 samples (80.0%)\n Test set: 200 samples (20.0%)\n HOW: Random split ensures both sets are representative\n\n5. Bayesian Inference (Prior Knowledge Integration):\n WHY: Want to incorporate what we know before seeing data\n HOW: Start with prior, update with data to get posterior\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;66;03m# Data suggests 80% chance\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Simplified: posterior = (prior * likelihood)\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m normalization\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# In practice, use Bayes' theorem properly\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Prior belief: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprior_belief\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'normalization' is not defined\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.6664478778839111,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5426990985870361,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95):        # # SOLUTION: Compute confidence interval    # Steps:    # 1. Calculate sample mean and standard error    # 2. Get t-critical value for confidence level    # 3. CI = mean \u00b1 t_critical * standard_error    pass\ndef t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\ndef interpret_p_value(p_value, alpha=0.05):        # # SOLUTION: Interpret p-value    # If p < alpha: significant difference    # If p >= alpha: no significant difference    pass\ndef compare_models(model1_scores, model2_scores, alpha=0.05):        # # SOLUTION:     # 1. Compute means and confidence intervals    # 2. Perform t-test    # 3. Interpret results    # 4. Return comprehensive comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95):        # # SOLUTION: Compute confidence interval    # Steps:    # 1. Calculate sample mean and standard error    # 2. Get t-critical value for confidence level    # 3. CI = mean \u00b1 t_critical * standard_error    pass\ndef t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\ndef interpret_p_value(p_value, alpha=0.05):        # # SOLUTION: Interpret p-value    # If p < alpha: significant difference    # If p >= alpha: no significant difference    pass\ndef compare_models(model1_scores, model2_scores, alpha=0.05):        # # SOLUTION:     # 1. Compute means and confidence intervals    # 2. Perform t-test    # 3. Interpret results    # 4. Return comprehensive comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/01_vectors_matrices_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8604447841644287,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/02_matrix_operations.ipynb",
      "status": "passed",
      "execution_time": 0.9215648174285889,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/03_eigenvalues_eigenvectors.ipynb",
      "status": "passed",
      "execution_time": 0.8688900470733643,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/04_substitution_elimination_linear_equations.ipynb",
      "status": "failed",
      "execution_time": 1.1134262084960938,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Substitution Method\")\nprint(\"=\" * 60)\n\n# Example: Solve 2x + y = 5, x - y = 1\n# Step 1: From second equation: x = 1 + y\n# Step 2: Substitute into first: 2(1 + y) + y = 5\n# Step 3: Solve: 2 + 2y + y = 5 => 3y = 3 => y = 1\n# Step 4: Substitute back: x = 1 + 1 = 2\n\ndef substitution_method(eq1, eq2):\n    \"\"\"\n    Solve system of 2 linear equations using substitution.\n    eq1: [a1, b1, c1] for a1*x + b1*y = c1\n    eq2: [a2, b2, c2] for a2*x + b2*y = c2\n    \"\"\"\n    a1, b1, c1 = eq1\n    a2, b2, c2 = eq2\n    \n    # Solve eq2 for x: x = (c2 - b2*y)\na2 (if a2 != 0)\n    if a2 != 0:\n        # x = (c2 - b2*y)\na2\n        # Substitute into eq1: a1*(c2 - b2*y)/a2 + b1*y = c1\n        # Simplify: (a1*c2)/a2 - (a1*b2*y)/a2 + b1*y = c1\n        # y*(b1 - a1*b2/a2) = c1 - a1*c2/a2\n        y = (c1 - a1*c2/a2)\n(b1 - a1*b2/a2)\n        x = (c2 - b2*y)\na2\n    else:\n        # If a2 == 0, solve for y first\n        y = c2\nb2 if b2 != 0 else 0\n        x = (c1 - b1*y)\na1\n    \n    return x, y\n\n# Test with: 2x + y = 5, x - y = 1\n# Expected: x = 2, y = 1\neq1 = [2, 1, 5]  # 2x + y = 5\neq2 = [1, -1, 1]  # x - y = 1\n\nx, y = substitution_method(eq1, eq2)\nprint(f\"\\nExample: 2x + y = 5, x - y = 1\")\nprint(f\"Solution: x = {x:.2f}, y = {y:.2f}\")\nprint(f\"Verification:\")\nprint(f\"  2({x:.2f}) + {y:.2f} = {2*x + y:.2f} (expected 5.00)\")\nprint(f\"  {x:.2f} - {y:.2f} = {x - y:.2f} (expected 1.00)\")\n\nprint(\"\\n\u2705 Substitution method implemented!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    a2 (if a2 != 0)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Substitution Method\")\nprint(\"=\" * 60)\n\n# Example: Solve 2x + y = 5, x - y = 1\n# Step 1: From second equation: x = 1 + y\n# Step 2: Substitute into first: 2(1 + y) + y = 5\n# Step 3: Solve: 2 + 2y + y = 5 => 3y = 3 => y = 1\n# Step 4: Substitute back: x = 1 + 1 = 2\n\ndef substitution_method(eq1, eq2):\n    \"\"\"\n    Solve system of 2 linear equations using substitution.\n    eq1: [a1, b1, c1] for a1*x + b1*y = c1\n    eq2: [a2, b2, c2] for a2*x + b2*y = c2\n    \"\"\"\n    a1, b1, c1 = eq1\n    a2, b2, c2 = eq2\n    \n    # Solve eq2 for x: x = (c2 - b2*y)\na2 (if a2 != 0)\n    if a2 != 0:\n        # x = (c2 - b2*y)\na2\n        # Substitute into eq1: a1*(c2 - b2*y)/a2 + b1*y = c1\n        # Simplify: (a1*c2)/a2 - (a1*b2*y)/a2 + b1*y = c1\n        # y*(b1 - a1*b2/a2) = c1 - a1*c2/a2\n        y = (c1 - a1*c2/a2)\n(b1 - a1*b2/a2)\n        x = (c2 - b2*y)\na2\n    else:\n        # If a2 == 0, solve for y first\n        y = c2\nb2 if b2 != 0 else 0\n        x = (c1 - b1*y)\na1\n    \n    return x, y\n\n# Test with: 2x + y = 5, x - y = 1\n# Expected: x = 2, y = 1\neq1 = [2, 1, 5]  # 2x + y = 5\neq2 = [1, -1, 1]  # x - y = 1\n\nx, y = substitution_method(eq1, eq2)\nprint(f\"\\nExample: 2x + y = 5, x - y = 1\")\nprint(f\"Solution: x = {x:.2f}, y = {y:.2f}\")\nprint(f\"Verification:\")\nprint(f\"  2({x:.2f}) + {y:.2f} = {2*x + y:.2f} (expected 5.00)\")\nprint(f\"  {x:.2f} - {y:.2f} = {x - y:.2f} (expected 1.00)\")\n\nprint(\"\\n\u2705 Substitution method implemented!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    a2 (if a2 != 0)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/05_determinants_inverse_matrices.ipynb",
      "status": "passed",
      "execution_time": 0.806981086730957,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/06_transformation_matrices_orthogonal_basis.ipynb",
      "status": "failed",
      "execution_time": 1.103201150894165,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Applying Transformation Matrices\")\nprint(\"=\" * 60)\n\n# Transformation matrices represent linear transformations\n# Examples: rotation, scaling, reflection, shearing\n\ndef apply_transformation(points, transformation_matrix):\n \n    \n    \"\"\"Apply transformation matrix to points\"\"\"\n return (transformation_matrix @ points.T).T\n\n# Example: 2D points\npoints = np.array([[1, 0],\n [0, 1],\n [1, 1],\n [2, 1]])\n\nprint(\"\\nOriginal points:\")\nprint(points)\n\n# Rotation matrix (90 degrees counterclockwise)\nrotation_90 = np.array([[0, -1],\n [1, 0]])\n\nrotated_points = apply_transformation(points, rotation_90)\nprint(\"\\nRotated 90\u00b0 counterclockwise:\")\nprint(rotated_points)\n\n# Scaling matrix\nscaling = np.array([[2, 0],\n [0, 3]])\n\nscaled_points = apply_transformation(points, scaling)\nprint(\"\\nScaled (x*2, y*3):\")\nprint(scaled_points)\n\n# Shear transformation\nshear = np.array([[1, 0.5],\n [0, 1]])\n\nsheared_points = apply_transformation(points, shear)\nprint(\"\\nSheared:\")\nprint(sheared_points)\n\n# Visualize transformations\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n# Original\naxes[0, 0].scatter(points[:, 0], points[:, 1], c='blue', s=100, alpha=0.7)\naxes[0, 0].plot([0, 0], [0, 2], 'b--', alpha=0.3)\naxes[0, 0].plot([0, 2], [0, 0], 'b--', alpha=0.3)\naxes[0, 0].set_title('Original Points')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(-2, 3)\naxes[0, 0].set_ylim(-2, 3)\naxes[0, 0].axis('equal')\n\n# Rotated\naxes[0, 1].scatter(rotated_points[:, 0], rotated_points[:, 1], c='red', s=100, alpha=0.7)\naxes[0, 1].plot([0, 0], [-2, 2], 'r--', alpha=0.3)\naxes[0, 1].plot([-2, 2], [0, 0], 'r--', alpha=0.3)\naxes[0, 1].set_title('Rotated 90\u00b0')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(-2, 3)\naxes[0, 1].set_ylim(-2, 3)\naxes[0, 1].axis('equal')\n\n# Scaled\naxes[1, 0].scatter(scaled_points[:, 0], scaled_points[:, 1], c='green', s=100, alpha=0.7)\naxes[1, 0].plot([0, 0], [0, 3], 'g--', alpha=0.3)\naxes[1, 0].plot([0, 4], [0, 0], 'g--', alpha=0.3)\naxes[1, 0].set_title('Scaled (x*2, y*3)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(-1, 5)\naxes[1, 0].set_ylim(-1, 4)\naxes[1, 0].axis('equal')\n\n# Sheared\naxes[1, 1].scatter(sheared_points[:, 0], sheared_points[:, 1], c='orange', s=100, alpha=0.7)\naxes[1, 1].plot([0, 0], [0, 2], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].plot([0, 3], [0, 0], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].set_title('Sheared')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].set_xlim(-1, 4)\naxes[1, 1].set_ylim(-1, 2)\naxes[1, 1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Transformation matrices applied and visualized!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (transformation_matrix @ points.T).T\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Applying Transformation Matrices\")\nprint(\"=\" * 60)\n\n# Transformation matrices represent linear transformations\n# Examples: rotation, scaling, reflection, shearing\n\ndef apply_transformation(points, transformation_matrix):\n \n    \n    \"\"\"Apply transformation matrix to points\"\"\"\n return (transformation_matrix @ points.T).T\n\n# Example: 2D points\npoints = np.array([[1, 0],\n [0, 1],\n [1, 1],\n [2, 1]])\n\nprint(\"\\nOriginal points:\")\nprint(points)\n\n# Rotation matrix (90 degrees counterclockwise)\nrotation_90 = np.array([[0, -1],\n [1, 0]])\n\nrotated_points = apply_transformation(points, rotation_90)\nprint(\"\\nRotated 90\u00b0 counterclockwise:\")\nprint(rotated_points)\n\n# Scaling matrix\nscaling = np.array([[2, 0],\n [0, 3]])\n\nscaled_points = apply_transformation(points, scaling)\nprint(\"\\nScaled (x*2, y*3):\")\nprint(scaled_points)\n\n# Shear transformation\nshear = np.array([[1, 0.5],\n [0, 1]])\n\nsheared_points = apply_transformation(points, shear)\nprint(\"\\nSheared:\")\nprint(sheared_points)\n\n# Visualize transformations\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n# Original\naxes[0, 0].scatter(points[:, 0], points[:, 1], c='blue', s=100, alpha=0.7)\naxes[0, 0].plot([0, 0], [0, 2], 'b--', alpha=0.3)\naxes[0, 0].plot([0, 2], [0, 0], 'b--', alpha=0.3)\naxes[0, 0].set_title('Original Points')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(-2, 3)\naxes[0, 0].set_ylim(-2, 3)\naxes[0, 0].axis('equal')\n\n# Rotated\naxes[0, 1].scatter(rotated_points[:, 0], rotated_points[:, 1], c='red', s=100, alpha=0.7)\naxes[0, 1].plot([0, 0], [-2, 2], 'r--', alpha=0.3)\naxes[0, 1].plot([-2, 2], [0, 0], 'r--', alpha=0.3)\naxes[0, 1].set_title('Rotated 90\u00b0')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(-2, 3)\naxes[0, 1].set_ylim(-2, 3)\naxes[0, 1].axis('equal')\n\n# Scaled\naxes[1, 0].scatter(scaled_points[:, 0], scaled_points[:, 1], c='green', s=100, alpha=0.7)\naxes[1, 0].plot([0, 0], [0, 3], 'g--', alpha=0.3)\naxes[1, 0].plot([0, 4], [0, 0], 'g--', alpha=0.3)\naxes[1, 0].set_title('Scaled (x*2, y*3)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(-1, 5)\naxes[1, 0].set_ylim(-1, 4)\naxes[1, 0].axis('equal')\n\n# Sheared\naxes[1, 1].scatter(sheared_points[:, 0], sheared_points[:, 1], c='orange', s=100, alpha=0.7)\naxes[1, 1].plot([0, 0], [0, 2], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].plot([0, 3], [0, 0], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].set_title('Sheared')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].set_xlim(-1, 4)\naxes[1, 1].set_ylim(-1, 2)\naxes[1, 1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Transformation matrices applied and visualized!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (transformation_matrix @ points.T).T\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/07_eigenvalue_analysis_large_matrices.ipynb",
      "status": "passed",
      "execution_time": 1.9803802967071533,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/08_ml_parameter_experiments.ipynb",
      "status": "passed",
      "execution_time": 1.8776512145996094,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/computing_determinants_and_inverse_matrices_computationally.ipynb",
      "status": "passed",
      "execution_time": 1.6244821548461914,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/experimenting_with_changes_in_ml_model_parameters_and_observing_changes_in_model.ipynb",
      "status": "passed",
      "execution_time": 1.67258882522583,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/implementing_substitutionelimination_techniques_for_solving_linear_equations.ipynb",
      "status": "passed",
      "execution_time": 1.5338242053985596,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/performing_vector_and_matrix_operations_using_pythonnumpy.ipynb",
      "status": "passed",
      "execution_time": 1.314621925354004,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/solving_eigenvalue_problems_programmatically_and_applying_eigenvalue_analysis_on.ipynb",
      "status": "passed",
      "execution_time": 1.2940187454223633,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/writing_code_to_apply_transformation_matrices_and_compute_orthogonal_basis_sets.ipynb",
      "status": "passed",
      "execution_time": 1.6264281272888184,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/01_derivatives_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8601982593536377,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/02_gradients_multivariable.ipynb",
      "status": "passed",
      "execution_time": 1.0083248615264893,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/03_gradient_descent.ipynb",
      "status": "passed",
      "execution_time": 0.997305154800415,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/04_backpropagation_neural_networks.ipynb",
      "status": "failed",
      "execution_time": 1.0538880825042725,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Simple Neural Network with Backpropagation\")\nprint(\"=\" * 60)\n\n# Activation functions\ndef sigmoid(x):\n    \"\"\"Sigmoid activation function\"\"\"\n    return 1\n(1 + np.exp(-np.clip(x, -500, 500)))\n\ndef sigmoid_derivative(x):\n    \"\"\"Derivative of sigmoid\"\"\"\n    s = sigmoid(x)\n    return s * (1 - s)\n\ndef relu(x):\n    \"\"\"ReLU activation function\"\"\"\n    return np.maximum(0, x)\n\ndef relu_derivative(x):\n    \"\"\"Derivative of ReLU\"\"\"\n    return (x > 0).astype(float)\n\n# Loss function\ndef mse_loss(y_pred, y_true):\n    \"\"\"Mean Squared Error loss\"\"\"\n    return np.mean((y_pred - y_true) ** 2)\n\ndef mse_loss_derivative(y_pred, y_true):\n    \"\"\"Derivative of MSE loss\"\"\"\n    return 2 * (y_pred - y_true)\nlen(y_true)\n\nprint(\"\\n\u2705 Activation and loss functions defined!\")\n------------------\n\n----- stdout -----\n============================================================\nPart 1: Simple Neural Network with Backpropagation\n============================================================\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sigmoid activation function\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mclip(x, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msigmoid_derivative\u001b[39m(x):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Derivative of sigmoid\"\"\"\u001b[39;00m\n\n\u001b[0;31mNameError\u001b[0m: name 'x' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Simple Neural Network with Backpropagation\")\nprint(\"=\" * 60)\n\n# Activation functions\ndef sigmoid(x):\n    \"\"\"Sigmoid activation function\"\"\"\n    return 1\n(1 + np.exp(-np.clip(x, -500, 500)))\n\ndef sigmoid_derivative(x):\n    \"\"\"Derivative of sigmoid\"\"\"\n    s = sigmoid(x)\n    return s * (1 - s)\n\ndef relu(x):\n    \"\"\"ReLU activation function\"\"\"\n    return np.maximum(0, x)\n\ndef relu_derivative(x):\n    \"\"\"Derivative of ReLU\"\"\"\n    return (x > 0).astype(float)\n\n# Loss function\ndef mse_loss(y_pred, y_true):\n    \"\"\"Mean Squared Error loss\"\"\"\n    return np.mean((y_pred - y_true) ** 2)\n\ndef mse_loss_derivative(y_pred, y_true):\n    \"\"\"Derivative of MSE loss\"\"\"\n    return 2 * (y_pred - y_true)\nlen(y_true)\n\nprint(\"\\n\u2705 Activation and loss functions defined!\")\n------------------\n\n----- stdout -----\n============================================================\nPart 1: Simple Neural Network with Backpropagation\n============================================================\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sigmoid activation function\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mclip(x, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msigmoid_derivative\u001b[39m(x):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Derivative of sigmoid\"\"\"\u001b[39;00m\n\n\u001b[0;31mNameError\u001b[0m: name 'x' is not defined\n\n",
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/05_function_approximation_ml.ipynb",
      "status": "failed",
      "execution_time": 1.6537489891052246,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Taylor Series Approximation\")\nprint(\"=\" * 60)\n\n# Taylor series: f(x) \u2248 f(a) + f'(a)(x-a) + f''(a)(x-a)\u00b2/2! + ...\n\ndef exp_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of exp(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # f^(n)(a) = exp(a) for all n\n result += (np.exp(a) * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\ndef sin_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of sin(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # Derivatives of sin cycle: sin, cos, -sin, -cos\n derivatives = [np.sin(a), np.cos(a), -np.sin(a), -np.cos(a)]\n result += (derivatives[n % 4] * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\n# Visualize approximations\nx = np.linspace(-2, 2, 100)\n\nplt.figure(figsize=(14, 5))\n# Exponential approximation\nplt.subplot(1, 2, 1)\nplt.plot(x, np.exp(x), 'b-', label='exp(x)', linewidth=2)\nfor n in [1, 2, 3, 5, 10]:\n y_approx = [exp_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of exp(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1, 8)\n\n# Sine approximation\nplt.subplot(1, 2, 2)\nplt.plot(x, np.sin(x), 'r-', label='sin(x)', linewidth=2)\nfor n in [1, 3, 5, 7, 9]:\n y_approx = [sin_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of sin(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1.5, 1.5)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Taylor series approximations visualized!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Taylor Series Approximation\")\nprint(\"=\" * 60)\n\n# Taylor series: f(x) \u2248 f(a) + f'(a)(x-a) + f''(a)(x-a)\u00b2/2! + ...\n\ndef exp_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of exp(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # f^(n)(a) = exp(a) for all n\n result += (np.exp(a) * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\ndef sin_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of sin(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # Derivatives of sin cycle: sin, cos, -sin, -cos\n derivatives = [np.sin(a), np.cos(a), -np.sin(a), -np.cos(a)]\n result += (derivatives[n % 4] * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\n# Visualize approximations\nx = np.linspace(-2, 2, 100)\n\nplt.figure(figsize=(14, 5))\n# Exponential approximation\nplt.subplot(1, 2, 1)\nplt.plot(x, np.exp(x), 'b-', label='exp(x)', linewidth=2)\nfor n in [1, 2, 3, 5, 10]:\n y_approx = [exp_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of exp(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1, 8)\n\n# Sine approximation\nplt.subplot(1, 2, 2)\nplt.plot(x, np.sin(x), 'r-', label='sin(x)', linewidth=2)\nfor n in [1, 3, 5, 7, 9]:\n y_approx = [sin_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of sin(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1.5, 1.5)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Taylor series approximations visualized!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/applying_function_approximation_on_real_world_ml_models.ipynb",
      "status": "passed",
      "execution_time": 1.5397839546203613,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/implementing_gradient_computations_for_multivariate_functions.ipynb",
      "status": "passed",
      "execution_time": 1.3218739032745361,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/programming_backpropagation_in_neural_networks_using_differentiation_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.3742990493774414,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/solving_differentiation_problems_using_symbolic_computation_tools.ipynb",
      "status": "passed",
      "execution_time": 1.5856778621673584,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/01_optimizers_comparison.ipynb",
      "status": "failed",
      "execution_time": 0.8041291236877441,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 2: Adam Optimizer\n# WHY: Adapts to each parameter, handles noise better\n# HOW: Tracks momentum + variance, adapts learning rate\n\nclass AdamOptimizer:\n    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1  # Momentum decay\n        self.beta2 = beta2  # Learning rate decay\n        self.m = 0  # First moment (mean of gradients)\n        self.v = 0  # Second moment (variance of gradients)\n        self.t = 0  # Time step\n    \n    def update(self, params, grads):\n        self.t += 1\n        self.m = self.beta1 * self.m + (1 - self.beta1) * grads  # Momentum\n        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2  # Variance\n        m_hat = self.m\n(1 - self.beta1**self.t)  # Bias correction\n        v_hat = self.v\n(1 - self.beta2**self.t)  # Bias correction\n        return params - self.lr * m_hat\n(np.sqrt(v_hat) + 1e-8)  # Adaptive step\n\n# Adam optimizer\nadam = AdamOptimizer(lr=0.1)\nx_adam = 0.0\nadam_path = [x_adam]\nadam_loss = [loss_function(x_adam)]\n\nfor i in range(30):\n    grad = loss_gradient(x_adam)\n    x_adam = adam.update(x_adam, grad)\n    adam_path.append(x_adam)\n    adam_loss.append(loss_function(x_adam))\n\nprint(\"\\nExample 2: Adam Optimizer\")\nprint(\"=\" * 60)\nprint(f\"Starting at x = 0.0\")\nprint(f\"After 30 iterations: x = {x_adam:.4f}, loss = {adam_loss[-1]:.4f}\")\nprint(f\"\\n\ud83d\udca1 WHY: Adapts to each parameter, handles noise better\")\nprint(f\"\ud83d\udca1 HOW: Tracks momentum + variance, adapts learning rate\")\nprint(f\"\ud83d\udca1 AFTER: Faster convergence, more stable!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 2: Adam Optimizer\n# WHY: Adapts to each parameter, handles noise better\n# HOW: Tracks momentum + variance, adapts learning rate\n\nclass AdamOptimizer:\n    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1  # Momentum decay\n        self.beta2 = beta2  # Learning rate decay\n        self.m = 0  # First moment (mean of gradients)\n        self.v = 0  # Second moment (variance of gradients)\n        self.t = 0  # Time step\n    \n    def update(self, params, grads):\n        self.t += 1\n        self.m = self.beta1 * self.m + (1 - self.beta1) * grads  # Momentum\n        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2  # Variance\n        m_hat = self.m\n(1 - self.beta1**self.t)  # Bias correction\n        v_hat = self.v\n(1 - self.beta2**self.t)  # Bias correction\n        return params - self.lr * m_hat\n(np.sqrt(v_hat) + 1e-8)  # Adaptive step\n\n# Adam optimizer\nadam = AdamOptimizer(lr=0.1)\nx_adam = 0.0\nadam_path = [x_adam]\nadam_loss = [loss_function(x_adam)]\n\nfor i in range(30):\n    grad = loss_gradient(x_adam)\n    x_adam = adam.update(x_adam, grad)\n    adam_path.append(x_adam)\n    adam_loss.append(loss_function(x_adam))\n\nprint(\"\\nExample 2: Adam Optimizer\")\nprint(\"=\" * 60)\nprint(f\"Starting at x = 0.0\")\nprint(f\"After 30 iterations: x = {x_adam:.4f}, loss = {adam_loss[-1]:.4f}\")\nprint(f\"\\n\ud83d\udca1 WHY: Adapts to each parameter, handles noise better\")\nprint(f\"\ud83d\udca1 HOW: Tracks momentum + variance, adapts learning rate\")\nprint(f\"\ud83d\udca1 AFTER: Faster convergence, more stable!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.1, beta1=0.9, beta2=0.999):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/02_loss_functions.ipynb",
      "status": "passed",
      "execution_time": 0.9628782272338867,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/03_statistical_measures.ipynb",
      "status": "failed",
      "execution_time": 0.8915920257568359,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 1: Statistical Measures\n# WHY: Need objective way to evaluate models\n# HOW: Compute error metrics\n\ndef calculate_statistics(predictions, targets):\n    \"\"\"Calculate statistical measures\"\"\"\n    errors = predictions - targets\n    mse = np.mean(errors**2)\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(errors))\n    r2 = 1 - np.sum(errors**2)\nnp.sum((targets - np.mean(targets))**2)\n    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\n\npredictions = np.array([2.1, 3.2, 4.0, 5.1])\ntargets = np.array([2.0, 3.0, 4.0, 5.0])\nstats = calculate_statistics(predictions, targets)\n\nprint(\"Example 1: Statistical Measures\")\nprint(\"=\" * 60)\nprint(f\"Predictions: {predictions}\")\nprint(f\"Targets:    {targets}\")\nprint(f\"\\nStatistical Measures:\")\nfor metric, value in stats.items():\n    print(f\"  - {metric}: {value:.4f}\")\n    if metric == 'R\u00b2':\n        print(f\"    \ud83d\udca1 WHY: Shows how much variance is explained\")\n        print(f\"    \ud83d\udca1 HOW: 1 - (error_variance\ntotal_variance)\")\n        print(f\"    \ud83d\udca1 AFTER: {value:.1%} of variance explained!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 1: Statistical Measures\n# WHY: Need objective way to evaluate models\n# HOW: Compute error metrics\n\ndef calculate_statistics(predictions, targets):\n    \"\"\"Calculate statistical measures\"\"\"\n    errors = predictions - targets\n    mse = np.mean(errors**2)\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(errors))\n    r2 = 1 - np.sum(errors**2)\nnp.sum((targets - np.mean(targets))**2)\n    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\n\npredictions = np.array([2.1, 3.2, 4.0, 5.1])\ntargets = np.array([2.0, 3.0, 4.0, 5.0])\nstats = calculate_statistics(predictions, targets)\n\nprint(\"Example 1: Statistical Measures\")\nprint(\"=\" * 60)\nprint(f\"Predictions: {predictions}\")\nprint(f\"Targets:    {targets}\")\nprint(f\"\\nStatistical Measures:\")\nfor metric, value in stats.items():\n    print(f\"  - {metric}: {value:.4f}\")\n    if metric == 'R\u00b2':\n        print(f\"    \ud83d\udca1 WHY: Shows how much variance is explained\")\n        print(f\"    \ud83d\udca1 HOW: 1 - (error_variance\ntotal_variance)\")\n        print(f\"    \ud83d\udca1 AFTER: {value:.1%} of variance explained!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R\u00b2': r2}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/04_regression_real_datasets.ipynb",
      "status": "failed",
      "execution_time": 0.6062288284301758,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing \nimport StandardScaler, PolynomialFeatures\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.datasets \nimport load_boston, fetch_california_housing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Regression Techniques to Real Datasets\")\nprint(\"=\" * 60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing \nimport StandardScaler, PolynomialFeatures\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.datasets \nimport load_boston, fetch_california_housing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Regression Techniques to Real Datasets\")\nprint(\"=\" * 60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/05_image_similarity_measures.ipynb",
      "status": "failed",
      "execution_time": 1.8508670330047607,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: Computing Angles and Distances Between Images\")\nprint(\"=\" * 60)\n\n# Select a few images for comparison\nimg1_idx = 0\nimg2_idx = 1\nimg3_idx = 100\n\nimg1_vec = image_vectors[img1_idx]\nimg2_vec = image_vectors[img2_idx]\nimg3_vec = image_vectors[img3_idx]\n\nprint(f\"\\nComparing images:\")\nprint(f\"  Image 1: Digit {labels[img1_idx]}\")\nprint(f\"  Image 2: Digit {labels[img2_idx]}\")\nprint(f\"  Image 3: Digit {labels[img3_idx]}\")\n\n# Euclidean distance (L2 norm)\ndef euclidean_distance(v1, v2):\n    \"\"\"Compute Euclidean distance between two vectors\"\"\"\n    return np.linalg.norm(v1 - v2)\n\n# Cosine similarity (inner product of normalized vectors)\ndef cosine_similarity(v1, v2):\n    \"\"\"Compute cosine similarity between two vectors\"\"\"\n    dot_product = np.dot(v1, v2)\n    norm1 = np.linalg.norm(v1)\n    norm2 = np.linalg.norm(v2)\n    if norm1 == 0 or norm2 == 0:\n        return 0\n    return dot_product\n(norm1 * norm2)\n\n# Angle between vectors (in radians and degrees)\ndef angle_between_vectors(v1, v2):\n    \"\"\"Compute angle between two vectors\"\"\"\n    cos_sim = cosine_similarity(v1, v2)\n    # Clamp to avoid numerical errors\n    cos_sim = np.clip(cos_sim, -1.0, 1.0)\n    angle_rad = np.arccos(cos_sim)\n    angle_deg = np.degrees(angle_rad)\n    return angle_rad, angle_deg\n\n# Compute distances and angles\ndist_12 = euclidean_distance(img1_vec, img2_vec)\ndist_13 = euclidean_distance(img1_vec, img3_vec)\nsim_12 = cosine_similarity(img1_vec, img2_vec)\nsim_13 = cosine_similarity(img1_vec, img3_vec)\nangle_12_rad, angle_12_deg = angle_between_vectors(img1_vec, img2_vec)\nangle_13_rad, angle_13_deg = angle_between_vectors(img1_vec, img3_vec)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Comparison Results:\")\nprint(\"=\" * 60)\nprint(f\"\\nImage 1 vs Image 2 (Digits {labels[img1_idx]} vs {labels[img2_idx]}):\")\nprint(f\"  Euclidean distance: {dist_12:.4f}\")\nprint(f\"  Cosine similarity: {sim_12:.4f}\")\nprint(f\"  Angle: {angle_12_deg:.2f}\u00b0 ({angle_12_rad:.4f} radians)\")\n\nprint(f\"\\nImage 1 vs Image 3 (Digits {labels[img1_idx]} vs {labels[img3_idx]}):\")\nprint(f\"  Euclidean distance: {dist_13:.4f}\")\nprint(f\"  Cosine similarity: {sim_13:.4f}\")\nprint(f\"  Angle: {angle_13_deg:.2f}\u00b0 ({angle_13_rad:.4f} radians)\")\n\n# Visualize comparisons\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\naxes[0].imshow(images[img1_idx], cmap='gray')\naxes[0].set_title(f'Image 1\\nDigit {labels[img1_idx]}')\naxes[0].axis('off')\naxes[1].imshow(images[img2_idx], cmap='gray')\naxes[1].set_title(f'Image 2\\nDigit {labels[img2_idx]}\\nDist: {dist_12:.2f}, Angle: {angle_12_deg:.1f}\u00b0')\naxes[1].axis('off')\naxes[2].imshow(images[img3_idx], cmap='gray')\naxes[2].set_title(f'Image 3\\nDigit {labels[img3_idx]}\\nDist: {dist_13:.2f}, Angle: {angle_13_deg:.1f}\u00b0')\naxes[2].axis('off')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Angles and distances computed!\")\n------------------\n\n----- stdout -----\n\n============================================================\nPart 2: Computing Angles and Distances Between Images\n============================================================\n\nComparing images:\n  Image 1: Digit 0\n  Image 2: Digit 1\n  Image 3: Digit 4\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dot_product\n\u001b[0;32m---> 33\u001b[0m (norm1 \u001b[38;5;241m*\u001b[39m norm2)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Angle between vectors (in radians and degrees)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mangle_between_vectors\u001b[39m(v1, v2):\n\n\u001b[0;31mNameError\u001b[0m: name 'norm1' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: Computing Angles and Distances Between Images\")\nprint(\"=\" * 60)\n\n# Select a few images for comparison\nimg1_idx = 0\nimg2_idx = 1\nimg3_idx = 100\n\nimg1_vec = image_vectors[img1_idx]\nimg2_vec = image_vectors[img2_idx]\nimg3_vec = image_vectors[img3_idx]\n\nprint(f\"\\nComparing images:\")\nprint(f\"  Image 1: Digit {labels[img1_idx]}\")\nprint(f\"  Image 2: Digit {labels[img2_idx]}\")\nprint(f\"  Image 3: Digit {labels[img3_idx]}\")\n\n# Euclidean distance (L2 norm)\ndef euclidean_distance(v1, v2):\n    \"\"\"Compute Euclidean distance between two vectors\"\"\"\n    return np.linalg.norm(v1 - v2)\n\n# Cosine similarity (inner product of normalized vectors)\ndef cosine_similarity(v1, v2):\n    \"\"\"Compute cosine similarity between two vectors\"\"\"\n    dot_product = np.dot(v1, v2)\n    norm1 = np.linalg.norm(v1)\n    norm2 = np.linalg.norm(v2)\n    if norm1 == 0 or norm2 == 0:\n        return 0\n    return dot_product\n(norm1 * norm2)\n\n# Angle between vectors (in radians and degrees)\ndef angle_between_vectors(v1, v2):\n    \"\"\"Compute angle between two vectors\"\"\"\n    cos_sim = cosine_similarity(v1, v2)\n    # Clamp to avoid numerical errors\n    cos_sim = np.clip(cos_sim, -1.0, 1.0)\n    angle_rad = np.arccos(cos_sim)\n    angle_deg = np.degrees(angle_rad)\n    return angle_rad, angle_deg\n\n# Compute distances and angles\ndist_12 = euclidean_distance(img1_vec, img2_vec)\ndist_13 = euclidean_distance(img1_vec, img3_vec)\nsim_12 = cosine_similarity(img1_vec, img2_vec)\nsim_13 = cosine_similarity(img1_vec, img3_vec)\nangle_12_rad, angle_12_deg = angle_between_vectors(img1_vec, img2_vec)\nangle_13_rad, angle_13_deg = angle_between_vectors(img1_vec, img3_vec)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Comparison Results:\")\nprint(\"=\" * 60)\nprint(f\"\\nImage 1 vs Image 2 (Digits {labels[img1_idx]} vs {labels[img2_idx]}):\")\nprint(f\"  Euclidean distance: {dist_12:.4f}\")\nprint(f\"  Cosine similarity: {sim_12:.4f}\")\nprint(f\"  Angle: {angle_12_deg:.2f}\u00b0 ({angle_12_rad:.4f} radians)\")\n\nprint(f\"\\nImage 1 vs Image 3 (Digits {labels[img1_idx]} vs {labels[img3_idx]}):\")\nprint(f\"  Euclidean distance: {dist_13:.4f}\")\nprint(f\"  Cosine similarity: {sim_13:.4f}\")\nprint(f\"  Angle: {angle_13_deg:.2f}\u00b0 ({angle_13_rad:.4f} radians)\")\n\n# Visualize comparisons\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\naxes[0].imshow(images[img1_idx], cmap='gray')\naxes[0].set_title(f'Image 1\\nDigit {labels[img1_idx]}')\naxes[0].axis('off')\naxes[1].imshow(images[img2_idx], cmap='gray')\naxes[1].set_title(f'Image 2\\nDigit {labels[img2_idx]}\\nDist: {dist_12:.2f}, Angle: {angle_12_deg:.1f}\u00b0')\naxes[1].axis('off')\naxes[2].imshow(images[img3_idx], cmap='gray')\naxes[2].set_title(f'Image 3\\nDigit {labels[img3_idx]}\\nDist: {dist_13:.2f}, Angle: {angle_13_deg:.1f}\u00b0')\naxes[2].axis('off')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Angles and distances computed!\")\n------------------\n\n----- stdout -----\n\n============================================================\nPart 2: Computing Angles and Distances Between Images\n============================================================\n\nComparing images:\n  Image 1: Digit 0\n  Image 2: Digit 1\n  Image 3: Digit 4\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dot_product\n\u001b[0;32m---> 33\u001b[0m (norm1 \u001b[38;5;241m*\u001b[39m norm2)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Angle between vectors (in radians and degrees)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mangle_between_vectors\u001b[39m(v1, v2):\n\n\u001b[0;31mNameError\u001b[0m: name 'norm1' is not defined\n\n",
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/applying_regression_techniques_to_fit_models_on_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.4822289943695068,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/implementing_gradient_descent_for_optimization_problems.ipynb",
      "status": "passed",
      "execution_time": 1.4565577507019043,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/implementing_projection_and_dimensionality_reduction_techniques_in_ml.ipynb",
      "status": "passed",
      "execution_time": 1.7198100090026855,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/representing_images_as_vectors_and_computing_angles_and_distances_between_them.ipynb",
      "status": "passed",
      "execution_time": 1.5602190494537354,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/writing_code_to_compute_basic_statistical_properties_of_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.6109068393707275,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/01_pca_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.7424108982086182,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/02_curse_dimensionality.ipynb",
      "status": "failed",
      "execution_time": 0.7776052951812744,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example 1: Curse of Dimensionality\n# WHY: High dimensions cause problems\n# HOW: Volume increases exponentially\n\ndef volume_ratio(dimensions):\n    \"\"\"Volume ratio in unit hypercube\"\"\"\n    # Volume of small cube\nVolume of unit cube\n    edge = 0.1\n    return edge ** dimensions\n\ndims = [1, 2, 5, 10, 20, 50]\nvolumes = [volume_ratio(d) for d in dims]\n\nprint(\"Example 1: Curse of Dimensionality\")\nprint(\"=\" * 60)\nprint(\"Volume ratio (0.1 edge cube\nunit cube) by dimension:\")\nfor d, v in zip(dims, volumes):\n    print(f\"  {d}D: {v:.2e}\")\nprint(f\"\\n\ud83d\udca1 WHY: Volume becomes tiny in high dimensions\")\nprint(f\"\ud83d\udca1 HOW: Volume = edge^dimensions (exponential decrease)\")\nprint(f\"\ud83d\udca1 AFTER: Data becomes extremely sparse!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Volume ratio (0.1 edge cube\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 17)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example 1: Curse of Dimensionality\n# WHY: High dimensions cause problems\n# HOW: Volume increases exponentially\n\ndef volume_ratio(dimensions):\n    \"\"\"Volume ratio in unit hypercube\"\"\"\n    # Volume of small cube\nVolume of unit cube\n    edge = 0.1\n    return edge ** dimensions\n\ndims = [1, 2, 5, 10, 20, 50]\nvolumes = [volume_ratio(d) for d in dims]\n\nprint(\"Example 1: Curse of Dimensionality\")\nprint(\"=\" * 60)\nprint(\"Volume ratio (0.1 edge cube\nunit cube) by dimension:\")\nfor d, v in zip(dims, volumes):\n    print(f\"  {d}D: {v:.2e}\")\nprint(f\"\\n\ud83d\udca1 WHY: Volume becomes tiny in high dimensions\")\nprint(f\"\ud83d\udca1 HOW: Volume = edge^dimensions (exponential decrease)\")\nprint(f\"\ud83d\udca1 AFTER: Data becomes extremely sparse!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Volume ratio (0.1 edge cube\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 17)\n\n\n",
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/03_feature_selection.ipynb",
      "status": "passed",
      "execution_time": 0.9532883167266846,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/04_svd_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.7157561779022217,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/05_tsne_visualization.ipynb",
      "status": "passed",
      "execution_time": 2.461361885070801,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/06_dimensionality_reduction_real_world_datasets.ipynb",
      "status": "passed",
      "execution_time": 3.2315542697906494,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/implementing_pca_using_python_for_dimensionality_reduction_of_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.6308057308197021,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/writing_code_to_apply_these_dimensionality_reduction_techniques_on_real_world_da.ipynb",
      "status": "passed",
      "execution_time": 1.8398540019989014,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/01_probability_distributions.ipynb",
      "status": "passed",
      "execution_time": 0.7640509605407715,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/02_statistical_inference.ipynb",
      "status": "passed",
      "execution_time": 0.7179019451141357,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/03_bayesian_inference.ipynb",
      "status": "passed",
      "execution_time": 1.375570297241211,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/04_central_limit_theorem_simulations.ipynb",
      "status": "passed",
      "execution_time": 2.1697568893432617,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/05_sampling_point_estimation.ipynb",
      "status": "passed",
      "execution_time": 1.8913652896881104,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/06_maximum_likelihood_estimation.ipynb",
      "status": "failed",
      "execution_time": 1.3562779426574707,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: MLE for Gaussian Distribution\")\nprint(\"=\" * 60)\n\n# Generate data from Gaussian distribution\nnp.random.seed(42)\ntrue_mu = 5.0\ntrue_sigma = 2.0\ndata = np.random.normal(true_mu, true_sigma, 100)\n\nprint(f\"\\nTrue parameters:\")\nprint(f\" \u03bc (mean): {true_mu}\")\nprint(f\" \u03c3 (std): {true_sigma}\")\nprint(f\" Sample size: {len(data)}\")\n\n# MLE for Gaussian: sample mean and sample std\nmle_mu = np.mean(data)\nmle_sigma = np.std(data, ddof=0) # MLE uses N, not N-1\n\nprint(f\"\\nMLE estimates:\")\nprint(f\" \u03bc_MLE (sample mean): {mle_mu:.4f}\")\nprint(f\" \u03c3_MLE (sample std): {mle_sigma:.4f}\")\n\n# Negative log-likelihood function (we minimize this)\ndef neg_log_likelihood_gaussian(params, data):\n \n    \n    \n    \"\"\"Negative log-likelihood for Gaussian distribution\"\"\"\n mu, sigma = paramsif sigma <= 0:\n return np.inf\n n = len(data)\n log_likelihood = -n * np.log(sigma * np.sqrt(2 * np.pi)) - np.sum((data - mu)**2)\n(2 * sigma**2)\n return -log_likelihood # Return negative for minimization\n\n# Optimize using scipy\nresult = minimize(lambda p: neg_log_likelihood_gaussian(p, data), \n x0=[mle_mu, mle_sigma], \n method='BFGS')\nmle_mu_opt = result.x[0]\nmle_sigma_opt = result.x[1]\n\nprint(f\"\\nMLE from optimization:\")\nprint(f\" \u03bc_MLE: {mle_mu_opt:.4f}\")\nprint(f\" \u03c3_MLE: {mle_sigma_opt:.4f}\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(data, bins=20, density=True, alpha=0.7, color='blue', label='Data')\nx = np.linspace(data.min(), data.max(), 100)\nplt.plot(x, stats.norm.pdf(x, true_mu, true_sigma), 'r-', linewidth=2, label=f'True (\u03bc={true_mu}, \u03c3={true_sigma})')\nplt.plot(x, stats.norm.pdf(x, mle_mu, mle_sigma), 'g--', linewidth=2, label=f'MLE (\u03bc={mle_mu:.2f}, \u03c3={mle_sigma:.2f})')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Gaussian Distribution MLE')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nmu_range = np.linspace(3, 7, 100)\nlog_likelihoods = [-neg_log_likelihood_gaussian([mu, mle_sigma], data) for mu in mu_range]\nplt.plot(mu_range, log_likelihoods, 'b-', linewidth=2)\nplt.axvline(true_mu, color='r', linestyle='--', label=f'True \u03bc={true_mu}')\nplt.axvline(mle_mu, color='g', linestyle='--', label=f'MLE \u03bc={mle_mu:.2f}')\nplt.xlabel('\u03bc (mean)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 MLE for Gaussian distribution implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:30\u001b[0;36m\u001b[0m\n\u001b[0;31m    mu, sigma = paramsif sigma <= 0:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: MLE for Gaussian Distribution\")\nprint(\"=\" * 60)\n\n# Generate data from Gaussian distribution\nnp.random.seed(42)\ntrue_mu = 5.0\ntrue_sigma = 2.0\ndata = np.random.normal(true_mu, true_sigma, 100)\n\nprint(f\"\\nTrue parameters:\")\nprint(f\" \u03bc (mean): {true_mu}\")\nprint(f\" \u03c3 (std): {true_sigma}\")\nprint(f\" Sample size: {len(data)}\")\n\n# MLE for Gaussian: sample mean and sample std\nmle_mu = np.mean(data)\nmle_sigma = np.std(data, ddof=0) # MLE uses N, not N-1\n\nprint(f\"\\nMLE estimates:\")\nprint(f\" \u03bc_MLE (sample mean): {mle_mu:.4f}\")\nprint(f\" \u03c3_MLE (sample std): {mle_sigma:.4f}\")\n\n# Negative log-likelihood function (we minimize this)\ndef neg_log_likelihood_gaussian(params, data):\n \n    \n    \n    \"\"\"Negative log-likelihood for Gaussian distribution\"\"\"\n mu, sigma = paramsif sigma <= 0:\n return np.inf\n n = len(data)\n log_likelihood = -n * np.log(sigma * np.sqrt(2 * np.pi)) - np.sum((data - mu)**2)\n(2 * sigma**2)\n return -log_likelihood # Return negative for minimization\n\n# Optimize using scipy\nresult = minimize(lambda p: neg_log_likelihood_gaussian(p, data), \n x0=[mle_mu, mle_sigma], \n method='BFGS')\nmle_mu_opt = result.x[0]\nmle_sigma_opt = result.x[1]\n\nprint(f\"\\nMLE from optimization:\")\nprint(f\" \u03bc_MLE: {mle_mu_opt:.4f}\")\nprint(f\" \u03c3_MLE: {mle_sigma_opt:.4f}\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(data, bins=20, density=True, alpha=0.7, color='blue', label='Data')\nx = np.linspace(data.min(), data.max(), 100)\nplt.plot(x, stats.norm.pdf(x, true_mu, true_sigma), 'r-', linewidth=2, label=f'True (\u03bc={true_mu}, \u03c3={true_sigma})')\nplt.plot(x, stats.norm.pdf(x, mle_mu, mle_sigma), 'g--', linewidth=2, label=f'MLE (\u03bc={mle_mu:.2f}, \u03c3={mle_sigma:.2f})')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Gaussian Distribution MLE')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nmu_range = np.linspace(3, 7, 100)\nlog_likelihoods = [-neg_log_likelihood_gaussian([mu, mle_sigma], data) for mu in mu_range]\nplt.plot(mu_range, log_likelihoods, 'b-', linewidth=2)\nplt.axvline(true_mu, color='r', linestyle='--', label=f'True \u03bc={true_mu}')\nplt.axvline(mle_mu, color='g', linestyle='--', label=f'MLE \u03bc={mle_mu:.2f}')\nplt.xlabel('\u03bc (mean)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 MLE for Gaussian distribution implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:30\u001b[0;36m\u001b[0m\n\u001b[0;31m    mu, sigma = paramsif sigma <= 0:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/07_hypothesis_testing_procedures.ipynb",
      "status": "passed",
      "execution_time": 1.3995110988616943,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/08_pvalues_confidence_intervals.ipynb",
      "status": "failed",
      "execution_time": 1.261012077331543,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Computing P-values\")\nprint(\"=\" * 60)\n\n# Generate sample data\nnp.random.seed(42)\ntrue_mean = 50\nsample_size = 30\nsample = np.random.normal(true_mean, 10, sample_size)\nsample_mean = np.mean(sample)\nsample_std = np.std(sample, ddof=1)\n\nprint(f\"\\nSample statistics:\")\nprint(f\"  Sample mean: {sample_mean:.4f}\")\nprint(f\"  Sample std: {sample_std:.4f}\")\nprint(f\"  Sample size: {sample_size}\")\n\n# Test H0: \u03bc = 50\nhypothesized_mean = 50\nt_statistic = (sample_mean - hypothesized_mean)\n(sample_std\nnp.sqrt(sample_size))\ndf = sample_size - 1\n\n# Compute p-value (two-tailed)\np_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df))\n\nprint(f\"\\nHypothesis Test: H0: \u03bc = {hypothesized_mean}\")\nprint(f\"  t-statistic: {t_statistic:.4f}\")\nprint(f\"  p-value: {p_value:.6f}\")\n\n# Compare with scipy function\nt_stat_scipy, p_value_scipy = stats.ttest_1samp(sample, hypothesized_mean)\nprint(f\"\\nVerification (scipy.stats.ttest_1samp):\")\nprint(f\"  t-statistic: {t_stat_scipy:.4f}\")\nprint(f\"  p-value: {p_value_scipy:.6f}\")\n\n# Visualize p-value\nplt.figure(figsize=(10, 6))\nx = np.linspace(-4, 4, 100)\nt_dist = stats.t.pdf(x, df)\nplt.plot(x, t_dist, 'b-', linewidth=2, label=f't-distribution (df={df})')\nplt.axvline(t_statistic, color='r', linestyle='--', linewidth=2, label=f't-statistic={t_statistic:.2f}')\nplt.axvline(-t_statistic, color='r', linestyle='--', linewidth=2)\nplt.fill_between(x, 0, t_dist, where=(x <= -abs(t_statistic)) | (x >= abs(t_statistic)), alpha=0.3, color='red', label=f'p-value region (p={p_value:.4f})')\nplt.xlabel('t-value')\nplt.ylabel('Density')\nplt.title('P-value Visualization (Two-Tailed Test)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(\"\\n\u2705 P-value computed and visualized!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    (sample_std\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Computing P-values\")\nprint(\"=\" * 60)\n\n# Generate sample data\nnp.random.seed(42)\ntrue_mean = 50\nsample_size = 30\nsample = np.random.normal(true_mean, 10, sample_size)\nsample_mean = np.mean(sample)\nsample_std = np.std(sample, ddof=1)\n\nprint(f\"\\nSample statistics:\")\nprint(f\"  Sample mean: {sample_mean:.4f}\")\nprint(f\"  Sample std: {sample_std:.4f}\")\nprint(f\"  Sample size: {sample_size}\")\n\n# Test H0: \u03bc = 50\nhypothesized_mean = 50\nt_statistic = (sample_mean - hypothesized_mean)\n(sample_std\nnp.sqrt(sample_size))\ndf = sample_size - 1\n\n# Compute p-value (two-tailed)\np_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df))\n\nprint(f\"\\nHypothesis Test: H0: \u03bc = {hypothesized_mean}\")\nprint(f\"  t-statistic: {t_statistic:.4f}\")\nprint(f\"  p-value: {p_value:.6f}\")\n\n# Compare with scipy function\nt_stat_scipy, p_value_scipy = stats.ttest_1samp(sample, hypothesized_mean)\nprint(f\"\\nVerification (scipy.stats.ttest_1samp):\")\nprint(f\"  t-statistic: {t_stat_scipy:.4f}\")\nprint(f\"  p-value: {p_value_scipy:.6f}\")\n\n# Visualize p-value\nplt.figure(figsize=(10, 6))\nx = np.linspace(-4, 4, 100)\nt_dist = stats.t.pdf(x, df)\nplt.plot(x, t_dist, 'b-', linewidth=2, label=f't-distribution (df={df})')\nplt.axvline(t_statistic, color='r', linestyle='--', linewidth=2, label=f't-statistic={t_statistic:.2f}')\nplt.axvline(-t_statistic, color='r', linestyle='--', linewidth=2)\nplt.fill_between(x, 0, t_dist, where=(x <= -abs(t_statistic)) | (x >= abs(t_statistic)), alpha=0.3, color='red', label=f'p-value region (p={p_value:.4f})')\nplt.xlabel('t-value')\nplt.ylabel('Density')\nplt.title('P-value Visualization (Two-Tailed Test)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(\"\\n\u2705 P-value computed and visualized!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    (sample_std\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/09_probability_ml_connections.ipynb",
      "status": "passed",
      "execution_time": 1.9021048545837402,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/applying_central_limit_theorem_with_simulations.ipynb",
      "status": "passed",
      "execution_time": 1.6043968200683594,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/computing_p_values_and_confidence_intervals.ipynb",
      "status": "passed",
      "execution_time": 1.7454731464385986,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/connecting_probability_theory_to_ml_model_implementations.ipynb",
      "status": "passed",
      "execution_time": 1.650644063949585,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/implementing_hypothesis_testing_procedures.ipynb",
      "status": "passed",
      "execution_time": 1.5440070629119873,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/implementing_maximum_likelihood_estimation_mle_for_different_distributions.ipynb",
      "status": "passed",
      "execution_time": 1.6210408210754395,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/performing_sampling_and_point_estimation.ipynb",
      "status": "passed",
      "execution_time": 1.7370610237121582,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/01_data_loading_exploration.ipynb",
      "status": "passed",
      "execution_time": 1.5247910022735596,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/02_data_cleaning.ipynb",
      "status": "failed",
      "execution_time": 2.327995777130127,
      "error": "An error occurred while executing the following cell:\n------------------\n# First, let's see how many missing values we have\nprint(\"\\n\" + \"=\" * 60)\nprint(\"2. Handling Missing Values\")\nprint(\"\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629\")\nprint(\"=\" * 60)\n\n# Note: df has been modified (duplicates added in Cell 6, outlier added in Cell 7)\n# This shows missing values in the current state of the data\nprint(\"\\n\ud83d\udd0d Missing values in current data:\")\nprint(\"\u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629 \u0641\u064a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062d\u0627\u0644\u064a\u0629:\")\n\n# df.isnull().sum()\n# - df.isnull(): Returns DataFrame with True/False (True = missing value, False = not missing)\n# - .sum(): Sums True values (counts missing values) for each column\n# - Returns Series with column names and count of missing values\n# - Alternative: df.isna() does the same thing\nmissing_before = df.isnull().sum()\nprint(missing_before)\n\n# missing_before.sum()\n# - .sum() on Series: Adds up all values in the Series\n# - This gives total missing values across all columns\nprint(f\"\\n   Total missing values: {missing_before.sum()}\")\n\n# df.shape[0] * df.shape[1]\n# - df.shape[0]: Number of rows\n# - df.shape[1]: Number of columns\n# - shape[0] * shape[1]: Total number of cells in DataFrame\n# - Used to calculate percentage of missing values\nprint(f\"   Percentage missing: {(missing_before.sum()\n(df.shape[0] * df.shape[1]) * 100):.1f}%\")\n\n------------------\n\n----- stdout -----\n\n============================================================\n2. Handling Missing Values\n\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629\n============================================================\n\n\ud83d\udd0d Missing values in current data:\n\u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629 \u0641\u064a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062d\u0627\u0644\u064a\u0629:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          688\nEmbarked         2\ndtype: int64\n\n   Total missing values: 867\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Total missing values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_before\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# df.shape[0] * df.shape[1]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# - df.shape[0]: Number of rows\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# - df.shape[1]: Number of columns\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# - shape[0] * shape[1]: Total number of cells in DataFrame\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# - Used to calculate percentage of missing values\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Percentage missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(missing_before\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     31\u001b[0m (df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# First, let's see how many missing values we have\nprint(\"\\n\" + \"=\" * 60)\nprint(\"2. Handling Missing Values\")\nprint(\"\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629\")\nprint(\"=\" * 60)\n\n# Note: df has been modified (duplicates added in Cell 6, outlier added in Cell 7)\n# This shows missing values in the current state of the data\nprint(\"\\n\ud83d\udd0d Missing values in current data:\")\nprint(\"\u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629 \u0641\u064a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062d\u0627\u0644\u064a\u0629:\")\n\n# df.isnull().sum()\n# - df.isnull(): Returns DataFrame with True/False (True = missing value, False = not missing)\n# - .sum(): Sums True values (counts missing values) for each column\n# - Returns Series with column names and count of missing values\n# - Alternative: df.isna() does the same thing\nmissing_before = df.isnull().sum()\nprint(missing_before)\n\n# missing_before.sum()\n# - .sum() on Series: Adds up all values in the Series\n# - This gives total missing values across all columns\nprint(f\"\\n   Total missing values: {missing_before.sum()}\")\n\n# df.shape[0] * df.shape[1]\n# - df.shape[0]: Number of rows\n# - df.shape[1]: Number of columns\n# - shape[0] * shape[1]: Total number of cells in DataFrame\n# - Used to calculate percentage of missing values\nprint(f\"   Percentage missing: {(missing_before.sum()\n(df.shape[0] * df.shape[1]) * 100):.1f}%\")\n\n------------------\n\n----- stdout -----\n\n============================================================\n2. Handling Missing Values\n\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629\n============================================================\n\n\ud83d\udd0d Missing values in current data:\n\u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0641\u0642\u0648\u062f\u0629 \u0641\u064a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062d\u0627\u0644\u064a\u0629:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          688\nEmbarked         2\ndtype: int64\n\n   Total missing values: 867\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Total missing values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_before\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# df.shape[0] * df.shape[1]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# - df.shape[0]: Number of rows\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# - df.shape[1]: Number of columns\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# - shape[0] * shape[1]: Total number of cells in DataFrame\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# - Used to calculate percentage of missing values\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Percentage missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(missing_before\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     31\u001b[0m (df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/03_data_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 0.8894369602203369,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/04_linear_regression.ipynb",
      "status": "passed",
      "execution_time": 0.9076030254364014,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/05_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 1.573897123336792,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world US Accidents dataset for Traffic Management\n# GDI Theme: Traffic Management - Understanding how visibility affects accident impact distance\n\nprint(\"\\n\ud83d\udce5 Loading US Accidents dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u062d\u0648\u0627\u062f\u062b \u0627\u0644\u0645\u0631\u0648\u0631 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\nprint(\" GDI Theme: Traffic Management - Visibility vs Accident Impact Distance\")\nprint(\" \u0627\u0644\u0645\u0648\u0636\u0648\u0639: \u0625\u062f\u0627\u0631\u0629 \u0627\u0644\u0645\u0631\u0648\u0631 - \u0627\u0644\u0631\u0624\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0645\u0633\u0627\u0641\u0629 \u062a\u0623\u062b\u064a\u0631 \u0627\u0644\u062d\u0648\u0627\u062f\u062b\")\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/us_accidents.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\ud83d\udcca Full dataset loaded: {len(df_full):,} records\")\n \n # Select relevant columns for polynomial regression\n # Feature: Visibility(mi) - visibility conditions during accident\n # Target: Distance(mi) - how far the accident impacts traffic\n cols_needed = ['Visibility(mi)', 'Distance(mi)']\n \n # Clean data: remove nulls and filter for meaningful data\n df_clean = df_full[cols_needed].dropna()\n \n # Filter for accidents with non-zero distance (more meaningful for analysis)\ndf_clean = df_clean[df_clean['Distance(mi)'] > 0].copy()\n \n # Sample for faster computation and clearer visualization\n # Using 2000 samples - good balance between data size and demonstration clarity\n sample_size = min(2000, len(df_clean))\n df = df_clean.sample(n=sample_size, random_state=73).copy().reset_index(drop=True)\n \n # Prepare features and target\n X = df[['Visibility(mi)']].values # Feature: Visibility (2D array for sklearn)\ny = df['Distance(mi)'].values # Target: Accident impact distance\n \n print(f\"\u2705 Clean data prepared: {len(df)} records\")\n print(f\" Feature: Visibility(mi) - visibility conditions (miles)\")\n print(f\" Target: Distance(mi) - accident impact distance (miles)\")\n \n print(f\"\\n\ud83d\udcca Dataset statistics:\")\nprint(df.describe())\n print(\"\\n\ud83d\udd0d Notice:\")\nprint(\" - This is REAL-WORLD traffic accident data!\")\nprint(\" - Relationship: Visibility vs Accident Impact Distance\")\nprint(\" - Hypothesis: Lower visibility \u2192 Longer impact distances (curved relationship)\")\n print(\" - This relationship is CURVED (non-linear), not a straight line!\")\n print(\" - At high visibility: Impact distances are small and stable\")\nprint(\" - At low visibility: Impact distances increase exponentially\")\nprint(\" - Linear regression will struggle with this CURVED pattern\")\nprint(\" - Polynomial regression will fit much better because it can model curves!\")\nprint(\"\\n\ud83d\udca1 GDI Traffic Management Context:\")\nprint(\" - Understanding this relationship helps in:\")\nprint(\" \u2022 Traffic flow prediction during poor visibility\")\nprint(\" \u2022 Emergency response planning\")\nprint(\" \u2022 Resource allocation for accident management\")\nprint(\" \u2022 Traffic safety assessment\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected location: ../../datasets/raw/us_accidents.csv\")\nprint(\" \ud83d\udca1 Please ensure the dataset is downloaded (see DOWNLOAD_INSTRUCTIONS.md)\")\n print(\"\\n Creating minimal synthetic data for demonstration...\")\n \n # Fallback: Create synthetic data with similar characteristics\n np.random.seed(73)\nn_samples = 200\n visibility = np.random.uniform(0.2, 10.0, n_samples)\n # Curved relationship: distance = a/visibility + noise\n distance = 0.1\n(visibility + 0.5) + np.random.normal(0, 0.02, n_samples)\ndistance = np.maximum(distance, 0.001) # Ensure positive\n \n X = visibility.reshape(-1, 1)\ny = distance\n \n df = pd.DataFrame({\n 'Visibility(mi)': visibility, 'Distance(mi)': distance\n })\n \n print(f\" \u26a0\ufe0f Using synthetic data ({n_samples} samples) - please use real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/us_accidents.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world US Accidents dataset for Traffic Management\n# GDI Theme: Traffic Management - Understanding how visibility affects accident impact distance\n\nprint(\"\\n\ud83d\udce5 Loading US Accidents dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u062d\u0648\u0627\u062f\u062b \u0627\u0644\u0645\u0631\u0648\u0631 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\nprint(\" GDI Theme: Traffic Management - Visibility vs Accident Impact Distance\")\nprint(\" \u0627\u0644\u0645\u0648\u0636\u0648\u0639: \u0625\u062f\u0627\u0631\u0629 \u0627\u0644\u0645\u0631\u0648\u0631 - \u0627\u0644\u0631\u0624\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0645\u0633\u0627\u0641\u0629 \u062a\u0623\u062b\u064a\u0631 \u0627\u0644\u062d\u0648\u0627\u062f\u062b\")\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/us_accidents.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\ud83d\udcca Full dataset loaded: {len(df_full):,} records\")\n \n # Select relevant columns for polynomial regression\n # Feature: Visibility(mi) - visibility conditions during accident\n # Target: Distance(mi) - how far the accident impacts traffic\n cols_needed = ['Visibility(mi)', 'Distance(mi)']\n \n # Clean data: remove nulls and filter for meaningful data\n df_clean = df_full[cols_needed].dropna()\n \n # Filter for accidents with non-zero distance (more meaningful for analysis)\ndf_clean = df_clean[df_clean['Distance(mi)'] > 0].copy()\n \n # Sample for faster computation and clearer visualization\n # Using 2000 samples - good balance between data size and demonstration clarity\n sample_size = min(2000, len(df_clean))\n df = df_clean.sample(n=sample_size, random_state=73).copy().reset_index(drop=True)\n \n # Prepare features and target\n X = df[['Visibility(mi)']].values # Feature: Visibility (2D array for sklearn)\ny = df['Distance(mi)'].values # Target: Accident impact distance\n \n print(f\"\u2705 Clean data prepared: {len(df)} records\")\n print(f\" Feature: Visibility(mi) - visibility conditions (miles)\")\n print(f\" Target: Distance(mi) - accident impact distance (miles)\")\n \n print(f\"\\n\ud83d\udcca Dataset statistics:\")\nprint(df.describe())\n print(\"\\n\ud83d\udd0d Notice:\")\nprint(\" - This is REAL-WORLD traffic accident data!\")\nprint(\" - Relationship: Visibility vs Accident Impact Distance\")\nprint(\" - Hypothesis: Lower visibility \u2192 Longer impact distances (curved relationship)\")\n print(\" - This relationship is CURVED (non-linear), not a straight line!\")\n print(\" - At high visibility: Impact distances are small and stable\")\nprint(\" - At low visibility: Impact distances increase exponentially\")\nprint(\" - Linear regression will struggle with this CURVED pattern\")\nprint(\" - Polynomial regression will fit much better because it can model curves!\")\nprint(\"\\n\ud83d\udca1 GDI Traffic Management Context:\")\nprint(\" - Understanding this relationship helps in:\")\nprint(\" \u2022 Traffic flow prediction during poor visibility\")\nprint(\" \u2022 Emergency response planning\")\nprint(\" \u2022 Resource allocation for accident management\")\nprint(\" \u2022 Traffic safety assessment\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected location: ../../datasets/raw/us_accidents.csv\")\nprint(\" \ud83d\udca1 Please ensure the dataset is downloaded (see DOWNLOAD_INSTRUCTIONS.md)\")\n print(\"\\n Creating minimal synthetic data for demonstration...\")\n \n # Fallback: Create synthetic data with similar characteristics\n np.random.seed(73)\nn_samples = 200\n visibility = np.random.uniform(0.2, 10.0, n_samples)\n # Curved relationship: distance = a/visibility + noise\n distance = 0.1\n(visibility + 0.5) + np.random.normal(0, 0.02, n_samples)\ndistance = np.maximum(distance, 0.001) # Ensure positive\n \n X = visibility.reshape(-1, 1)\ny = distance\n \n df = pd.DataFrame({\n 'Visibility(mi)': visibility, 'Distance(mi)': distance\n })\n \n print(f\" \u26a0\ufe0f Using synthetic data ({n_samples} samples) - please use real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/us_accidents.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/06_ridge_lasso_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6465990543365479,
      "error": "An error occurred while executing the following cell:\n------------------\n# Generate sample data with multiple features_np.random.seed(42)\nn_samples = 100\n\n# Create features with some correlation_X = np.random.randn(n_samples, 5)\n# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for regularization)\nscaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\nX_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\nX_test_scaled = scaler.transform(X_test)\nprint(f\"Training set: {X_train_scaled.shape}\")\nprint(f\"Test set: {X_test_scaled.shape}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Generate sample data with multiple features_np.random.seed(42)\nn_samples = 100\n\n# Create features with some correlation_X = np.random.randn(n_samples, 5)\n# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for regularization)\nscaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\nX_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\nX_test_scaled = scaler.transform(X_test)\nprint(f\"Training set: {X_train_scaled.shape}\")\nprint(f\"Test set: {X_test_scaled.shape}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/07_svr_decision_tree_regression.ipynb",
      "status": "failed",
      "execution_time": 0.7403521537780762,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.svm \nimport SVR\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.metrics \nimport mean_squared_error, r2_score\nfrom sklearn.preprocessing \nimport StandardScaler_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.svm \nimport SVR\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.metrics \nimport mean_squared_error, r2_score\nfrom sklearn.preprocessing \nimport StandardScaler_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/comparing_regression_algorithms_on_real_datasets.ipynb",
      "status": "failed",
      "execution_time": 0.815809965133667,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/implementing_decision_tree_and_random_forest_regression.ipynb",
      "status": "failed",
      "execution_time": 0.7980978488922119,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/visualizing_regression_results_and_residuals.ipynb",
      "status": "failed",
      "execution_time": 0.8065700531005859,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.817451000213623,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plti_mport seaborn as sn\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plti_mport seaborn as sn\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plti_mport seaborn as sn\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plti_mport seaborn as sn\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.7883410453796387,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_03_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 1.664353847503662,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 3: Polynomial Regression Practice\n\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\n\nInstructions:\n1. Load the provided dataset_2. Create polynomial regression models with different degrees_3. Detect overfitting by comparing train vs test performance_4. Find the optimal polynomial degree_5. Visualize the results_6. Understand the bias-variance tradeoff\n\nUse the provided dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample non-linear data_np.random.seed(123)\nX = np.linspace(0, 10, 200).reshape(-1, 1)\n# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\n\ndf = pd.DataFrame({'x': X.flatten(), 'y': y})\n\nprint(\"Dataset Info:\")\nprint(f\"Shape: {df.shape}\")\nprint(df.head())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train polynomial regression with degree 1 (linear)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Polynomial Regression (degree=1)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=1\n# Train LinearRegression\n# Evaluate on both train and test\n# Your code here...\n\n# Task 3: Train polynomial regression with degree 2_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Polynomial Regression (degree=2)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=2\n# Train and evaluate\n# Your code here...\n\n# Task 4: Train polynomial regression with degree 5_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Polynomial Regression (degree=5)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=5\n# Train and evaluate\n# Notice overfitting (high train accuracy, lower test accuracy)\n# Your code here...\n\n# Task 5: Find optimal degree using validation_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Find optimal polynomial degree\")\nprint(\"=\"*60)\n# Test degrees from 1 to 10\n# Plot degree vs MSE (both train and test)\n# Find degree with best test performance\n# Your code here...\n\n# Task 6: Visualize results_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize polynomial fits\")\nprint(\"=\"*60)\n# Plot original data\n# Plot polynomial fits for different degrees\n# Show how higher degrees can overfit\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Info:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 3: Polynomial Regression Practice\n\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\n\nInstructions:\n1. Load the provided dataset_2. Create polynomial regression models with different degrees_3. Detect overfitting by comparing train vs test performance_4. Find the optimal polynomial degree_5. Visualize the results_6. Understand the bias-variance tradeoff\n\nUse the provided dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample non-linear data_np.random.seed(123)\nX = np.linspace(0, 10, 200).reshape(-1, 1)\n# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\n\ndf = pd.DataFrame({'x': X.flatten(), 'y': y})\n\nprint(\"Dataset Info:\")\nprint(f\"Shape: {df.shape}\")\nprint(df.head())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train polynomial regression with degree 1 (linear)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Polynomial Regression (degree=1)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=1\n# Train LinearRegression\n# Evaluate on both train and test\n# Your code here...\n\n# Task 3: Train polynomial regression with degree 2_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Polynomial Regression (degree=2)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=2\n# Train and evaluate\n# Your code here...\n\n# Task 4: Train polynomial regression with degree 5_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Polynomial Regression (degree=5)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=5\n# Train and evaluate\n# Notice overfitting (high train accuracy, lower test accuracy)\n# Your code here...\n\n# Task 5: Find optimal degree using validation_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Find optimal polynomial degree\")\nprint(\"=\"*60)\n# Test degrees from 1 to 10\n# Plot degree vs MSE (both train and test)\n# Find degree with best test performance\n# Your code here...\n\n# Task 6: Visualize results_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize polynomial fits\")\nprint(\"=\"*60)\n# Plot original data\n# Plot polynomial fits for different degrees\n# Show how higher degrees can overfit\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Info:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_04_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 1.5786528587341309,
      "error": "An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 1.3979840278625488,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 1: Data Processing Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062aInstructions:1. Load the sample dataset provided below2. Explore the data (shape, info, statistics)3. Handle missing values appropriately4. Remove any duplicates5. Create visualizations (at least 2 different plots)\nDataset: Sales data for a retail stor_e\"\"\"\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dataset: Sales data for a retail stor_e\"\"\"\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 3)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 1: Data Processing Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062aInstructions:1. Load the sample dataset provided below2. Explore the data (shape, info, statistics)3. Handle missing values appropriately4. Remove any duplicates5. Create visualizations (at least 2 different plots)\nDataset: Sales data for a retail stor_e\"\"\"\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dataset: Sales data for a retail stor_e\"\"\"\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 3)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.6004071235656738,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_03_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5347771644592285,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 3: Polynomial Regression Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062fInstructions:1. Load the provided dataset2. Create polynomial regression models with different degrees3. Detect overfitting by comparing train vs test performance4. Find the optimal polynomial degree5. Visualize the results6. Understand the bias-variance tradeoffUse the provided dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score# Generate sample non-linear datanp.random.seed(123)X = np.linspace(0, 10, 200).reshape(-1, 1)# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noisey = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)df = pd.DataFrame({'x': X.flatten(), 'y': y})print(\"Dataset Info:\")print(f\"Shape: {df.shape}\")print(df.head())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train polynomial regression with degree 1 (linear)print(\"\\n\" + \"=\"*60)print(\"Task 2: Polynomial Regression (degree=1)\")print(\"=\"*60)# Use PolynomialFeatures with degree=1# Train LinearRegression# Evaluate on both train and test# Your code here...\n# Task 3: Train polynomial regression with degree 2\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Polynomial Regression (degree=5)\")print(\"=\"*60)# Use PolynomialFeatures with degree=5# Train and evaluate# Notice overfitting (high train accuracy, lower test accuracy)# Your code here...# Task 5: Find optimal degree using validation\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Find optimal polynomial degree\")print(\"=\"*60)# Test degrees from 1 to 10# Plot degree vs MSE (both train and test)# Find degree with best test performance# Your code here...# Task 6: Visualize results\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize polynomial fits\")print(\"=\"*60)# Plot original data# Plot polynomial fits for different degrees# Show how higher degrees can overfit# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 3: Polynomial Regression Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062fInstructions:1. Load the provided dataset2. Create polynomial regression models with different degrees3. Detect overfitting by comparing train vs test performance4. Find the optimal polynomial degree5. Visualize the results6. Understand the bias-variance tradeoffUse the provided dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score# Generate sample non-linear datanp.random.seed(123)X = np.linspace(0, 10, 200).reshape(-1, 1)# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noisey = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)df = pd.DataFrame({'x': X.flatten(), 'y': y})print(\"Dataset Info:\")print(f\"Shape: {df.shape}\")print(df.head())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train polynomial regression with degree 1 (linear)print(\"\\n\" + \"=\"*60)print(\"Task 2: Polynomial Regression (degree=1)\")print(\"=\"*60)# Use PolynomialFeatures with degree=1# Train LinearRegression# Evaluate on both train and test# Your code here...\n# Task 3: Train polynomial regression with degree 2\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Polynomial Regression (degree=5)\")print(\"=\"*60)# Use PolynomialFeatures with degree=5# Train and evaluate# Notice overfitting (high train accuracy, lower test accuracy)# Your code here...# Task 5: Find optimal degree using validation\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Find optimal polynomial degree\")print(\"=\"*60)# Test degrees from 1 to 10# Plot degree vs MSE (both train and test)# Find degree with best test performance# Your code here...# Task 6: Visualize results\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize polynomial fits\")print(\"=\"*60)# Plot original data# Plot polynomial fits for different degrees# Show how higher degrees can overfit# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_04_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 1.5598442554473877,
      "error": "An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit2-regression/examples/01_ridge_lasso_regression.ipynb",
      "status": "failed",
      "execution_time": 0.004130125045776367,
      "error": "Notebook does not appear to be JSON: '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"m...",
      "error_traceback": "Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 19, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/opt/anaconda3/lib/python3.13/json/decoder.py\", line 345, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1357 column 1 (char 66122)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 75, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 25, in parse_json\n    raise NotJSONError(message) from e\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"m...\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 1.6649458408355713,
      "error": "An error occurred while executing the following cell:\n------------------\n# 4. Comparing Different Models with Cross-Validation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"4. Comparing Different Models with Cross-Validation\")\nprint(\"\u0645\u0642\u0627\u0631\u0646\u0629 \u0646\u0645\u0627\u0630\u062c \u0645\u062e\u062a\u0644\u0641\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\")\nprint(\"=\" * 60)\nmodels = {\n    'Linear Regression': LinearRegression(), 'Ridge (\u03b1=1)': Ridge(alpha=1.0), 'Ridge (\u03b1=10)': Ridge(alpha=10.0), 'Lasso (\u03b1=0.1)': Lasso(alpha=0.1), 'Lasso (\u03b1=1)': Lasso(alpha=1.0)\n}\nresults = []\nfor name, model in models.items():\n    cv_scores = cross_val_score(model, X_scaled, y,\n                                cv=kfold, scoring='neg_mean_squared_error')\n    results.append({\n        'Model': name, 'Mean MSE': -cv_scores.mean(),\n        'Std MSE': cv_scores.std(), 'Mean R\u00b2': cross_val_score(model, X_scaled, y, cv=kfold, scoring='r2').mean()\n    })\n# pd.DataFrame(data)\n# - pd.DataFrame(): Creates pandas DataFrame (2D table-like structure)\n# - data: Dictionary where keys become column names, values become column data\n#   - Each key-value pair: key = column name, value = list of values for that column\n# - Returns DataFrame with rows and columns\n# - DataFrame is the main pandas data structure (like Excel spreadsheet in Python)\n\nresults_df = pd.DataFrame(results)\nprint(\"\\nModel Comparison:\")\nprint(results_df.to_string(index=False))\n\n# Add interpretation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Interpreting Cross-Validation Results | \u062a\u0641\u0633\u064a\u0631 \u0646\u062a\u0627\u0626\u062c \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\")\nprint(\"=\" * 60)\n\nbest_mse_idx = results_df['Mean MSE'].idxmin()\nbest_r2_idx = results_df['Mean R\u00b2'].idxmax()\nbest_model_mse = results_df.loc[best_mse_idx, 'Model']\nbest_model_r2 = results_df.loc[best_r2_idx, 'Model']\n\nprint(f\"\\n\ud83d\udcca Best Model by MSE: {best_model_mse}\")\nprint(f\"   - Mean MSE: {results_df.loc[best_mse_idx, 'Mean MSE']:.4f}\")\nprint(f\"   - Std MSE: {results_df.loc[best_mse_idx, 'Std MSE']:.4f}\")\nprint(f\"   - Lower MSE = better predictions\")\n\nprint(f\"\\n\ud83d\udcca Best Model by R\u00b2: {best_model_r2}\")\nbest_r2_value = results_df.loc[best_r2_idx, 'Mean R\u00b2']\nprint(f\"   - Mean R\u00b2: {best_r2_value:.4f} ({best_r2_value*100:.1f}%)\")\nprint(f\"   - Higher R\u00b2 = explains more variance\")\nprint(f\"   - {best_r2_value*100:.1f}% variance explained is REASONABLE for crime/social data\")\nprint(f\"   - Context: With 3 features, {best_r2_value*100:.0f}% is quite good for GDI analysis!\")\n\nprint(f\"\\n\ud83d\udd0d Understanding Standard Deviation:\")\nprint(f\"   - Std MSE shows variability across folds\")\nprint(f\"   - Lower std = more consistent performance\")\nprint(f\"   - High std = model performance varies a lot\")\n\nfor idx, row in results_df.iterrows():\n    std_ratio = row['Std MSE']\nrow['Mean MSE']\n    if std_ratio < 0.1:\n        consistency = \"\u2705 Very consistent\"\n    elif std_ratio < 0.2:\n        consistency = \"\u2705 Consistent\"\n    else:\n        consistency = \"\u26a0\ufe0f  Variable\"\n    print(f\"   - {row['Model']}: Std/MSE ratio = {std_ratio:.2f} ({consistency})\")\n\nprint(f\"\\n\ud83d\udcca Regularization Analysis:\")\nridge_models = results_df[results_df['Model'].str.contains('Ridge')]\nlasso_models = results_df[results_df['Model'].str.contains('Lasso')]\n\nif len(ridge_models) > 0:\n    best_ridge = ridge_models.loc[ridge_models['Mean MSE'].idxmin()]\n    print(f\"   - Best Ridge: {best_ridge['Model']} (MSE: {best_ridge['Mean MSE']:.4f})\")\n    print(f\"   - Alpha = 1.0 vs 10.0: {'Lower alpha is better' if best_ridge['Model'].endswith('1)') else 'Higher alpha is better'}\")\n\nif len(lasso_models) > 0:\n    best_lasso = lasso_models.loc[lasso_models['Mean MSE'].idxmin()]\n    print(f\"   - Best Lasso: {best_lasso['Model']} (MSE: {best_lasso['Mean MSE']:.4f})\")\n    print(f\"   - Alpha = 0.1 vs 1.0: {'Lower alpha is better' if best_lasso['Model'].endswith('0.1)') else 'Higher alpha is better'}\")\n\nprint(f\"\\n\ud83d\udcda What This Teaches Us:\")\nprint(f\"   - Cross-validation gives reliable model comparison\")\nprint(f\"   - Mean shows average performance, Std shows consistency\")\nprint(f\"   - Lower std = more reliable model\")\nprint(f\"   - Compare models using both mean and std\")\nprint(f\"   - Regularization (Ridge/Lasso) may or may not improve performance\")\nprint(f\"   - Alpha (regularization strength) needs tuning - not always better\")\nprint(f\"   - CV prevents overfitting to a single train/test split\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[11], line 58\u001b[0;36m\u001b[0m\n\u001b[0;31m    if std_ratio < 0.1:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# 4. Comparing Different Models with Cross-Validation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"4. Comparing Different Models with Cross-Validation\")\nprint(\"\u0645\u0642\u0627\u0631\u0646\u0629 \u0646\u0645\u0627\u0630\u062c \u0645\u062e\u062a\u0644\u0641\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\")\nprint(\"=\" * 60)\nmodels = {\n    'Linear Regression': LinearRegression(), 'Ridge (\u03b1=1)': Ridge(alpha=1.0), 'Ridge (\u03b1=10)': Ridge(alpha=10.0), 'Lasso (\u03b1=0.1)': Lasso(alpha=0.1), 'Lasso (\u03b1=1)': Lasso(alpha=1.0)\n}\nresults = []\nfor name, model in models.items():\n    cv_scores = cross_val_score(model, X_scaled, y,\n                                cv=kfold, scoring='neg_mean_squared_error')\n    results.append({\n        'Model': name, 'Mean MSE': -cv_scores.mean(),\n        'Std MSE': cv_scores.std(), 'Mean R\u00b2': cross_val_score(model, X_scaled, y, cv=kfold, scoring='r2').mean()\n    })\n# pd.DataFrame(data)\n# - pd.DataFrame(): Creates pandas DataFrame (2D table-like structure)\n# - data: Dictionary where keys become column names, values become column data\n#   - Each key-value pair: key = column name, value = list of values for that column\n# - Returns DataFrame with rows and columns\n# - DataFrame is the main pandas data structure (like Excel spreadsheet in Python)\n\nresults_df = pd.DataFrame(results)\nprint(\"\\nModel Comparison:\")\nprint(results_df.to_string(index=False))\n\n# Add interpretation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Interpreting Cross-Validation Results | \u062a\u0641\u0633\u064a\u0631 \u0646\u062a\u0627\u0626\u062c \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\")\nprint(\"=\" * 60)\n\nbest_mse_idx = results_df['Mean MSE'].idxmin()\nbest_r2_idx = results_df['Mean R\u00b2'].idxmax()\nbest_model_mse = results_df.loc[best_mse_idx, 'Model']\nbest_model_r2 = results_df.loc[best_r2_idx, 'Model']\n\nprint(f\"\\n\ud83d\udcca Best Model by MSE: {best_model_mse}\")\nprint(f\"   - Mean MSE: {results_df.loc[best_mse_idx, 'Mean MSE']:.4f}\")\nprint(f\"   - Std MSE: {results_df.loc[best_mse_idx, 'Std MSE']:.4f}\")\nprint(f\"   - Lower MSE = better predictions\")\n\nprint(f\"\\n\ud83d\udcca Best Model by R\u00b2: {best_model_r2}\")\nbest_r2_value = results_df.loc[best_r2_idx, 'Mean R\u00b2']\nprint(f\"   - Mean R\u00b2: {best_r2_value:.4f} ({best_r2_value*100:.1f}%)\")\nprint(f\"   - Higher R\u00b2 = explains more variance\")\nprint(f\"   - {best_r2_value*100:.1f}% variance explained is REASONABLE for crime/social data\")\nprint(f\"   - Context: With 3 features, {best_r2_value*100:.0f}% is quite good for GDI analysis!\")\n\nprint(f\"\\n\ud83d\udd0d Understanding Standard Deviation:\")\nprint(f\"   - Std MSE shows variability across folds\")\nprint(f\"   - Lower std = more consistent performance\")\nprint(f\"   - High std = model performance varies a lot\")\n\nfor idx, row in results_df.iterrows():\n    std_ratio = row['Std MSE']\nrow['Mean MSE']\n    if std_ratio < 0.1:\n        consistency = \"\u2705 Very consistent\"\n    elif std_ratio < 0.2:\n        consistency = \"\u2705 Consistent\"\n    else:\n        consistency = \"\u26a0\ufe0f  Variable\"\n    print(f\"   - {row['Model']}: Std/MSE ratio = {std_ratio:.2f} ({consistency})\")\n\nprint(f\"\\n\ud83d\udcca Regularization Analysis:\")\nridge_models = results_df[results_df['Model'].str.contains('Ridge')]\nlasso_models = results_df[results_df['Model'].str.contains('Lasso')]\n\nif len(ridge_models) > 0:\n    best_ridge = ridge_models.loc[ridge_models['Mean MSE'].idxmin()]\n    print(f\"   - Best Ridge: {best_ridge['Model']} (MSE: {best_ridge['Mean MSE']:.4f})\")\n    print(f\"   - Alpha = 1.0 vs 10.0: {'Lower alpha is better' if best_ridge['Model'].endswith('1)') else 'Higher alpha is better'}\")\n\nif len(lasso_models) > 0:\n    best_lasso = lasso_models.loc[lasso_models['Mean MSE'].idxmin()]\n    print(f\"   - Best Lasso: {best_lasso['Model']} (MSE: {best_lasso['Mean MSE']:.4f})\")\n    print(f\"   - Alpha = 0.1 vs 1.0: {'Lower alpha is better' if best_lasso['Model'].endswith('0.1)') else 'Higher alpha is better'}\")\n\nprint(f\"\\n\ud83d\udcda What This Teaches Us:\")\nprint(f\"   - Cross-validation gives reliable model comparison\")\nprint(f\"   - Mean shows average performance, Std shows consistency\")\nprint(f\"   - Lower std = more reliable model\")\nprint(f\"   - Compare models using both mean and std\")\nprint(f\"   - Regularization (Ridge/Lasso) may or may not improve performance\")\nprint(f\"   - Alpha (regularization strength) needs tuning - not always better\")\nprint(f\"   - CV prevents overfitting to a single train/test split\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[11], line 58\u001b[0;36m\u001b[0m\n\u001b[0;31m    if std_ratio < 0.1:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/03_bias_variance_learning_curves.ipynb",
      "status": "failed",
      "execution_time": 0.5340240001678467,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve, validation_curve\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.preprocessing \nimport PolynomialFeatures\nfrom sklearn.pipeline \nimport Pipeline\nfrom sklearn.metrics \nimport mean_squared_error_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve, validation_curve\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.preprocessing \nimport PolynomialFeatures\nfrom sklearn.pipeline \nimport Pipeline\nfrom sklearn.metrics \nimport mean_squared_error_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/04_regression_evaluation_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.6622529029846191,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport mean_squared_error, mean_absolute_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRegression Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nMSE (Mean Squared Error):\")\nprint(\"  - Average squared differences\")\nprint(\"  - Penalizes large errors\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nRMSE (Root Mean Squared Error):\")\nprint(\"  - Square root of MSE\")\nprint(\"  - Same units as target\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nMAE (Mean Absolute Error):\")\nprint(\"  - Average absolute differences\")\nprint(\"  - Less sensitive to outliers\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nR\u00b2 (Coefficient of Determination):\")\nprint(\"  - Proportion of variance explained\")\nprint(\"  - Range: -\u221e to 1\")\nprint(\"  - Higher is better (closer to 1)\")\n\nprint(\"\\n\u2705 Regression metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport mean_squared_error, mean_absolute_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRegression Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nMSE (Mean Squared Error):\")\nprint(\"  - Average squared differences\")\nprint(\"  - Penalizes large errors\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nRMSE (Root Mean Squared Error):\")\nprint(\"  - Square root of MSE\")\nprint(\"  - Same units as target\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nMAE (Mean Absolute Error):\")\nprint(\"  - Average absolute differences\")\nprint(\"  - Less sensitive to outliers\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nR\u00b2 (Coefficient of Determination):\")\nprint(\"  - Proportion of variance explained\")\nprint(\"  - Range: -\u221e to 1\")\nprint(\"  - Higher is better (closer to 1)\")\n\nprint(\"\\n\u2705 Regression metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/05_leave_one_out_stratified_cv.ipynb",
      "status": "failed",
      "execution_time": 0.6326851844787598,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport LeaveOneOut, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model \nimport LinearRegression_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nLeave-One-Out and Stratified Cross-Validation\")\nprint(\"=\" * 60)\n\nprint(\"\\nLeave-One-Out CV:\")\nprint(\"  - Each sample as test set\")\nprint(\"  - Maximum data usage\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nStratified Cross-Validation:\")\nprint(\"  - Preserves class distribution\")\nprint(\"  - Important for imbalanced data\")\nprint(\"  - Better for classification\")\n\nprint(\"\\n\u2705 Advanced CV concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport LeaveOneOut, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model \nimport LinearRegression_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nLeave-One-Out and Stratified Cross-Validation\")\nprint(\"=\" * 60)\n\nprint(\"\\nLeave-One-Out CV:\")\nprint(\"  - Each sample as test set\")\nprint(\"  - Maximum data usage\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nStratified Cross-Validation:\")\nprint(\"  - Preserves class distribution\")\nprint(\"  - Important for imbalanced data\")\nprint(\"  - Better for classification\")\n\nprint(\"\\n\u2705 Advanced CV concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/06_overfitting_underfitting_handling.ipynb",
      "status": "failed",
      "execution_time": 0.7469608783721924,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve\nfrom sklearn.linear_model \nimport LinearRegression, Ridge\nfrom sklearn.tree \nimport DecisionTreeRegressor_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nIdentifying and Handling Overfitting/Underfitting\")\nprint(\"=\" * 60)\n\nprint(\"\\nOverfitting Signs:\")\nprint(\"  - High training accuracy, low validation accuracy\")\nprint(\"  - Large gap between train/test performance\")\nprint(\"  - Model too complex\")\n\nprint(\"\\nUnderfitting Signs:\")\nprint(\"  - Low training accuracy\")\nprint(\"  - Low validation accuracy\")\nprint(\"  - Model too simple\")\n\nprint(\"\\nSolutions:\")\nprint(\"  - Regularization (L1, L2)\")\nprint(\"  - Cross-validation\")\nprint(\"  - Feature selection\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 Overfitting/underfitting concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve\nfrom sklearn.linear_model \nimport LinearRegression, Ridge\nfrom sklearn.tree \nimport DecisionTreeRegressor_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nIdentifying and Handling Overfitting/Underfitting\")\nprint(\"=\" * 60)\n\nprint(\"\\nOverfitting Signs:\")\nprint(\"  - High training accuracy, low validation accuracy\")\nprint(\"  - Large gap between train/test performance\")\nprint(\"  - Model too complex\")\n\nprint(\"\\nUnderfitting Signs:\")\nprint(\"  - Low training accuracy\")\nprint(\"  - Low validation accuracy\")\nprint(\"  - Model too simple\")\n\nprint(\"\\nSolutions:\")\nprint(\"  - Regularization (L1, L2)\")\nprint(\"  - Cross-validation\")\nprint(\"  - Feature selection\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 Overfitting/underfitting concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/07_optimal_model_complexity.ipynb",
      "status": "failed",
      "execution_time": 0.7594661712646484,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport validation_curve, GridSearchCV\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.linear_model \nimport Ridge_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSelecting Optimal Model Complexity\")\nprint(\"=\" * 60)\n\nprint(\"\\nValidation Sets:\")\nprint(\"  - Separate from training/test\")\nprint(\"  - Used for hyperparameter tuning\")\nprint(\"  - Prevents overfitting\")\n\nprint(\"\\nComplexity Tuning:\")\nprint(\"  - Tree depth\")\nprint(\"  - Regularization strength\")\nprint(\"  - Number of features\")\nprint(\"  - Model architecture\")\n\nprint(\"\\nMethods:\")\nprint(\"  - Validation curves\")\nprint(\"  - Grid search\")\nprint(\"  - Random search\")\nprint(\"  - Cross-validation\")\n\nprint(\"\\n\u2705 Model complexity selection concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport validation_curve, GridSearchCV\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.linear_model \nimport Ridge_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSelecting Optimal Model Complexity\")\nprint(\"=\" * 60)\n\nprint(\"\\nValidation Sets:\")\nprint(\"  - Separate from training/test\")\nprint(\"  - Used for hyperparameter tuning\")\nprint(\"  - Prevents overfitting\")\n\nprint(\"\\nComplexity Tuning:\")\nprint(\"  - Tree depth\")\nprint(\"  - Regularization strength\")\nprint(\"  - Number of features\")\nprint(\"  - Model architecture\")\n\nprint(\"\\nMethods:\")\nprint(\"  - Validation curves\")\nprint(\"  - Grid search\")\nprint(\"  - Random search\")\nprint(\"  - Cross-validation\")\n\nprint(\"\\n\u2705 Model complexity selection concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/08_comparing_model_performance.ipynb",
      "status": "failed",
      "execution_time": 0.5370209217071533,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Model Performance Across Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nComparison Metrics:\")\nprint(\"  - Cross-validation scores\")\nprint(\"  - Training time\")\nprint(\"  - Prediction time\")\nprint(\"  - Model complexity\")\n\nprint(\"\\nVisualization:\")\nprint(\"  - Bar charts\")\nprint(\"  - Box plots\")\nprint(\"  - Performance tables\")\nprint(\"  - Statistical tests\")\n\nprint(\"\\n\u2705 Model comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Model Performance Across Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nComparison Metrics:\")\nprint(\"  - Cross-validation scores\")\nprint(\"  - Training time\")\nprint(\"  - Prediction time\")\nprint(\"  - Model complexity\")\n\nprint(\"\\nVisualization:\")\nprint(\"  - Bar charts\")\nprint(\"  - Box plots\")\nprint(\"  - Performance tables\")\nprint(\"  - Statistical tests\")\n\nprint(\"\\n\u2705 Model comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/08_decision_tree_random_forest_regression.ipynb",
      "status": "passed",
      "execution_time": 1.795504093170166,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/09_comparing_regression_algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.5377500057220459,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Regression Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nAlgorithms to Compare:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Ridge Regression\")\nprint(\"  - Lasso Regression\")\nprint(\"  - Decision Tree\")\nprint(\"  - Random Forest\")\n\nprint(\"\\nEvaluation Metrics:\")\nprint(\"  - MSE (Mean Squared Error)\")\nprint(\"  - RMSE (Root Mean Squared Error)\")\nprint(\"  - MAE (Mean Absolute Error)\")\nprint(\"  - R\u00b2 (Coefficient of Determination)\")\n\nprint(\"\\n\u2705 Regression comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Regression Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nAlgorithms to Compare:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Ridge Regression\")\nprint(\"  - Lasso Regression\")\nprint(\"  - Decision Tree\")\nprint(\"  - Random Forest\")\n\nprint(\"\\nEvaluation Metrics:\")\nprint(\"  - MSE (Mean Squared Error)\")\nprint(\"  - RMSE (Root Mean Squared Error)\")\nprint(\"  - MAE (Mean Absolute Error)\")\nprint(\"  - R\u00b2 (Coefficient of Determination)\")\n\nprint(\"\\n\u2705 Regression comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/10_visualizing_regression_results_residuals.ipynb",
      "status": "failed",
      "execution_time": 0.7530698776245117,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.metrics \nimport mean_squared_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nVisualizing Regression Results and Residuals\")\nprint(\"=\" * 60)\n\nprint(\"\\nVisualizations:\")\nprint(\"  - Predicted vs Actual scatter plot\")\nprint(\"  - Residual plots\")\nprint(\"  - Residual distribution\")\nprint(\"  - Q-Q plots for normality\")\n\nprint(\"\\nResidual Analysis:\")\nprint(\"  - Check for patterns\")\nprint(\"  - Identify outliers\")\nprint(\"  - Verify assumptions\")\nprint(\"  - Diagnose model issues\")\n\nprint(\"\\n\u2705 Visualization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.metrics \nimport mean_squared_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nVisualizing Regression Results and Residuals\")\nprint(\"=\" * 60)\n\nprint(\"\\nVisualizations:\")\nprint(\"  - Predicted vs Actual scatter plot\")\nprint(\"  - Residual plots\")\nprint(\"  - Residual distribution\")\nprint(\"  - Q-Q plots for normality\")\n\nprint(\"\\nResidual Analysis:\")\nprint(\"  - Check for patterns\")\nprint(\"  - Identify outliers\")\nprint(\"  - Verify assumptions\")\nprint(\"  - Diagnose model issues\")\n\nprint(\"\\n\u2705 Visualization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/comparing_model_performance_across_different_algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.651547908782959,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/computing_regression_evaluation_metrics_mse_rmse_mae_r\u00b2.ipynb",
      "status": "failed",
      "execution_time": 0.5978569984436035,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/identifying_and_handling_overfittingunderfitting.ipynb",
      "status": "failed",
      "execution_time": 0.6064410209655762,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/performing_leave_one_out_and_stratified_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.5318601131439209,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/selecting_optimal_model_complexity_using_validation_sets.ipynb",
      "status": "failed",
      "execution_time": 0.7501459121704102,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6250870227813721,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lassof\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lassof\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit2-regression/exercises/exercise_02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.7490231990814209,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 2: Cross-Validation Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\n\nInstructions:\n1. Load the provided dataset_2. Implement K-Fold cross-validation manually_3. Use sklearn's KFold for cross-validation_4. Compare single train-test split vs K-Fold CV_5. Calculate mean and std of CV scores_6. Understand why CV gives more reliable estimates\n\nDataset: Regression dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample regression data_np.random.seed(123)\nX = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ny = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Single train-test split (baseline)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Single train-test split\")\nprint(\"=\"*60)\n# Split data 80/20\n# Train Linear Regression\n# Evaluate on test set\n# Print MSE and R\u00b2\n# Your code here...\n\n# Task 2: Manual K-Fold cross-validation (K=5)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Manual K-Fold CV (K=5)\")\nprint(\"=\"*60)\n# Split data into 5 folds manually\n# For each fold:\n#   - Train on 4 folds, test on 1 fold\n#   - Calculate MSE and R\u00b2\n# Store all scores\n# Print mean and std of scores\n# Your code here...\n\n# Task 3: Use sklearn's KFold_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: sklearn KFold\")\nprint(\"=\"*60)\n# Use KFold(n_splits=5, shuffle=True, random_state=123)\n# Implement CV loop using KFold\n# Calculate mean and std of scores\n# Your code here...\n\n# Task 4: Use cross_val_score_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: cross_val_score\")\nprint(\"=\"*60)\n# Use sklearn's cross_val_score function\n# Much simpler than manual implementation!\n# Print mean and std\n# Your code here...\n\n# Task 5: Compare single split vs CV_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare single split vs CV\")\nprint(\"=\"*60)\n# Show that CV gives more reliable estimate\n# Single split: One score (might be lucky/unlucky)\n# CV: Multiple scores, mean gives better estimate\n# Your code here...\n\n# Task 6: Visualize CV score distribution_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize CV scores\")\nprint(\"=\"*60)\n# Plot histogram of CV scores\n# Show mean and std\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 2: Cross-Validation Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\n\nInstructions:\n1. Load the provided dataset_2. Implement K-Fold cross-validation manually_3. Use sklearn's KFold for cross-validation_4. Compare single train-test split vs K-Fold CV_5. Calculate mean and std of CV scores_6. Understand why CV gives more reliable estimates\n\nDataset: Regression dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample regression data_np.random.seed(123)\nX = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ny = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Single train-test split (baseline)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Single train-test split\")\nprint(\"=\"*60)\n# Split data 80/20\n# Train Linear Regression\n# Evaluate on test set\n# Print MSE and R\u00b2\n# Your code here...\n\n# Task 2: Manual K-Fold cross-validation (K=5)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Manual K-Fold CV (K=5)\")\nprint(\"=\"*60)\n# Split data into 5 folds manually\n# For each fold:\n#   - Train on 4 folds, test on 1 fold\n#   - Calculate MSE and R\u00b2\n# Store all scores\n# Print mean and std of scores\n# Your code here...\n\n# Task 3: Use sklearn's KFold_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: sklearn KFold\")\nprint(\"=\"*60)\n# Use KFold(n_splits=5, shuffle=True, random_state=123)\n# Implement CV loop using KFold\n# Calculate mean and std of scores\n# Your code here...\n\n# Task 4: Use cross_val_score_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: cross_val_score\")\nprint(\"=\"*60)\n# Use sklearn's cross_val_score function\n# Much simpler than manual implementation!\n# Print mean and std\n# Your code here...\n\n# Task 5: Compare single split vs CV_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare single split vs CV\")\nprint(\"=\"*60)\n# Show that CV gives more reliable estimate\n# Single split: One score (might be lucky/unlucky)\n# CV: Multiple scores, mean gives better estimate\n# Your code here...\n\n# Task 6: Visualize CV score distribution_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize CV scores\")\nprint(\"=\"*60)\n# Plot histogram of CV scores\n# Show mean and std\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit2-regression/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.561445951461792,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "Course 04/unit2-regression/solutions/solution_02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.6203010082244873,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 2 - Exercise 2: Cross-Validation Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639Instructions:1. Load the provided dataset2. Implement K-Fold cross-validation manually3. Use sklearn's KFold for cross-validation4. Compare single train-test split vs K-Fold CV5. Calculate mean and std of CV scores6. Understand why CV gives more reliable estimatesDataset: Regression dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Generate sample regression datanp.random.seed(123)X = np.random.randn(300, 5)y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: sklearn KFold\")print(\"=\"*60)# Use KFold(n_splits=5, shuffle=True, random_state=123)# Implement CV loop using KFold# Calculate mean and std of scores# Your code here...# Task 4: Use cross_val_score\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: cross_val_score\")print(\"=\"*60)# Use sklearn's cross_val_score function# Much simpler than manual implementation!# Print mean and std# Your code here...# Task 5: Compare single split vs CV\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare single split vs CV\")print(\"=\"*60)# Show that CV gives more reliable estimate# Single split: One score (might be lucky/unlucky)# CV: Multiple scores, mean gives better estimate# Your code here...# Task 6: Visualize CV score distribution\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize CV scores\")print(\"=\"*60)# Plot histogram of CV scores# Show mean and std# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 2 - Exercise 2: Cross-Validation Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639Instructions:1. Load the provided dataset2. Implement K-Fold cross-validation manually3. Use sklearn's KFold for cross-validation4. Compare single train-test split vs K-Fold CV5. Calculate mean and std of CV scores6. Understand why CV gives more reliable estimatesDataset: Regression dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Generate sample regression datanp.random.seed(123)X = np.random.randn(300, 5)y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: sklearn KFold\")print(\"=\"*60)# Use KFold(n_splits=5, shuffle=True, random_state=123)# Implement CV loop using KFold# Calculate mean and std of scores# Your code here...# Task 4: Use cross_val_score\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: cross_val_score\")print(\"=\"*60)# Use sklearn's cross_val_score function# Much simpler than manual implementation!# Print mean and std# Your code here...# Task 5: Compare single split vs CV\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare single split vs CV\")print(\"=\"*60)# Show that CV gives more reliable estimate# Single split: One score (might be lucky/unlucky)# CV: Multiple scores, mean gives better estimate# Your code here...# Task 6: Visualize CV score distribution\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize CV scores\")print(\"=\"*60)# Plot histogram of CV scores# Show mean and std# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/examples/01_logistic_regression.ipynb",
      "status": "passed",
      "execution_time": 0.836651086807251,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/02_decision_trees.ipynb",
      "status": "passed",
      "execution_time": 0.8180956840515137,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/03_svm.ipynb",
      "status": "failed",
      "execution_time": 0.004086017608642578,
      "error": "Notebook does not appear to be JSON: '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"m...",
      "error_traceback": "Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 19, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/opt/anaconda3/lib/python3.13/json/decoder.py\", line 345, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 2442 column 1 (char 452059)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 75, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 25, in parse_json\n    raise NotJSONError(message) from e\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"m...\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/04_knn.ipynb",
      "status": "failed",
      "execution_time": 0.6160919666290283,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build KNN classification models import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.neighbors import KNeighborsClassifier # KNN classifier\nfrom sklearn.preprocessing import StandardScaler # CRITICAL for KNN! Must scale features\nfrom sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda Key KNN Concepts:\")\nprint(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\nprint(\" - K parameter: Number of neighbors to consider (critical hyperparameter)\")\nprint(\" - Distance metrics: Euclidean (default), Manhattan, etc.\")\nprint(\" - Lazy learning: No training phase, just prediction\")\nprint(\"\\n \u26a0\ufe0f IMPORTANT: KNN requires feature scaling! Always use StandardScaler!\")\nprint(\" \ud83d\udca1 Why? Distance calculations are affected by feature scales!\")\nprint(\"\\n \ud83c\udfaf GDI Theme: Financial Investigations & Administrative Crimes Detection\")\nprint(\" \ud83d\udca1 We'll use credit card fraud data to detect fraudulent transactions!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build KNN classification models import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.neighbors import KNeighborsClassifier # KNN classifier\nfrom sklearn.preprocessing import StandardScaler # CRITICAL for KNN! Must scale features\nfrom sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda Key KNN Concepts:\")\nprint(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\nprint(\" - K parameter: Number of neighbors to consider (critical hyperparameter)\")\nprint(\" - Distance metrics: Euclidean (default), Manhattan, etc.\")\nprint(\" - Lazy learning: No training phase, just prediction\")\nprint(\"\\n \u26a0\ufe0f IMPORTANT: KNN requires feature scaling! Always use StandardScaler!\")\nprint(\" \ud83d\udca1 Why? Distance calculations are affected by feature scales!\")\nprint(\"\\n \ud83c\udfaf GDI Theme: Financial Investigations & Administrative Crimes Detection\")\nprint(\" \ud83d\udca1 We'll use credit card fraud data to detect fraudulent transactions!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/05_random_forest_naive_bayes.ipynb",
      "status": "failed",
      "execution_time": 1.7056219577789307,
      "error": "An error occurred while executing the following cell:\n------------------\n# Generate classification dataset\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n                          n_redundant=5, n_classes=2, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\nrf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\nrf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\nrf_pred_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"=\" * 60)\nprint(\"Random Forest Classifier:\")\nprint(\"=\" * 60)\nprint(f\"Accuracy: {rf.score(X_test, y_test):.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, rf_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, rf_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Generate classification dataset\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n                          n_redundant=5, n_classes=2, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\nrf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\nrf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\nrf_pred_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"=\" * 60)\nprint(\"Random Forest Classifier:\")\nprint(\"=\" * 60)\nprint(f\"Accuracy: {rf.score(X_test, y_test):.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, rf_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, rf_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/06_ensemble_methods_bagging_boosting.ipynb",
      "status": "failed",
      "execution_time": 0.6121459007263184,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.datasets \nimport make_classification\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.tree \nimport DecisionTreeClassifier\nfrom sklearn.ensemble \nimport BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics \nimport accuracy_score, classification_report_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.datasets \nimport make_classification\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.tree \nimport DecisionTreeClassifier\nfrom sklearn.ensemble \nimport BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics \nimport accuracy_score, classification_report_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/07_svm_kernels_comparison.ipynb",
      "status": "passed",
      "execution_time": 1.63364577293396,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/08_classification_evaluation_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.7454988956451416,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nimport seaborn as sns_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nClassification Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nConfusion Matrix:\")\nprint(\"  - True Positives, True Negatives\")\nprint(\"  - False Positives, False Negatives\")\nprint(\"  - Visual representation\")\n\nprint(\"\\nROC Curve:\")\nprint(\"  - True Positive Rate vs False Positive Rate\")\nprint(\"  - AUC score\")\nprint(\"  - Threshold selection\")\n\nprint(\"\\nPrecision and Recall:\")\nprint(\"  - Precision: TP\n(TP + FP)\")\nprint(\"  - Recall: TP\n(TP + FN)\")\nprint(\"  - F1: Harmonic mean\")\n\nprint(\"\\n\u2705 Classification metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  - Precision: TP\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 21)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nimport seaborn as sns_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nClassification Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nConfusion Matrix:\")\nprint(\"  - True Positives, True Negatives\")\nprint(\"  - False Positives, False Negatives\")\nprint(\"  - Visual representation\")\n\nprint(\"\\nROC Curve:\")\nprint(\"  - True Positive Rate vs False Positive Rate\")\nprint(\"  - AUC score\")\nprint(\"  - Threshold selection\")\n\nprint(\"\\nPrecision and Recall:\")\nprint(\"  - Precision: TP\n(TP + FP)\")\nprint(\"  - Recall: TP\n(TP + FN)\")\nprint(\"  - F1: Harmonic mean\")\n\nprint(\"\\n\u2705 Classification metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  - Precision: TP\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 21)\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/evaluating_classification_models_using_confusion_matrices_roc_curves_and_analyzi.ipynb",
      "status": "failed",
      "execution_time": 0.6409170627593994,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/using_svm_with_different_kernels_linear_polynomial_rbf_to_handle_complex_classif.ipynb",
      "status": "failed",
      "execution_time": 0.6177339553833008,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6032700538635254,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, classification_report,\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, classification_report,\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_02_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 1.843095064163208,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 2: Logistic Regression Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\nInstructions:\n1. Load the provided dataset_2. Train a Logistic Regression classifier_3. Calculate and display all classification metrics (accuracy, precision, recall, F1)\n4. Create and visualize a confusion matrix_5. Create and visualize an ROC curve_6. Experiment with different thresholds_7. Handle class imbalance using class weights\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_curve, roc_auc_score, classification_report\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=1000, n_features=10,\n    n_informative=6,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20, use stratify)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Scale the features (important for logistic regression!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Scale features\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 3: Train a Logistic Regression model (default parameters)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train Logistic Regression model\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 4: Make predictions and calculate metrics_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Calculate classification metrics\")\nprint(\"=\"*60)\n# Calculate: accuracy, precision, recall, F1-score\n# Your code here...\n\n# Task 5: Create and visualize confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create confusion matrix and visualize it with seaborn heatmap\n# Your code here...\n\n# Task 6: Get prediction probabilities and create ROC curve_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: ROC Curve\")\nprint(\"=\"*60)\n# Get probabilities using .predict_proba()\n# Calculate ROC curve (fpr, tpr, thresholds)\n# Calculate AUC score\n# Plot ROC curve with AUC value\n# Your code here...\n\n# Task 7: Train model with class weights to handle imbalance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Handle class imbalance with class weights\")\nprint(\"=\"*60)\n# Train new model with class_weight='balanced'\n# Compare metrics with previous model\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     27\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     28\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 35\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 2: Logistic Regression Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\nInstructions:\n1. Load the provided dataset_2. Train a Logistic Regression classifier_3. Calculate and display all classification metrics (accuracy, precision, recall, F1)\n4. Create and visualize a confusion matrix_5. Create and visualize an ROC curve_6. Experiment with different thresholds_7. Handle class imbalance using class weights\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_curve, roc_auc_score, classification_report\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=1000, n_features=10,\n    n_informative=6,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20, use stratify)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Scale the features (important for logistic regression!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Scale features\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 3: Train a Logistic Regression model (default parameters)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train Logistic Regression model\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 4: Make predictions and calculate metrics_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Calculate classification metrics\")\nprint(\"=\"*60)\n# Calculate: accuracy, precision, recall, F1-score\n# Your code here...\n\n# Task 5: Create and visualize confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create confusion matrix and visualize it with seaborn heatmap\n# Your code here...\n\n# Task 6: Get prediction probabilities and create ROC curve_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: ROC Curve\")\nprint(\"=\"*60)\n# Get probabilities using .predict_proba()\n# Calculate ROC curve (fpr, tpr, thresholds)\n# Calculate AUC score\n# Plot ROC curve with AUC value\n# Your code here...\n\n# Task 7: Train model with class weights to handle imbalance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Handle class imbalance with class weights\")\nprint(\"=\"*60)\n# Train new model with class_weight='balanced'\n# Compare metrics with previous model\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     27\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     28\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 35\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_03_svm.ipynb",
      "status": "failed",
      "execution_time": 1.9177839756011963,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 3: Support Vector Machine (SVM) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)\n\nInstructions:\n1. Load the provided dataset_2. Train SVM models with different kernels (Linear, RBF, Polynomial)\n3. Compare their performance_4. Tune hyperparameters (C and gamma for RBF)\n5. Visualize decision boundaries (if 2D) or compare metrics_6. Find the best kernel and hyperparameters\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score\n)\n\n# Generate sample classification data_np.random.seed(123)\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=500, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data and scale features (CRITICAL for SVM!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split and scale data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Linear SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Linear SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='linear', C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Train RBF SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train RBF SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='rbf', C=1.0, gamma='scale'\n# Evaluate and print metrics\n# Your code here...\n\n# Task 4: Train Polynomial SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train Polynomial SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='poly', degree=3, C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 5: Compare all three kernels_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare kernels\")\nprint(\"=\"*60)\n# Create a comparison table or visualization\n# Show which kernel performs best\n# Your code here...\n\n# Task 6: Tune C parameter for RBF kernel_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Tune C parameter for RBF\")\nprint(\"=\"*60)\n# Try different C values: [0.1, 1.0, 10.0, 100.0]\n# Find the best C value\n# Your code here...\n\n# Task 7: (Optional) Tune gamma parameter for RBF_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: (Optional) Tune gamma parameter\")\nprint(\"=\"*60)\n# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]\n# Find the best gamma value\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     28\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 3: Support Vector Machine (SVM) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)\n\nInstructions:\n1. Load the provided dataset_2. Train SVM models with different kernels (Linear, RBF, Polynomial)\n3. Compare their performance_4. Tune hyperparameters (C and gamma for RBF)\n5. Visualize decision boundaries (if 2D) or compare metrics_6. Find the best kernel and hyperparameters\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score\n)\n\n# Generate sample classification data_np.random.seed(123)\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=500, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data and scale features (CRITICAL for SVM!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split and scale data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Linear SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Linear SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='linear', C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Train RBF SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train RBF SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='rbf', C=1.0, gamma='scale'\n# Evaluate and print metrics\n# Your code here...\n\n# Task 4: Train Polynomial SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train Polynomial SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='poly', degree=3, C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 5: Compare all three kernels_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare kernels\")\nprint(\"=\"*60)\n# Create a comparison table or visualization\n# Show which kernel performs best\n# Your code here...\n\n# Task 6: Tune C parameter for RBF kernel_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Tune C parameter for RBF\")\nprint(\"=\"*60)\n# Try different C values: [0.1, 1.0, 10.0, 100.0]\n# Find the best C value\n# Your code here...\n\n# Task 7: (Optional) Tune gamma parameter for RBF_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: (Optional) Tune gamma parameter\")\nprint(\"=\"*60)\n# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]\n# Find the best gamma value\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     28\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_04_knn.ipynb",
      "status": "failed",
      "execution_time": 1.644146203994751,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)\n\nInstructions:\n1. Load the provided dataset_2. Scale the features (CRITICAL for KNN!)\n3. Train KNN models with different K values_4. Find the optimal K value using validation_5. Evaluate the final model with optimal K_6. Compare KNN with and without feature scaling (demonstrate importance)\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=800, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Demonstrate why scaling is critical_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Compare KNN with and without scaling\")\nprint(\"=\"*60)\n# Train KNN WITHOUT scaling (use original data)\n# Train KNN WITH scaling (use StandardScaler)\n# Compare accuracies - show the difference!\n# Your code here...\n\n# Task 3: Find optimal K value_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Find optimal K value\")\nprint(\"=\"*60)\n# Test K values from 1 to 30 (odd numbers only)\n# Plot K vs Accuracy (both train and test)\n# Find the K with best test accuracy\n# Your code here...\n\n# Task 4: Train final KNN model with optimal K_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train final model with optimal K\")\nprint(\"=\"*60)\n# Train KNN with the best K value found\n# Evaluate with all metrics (accuracy, precision, recall, F1)\n# Your code here...\n\n# Task 5: Create confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create and visualize confusion matrix\n# Your code here...\n\n# Task 6: (Optional) Compare KNN with other classifiers_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: (Optional) Compare with other classifiers\")\nprint(\"=\"*60)\n# Compare KNN with Logistic Regression or Decision Tree\n# Show which performs better on this dataset\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 4 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     26\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     27\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)\n\nInstructions:\n1. Load the provided dataset_2. Scale the features (CRITICAL for KNN!)\n3. Train KNN models with different K values_4. Find the optimal K value using validation_5. Evaluate the final model with optimal K_6. Compare KNN with and without feature scaling (demonstrate importance)\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=800, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Demonstrate why scaling is critical_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Compare KNN with and without scaling\")\nprint(\"=\"*60)\n# Train KNN WITHOUT scaling (use original data)\n# Train KNN WITH scaling (use StandardScaler)\n# Compare accuracies - show the difference!\n# Your code here...\n\n# Task 3: Find optimal K value_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Find optimal K value\")\nprint(\"=\"*60)\n# Test K values from 1 to 30 (odd numbers only)\n# Plot K vs Accuracy (both train and test)\n# Find the K with best test accuracy\n# Your code here...\n\n# Task 4: Train final KNN model with optimal K_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train final model with optimal K\")\nprint(\"=\"*60)\n# Train KNN with the best K value found\n# Evaluate with all metrics (accuracy, precision, recall, F1)\n# Your code here...\n\n# Task 5: Create confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create and visualize confusion matrix\n# Your code here...\n\n# Task 6: (Optional) Compare KNN with other classifiers_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: (Optional) Compare with other classifiers\")\nprint(\"=\"*60)\n# Compare KNN with Logistic Regression or Decision Tree\n# Show which performs better on this dataset\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 4 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     26\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     27\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7376277446746826,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as \nfrom sklearn.model_selection import np\nfrom from sklearn.tree import train_test_split\nfrom from sklearn.ensemble import DecisionTreeClassifier\nfrom from sklearn.metrics import RandomForestClassifier_from(accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as \nfrom sklearn.model_selection import np\nfrom from sklearn.tree import train_test_split\nfrom from sklearn.ensemble import DecisionTreeClassifier\nfrom from sklearn.metrics import RandomForestClassifier_from(accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_02_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.6661498546600342,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 2: Logistic Regression Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064aInstructions:1. Load the provided dataset2. Train a Logistic Regression classifier3. Calculate and display all classification metrics (accuracy, precision, recall, F1)4. Create and visualize a confusion matrix5. Create and visualize an ROC curve6. Experiment with different thresholds7. Handle class imbalance using class weightsDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)\nfrom sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=1000,    n_features=10,    n_informative=6,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Calculate classification metrics\")print(\"=\"*60)# Calculate: accuracy, precision, recall, F1-score# Your code here...# Task 5: Create and visualize confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create confusion matrix and visualize it with seaborn heatmap# Your code here...# Task 6: Get prediction probabilities and create ROC curve\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: ROC Curve\")print(\"=\"*60)# Get probabilities using .predict_proba()# Calculate ROC curve (fpr, tpr, thresholds)# Calculate AUC score# Plot ROC curve with AUC value# Your code here...# Task 7: Train model with class weights to handle imbalance\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Handle class imbalance with class weights\")print(\"=\"*60)# Train new model with class_weight='balanced'# Compare metrics with previous model# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 2: Logistic Regression Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064aInstructions:1. Load the provided dataset2. Train a Logistic Regression classifier3. Calculate and display all classification metrics (accuracy, precision, recall, F1)4. Create and visualize a confusion matrix5. Create and visualize an ROC curve6. Experiment with different thresholds7. Handle class imbalance using class weightsDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)\nfrom sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=1000,    n_features=10,    n_informative=6,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Calculate classification metrics\")print(\"=\"*60)# Calculate: accuracy, precision, recall, F1-score# Your code here...# Task 5: Create and visualize confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create confusion matrix and visualize it with seaborn heatmap# Your code here...# Task 6: Get prediction probabilities and create ROC curve\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: ROC Curve\")print(\"=\"*60)# Get probabilities using .predict_proba()# Calculate ROC curve (fpr, tpr, thresholds)# Calculate AUC score# Plot ROC curve with AUC value# Your code here...# Task 7: Train model with class weights to handle imbalance\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Handle class imbalance with class weights\")print(\"=\"*60)# Train new model with class_weight='balanced'# Compare metrics with previous model# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_03_svm.ipynb",
      "status": "failed",
      "execution_time": 0.7491860389709473,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 3: Support Vector Machine (SVM) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)Instructions:1. Load the provided dataset2. Train SVM models with different kernels (Linear, RBF, Polynomial)3. Compare their performance4. Tune hyperparameters (C and gamma for RBF)5. Visualize decision boundaries (if 2D)\nor compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score)\n# Generate sample classification datanp.random.seed(123)from sklearn.datasets import make_classificationX, y = make_classification(    n_samples=500,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Train Linear SVM\")print(\"=\"*60)# Train SVM with kernel='linear', C=1.0# Evaluate and print metrics# Your code here...# Task 3: Train RBF SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train RBF SVM\")print(\"=\"*60)# Train SVM with kernel='rbf', C=1.0, gamma='scale'# Evaluate and print metrics# Your code here...# Task 4: Train Polynomial SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train Polynomial SVM\")print(\"=\"*60)# Train SVM with kernel='poly', degree=3, C=1.0# Evaluate and print metrics# Your code here...# Task 5: Compare all three kernels\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare kernels\")print(\"=\"*60)# Create a comparison table or visualization# Show which kernel performs best# Your code here...# Task 6: Tune C parameter for RBF kernel\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Tune C parameter for RBF\")print(\"=\"*60)# Try different C values: [0.1, 1.0, 10.0, 100.0]# Find the best C value# Your code here...# Task 7: (Optional) Tune gamma parameter for RBF\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: (Optional) Tune gamma parameter\")print(\"=\"*60)# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]# Find the best gamma value# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    or compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\u001b[0m\n\u001b[0m                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 18)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 3: Support Vector Machine (SVM) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)Instructions:1. Load the provided dataset2. Train SVM models with different kernels (Linear, RBF, Polynomial)3. Compare their performance4. Tune hyperparameters (C and gamma for RBF)5. Visualize decision boundaries (if 2D)\nor compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score)\n# Generate sample classification datanp.random.seed(123)from sklearn.datasets import make_classificationX, y = make_classification(    n_samples=500,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Train Linear SVM\")print(\"=\"*60)# Train SVM with kernel='linear', C=1.0# Evaluate and print metrics# Your code here...# Task 3: Train RBF SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train RBF SVM\")print(\"=\"*60)# Train SVM with kernel='rbf', C=1.0, gamma='scale'# Evaluate and print metrics# Your code here...# Task 4: Train Polynomial SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train Polynomial SVM\")print(\"=\"*60)# Train SVM with kernel='poly', degree=3, C=1.0# Evaluate and print metrics# Your code here...# Task 5: Compare all three kernels\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare kernels\")print(\"=\"*60)# Create a comparison table or visualization# Show which kernel performs best# Your code here...# Task 6: Tune C parameter for RBF kernel\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Tune C parameter for RBF\")print(\"=\"*60)# Try different C values: [0.1, 1.0, 10.0, 100.0]# Find the best C value# Your code here...# Task 7: (Optional) Tune gamma parameter for RBF\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: (Optional) Tune gamma parameter\")print(\"=\"*60)# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]# Find the best gamma value# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    or compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\u001b[0m\n\u001b[0m                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 18)\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_04_knn.ipynb",
      "status": "failed",
      "execution_time": 0.8098139762878418,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)Instructions:1. Load the provided dataset2. Scale the features (CRITICAL for KNN!)3. Train KNN models with different K values4. Find the optimal K value using validation5. Evaluate the final model with optimal K6. Compare KNN with and without feature scaling (demonstrate importance)Dataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)\nfrom sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=800,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Demonstrate why scaling is critical\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Compare KNN with and without scaling\")print(\"=\"*60)# Train KNN WITHOUT scaling (use original data)# Train KNN WITH scaling (use StandardScaler)# Compare accuracies - show the difference!# Your code here...# Task 3: Find optimal K value\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Find optimal K value\")print(\"=\"*60)# Test K values from 1 to 30 (odd numbers only)# Plot K vs Accuracy (both train and test)# Find the K with best test accuracy# Your code here...# Task 4: Train final KNN model with optimal K\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train final model with optimal K\")print(\"=\"*60)# Train KNN with the best K value found# Evaluate with all metrics (accuracy, precision, recall, F1)# Your code here...# Task 5: Create confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create and visualize confusion matrix# Your code here...# Task 6: (Optional) Compare KNN with other classifiers\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: (Optional) Compare with other classifiers\")print(\"=\"*60)# Compare KNN with Logistic Regression or Decision Tree# Show which performs better on this dataset# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 4 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)Instructions:1. Load the provided dataset2. Scale the features (CRITICAL for KNN!)3. Train KNN models with different K values4. Find the optimal K value using validation5. Evaluate the final model with optimal K6. Compare KNN with and without feature scaling (demonstrate importance)Dataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)\nfrom sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=800,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Demonstrate why scaling is critical\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Compare KNN with and without scaling\")print(\"=\"*60)# Train KNN WITHOUT scaling (use original data)# Train KNN WITH scaling (use StandardScaler)# Compare accuracies - show the difference!# Your code here...# Task 3: Find optimal K value\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Find optimal K value\")print(\"=\"*60)# Test K values from 1 to 30 (odd numbers only)# Plot K vs Accuracy (both train and test)# Find the K with best test accuracy# Your code here...# Task 4: Train final KNN model with optimal K\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train final model with optimal K\")print(\"=\"*60)# Train KNN with the best K value found# Evaluate with all metrics (accuracy, precision, recall, F1)# Your code here...# Task 5: Create confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create and visualize confusion matrix# Your code here...# Task 6: (Optional) Compare KNN with other classifiers\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: (Optional) Compare with other classifiers\")print(\"=\"*60)# Compare KNN with Logistic Regression or Decision Tree# Show which performs better on this dataset# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 4 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit4-clustering/examples/01_kmeans_clustering.ipynb",
      "status": "failed",
      "execution_time": 1.8050930500030518,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world US Crime Statistics dataset\n# This is REAL state crime data for Internal Intelligence analysis\n# K-Means will identify states with similar crime patterns!\n\nprint(\"\\n\ud83d\udce5 Loading US Crime Statistics Dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062c\u0631\u064a\u0645\u0629 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\ntry:\n # Load crime statistics dataset\n df = # File not found: ../../datasets/raw/crime_statistics.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\u2705 Real-world Crime Statistics dataset loaded!\")\nprint(f\" \ud83d\udcca This is REAL crime data (UCI Communities and Crime dataset)\")\n print(f\" \ud83d\udcc8 Contains {len(df)} communities with 4 crime metrics\")\n print(f\" \ud83c\udfaf Features: Murder, Assault, UrbanPop, Rape\")\nprint(f\" \ud83d\udca1 GDI Application: Internal Intelligence - identifying communities with similar crime patterns\")\nprint(f\"\\n\ud83d\udd0d Important: Understanding Unsupervised Learning\")\nprint(\" \u26a0\ufe0f The 'State' column is NOT a label - it's just an identifier (like row ID)\")\n print(\" \u2705 Unsupervised learning means: NO TARGET VARIABLE (no 'correct' clusters)\")\n print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\nfor clustering\")\n print(\" \u2705 The State/Community names are EXCLUDED from clustering (just for reference)\")\n print(\" \u2705 Clustering finds patterns WITHOUT knowing the 'correct' answer\")\nprint(\"\\n\ud83d\udcca Dataset Structure:\")\nprint(\" - State/Community: Identifier only (NOT used for clustering)\")\n print(\" - Murder, Assault, UrbanPop, Rape: Features used for clustering\")\nprint(\" - NO TARGET VARIABLE: This is why it's unsupervised!\")\nprint(\" - Clustering will discover groups automatically (no labels to learn from)\")\n \n # Prepare features for clustering\n # IMPORTANT: Exclude State column - it's just an identifier, NOT a feature or label!\n # In unsupervised learning:\n # - NO labels/targets (no \"correct\" clusters to learn)\n # - Only features (Murder, Assault, UrbanPop, Rape)\n # - State column is just for identification (like row numbers)\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n X_all = df[feature_cols].values # Only use the 4 features, exclude State column\n \n # Use 2 features for 2D visualization (Murder, Assault - most important crime metrics)\n X_2d = df[['Murder', 'Assault']].values\n \n print(f\"\\n\ud83d\udcca Data Preparation:\")\nprint(f\" - X_2d: 2 features for visualization (Murder, Assault)\")\n print(f\" - X_all: All 4 features for clustering (Murder, Assault, UrbanPop, Rape)\")\n print(f\" - We'll use X_all for clustering, X_2d for visualization\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Please ensure 'crime_statistics.csv' is in '../../datasets/raw/'\")\nprint(\" Creating minimal structure for demonstration...\")\n # Fallback: Create minimal structure\n X_all = np.random.randn(50, 4)\n X_2d = X_all[:, [0, 1]]\n df = pd.DataFrame(X_all, columns=['Murder', 'Assault', 'UrbanPop', 'Rape'])\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n print(\" \u26a0\ufe0f Using synthetic data - please download the real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 21)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world US Crime Statistics dataset\n# This is REAL state crime data for Internal Intelligence analysis\n# K-Means will identify states with similar crime patterns!\n\nprint(\"\\n\ud83d\udce5 Loading US Crime Statistics Dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062c\u0631\u064a\u0645\u0629 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\ntry:\n # Load crime statistics dataset\n df = # File not found: ../../datasets/raw/crime_statistics.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\u2705 Real-world Crime Statistics dataset loaded!\")\nprint(f\" \ud83d\udcca This is REAL crime data (UCI Communities and Crime dataset)\")\n print(f\" \ud83d\udcc8 Contains {len(df)} communities with 4 crime metrics\")\n print(f\" \ud83c\udfaf Features: Murder, Assault, UrbanPop, Rape\")\nprint(f\" \ud83d\udca1 GDI Application: Internal Intelligence - identifying communities with similar crime patterns\")\nprint(f\"\\n\ud83d\udd0d Important: Understanding Unsupervised Learning\")\nprint(\" \u26a0\ufe0f The 'State' column is NOT a label - it's just an identifier (like row ID)\")\n print(\" \u2705 Unsupervised learning means: NO TARGET VARIABLE (no 'correct' clusters)\")\n print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\nfor clustering\")\n print(\" \u2705 The State/Community names are EXCLUDED from clustering (just for reference)\")\n print(\" \u2705 Clustering finds patterns WITHOUT knowing the 'correct' answer\")\nprint(\"\\n\ud83d\udcca Dataset Structure:\")\nprint(\" - State/Community: Identifier only (NOT used for clustering)\")\n print(\" - Murder, Assault, UrbanPop, Rape: Features used for clustering\")\nprint(\" - NO TARGET VARIABLE: This is why it's unsupervised!\")\nprint(\" - Clustering will discover groups automatically (no labels to learn from)\")\n \n # Prepare features for clustering\n # IMPORTANT: Exclude State column - it's just an identifier, NOT a feature or label!\n # In unsupervised learning:\n # - NO labels/targets (no \"correct\" clusters to learn)\n # - Only features (Murder, Assault, UrbanPop, Rape)\n # - State column is just for identification (like row numbers)\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n X_all = df[feature_cols].values # Only use the 4 features, exclude State column\n \n # Use 2 features for 2D visualization (Murder, Assault - most important crime metrics)\n X_2d = df[['Murder', 'Assault']].values\n \n print(f\"\\n\ud83d\udcca Data Preparation:\")\nprint(f\" - X_2d: 2 features for visualization (Murder, Assault)\")\n print(f\" - X_all: All 4 features for clustering (Murder, Assault, UrbanPop, Rape)\")\n print(f\" - We'll use X_all for clustering, X_2d for visualization\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Please ensure 'crime_statistics.csv' is in '../../datasets/raw/'\")\nprint(\" Creating minimal structure for demonstration...\")\n # Fallback: Create minimal structure\n X_all = np.random.randn(50, 4)\n X_2d = X_all[:, [0, 1]]\n df = pd.DataFrame(X_all, columns=['Murder', 'Assault', 'UrbanPop', 'Rape'])\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n print(\" \u26a0\ufe0f Using synthetic data - please download the real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 21)\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/02_hierarchical_clustering.ipynb",
      "status": "passed",
      "execution_time": 3.319798231124878,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/03_pca.ipynb",
      "status": "failed",
      "execution_time": 1.7976329326629639,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"3. PCA with 2 Components (for visualization)\")\nprint(\"PCA \u0645\u0639 \u0645\u0643\u0648\u0646\u064a\u0646 (\u0644\u0644\u062a\u062e\u064a\u0644)\")\nprint(\"=\" * 60)\n\n# Create PCA with 2 components\n# n_components=2: Reduce high-dimensional data to 2 dimensions\n# This allows us to visualize the data in 2D!\npca_2d = PCA(n_components=2, random_state=73)  # Using 73 for consistency\n# .fit_transform(data)\n# - Two operations in one: .fit() then .transform()\n#   1. .fit(): Learns parameters from data (mean/std, categories, etc.)\n#   2. .transform(): Applies transformation using learned parameters\n# - Use on training data\n# - For test data, use only .transform() (don't refit!)\n\nX_pca_2d = pca_2d.fit_transform(X_scaled)\n\n# Calculate explained variance\npc1_var = pca_2d.explained_variance_ratio_[0]\npc2_var = pca_2d.explained_variance_ratio_[1]\ntotal_var = pc1_var + pc2_var\n\nprint(f\"\\n\ud83d\udcca PCA Results (2 Components):\")\nprint(f\"   PC1: {pc1_var:.4f} ({pc1_var*100:.2f}% variance)\")\nprint(f\"   PC2: {pc2_var:.4f} ({pc2_var*100:.2f}% variance)\")\nprint(f\"   Total: {total_var:.4f} ({total_var*100:.2f}% variance)\")\n\n# Add interpretation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Interpreting 2-Component PCA | \u062a\u0641\u0633\u064a\u0631 PCA \u0628\u0645\u0643\u0648\u0646\u064a\u0646\")\nprint(\"=\" * 60)\n\nprint(f\"\\n\ud83d\udcca Dimensionality Reduction Summary:\")\nprint(f\"   - Original dimensions: {X_scaled.shape[1]} features\")\nprint(f\"   - Reduced dimensions: 2 components\")\nprint(f\"   - Reduction: {((X_scaled.shape[1] - 2)\nX_scaled.shape[1] * 100):.1f}% fewer dimensions ({X_scaled.shape[1]} \u2192 2)\")\nprint(f\"   - Information preserved: {total_var*100:.2f}% of variance\")\n\nif total_var >= 0.95:\n    print(f\"   - \u2705 Excellent reduction! >95% variance preserved\")\n    print(f\"   - Can safely use 2D for visualization without losing much information\")\nelif total_var >= 0.90:\n    print(f\"   - \u2705 Good reduction! >90% variance preserved\")\n    print(f\"   - Acceptable for visualization, some information lost\")\nelse:\n    print(f\"   - \u26a0\ufe0f  Significant information loss (<90% preserved)\")\n    print(f\"   - May need more components for accurate representation\")\n\nprint(f\"\\n\ud83d\udcca Component Importance:\")\nprint(f\"   - PC1: {pc1_var*100:.2f}% variance (dominant component)\")\nprint(f\"   - PC2: {pc2_var*100:.2f}% variance (secondary component)\")\nprint(f\"   - PC1 is {pc1_var/pc2_var:.1f}x more important than PC2\")\n\nprint(f\"\\n\ud83d\udcda What This Teaches Us:\")\nprint(f\"   - PCA reduces dimensions while preserving most information\")\nprint(f\"   - 2 components are perfect for 2D visualization\")\nprint(f\"   - Can plot high-dimensional data in 2D/3D for visualization\")\nprint(f\"   - Trade-off: Fewer components = less information but simpler visualization\")\nprint(f\"   - Use 2-3 components for visualization, more for ML models\")\n\nprint(f\"\\n   \u2705 Reduced from {X_scaled.shape[1]} dimensions to 2 dimensions!\")\nprint(f\"   - Kept {total_var*100:.1f}% of original variance\")\nprint(f\"   - Can now visualize high-dimensional network traffic data in 2D!\")\nprint(f\"   - Lost {100-total_var*100:.1f}% of information (acceptable for visualization)\")\nprint(f\"   - GDI Application: Cyber Threats - network traffic visualized for threat pattern analysis\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[6], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   - Reduction: {((X_scaled.shape[1] - 2)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"3. PCA with 2 Components (for visualization)\")\nprint(\"PCA \u0645\u0639 \u0645\u0643\u0648\u0646\u064a\u0646 (\u0644\u0644\u062a\u062e\u064a\u0644)\")\nprint(\"=\" * 60)\n\n# Create PCA with 2 components\n# n_components=2: Reduce high-dimensional data to 2 dimensions\n# This allows us to visualize the data in 2D!\npca_2d = PCA(n_components=2, random_state=73)  # Using 73 for consistency\n# .fit_transform(data)\n# - Two operations in one: .fit() then .transform()\n#   1. .fit(): Learns parameters from data (mean/std, categories, etc.)\n#   2. .transform(): Applies transformation using learned parameters\n# - Use on training data\n# - For test data, use only .transform() (don't refit!)\n\nX_pca_2d = pca_2d.fit_transform(X_scaled)\n\n# Calculate explained variance\npc1_var = pca_2d.explained_variance_ratio_[0]\npc2_var = pca_2d.explained_variance_ratio_[1]\ntotal_var = pc1_var + pc2_var\n\nprint(f\"\\n\ud83d\udcca PCA Results (2 Components):\")\nprint(f\"   PC1: {pc1_var:.4f} ({pc1_var*100:.2f}% variance)\")\nprint(f\"   PC2: {pc2_var:.4f} ({pc2_var*100:.2f}% variance)\")\nprint(f\"   Total: {total_var:.4f} ({total_var*100:.2f}% variance)\")\n\n# Add interpretation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Interpreting 2-Component PCA | \u062a\u0641\u0633\u064a\u0631 PCA \u0628\u0645\u0643\u0648\u0646\u064a\u0646\")\nprint(\"=\" * 60)\n\nprint(f\"\\n\ud83d\udcca Dimensionality Reduction Summary:\")\nprint(f\"   - Original dimensions: {X_scaled.shape[1]} features\")\nprint(f\"   - Reduced dimensions: 2 components\")\nprint(f\"   - Reduction: {((X_scaled.shape[1] - 2)\nX_scaled.shape[1] * 100):.1f}% fewer dimensions ({X_scaled.shape[1]} \u2192 2)\")\nprint(f\"   - Information preserved: {total_var*100:.2f}% of variance\")\n\nif total_var >= 0.95:\n    print(f\"   - \u2705 Excellent reduction! >95% variance preserved\")\n    print(f\"   - Can safely use 2D for visualization without losing much information\")\nelif total_var >= 0.90:\n    print(f\"   - \u2705 Good reduction! >90% variance preserved\")\n    print(f\"   - Acceptable for visualization, some information lost\")\nelse:\n    print(f\"   - \u26a0\ufe0f  Significant information loss (<90% preserved)\")\n    print(f\"   - May need more components for accurate representation\")\n\nprint(f\"\\n\ud83d\udcca Component Importance:\")\nprint(f\"   - PC1: {pc1_var*100:.2f}% variance (dominant component)\")\nprint(f\"   - PC2: {pc2_var*100:.2f}% variance (secondary component)\")\nprint(f\"   - PC1 is {pc1_var/pc2_var:.1f}x more important than PC2\")\n\nprint(f\"\\n\ud83d\udcda What This Teaches Us:\")\nprint(f\"   - PCA reduces dimensions while preserving most information\")\nprint(f\"   - 2 components are perfect for 2D visualization\")\nprint(f\"   - Can plot high-dimensional data in 2D/3D for visualization\")\nprint(f\"   - Trade-off: Fewer components = less information but simpler visualization\")\nprint(f\"   - Use 2-3 components for visualization, more for ML models\")\n\nprint(f\"\\n   \u2705 Reduced from {X_scaled.shape[1]} dimensions to 2 dimensions!\")\nprint(f\"   - Kept {total_var*100:.1f}% of original variance\")\nprint(f\"   - Can now visualize high-dimensional network traffic data in 2D!\")\nprint(f\"   - Lost {100-total_var*100:.1f}% of information (acceptable for visualization)\")\nprint(f\"   - GDI Application: Cyber Threats - network traffic visualized for threat pattern analysis\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[6], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   - Reduction: {((X_scaled.shape[1] - 2)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/04_lda_tsne_umap.ipynb",
      "status": "failed",
      "execution_time": 0.6815309524536133,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets \nimport make_classification, load_iris\nfrom sklearn.discriminant_analysis \nimport LinearDiscriminantAnalysis\nfrom sklearn.decomposition \nimport PCA\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom sklearn.metrics \nimport accuracy_score\n\n# Try importing t-SNE and UMAP\ntry:\n    from sklearn.manifold \nimport TSNE_HAS_TSNE = True\nexcept ImportError:\n    HAS_TSNE = False_\nprint(\"\u26a0\ufe0f  t-SNE not available (install scikit-learn)\")\n\ntry:\n    import umap_HAS_UMAP = True\nexcept ImportError:\n    HAS_UMAP = False_\nprint(\"\u26a0\ufe0f  UMAP not available (install with: pip install umap-learn)\")\n\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets \nimport make_classification, load_iris\nfrom sklearn.discriminant_analysis \nimport LinearDiscriminantAnalysis\nfrom sklearn.decomposition \nimport PCA\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom sklearn.metrics \nimport accuracy_score\n\n# Try importing t-SNE and UMAP\ntry:\n    from sklearn.manifold \nimport TSNE_HAS_TSNE = True\nexcept ImportError:\n    HAS_TSNE = False_\nprint(\"\u26a0\ufe0f  t-SNE not available (install scikit-learn)\")\n\ntry:\n    import umap_HAS_UMAP = True\nexcept ImportError:\n    HAS_UMAP = False_\nprint(\"\u26a0\ufe0f  UMAP not available (install with: pip install umap-learn)\")\n\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/05_elbow_method_silhouette_score.ipynb",
      "status": "failed",
      "execution_time": 0.6223199367523193,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.metrics \nimport silhouette_score\nfrom sklearn.datasets \nimport make_blobs_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nElbow Method and Silhouette Score\")\nprint(\"=\" * 60)\n\nprint(\"\\nElbow Method:\")\nprint(\"  - Plot within-cluster sum of squares (WCSS)\")\nprint(\"  - Look for 'elbow' in the curve\")\nprint(\"  - Indicates optimal k\")\n\nprint(\"\\nSilhouette Score:\")\nprint(\"  - Measures cluster quality\")\nprint(\"  - Range: -1 to 1\")\nprint(\"  - Higher is better\")\nprint(\"  - Compare across different k values\")\n\nprint(\"\\n\u2705 Cluster optimization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.metrics \nimport silhouette_score\nfrom sklearn.datasets \nimport make_blobs_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nElbow Method and Silhouette Score\")\nprint(\"=\" * 60)\n\nprint(\"\\nElbow Method:\")\nprint(\"  - Plot within-cluster sum of squares (WCSS)\")\nprint(\"  - Look for 'elbow' in the curve\")\nprint(\"  - Indicates optimal k\")\n\nprint(\"\\nSilhouette Score:\")\nprint(\"  - Measures cluster quality\")\nprint(\"  - Range: -1 to 1\")\nprint(\"  - Higher is better\")\nprint(\"  - Compare across different k values\")\n\nprint(\"\\n\u2705 Cluster optimization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/06_evaluating_clustering_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.8138799667358398,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nfrom sklearn.metrics \nimport davies_bouldin_score, calinski_harabasz_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nEvaluating Clustering Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nClustering Metrics:\")\nprint(\"  - Silhouette Score: Cohesion and separation\")\nprint(\"  - Adjusted Rand Index: Agreement with ground truth\")\nprint(\"  - Normalized Mutual Information: Information shared\")\nprint(\"  - Davies-Bouldin Index: Average similarity ratio\")\nprint(\"  - Calinski-Harabasz Index: Ratio of between/within cluster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Silhouette: General quality assessment\")\nprint(\"  - ARI/NMI: When ground truth available\")\nprint(\"  - DB Index: Lower is better\")\nprint(\"  - CH Index: Higher is better\")\n\nprint(\"\\n\u2705 Clustering evaluation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nfrom sklearn.metrics \nimport davies_bouldin_score, calinski_harabasz_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nEvaluating Clustering Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nClustering Metrics:\")\nprint(\"  - Silhouette Score: Cohesion and separation\")\nprint(\"  - Adjusted Rand Index: Agreement with ground truth\")\nprint(\"  - Normalized Mutual Information: Information shared\")\nprint(\"  - Davies-Bouldin Index: Average similarity ratio\")\nprint(\"  - Calinski-Harabasz Index: Ratio of between/within cluster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Silhouette: General quality assessment\")\nprint(\"  - ARI/NMI: When ground truth available\")\nprint(\"  - DB Index: Lower is better\")\nprint(\"  - CH Index: Higher is better\")\n\nprint(\"\\n\u2705 Clustering evaluation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/evaluating_clustering_models_using_appropriate_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.5445871353149414,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/using_elbow_method_and_silhouette_score_to_determine_optimal_number_of_clusters.ipynb",
      "status": "failed",
      "execution_time": 0.5347349643707275,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7993528842926025,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.cluster import rom KMeans, AgglomerativeClusteringf\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster import rom KMeans, AgglomerativeClusteringf\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.cluster import rom KMeans, AgglomerativeClusteringf\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster import rom KMeans, AgglomerativeClusteringf\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit4-clustering/exercises/exercise_02_pca.ipynb",
      "status": "failed",
      "execution_time": 0.7318079471588135,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\n\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)\n\nInstructions:\n1. Load the provided dataset_2. Apply PCA to reduce dimensionality_3. Analyze explained variance_4. Choose optimal number of components_5. Visualize data in reduced dimensions_6. Compare original vs PCA-transformed data\n\nDataset: Multi-dimensional dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n\n# Load Iris dataset (4 features, 3 classes)\niris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\nX = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Features: {feature_names}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Scale the data (CRITICAL for PCA!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Scale data\")\nprint(\"=\"*60)\n# Use StandardScaler\n# Your code here...\n\n# Task 2: Apply PCA with all components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Apply PCA (all components)\")\nprint(\"=\"*60)\n# Create PCA object\n# Fit and transform the data\n# Your code here...\n\n# Task 3: Analyze explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Explained variance analysis\")\nprint(\"=\"*60)\n# Get explained_variance_ratio_ for each component\n# Calculate cumulative explained variance\n# Print: Each component's variance, cumulative variance\n# Your code here...\n\n# Task 4: Visualize explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Visualize explained variance\")\nprint(\"=\"*60)\n# Plot: Component number vs Explained variance\n# Plot: Component number vs Cumulative explained variance\n# Your code here...\n\n# Task 5: Reduce to 2D for visualization_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Reduce to 2D\")\nprint(\"=\"*60)\n# Apply PCA with n_components=2\n# Transform data to 2D\n# Visualize in 2D (color by original class labels)\n# Your code here...\n\n# Task 6: Find optimal number of components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Find optimal number of components\")\nprint(\"=\"*60)\n# Find number of components that explain 95% of variance\n# Find number of components that explain 99% of variance\n# Your code here...\n\n# Task 7: Compare original vs PCA-transformed_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Compare original vs PCA\")\nprint(\"=\"*60)\n# Show: Original has 4 features, PCA can reduce to 2-3\n# Show: PCA preserves most information with fewer features\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    iris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\n\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)\n\nInstructions:\n1. Load the provided dataset_2. Apply PCA to reduce dimensionality_3. Analyze explained variance_4. Choose optimal number of components_5. Visualize data in reduced dimensions_6. Compare original vs PCA-transformed data\n\nDataset: Multi-dimensional dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n\n# Load Iris dataset (4 features, 3 classes)\niris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\nX = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Features: {feature_names}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Scale the data (CRITICAL for PCA!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Scale data\")\nprint(\"=\"*60)\n# Use StandardScaler\n# Your code here...\n\n# Task 2: Apply PCA with all components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Apply PCA (all components)\")\nprint(\"=\"*60)\n# Create PCA object\n# Fit and transform the data\n# Your code here...\n\n# Task 3: Analyze explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Explained variance analysis\")\nprint(\"=\"*60)\n# Get explained_variance_ratio_ for each component\n# Calculate cumulative explained variance\n# Print: Each component's variance, cumulative variance\n# Your code here...\n\n# Task 4: Visualize explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Visualize explained variance\")\nprint(\"=\"*60)\n# Plot: Component number vs Explained variance\n# Plot: Component number vs Cumulative explained variance\n# Your code here...\n\n# Task 5: Reduce to 2D for visualization_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Reduce to 2D\")\nprint(\"=\"*60)\n# Apply PCA with n_components=2\n# Transform data to 2D\n# Visualize in 2D (color by original class labels)\n# Your code here...\n\n# Task 6: Find optimal number of components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Find optimal number of components\")\nprint(\"=\"*60)\n# Find number of components that explain 95% of variance\n# Find number of components that explain 99% of variance\n# Your code here...\n\n# Task 7: Compare original vs PCA-transformed_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Compare original vs PCA\")\nprint(\"=\"*60)\n# Show: Original has 4 features, PCA can reduce to 2-3\n# Show: PCA preserves most information with fewer features\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    iris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit4-clustering/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.859713077545166,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.cluster import plt\nfrom KMeans, from sklearn.preprocessing import AgglomerativeClustering\nfrom from sklearn.metrics import StandardScaler\nfrom silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.cluster import plt\nfrom KMeans, from sklearn.preprocessing import AgglomerativeClustering\nfrom from sklearn.metrics import StandardScaler\nfrom silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "Course 04/unit4-clustering/solutions/solution_02_pca.ipynb",
      "status": "failed",
      "execution_time": 0.600656270980835,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)Instructions:1. Load the provided dataset2. Apply PCA to reduce dimensionality3. Analyze explained variance4. Choose optimal number of components5. Visualize data in reduced dimensions6. Compare original vs PCA-transformed dataDataset: Multi-dimensional dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n# Load Iris dataset (4 features, 3 classes)iris = load_iris()X = iris.datay = iris.targetfeature_names = iris.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Apply PCA (all components)\")print(\"=\"*60)# Create PCA object# Fit and transform the data# Your code here...# Task 3: Analyze explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Explained variance analysis\")print(\"=\"*60)# Get explained_variance_ratio_ for each component# Calculate cumulative explained variance# Print: Each component's variance, cumulative variance# Your code here...# Task 4: Visualize explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Visualize explained variance\")print(\"=\"*60)# Plot: Component number vs Explained variance# Plot: Component number vs Cumulative explained variance# Your code here...# Task 5: Reduce to 2D for visualization\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Reduce to 2D\")print(\"=\"*60)# Apply PCA with n_components=2# Transform data to 2D# Visualize in 2D (color by original class labels)# Your code here...# Task 6: Find optimal number of components\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Find optimal number of components\")print(\"=\"*60)# Find number of components that explain 95% of variance# Find number of components that explain 99% of variance# Your code here...# Task 7: Compare original vs PCA-transformed\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Compare original vs PCA\")print(\"=\"*60)# Show: Original has 4 features, PCA can reduce to 2-3# Show: PCA preserves most information with fewer features# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)Instructions:1. Load the provided dataset2. Apply PCA to reduce dimensionality3. Analyze explained variance4. Choose optimal number of components5. Visualize data in reduced dimensions6. Compare original vs PCA-transformed dataDataset: Multi-dimensional dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n# Load Iris dataset (4 features, 3 classes)iris = load_iris()X = iris.datay = iris.targetfeature_names = iris.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Apply PCA (all components)\")print(\"=\"*60)# Create PCA object# Fit and transform the data# Your code here...# Task 3: Analyze explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Explained variance analysis\")print(\"=\"*60)# Get explained_variance_ratio_ for each component# Calculate cumulative explained variance# Print: Each component's variance, cumulative variance# Your code here...# Task 4: Visualize explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Visualize explained variance\")print(\"=\"*60)# Plot: Component number vs Explained variance# Plot: Component number vs Cumulative explained variance# Your code here...# Task 5: Reduce to 2D for visualization\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Reduce to 2D\")print(\"=\"*60)# Apply PCA with n_components=2# Transform data to 2D# Visualize in 2D (color by original class labels)# Your code here...# Task 6: Find optimal number of components\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Find optimal number of components\")print(\"=\"*60)# Find number of components that explain 95% of variance# Find number of components that explain 99% of variance# Your code here...# Task 7: Compare original vs PCA-transformed\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Compare original vs PCA\")print(\"=\"*60)# Show: Original has 4 features, PCA can reduce to 2-3# Show: PCA preserves most information with fewer features# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/01_grid_search.ipynb",
      "status": "passed",
      "execution_time": 56.22885799407959,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/02_boosting.ipynb",
      "status": "passed",
      "execution_time": 1.9850192070007324,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/03_cross_validation_hyperparameter_tuning.ipynb",
      "status": "failed",
      "execution_time": 0.7465047836303711,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport cross_val_score, KFold\nfrom sklearn.model_selection \nimport validation_curve\nfrom sklearn.ensemble \nimport RandomForestClassifier_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nCross-Validation and Hyperparameter Tuning\")\nprint(\"=\" * 60)\n\nprint(\"\\nCross-Validation:\")\nprint(\"  - k-fold CV: Split into k folds\")\nprint(\"  - Stratified CV: Preserve class distribution\")\nprint(\"  - Leave-one-out: Each sample as test\")\n\nprint(\"\\nHyperparameter Tuning:\")\nprint(\"  - Grid Search: Exhaustive search\")\nprint(\"  - Random Search: Random sampling\")\nprint(\"  - Validation curves: Visualize parameter impact\")\nprint(\"  - Nested CV: Avoid overfitting\")\n\nprint(\"\\n\u2705 CV and hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport cross_val_score, KFold\nfrom sklearn.model_selection \nimport validation_curve\nfrom sklearn.ensemble \nimport RandomForestClassifier_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nCross-Validation and Hyperparameter Tuning\")\nprint(\"=\" * 60)\n\nprint(\"\\nCross-Validation:\")\nprint(\"  - k-fold CV: Split into k folds\")\nprint(\"  - Stratified CV: Preserve class distribution\")\nprint(\"  - Leave-one-out: Each sample as test\")\n\nprint(\"\\nHyperparameter Tuning:\")\nprint(\"  - Grid Search: Exhaustive search\")\nprint(\"  - Random Search: Random sampling\")\nprint(\"  - Validation curves: Visualize parameter impact\")\nprint(\"  - Nested CV: Avoid overfitting\")\n\nprint(\"\\n\u2705 CV and hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/04_grid_search_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.7967360019683838,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint, uniform_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nGrid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search over parameter grid\")\nprint(\"  - Guarantees finding best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling of parameters\")\nprint(\"  - More efficient for large spaces\")\nprint(\"  - Often finds good solutions faster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Grid Search: Small parameter spaces\")\nprint(\"  - Random Search: Large parameter spaces\")\nprint(\"  - Both use cross-validation\")\n\nprint(\"\\n\u2705 Search strategies concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint, uniform_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nGrid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search over parameter grid\")\nprint(\"  - Guarantees finding best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling of parameters\")\nprint(\"  - More efficient for large spaces\")\nprint(\"  - Often finds good solutions faster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Grid Search: Small parameter spaces\")\nprint(\"  - Random Search: Large parameter spaces\")\nprint(\"  - Both use cross-validation\")\n\nprint(\"\\n\u2705 Search strategies concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/05_comparing_boosting_traditional_methods.ipynb",
      "status": "passed",
      "execution_time": 1.5968830585479736,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/applying_confusion_matrices_plotting_roc_curves_for_classification_models.ipynb",
      "status": "failed",
      "execution_time": 0.535301923751831,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/comparing_performance_with_traditional_methods.ipynb",
      "status": "failed",
      "execution_time": 0.7389259338378906,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/evaluating_models_on_real_datasets_using_performance_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.610914945602417,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/implementing_cross_validation_and_hyperparameter_tuning_using_python.ipynb",
      "status": "failed",
      "execution_time": 0.7916548252105713,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/implementing_final_project_applying_learned_techniques_on_real_dataset_evaluatin.ipynb",
      "status": "failed",
      "execution_time": 0.7423579692840576,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/tuning_models_for_optimal_performance_and_documenting_improvements.ipynb",
      "status": "failed",
      "execution_time": 0.816176176071167,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/using_grid_search_and_random_search_in_scikit_learn_to_optimize_parameters.ipynb",
      "status": "failed",
      "execution_time": 0.5867860317230225,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7409977912902832,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_reportf\nfrom sklearn.datasets import rom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import rom make_classification\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_reportf\nfrom sklearn.datasets import rom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import rom make_classification\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit5-model-selection/exercises/exercise_02_boosting.ipynb",
      "status": "failed",
      "execution_time": 1.683690071105957,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Exercise 2: Boosting Algorithms Practice\n\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632\n\nInstructions:\n1. Load the provided dataset_2. Train XGBoost model (if available)\n3. Train LightGBM model (if available)\n4. Compare with Random Forest (bagging)\n5. Compare boosting algorithms with each other_6. Interpret feature importance_7. Understand boosting vs bagging\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve\n)\nfrom sklearn.datasets import load_breast_cancer\n\n# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\nX = cancer_data.data_y = cancer_data.target_df = pd.DataFrame(X, columns=cancer_data.feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Random Forest (bagging - for comparison)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Random Forest (bagging)\")\nprint(\"=\"*60)\n# Train RandomForestClassifier\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Try to import and train XGBoost_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train XGBoost (if available)\")\nprint(\"=\"*60)\n# Try: import xgboost as xgb\n# If available: Train XGBClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 4: Try to import and train LightGBM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train LightGBM (if available)\")\nprint(\"=\"*60)\n# Try: import lightgbm as lgb\n# If available: Train LGBMClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 5: Compare all models_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare models\")\nprint(\"=\"*60)\n# Create comparison table\n# Show: Random Forest vs XGBoost vs LightGBM\n# Show which performs best\n# Your code here...\n\n# Task 6: Feature importance comparison_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Feature importance\")\nprint(\"=\"*60)\n# Get feature importance from all models\n# Visualize and compare\n# Show which features are most important\n# Your code here...\n\n# Task 7: Understand boosting vs bagging_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Boosting vs Bagging\")\nprint(\"=\"*60)\n# Explain the difference:\n# - Bagging (RF): Models trained in parallel, then averaged\n# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_breast_cancer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mtarget_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mcancer_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'X' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Exercise 2: Boosting Algorithms Practice\n\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632\n\nInstructions:\n1. Load the provided dataset_2. Train XGBoost model (if available)\n3. Train LightGBM model (if available)\n4. Compare with Random Forest (bagging)\n5. Compare boosting algorithms with each other_6. Interpret feature importance_7. Understand boosting vs bagging\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve\n)\nfrom sklearn.datasets import load_breast_cancer\n\n# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\nX = cancer_data.data_y = cancer_data.target_df = pd.DataFrame(X, columns=cancer_data.feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Random Forest (bagging - for comparison)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Random Forest (bagging)\")\nprint(\"=\"*60)\n# Train RandomForestClassifier\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Try to import and train XGBoost_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train XGBoost (if available)\")\nprint(\"=\"*60)\n# Try: import xgboost as xgb\n# If available: Train XGBClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 4: Try to import and train LightGBM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train LightGBM (if available)\")\nprint(\"=\"*60)\n# Try: import lightgbm as lgb\n# If available: Train LGBMClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 5: Compare all models_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare models\")\nprint(\"=\"*60)\n# Create comparison table\n# Show: Random Forest vs XGBoost vs LightGBM\n# Show which performs best\n# Your code here...\n\n# Task 6: Feature importance comparison_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Feature importance\")\nprint(\"=\"*60)\n# Get feature importance from all models\n# Visualize and compare\n# Show which features are most important\n# Your code here...\n\n# Task 7: Understand boosting vs bagging_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Boosting vs Bagging\")\nprint(\"=\"*60)\n# Explain the difference:\n# - Bagging (RF): Models trained in parallel, then averaged\n# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_breast_cancer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mtarget_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mcancer_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'X' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit5-model-selection/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6726357936859131,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as \nfrom sklearn.model_selection import np\nfrom train_test_split, from sklearn.ensemble import GridSearchCV\nfrom from sklearn.metrics import RandomForestClassifier\nfrom accuracy_score, from sklearn.datasets import classification_report\nfrom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as \nfrom sklearn.model_selection import np\nfrom train_test_split, from sklearn.ensemble import GridSearchCV\nfrom from sklearn.metrics import RandomForestClassifier\nfrom accuracy_score, from sklearn.datasets import classification_report\nfrom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "Course 04/unit5-model-selection/solutions/solution_02_boosting.ipynb",
      "status": "failed",
      "execution_time": 0.684736967086792,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 5 - Exercise 2: Boosting Algorithms Practice\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632Instructions:1. Load the provided dataset2. Train XGBoost model (if available)3. Train LightGBM model (if available)4. Compare with Random Forest (bagging)5. Compare boosting algorithms with each other6. Interpret feature importance7. Understand boosting vs baggingDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)\nfrom sklearn.datasets import load_breast_cancer\n# Load real-world Breast Cancer datasetcancer_data = load_breast_cancer()X = cancer_data.datay = cancer_data.targetdf = pd.DataFrame(X, columns=cancer_data.feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train Random Forest (bagging - for comparison)print(\"\\n\" + \"=\"*60)print(\"Task 2: Train Random Forest (bagging)\")print(\"=\"*60)# Train RandomForestClassifier# Evaluate and print metrics# Your code here...# Task 3: Try to import and train XGBoost\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train XGBoost (if available)\")print(\"=\"*60)# Try: import xgboost as xgb# If available: Train XGBClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 4: Try to import and train LightGBM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train LightGBM (if available)\")print(\"=\"*60)# Try: import lightgbm as lgb# If available: Train LGBMClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 5: Compare all models\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare models\")print(\"=\"*60)# Create comparison table# Show: Random Forest vs XGBoost vs LightGBM# Show which performs best# Your code here...# Task 6: Feature importance comparison\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Feature importance\")print(\"=\"*60)# Get feature importance from all models# Visualize and compare# Show which features are most important# Your code here...# Task 7: Understand boosting vs bagging\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Boosting vs Bagging\")print(\"=\"*60)# Explain the difference:# - Bagging (RF): Models trained in parallel, then averaged# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 5 - Exercise 2: Boosting Algorithms Practice\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632Instructions:1. Load the provided dataset2. Train XGBoost model (if available)3. Train LightGBM model (if available)4. Compare with Random Forest (bagging)5. Compare boosting algorithms with each other6. Interpret feature importance7. Understand boosting vs baggingDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)\nfrom sklearn.datasets import load_breast_cancer\n# Load real-world Breast Cancer datasetcancer_data = load_breast_cancer()X = cancer_data.datay = cancer_data.targetdf = pd.DataFrame(X, columns=cancer_data.feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train Random Forest (bagging - for comparison)print(\"\\n\" + \"=\"*60)print(\"Task 2: Train Random Forest (bagging)\")print(\"=\"*60)# Train RandomForestClassifier# Evaluate and print metrics# Your code here...# Task 3: Try to import and train XGBoost\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train XGBoost (if available)\")print(\"=\"*60)# Try: import xgboost as xgb# If available: Train XGBClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 4: Try to import and train LightGBM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train LightGBM (if available)\")print(\"=\"*60)# Try: import lightgbm as lgb# If available: Train LGBMClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 5: Compare all models\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare models\")print(\"=\"*60)# Create comparison table# Show: Random Forest vs XGBoost vs LightGBM# Show which performs best# Your code here...# Task 6: Feature importance comparison\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Feature importance\")print(\"=\"*60)# Get feature importance from all models# Visualize and compare# Show which features are most important# Your code here...# Task 7: Understand boosting vs bagging\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Boosting vs Bagging\")print(\"=\"*60)# Explain the difference:# - Bagging (RF): Models trained in parallel, then averaged# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "Course 05/unit1-introduction/examples/01_data_science_intro.ipynb",
      "status": "passed",
      "execution_time": 2.537147283554077,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/02_pandas_numpy_basics.ipynb",
      "status": "failed",
      "execution_time": 1.9507341384887695,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83d\udeab DEMONSTRATING THE DEAD END: pandas Performance on Large Data\")\nprint(\"=\" * 70)\n\nimport time\n\n# Create a large dataset to demonstrate the problem\n# Why 1 million rows? Large enough to show performance issues, realistic for real-world data\nprint(\"\\n\ud83d\udcca Creating large dataset (1 million rows)...\")\nlarge_n = 1_000_000  # 1 million rows\n\n# Simulate large sales dataset\nlarge_data = {\n    'sales': np.random.normal(1000, 200, large_n),\n    'customers': np.random.poisson(50, large_n),\n    'product_id': np.random.randint(1, 100, large_n),\n    'region': np.random.choice(['North', 'South', 'East', 'West'], large_n)\n}\n\n# Time pandas operations on large dataset\nprint(f\"\\n\u23f1\ufe0f  Testing pandas performance on {large_n:,} rows...\")\nstart_time = time.time()\n\nlarge_df = pd.DataFrame(large_data)\n\n# Perform common operations\nresult = large_df.groupby('region')['sales'].mean()\ntotal_sales = large_df['sales'].sum()\navg_customers = large_df['customers'].mean()\n\npandas_time = time.time() - start_time\n\nprint(f\"\\n\u2705 pandas completed operations in {pandas_time:.2f} seconds\")\nprint(f\"   - Created DataFrame: {large_df.shape[0]:,} rows \u00d7 {large_df.shape[1]} columns\")\nprint(f\"   - Grouped by region and calculated mean sales\")\nprint(f\"   - Calculated total sales and average customers\")\nprint(f\"\\n\u26a0\ufe0f  Performance Issue:\")\nprint(f\"   - {pandas_time:.2f} seconds for 1 million rows\")\nprint(f\"   - For 10 million rows, this would take ~{pandas_time * 10:.1f} seconds ({pandas_time * 10\n60:.1f} minutes)\")\nprint(f\"   - For 100 million rows, this would take ~{pandas_time * 100\n60:.1f} minutes\")\nprint(f\"\\n\ud83d\udca1 The Problem:\")\nprint(f\"   - pandas uses CPU processing (single-threaded for many operations)\")\nprint(f\"   - Large datasets require more time and memory\")\nprint(f\"   - Real-world datasets can be 10-100x larger than this!\")\n\nprint(\"\\n\" + \"=\" * 70)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[10], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   - For 10 million rows, this would take ~{pandas_time * 10:.1f} seconds ({pandas_time * 10\u001b[0m\n\u001b[0m                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83d\udeab DEMONSTRATING THE DEAD END: pandas Performance on Large Data\")\nprint(\"=\" * 70)\n\nimport time\n\n# Create a large dataset to demonstrate the problem\n# Why 1 million rows? Large enough to show performance issues, realistic for real-world data\nprint(\"\\n\ud83d\udcca Creating large dataset (1 million rows)...\")\nlarge_n = 1_000_000  # 1 million rows\n\n# Simulate large sales dataset\nlarge_data = {\n    'sales': np.random.normal(1000, 200, large_n),\n    'customers': np.random.poisson(50, large_n),\n    'product_id': np.random.randint(1, 100, large_n),\n    'region': np.random.choice(['North', 'South', 'East', 'West'], large_n)\n}\n\n# Time pandas operations on large dataset\nprint(f\"\\n\u23f1\ufe0f  Testing pandas performance on {large_n:,} rows...\")\nstart_time = time.time()\n\nlarge_df = pd.DataFrame(large_data)\n\n# Perform common operations\nresult = large_df.groupby('region')['sales'].mean()\ntotal_sales = large_df['sales'].sum()\navg_customers = large_df['customers'].mean()\n\npandas_time = time.time() - start_time\n\nprint(f\"\\n\u2705 pandas completed operations in {pandas_time:.2f} seconds\")\nprint(f\"   - Created DataFrame: {large_df.shape[0]:,} rows \u00d7 {large_df.shape[1]} columns\")\nprint(f\"   - Grouped by region and calculated mean sales\")\nprint(f\"   - Calculated total sales and average customers\")\nprint(f\"\\n\u26a0\ufe0f  Performance Issue:\")\nprint(f\"   - {pandas_time:.2f} seconds for 1 million rows\")\nprint(f\"   - For 10 million rows, this would take ~{pandas_time * 10:.1f} seconds ({pandas_time * 10\n60:.1f} minutes)\")\nprint(f\"   - For 100 million rows, this would take ~{pandas_time * 100\n60:.1f} minutes\")\nprint(f\"\\n\ud83d\udca1 The Problem:\")\nprint(f\"   - pandas uses CPU processing (single-threaded for many operations)\")\nprint(f\"   - Large datasets require more time and memory\")\nprint(f\"   - Real-world datasets can be 10-100x larger than this!\")\n\nprint(\"\\n\" + \"=\" * 70)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[10], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   - For 10 million rows, this would take ~{pandas_time * 10:.1f} seconds ({pandas_time * 10\u001b[0m\n\u001b[0m                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/03_cudf_introduction.ipynb",
      "status": "failed",
      "execution_time": 0.9792699813842773,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83d\udd17 SOLVING THE PROBLEM FROM EXAMPLE 2\")\nprint(\"=\" * 70)\nprint(\"\\n\ud83d\udccb Problem from Example 2:\")\nprint(\"   - pandas was slow on large datasets (millions of rows)\")\nprint(\"   - CPU processing had performance limitations\")\nprint(\"   - We need a solution for large-scale data science\")\nprint(\"\\n\ud83d\udca1 Solution: GPU Acceleration with cuDF\")\nprint(\"   - Same operations, but 10-100x faster\")\nprint(\"   - Parallel processing on GPU\")\nprint(\"   - Perfect for large datasets!\")\n\n# Create the same large dataset from Example 2\nprint(\"\\n\ud83d\udcca Creating same large dataset from Example 2 (1 million rows)...\")\nlarge_n = 1_000_000  # Same size as Example 2\n\nlarge_data = {\n    'sales': np.random.normal(1000, 200, large_n),\n    'customers': np.random.poisson(50, large_n),\n    'product_id': np.random.randint(1, 100, large_n),\n    'region': np.random.choice(['North', 'South', 'East', 'West'], large_n)\n}\n\n# Test pandas (CPU) - same as Example 2\nprint(\"\\n\u23f1\ufe0f  Testing pandas (CPU) performance...\")\nstart_time = time.time()\npandas_df = pd.DataFrame(large_data)\npandas_result = pandas_df.groupby('region')['sales'].mean()\npandas_total = pandas_df['sales'].sum()\npandas_avg = pandas_df['customers'].mean()\npandas_time = time.time() - start_time\n\nprint(f\"   \u2705 pandas (CPU): {pandas_time:.2f} seconds\")\n\n# Test cuDF (GPU) if available\nif CUDF_AVAILABLE:\n    print(\"\\n\u23f1\ufe0f  Testing cuDF (GPU) performance...\")\n    start_time = time.time()\n    cudf_df = cudf.DataFrame(large_data)\n    cudf_result = cudf_df.groupby('region')['sales'].mean()\n    cudf_total = cudf_df['sales'].sum()\n    cudf_avg = cudf_df['customers'].mean()\n    cudf_time = time.time() - start_time\n    \n    speedup = pandas_time\ncudf_time\n    print(f\"   \u2705 cuDF (GPU): {cudf_time:.2f} seconds\")\n    print(f\"\\n\ud83d\ude80 GPU Speedup: {speedup:.1f}x faster!\")\n    print(f\"   - pandas: {pandas_time:.2f}s\")\n    print(f\"   - cuDF: {cudf_time:.2f}s\")\n    print(f\"   - Time saved: {pandas_time - cudf_time:.2f} seconds ({((pandas_time - cudf_time)\npandas_time * 100):.1f}% faster)\")\nelse:\n    # Simulate GPU speedup for demonstration\n    cudf_time = pandas_time\n10  # Simulate 10x speedup\n    speedup = pandas_time\ncudf_time\n    print(f\"\\n\u23f1\ufe0f  Simulated cuDF (GPU) performance (cuDF not available):\")\n    print(f\"   \u2705 cuDF (GPU): {cudf_time:.2f} seconds (simulated)\")\n    print(f\"\\n\ud83d\ude80 GPU Speedup: {speedup:.1f}x faster! (simulated)\")\n    print(f\"   - pandas: {pandas_time:.2f}s\")\n    print(f\"   - cuDF: {cudf_time:.2f}s (simulated)\")\n    print(f\"   - Time saved: {pandas_time - cudf_time:.2f} seconds ({((pandas_time - cudf_time)\npandas_time * 100):.1f}% faster)\")\n\nprint(\"\\n\ud83d\udca1 Key Insight:\")\nprint(\"   - Same operations, same data, but GPU is MUCH faster!\")\nprint(\"   - This solves the performance dead end from Example 2!\")\nprint(\"   - For even larger datasets, the speedup is even more dramatic!\")\n\nprint(\"\\n\" + \"=\" * 70)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 47\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   \u2705 cuDF (GPU): {cudf_time:.2f} seconds\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83d\udd17 SOLVING THE PROBLEM FROM EXAMPLE 2\")\nprint(\"=\" * 70)\nprint(\"\\n\ud83d\udccb Problem from Example 2:\")\nprint(\"   - pandas was slow on large datasets (millions of rows)\")\nprint(\"   - CPU processing had performance limitations\")\nprint(\"   - We need a solution for large-scale data science\")\nprint(\"\\n\ud83d\udca1 Solution: GPU Acceleration with cuDF\")\nprint(\"   - Same operations, but 10-100x faster\")\nprint(\"   - Parallel processing on GPU\")\nprint(\"   - Perfect for large datasets!\")\n\n# Create the same large dataset from Example 2\nprint(\"\\n\ud83d\udcca Creating same large dataset from Example 2 (1 million rows)...\")\nlarge_n = 1_000_000  # Same size as Example 2\n\nlarge_data = {\n    'sales': np.random.normal(1000, 200, large_n),\n    'customers': np.random.poisson(50, large_n),\n    'product_id': np.random.randint(1, 100, large_n),\n    'region': np.random.choice(['North', 'South', 'East', 'West'], large_n)\n}\n\n# Test pandas (CPU) - same as Example 2\nprint(\"\\n\u23f1\ufe0f  Testing pandas (CPU) performance...\")\nstart_time = time.time()\npandas_df = pd.DataFrame(large_data)\npandas_result = pandas_df.groupby('region')['sales'].mean()\npandas_total = pandas_df['sales'].sum()\npandas_avg = pandas_df['customers'].mean()\npandas_time = time.time() - start_time\n\nprint(f\"   \u2705 pandas (CPU): {pandas_time:.2f} seconds\")\n\n# Test cuDF (GPU) if available\nif CUDF_AVAILABLE:\n    print(\"\\n\u23f1\ufe0f  Testing cuDF (GPU) performance...\")\n    start_time = time.time()\n    cudf_df = cudf.DataFrame(large_data)\n    cudf_result = cudf_df.groupby('region')['sales'].mean()\n    cudf_total = cudf_df['sales'].sum()\n    cudf_avg = cudf_df['customers'].mean()\n    cudf_time = time.time() - start_time\n    \n    speedup = pandas_time\ncudf_time\n    print(f\"   \u2705 cuDF (GPU): {cudf_time:.2f} seconds\")\n    print(f\"\\n\ud83d\ude80 GPU Speedup: {speedup:.1f}x faster!\")\n    print(f\"   - pandas: {pandas_time:.2f}s\")\n    print(f\"   - cuDF: {cudf_time:.2f}s\")\n    print(f\"   - Time saved: {pandas_time - cudf_time:.2f} seconds ({((pandas_time - cudf_time)\npandas_time * 100):.1f}% faster)\")\nelse:\n    # Simulate GPU speedup for demonstration\n    cudf_time = pandas_time\n10  # Simulate 10x speedup\n    speedup = pandas_time\ncudf_time\n    print(f\"\\n\u23f1\ufe0f  Simulated cuDF (GPU) performance (cuDF not available):\")\n    print(f\"   \u2705 cuDF (GPU): {cudf_time:.2f} seconds (simulated)\")\n    print(f\"\\n\ud83d\ude80 GPU Speedup: {speedup:.1f}x faster! (simulated)\")\n    print(f\"   - pandas: {pandas_time:.2f}s\")\n    print(f\"   - cuDF: {cudf_time:.2f}s (simulated)\")\n    print(f\"   - Time saved: {pandas_time - cudf_time:.2f} seconds ({((pandas_time - cudf_time)\npandas_time * 100):.1f}% faster)\")\n\nprint(\"\\n\ud83d\udca1 Key Insight:\")\nprint(\"   - Same operations, same data, but GPU is MUCH faster!\")\nprint(\"   - This solves the performance dead end from Example 2!\")\nprint(\"   - For even larger datasets, the speedup is even more dramatic!\")\n\nprint(\"\\n\" + \"=\" * 70)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 47\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   \u2705 cuDF (GPU): {cudf_time:.2f} seconds\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/04_python_basics_loops_conditions.ipynb",
      "status": "passed",
      "execution_time": 0.7482929229736328,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/05_jupyter_notebooks_best_practices.ipynb",
      "status": "passed",
      "execution_time": 0.7370328903198242,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/06_data_structures_lists_dictionaries.ipynb",
      "status": "passed",
      "execution_time": 0.5356101989746094,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/07_data_science_applications.ipynb",
      "status": "passed",
      "execution_time": 0.9411118030548096,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/data_science_applications_working_on_small_real_world_projects_using_data_scienc.ipynb",
      "status": "failed",
      "execution_time": 0.7326791286468506,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/python_programming_executing_python_code_to_solve_basic_tasks_like_arithmetic_op.ipynb",
      "status": "failed",
      "execution_time": 0.7414321899414062,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/using_jupyter_notebooks_writing_and_executing_code_in_jupyter_notebooks_combinin.ipynb",
      "status": "failed",
      "execution_time": 0.7358307838439941,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/working_with_data_structures_performing_tasks_like_indexing_slicing_and_transfor.ipynb",
      "status": "failed",
      "execution_time": 0.7503190040588379,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 1.414564847946167,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "exercise"
    },
    {
      "path": "Course 05/unit1-introduction/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 1.675630807876587,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "other"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/04_data_loading.ipynb",
      "status": "passed",
      "execution_time": 1.1327087879180908,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/05_feature_transformation_scaling_encoding.ipynb",
      "status": "failed",
      "execution_time": 0.7471780776977539,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFeature Transformation: Scaling and Encoding\")\nprint(\"=\" * 60)\n\nprint(\"\\nScaling:\")\nprint(\"  - StandardScaler: Mean 0, std 1\")\nprint(\"  - MinMaxScaler: Range [0, 1]\")\nprint(\"  - RobustScaler: Median and IQR\")\nprint(\"  - Normalization\")\n\nprint(\"\\nEncoding:\")\nprint(\"  - Label Encoding: Ordinal categories\")\nprint(\"  - One-Hot Encoding: Nominal categories\")\nprint(\"  - Target Encoding: Mean target\")\nprint(\"  - Frequency Encoding\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Scaling: Numerical features\")\nprint(\"  - Encoding: Categorical features\")\nprint(\"  - Before ML models\")\nprint(\"  - For distance-based algorithms\")\n\nprint(\"\\n\u2705 Feature transformation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFeature Transformation: Scaling and Encoding\")\nprint(\"=\" * 60)\n\nprint(\"\\nScaling:\")\nprint(\"  - StandardScaler: Mean 0, std 1\")\nprint(\"  - MinMaxScaler: Range [0, 1]\")\nprint(\"  - RobustScaler: Median and IQR\")\nprint(\"  - Normalization\")\n\nprint(\"\\nEncoding:\")\nprint(\"  - Label Encoding: Ordinal categories\")\nprint(\"  - One-Hot Encoding: Nominal categories\")\nprint(\"  - Target Encoding: Mean target\")\nprint(\"  - Frequency Encoding\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Scaling: Numerical features\")\nprint(\"  - Encoding: Categorical features\")\nprint(\"  - Before ML models\")\nprint(\"  - For distance-based algorithms\")\n\nprint(\"\\n\u2705 Feature transformation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/05_missing_values_duplicates.ipynb",
      "status": "failed",
      "execution_time": 1.4453730583190918,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n2. Detecting Missing Values\")\nprint(\"-\" * 70)\nprint(\"\\nMissing values per column\")\nmissing_counts = df.isnull().sum()\nmissing_percent = (df.isnull().sum()\nlen(df)) * 100\nmissing_df = pd.DataFrame({\n'Column': missing_counts.index, 'Missing Count': missing_counts.values,\n'Missing %': missing_percent.values\n})\nmissing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\nprint(missing_df.to_string(index=False))\nprint(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\nprint(f\"  : {df.isnull().sum().sum()}\")\n# Visualize missing values\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('Missing Values Analysis', fontsize=16, weight='bold')\n# Plot 1: Missing values bar chart\nif len(missing_df) > 0:\n    axes[0, 0].bar(missing_df['Column'], missing_df['Missing Count'],\n                   color='#FF6B6B', edgecolor='black')\naxes[0, 0].set_title('Missing Values Count', fontsize=12, weight='bold')\naxes[0, 0].set_xlabel('Column')\naxes[0, 0].set_ylabel('Count')\naxes[0, 0].tick_params(axis='x', rotation=45)\naxes[0, 0].grid(True, alpha=0.3, axis='y')\n# Plot 2: Missing values percentage\nif len(missing_df) > 0:\n    axes[0, 1].bar(missing_df['Column'], missing_df['Missing %'],\n                   color='#4ECDC4', edgecolor='black')\naxes[0, 1].set_title('Missing Values Percentage', fontsize=12, weight='bold')\naxes[0, 1].set_xlabel('Column')\naxes[0, 1].set_ylabel('Percentage (%)')\naxes[0, 1].tick_params(axis='x', rotation=45)\naxes[0, 1].grid(True, alpha=0.3, axis='y')\n# Plot 3: Missing values matrix (if missingno available)\nif MISSINGNO_AVAILABLE and msno is not None:\n    try:\n        msno.matrix(df, ax=axes[1, 0], sparkline=False)\n        axes[1, 0].set_title('Missing Values Matrix', fontsize=12, weight='bold')\n    except:\n        axes[1, 0].text(0.5, 0.5, 'Missingno visualization\\nnot available',\n        ha='center', va='center', transform=axes[1, 0].transAxes)\n        axes[1, 0].axis('off')\nelse:\n    axes[1, 0].text(0.5, 0.5, 'Missingno not available\\n(optional library)', ha='center', va='center', transform=axes[1, 0].transAxes)\n    axes[1, 0].axis('off')\n# Plot 4: Heatmap of missing values\nmissing_heatmap = df.isnull()\nsns.heatmap(missing_heatmap, yticklabels=False, cbar=True, ax=axes[1, 1],\ncmap='YlOrRd')\naxes[1, 1].set_title('Missing Values Heatmap', fontsize=12, weight='bold')\nplt.tight_layout()\nplt.savefig('missing_values_analysis.png', dpi=300, bbox_inches='tight')\nprint(\"\\n\u2713 Missing values visualization saved\")\nprint(\"\u2713     \")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    missing_percent = (df.isnull().sum()\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n2. Detecting Missing Values\")\nprint(\"-\" * 70)\nprint(\"\\nMissing values per column\")\nmissing_counts = df.isnull().sum()\nmissing_percent = (df.isnull().sum()\nlen(df)) * 100\nmissing_df = pd.DataFrame({\n'Column': missing_counts.index, 'Missing Count': missing_counts.values,\n'Missing %': missing_percent.values\n})\nmissing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\nprint(missing_df.to_string(index=False))\nprint(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\nprint(f\"  : {df.isnull().sum().sum()}\")\n# Visualize missing values\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('Missing Values Analysis', fontsize=16, weight='bold')\n# Plot 1: Missing values bar chart\nif len(missing_df) > 0:\n    axes[0, 0].bar(missing_df['Column'], missing_df['Missing Count'],\n                   color='#FF6B6B', edgecolor='black')\naxes[0, 0].set_title('Missing Values Count', fontsize=12, weight='bold')\naxes[0, 0].set_xlabel('Column')\naxes[0, 0].set_ylabel('Count')\naxes[0, 0].tick_params(axis='x', rotation=45)\naxes[0, 0].grid(True, alpha=0.3, axis='y')\n# Plot 2: Missing values percentage\nif len(missing_df) > 0:\n    axes[0, 1].bar(missing_df['Column'], missing_df['Missing %'],\n                   color='#4ECDC4', edgecolor='black')\naxes[0, 1].set_title('Missing Values Percentage', fontsize=12, weight='bold')\naxes[0, 1].set_xlabel('Column')\naxes[0, 1].set_ylabel('Percentage (%)')\naxes[0, 1].tick_params(axis='x', rotation=45)\naxes[0, 1].grid(True, alpha=0.3, axis='y')\n# Plot 3: Missing values matrix (if missingno available)\nif MISSINGNO_AVAILABLE and msno is not None:\n    try:\n        msno.matrix(df, ax=axes[1, 0], sparkline=False)\n        axes[1, 0].set_title('Missing Values Matrix', fontsize=12, weight='bold')\n    except:\n        axes[1, 0].text(0.5, 0.5, 'Missingno visualization\\nnot available',\n        ha='center', va='center', transform=axes[1, 0].transAxes)\n        axes[1, 0].axis('off')\nelse:\n    axes[1, 0].text(0.5, 0.5, 'Missingno not available\\n(optional library)', ha='center', va='center', transform=axes[1, 0].transAxes)\n    axes[1, 0].axis('off')\n# Plot 4: Heatmap of missing values\nmissing_heatmap = df.isnull()\nsns.heatmap(missing_heatmap, yticklabels=False, cbar=True, ax=axes[1, 1],\ncmap='YlOrRd')\naxes[1, 1].set_title('Missing Values Heatmap', fontsize=12, weight='bold')\nplt.tight_layout()\nplt.savefig('missing_values_analysis.png', dpi=300, bbox_inches='tight')\nprint(\"\\n\u2713 Missing values visualization saved\")\nprint(\"\u2713     \")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    missing_percent = (df.isnull().sum()\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/06_eda_visualizations.ipynb",
      "status": "passed",
      "execution_time": 1.6971380710601807,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/06_outliers_transformation.ipynb",
      "status": "passed",
      "execution_time": 2.6428868770599365,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/07_cudf_import_export_gpu.ipynb",
      "status": "failed",
      "execution_time": 0.7348051071166992,
      "error": "An error occurred while executing the following cell:\n------------------\n# Try importing cuDF (requires CUDA and RAPIDS installation)\ntry:\n    import cudf\n    import pandas as pd\n    import numpy as np_HAS_CUDF = True_\nprint(\"\u2705 cuDF imported successfully!\")\nprint(f\"cuDF version: {cudf.__version__}\")\nexcept ImportError:\n    HAS_CUDF = False\n    import pandas as pd\n    import numpy as np_\nprint(\"\u26a0\ufe0f  cuDF not available. Install RAPIDS for GPU acceleration:\")\nprint(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\")\nprint(\"   Continuing with Pandas examples...\")\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_HAS_CUDF = True_\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Try importing cuDF (requires CUDA and RAPIDS installation)\ntry:\n    import cudf\n    import pandas as pd\n    import numpy as np_HAS_CUDF = True_\nprint(\"\u2705 cuDF imported successfully!\")\nprint(f\"cuDF version: {cudf.__version__}\")\nexcept ImportError:\n    HAS_CUDF = False\n    import pandas as pd\n    import numpy as np_\nprint(\"\u26a0\ufe0f  cuDF not available. Install RAPIDS for GPU acceleration:\")\nprint(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\")\nprint(\"   Continuing with Pandas examples...\")\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_HAS_CUDF = True_\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/feature_transformation_transforming_data_eg_scaling_encoding_to_prepare_it_for_a.ipynb",
      "status": "failed",
      "execution_time": 0.7360970973968506,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/performing_eda_visualizing_data_distributions_and_relationships_to_discover_insi.ipynb",
      "status": "failed",
      "execution_time": 0.6177420616149902,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/04_chart_types_matplotlib_seaborn.ipynb",
      "status": "passed",
      "execution_time": 1.4876880645751953,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/05_interactive_visualizations_plotly.ipynb",
      "status": "passed",
      "execution_time": 0.8977360725402832,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/06_customizing_annotating_visualizations.ipynb",
      "status": "passed",
      "execution_time": 1.3983469009399414,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/07_matplotlib_basics.ipynb",
      "status": "passed",
      "execution_time": 2.332669973373413,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/07_visualization_best_practices.ipynb",
      "status": "passed",
      "execution_time": 1.706543207168579,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/08_seaborn_plots.ipynb",
      "status": "passed",
      "execution_time": 4.231767177581787,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/09_plotly_interactive.ipynb",
      "status": "passed",
      "execution_time": 1.264631748199463,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/applying_visualization_best_practices_for_data_storytelling.ipynb",
      "status": "failed",
      "execution_time": 0.5744411945343018,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/building_interactive_visualizations_and_dashboards_with_plotly.ipynb",
      "status": "failed",
      "execution_time": 0.6253402233123779,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/creating_various_chart_types_using_matplotlib_and_seaborn.ipynb",
      "status": "failed",
      "execution_time": 0.745380163192749,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/05_pandas_data_manipulation.ipynb",
      "status": "passed",
      "execution_time": 1.0323519706726074,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/06_data_preparation_ml_tasks.ipynb",
      "status": "failed",
      "execution_time": 0.661553144454956,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nData Preparation for ML Tasks\")\nprint(\"=\" * 60)\n\nprint(\"\\nMissing Values:\")\nprint(\"  - Detection: isnull(), info()\")\nprint(\"  - Removal: dropna()\")\nprint(\"  - Imputation: fillna(), SimpleImputer\")\nprint(\"  - Forward/backward fill\")\n\nprint(\"\\nCategorical Encoding:\")\nprint(\"  - Label Encoding\")\nprint(\"  - One-Hot Encoding\")\nprint(\"  - Ordinal Encoding\")\nprint(\"  - Target Encoding\")\n\nprint(\"\\nData Splitting:\")\nprint(\"  - Train/Test split\")\nprint(\"  - Train/Validation/Test\")\nprint(\"  - Stratified splitting\")\nprint(\"  - Time-based splitting\")\n\nprint(\"\\n\u2705 Data preparation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nData Preparation for ML Tasks\")\nprint(\"=\" * 60)\n\nprint(\"\\nMissing Values:\")\nprint(\"  - Detection: isnull(), info()\")\nprint(\"  - Removal: dropna()\")\nprint(\"  - Imputation: fillna(), SimpleImputer\")\nprint(\"  - Forward/backward fill\")\n\nprint(\"\\nCategorical Encoding:\")\nprint(\"  - Label Encoding\")\nprint(\"  - One-Hot Encoding\")\nprint(\"  - Ordinal Encoding\")\nprint(\"  - Target Encoding\")\n\nprint(\"\\nData Splitting:\")\nprint(\"  - Train/Test split\")\nprint(\"  - Train/Validation/Test\")\nprint(\"  - Stratified splitting\")\nprint(\"  - Time-based splitting\")\n\nprint(\"\\n\u2705 Data preparation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/07_implementing_ml_models_scikit_learn.ipynb",
      "status": "failed",
      "execution_time": 0.534661054611206,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge/Lasso Regression\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nWorkflow:\")\nprint(\"  1. Prepare data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge/Lasso Regression\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nWorkflow:\")\nprint(\"  1. Prepare data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/07_implementing_ml_models_sklearn.ipynb",
      "status": "failed",
      "execution_time": 0.6349430084228516,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge, Lasso\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nScikit-learn Workflow:\")\nprint(\"  1. Import model\")\nprint(\"  2. Create instance\")\nprint(\"  3. Fit on training data\")\nprint(\"  4. Predict on test data\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\n\u2705 Scikit-learn ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge, Lasso\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nScikit-learn Workflow:\")\nprint(\"  1. Import model\")\nprint(\"  2. Create instance\")\nprint(\"  3. Fit on training data\")\nprint(\"  4. Predict on test data\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\n\u2705 Scikit-learn ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/08_supervised_learning_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.6493091583251953,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.metrics \nimport accuracy_score, confusion_matrix, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSupervised Learning: Logistic Regression\")\nprint(\"=\" * 60)\n\nprint(\"\\nSupervised Learning:\")\nprint(\"  - Uses labeled training data\")\nprint(\"  - Learns mapping from inputs to outputs\")\nprint(\"  - Can predict on new data\")\nprint(\"  - Classification and regression\")\n\nprint(\"\\nLogistic Regression:\")\nprint(\"  - Binary classification\")\nprint(\"  - Multi-class classification\")\nprint(\"  - Probabilistic output\")\nprint(\"  - Linear decision boundary\")\n\nprint(\"\\nTraining Process:\")\nprint(\"  1. Prepare labeled data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\nprint(\"  5. Make predictions\")\n\nprint(\"\\n\u2705 Supervised learning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.metrics \nimport accuracy_score, confusion_matrix, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSupervised Learning: Logistic Regression\")\nprint(\"=\" * 60)\n\nprint(\"\\nSupervised Learning:\")\nprint(\"  - Uses labeled training data\")\nprint(\"  - Learns mapping from inputs to outputs\")\nprint(\"  - Can predict on new data\")\nprint(\"  - Classification and regression\")\n\nprint(\"\\nLogistic Regression:\")\nprint(\"  - Binary classification\")\nprint(\"  - Multi-class classification\")\nprint(\"  - Probabilistic output\")\nprint(\"  - Linear decision boundary\")\n\nprint(\"\\nTraining Process:\")\nprint(\"  1. Prepare labeled data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\nprint(\"  5. Make predictions\")\n\nprint(\"\\n\u2705 Supervised learning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/09_unsupervised_learning_kmeans.ipynb",
      "status": "passed",
      "execution_time": 1.7493677139282227,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/10_hyperparameter_tuning_grid_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.7571439743041992,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nHyperparameter Tuning: Grid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search\")\nprint(\"  - Tests all combinations\")\nprint(\"  - Guarantees best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling\")\nprint(\"  - More efficient\")\nprint(\"  - Good for large spaces\")\nprint(\"  - Often finds good solutions\")\n\nprint(\"\\nHyperparameters:\")\nprint(\"  - Learning rate\")\nprint(\"  - Number of trees\")\nprint(\"  - Max depth\")\nprint(\"  - Regularization strength\")\n\nprint(\"\\n\u2705 Hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nHyperparameter Tuning: Grid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search\")\nprint(\"  - Tests all combinations\")\nprint(\"  - Guarantees best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling\")\nprint(\"  - More efficient\")\nprint(\"  - Good for large spaces\")\nprint(\"  - Often finds good solutions\")\n\nprint(\"\\nHyperparameters:\")\nprint(\"  - Learning rate\")\nprint(\"  - Number of trees\")\nprint(\"  - Max depth\")\nprint(\"  - Regularization strength\")\n\nprint(\"\\n\u2705 Hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/10_linear_regression.ipynb",
      "status": "passed",
      "execution_time": 1.9009840488433838,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/11_classification.ipynb",
      "status": "passed",
      "execution_time": 2.2631499767303467,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/11_real_world_problem_solving.ipynb",
      "status": "failed",
      "execution_time": 0.85060715675354,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nReal-World Problem Solving\")\nprint(\"=\" * 60)\n\nprint(\"\\nCombining Approaches:\")\nprint(\"  - Unsupervised: Discover patterns\")\nprint(\"  - Supervised: Predict outcomes\")\nprint(\"  - Feature engineering\")\nprint(\"  - Dimensionality reduction\")\n\nprint(\"\\nProblem-Solving Steps:\")\nprint(\"  1. Understand problem\")\nprint(\"  2. Explore data (unsupervised)\")\nprint(\"  3. Engineer features\")\nprint(\"  4. Build predictive model (supervised)\")\nprint(\"  5. Evaluate and iterate\")\n\nprint(\"\\nExample Workflow:\")\nprint(\"  - Clustering for segmentation\")\nprint(\"  - Classification for prediction\")\nprint(\"  - Dimensionality reduction\")\nprint(\"  - Feature selection\")\n\nprint(\"\\n\u2705 Real-world problem solving concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nReal-World Problem Solving\")\nprint(\"=\" * 60)\n\nprint(\"\\nCombining Approaches:\")\nprint(\"  - Unsupervised: Discover patterns\")\nprint(\"  - Supervised: Predict outcomes\")\nprint(\"  - Feature engineering\")\nprint(\"  - Dimensionality reduction\")\n\nprint(\"\\nProblem-Solving Steps:\")\nprint(\"  1. Understand problem\")\nprint(\"  2. Explore data (unsupervised)\")\nprint(\"  3. Engineer features\")\nprint(\"  4. Build predictive model (supervised)\")\nprint(\"  5. Evaluate and iterate\")\n\nprint(\"\\nExample Workflow:\")\nprint(\"  - Clustering for segmentation\")\nprint(\"  - Classification for prediction\")\nprint(\"  - Dimensionality reduction\")\nprint(\"  - Feature selection\")\n\nprint(\"\\n\u2705 Real-world problem solving concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/12_model_evaluation.ipynb",
      "status": "failed",
      "execution_time": 6.205672979354858,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83d\udeab DEMONSTRATING THE DEAD END: CPU Performance on Large Datasets\")\nprint(\"=\" * 70)\n\nimport time\n\n# Simulate large dataset\nprint(f\"\\n\ud83d\udcca Testing CPU Performance on Large Dataset:\")\nlarge_n = 100_000  # 100k samples (real-world can be millions)\n\n# Create large dataset\nX_large = np.random.randn(large_n, 10)\ny_large = (X_large[:, 0] + X_large[:, 1] > 0).astype(int)\n\nprint(f\"   - Dataset size: {large_n:,} samples \u00d7 10 features\")\nprint(f\"   - Task: Training and evaluating model\")\n\n# Time CPU-based training and evaluation\nprint(f\"\\n\u23f1\ufe0f  Testing CPU Performance:\")\nstart_time = time.time()\n\n# Train model\nclf_large = LogisticRegression(random_state=42, max_iter=1000)\nclf_large.fit(X_large, y_large)\n\n# Evaluate with cross-validation (5-fold)\ncv_scores_large = cross_val_score(clf_large, X_large, y_large, cv=5, n_jobs=-1)\n\ncpu_time = time.time() - start_time\n\nprint(f\"   \u2705 CPU completed in {cpu_time:.2f} seconds\")\nprint(f\"   - Training + 5-fold cross-validation\")\nprint(f\"   - Mean CV score: {cv_scores_large.mean():.4f}\")\n\nprint(f\"\\n\u26a0\ufe0f  Performance Issue:\")\nprint(f\"   - {cpu_time:.2f} seconds for 100k samples\")\nprint(f\"   - For 1 million samples, this would take ~{cpu_time * 10:.1f} seconds ({cpu_time * 10\n60:.1f} minutes)\")\nprint(f\"   - For 10 million samples, this would take ~{cpu_time * 100\n60:.1f} minutes\")\nprint(f\"   - Real-world datasets can be 10-100x larger!\")\n\nprint(f\"\\n\ud83d\udca1 The Problem:\")\nprint(f\"   - CPU processing is sequential (one operation at a time)\")\nprint(f\"   - Large datasets require more time and computation\")\nprint(f\"   - Cross-validation multiplies the time (5-fold = 5x training time)\")\nprint(f\"   - For large-scale ML, we need GPU acceleration!\")\n\nprint(f\"\\n\u27a1\ufe0f  Solution Needed:\")\nprint(f\"   - We need GPU acceleration for ML training and evaluation\")\nprint(f\"   - We need parallel processing for faster computation\")\nprint(f\"   - We need GPU-accelerated ML libraries\")\nprint(f\"   - This leads us to Example 13: CPU vs GPU for ML\")\n\nprint(\"\\n\" + \"=\" * 70)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[10], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   - For 1 million samples, this would take ~{cpu_time * 10:.1f} seconds ({cpu_time * 10\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83d\udeab DEMONSTRATING THE DEAD END: CPU Performance on Large Datasets\")\nprint(\"=\" * 70)\n\nimport time\n\n# Simulate large dataset\nprint(f\"\\n\ud83d\udcca Testing CPU Performance on Large Dataset:\")\nlarge_n = 100_000  # 100k samples (real-world can be millions)\n\n# Create large dataset\nX_large = np.random.randn(large_n, 10)\ny_large = (X_large[:, 0] + X_large[:, 1] > 0).astype(int)\n\nprint(f\"   - Dataset size: {large_n:,} samples \u00d7 10 features\")\nprint(f\"   - Task: Training and evaluating model\")\n\n# Time CPU-based training and evaluation\nprint(f\"\\n\u23f1\ufe0f  Testing CPU Performance:\")\nstart_time = time.time()\n\n# Train model\nclf_large = LogisticRegression(random_state=42, max_iter=1000)\nclf_large.fit(X_large, y_large)\n\n# Evaluate with cross-validation (5-fold)\ncv_scores_large = cross_val_score(clf_large, X_large, y_large, cv=5, n_jobs=-1)\n\ncpu_time = time.time() - start_time\n\nprint(f\"   \u2705 CPU completed in {cpu_time:.2f} seconds\")\nprint(f\"   - Training + 5-fold cross-validation\")\nprint(f\"   - Mean CV score: {cv_scores_large.mean():.4f}\")\n\nprint(f\"\\n\u26a0\ufe0f  Performance Issue:\")\nprint(f\"   - {cpu_time:.2f} seconds for 100k samples\")\nprint(f\"   - For 1 million samples, this would take ~{cpu_time * 10:.1f} seconds ({cpu_time * 10\n60:.1f} minutes)\")\nprint(f\"   - For 10 million samples, this would take ~{cpu_time * 100\n60:.1f} minutes\")\nprint(f\"   - Real-world datasets can be 10-100x larger!\")\n\nprint(f\"\\n\ud83d\udca1 The Problem:\")\nprint(f\"   - CPU processing is sequential (one operation at a time)\")\nprint(f\"   - Large datasets require more time and computation\")\nprint(f\"   - Cross-validation multiplies the time (5-fold = 5x training time)\")\nprint(f\"   - For large-scale ML, we need GPU acceleration!\")\n\nprint(f\"\\n\u27a1\ufe0f  Solution Needed:\")\nprint(f\"   - We need GPU acceleration for ML training and evaluation\")\nprint(f\"   - We need parallel processing for faster computation\")\nprint(f\"   - We need GPU-accelerated ML libraries\")\nprint(f\"   - This leads us to Example 13: CPU vs GPU for ML\")\n\nprint(\"\\n\" + \"=\" * 70)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[10], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"   - For 1 million samples, this would take ~{cpu_time * 10:.1f} seconds ({cpu_time * 10\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/13_cpu_vs_gpu_ml.ipynb",
      "status": "failed",
      "execution_time": 1.7045319080352783,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n2. Regression: CPU vs GPU\")\nprint(\"-\" * 70)\nX_train, X_test, y_train, y_test = train_test_split(\nX, y_regression, test_size=0.2, random_state=42)\n# CPU (scikit-learn)\nprint(\"\\nTraining CPU model (scikit-learn)...\")\nstart_time = time.time()\ncpu_model = LinearRegression()\ncpu_model.fit(X_train, y_train)\ncpu_train_time = time.time() - start_time\nstart_time = time.time()\ncpu_pred = cpu_model.predict(X_test)\ncpu_pred_time = time.time() - start_time\ncpu_r2 = r2_score(y_test, cpu_pred)\nprint(f\"CPU Training Time: {cpu_train_time:.4f} seconds\")\nprint(f\"CPU Prediction Time: {cpu_pred_time:.4f} seconds\")\nprint(f\"CPU R\u00b2 Score: {cpu_r2:.4f}\")\n# GPU (cuML) or simulated\nif CUML_AVAILABLE:\n    print(\"\\nTraining GPU model (cuML)...\")\n    start_time = time.time()\n    gpu_model = cuLinearRegression()\n    gpu_model.fit(X_train, y_train)\n    gpu_train_time = time.time() - start_time\n    start_time = time.time()\n    gpu_pred = gpu_model.predict(X_test)\n    gpu_pred_time = time.time() - start_time\n    gpu_r2 = r2_score(y_test.get(), gpu_pred.get()) if hasattr(gpu_pred, 'get') else r2_score(y_test, gpu_pred)\n    print(f\"GPU Training Time: {gpu_train_time:.4f} seconds\")\n    print(f\"GPU Prediction Time: {gpu_pred_time:.4f} seconds\")\n    print(f\"GPU R\u00b2 Score: {gpu_r2:.4f}\")\n    print(f\"\\nSpeedup - Training: {cpu_train_time/gpu_train_time:.2f}x\")\n    print(f\"Speedup - Prediction: {cpu_pred_time/gpu_pred_time:.2f}x\")\nelse:\n    print(\"\\n\u26a0 Simulating GPU performance (cuML not available)\")\n    gpu_train_time = cpu_train_time\n5  # Simulate 5x speedup\n    gpu_pred_time = cpu_pred_time\n5\ngpu_r2 = cpu_r2\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 38\u001b[0;36m\u001b[0m\n\u001b[0;31m    gpu_pred_time = cpu_pred_time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n2. Regression: CPU vs GPU\")\nprint(\"-\" * 70)\nX_train, X_test, y_train, y_test = train_test_split(\nX, y_regression, test_size=0.2, random_state=42)\n# CPU (scikit-learn)\nprint(\"\\nTraining CPU model (scikit-learn)...\")\nstart_time = time.time()\ncpu_model = LinearRegression()\ncpu_model.fit(X_train, y_train)\ncpu_train_time = time.time() - start_time\nstart_time = time.time()\ncpu_pred = cpu_model.predict(X_test)\ncpu_pred_time = time.time() - start_time\ncpu_r2 = r2_score(y_test, cpu_pred)\nprint(f\"CPU Training Time: {cpu_train_time:.4f} seconds\")\nprint(f\"CPU Prediction Time: {cpu_pred_time:.4f} seconds\")\nprint(f\"CPU R\u00b2 Score: {cpu_r2:.4f}\")\n# GPU (cuML) or simulated\nif CUML_AVAILABLE:\n    print(\"\\nTraining GPU model (cuML)...\")\n    start_time = time.time()\n    gpu_model = cuLinearRegression()\n    gpu_model.fit(X_train, y_train)\n    gpu_train_time = time.time() - start_time\n    start_time = time.time()\n    gpu_pred = gpu_model.predict(X_test)\n    gpu_pred_time = time.time() - start_time\n    gpu_r2 = r2_score(y_test.get(), gpu_pred.get()) if hasattr(gpu_pred, 'get') else r2_score(y_test, gpu_pred)\n    print(f\"GPU Training Time: {gpu_train_time:.4f} seconds\")\n    print(f\"GPU Prediction Time: {gpu_pred_time:.4f} seconds\")\n    print(f\"GPU R\u00b2 Score: {gpu_r2:.4f}\")\n    print(f\"\\nSpeedup - Training: {cpu_train_time/gpu_train_time:.2f}x\")\n    print(f\"Speedup - Prediction: {cpu_pred_time/gpu_pred_time:.2f}x\")\nelse:\n    print(\"\\n\u26a0 Simulating GPU performance (cuML not available)\")\n    gpu_train_time = cpu_train_time\n5  # Simulate 5x speedup\n    gpu_pred_time = cpu_pred_time\n5\ngpu_r2 = cpu_r2\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 38\u001b[0;36m\u001b[0m\n\u001b[0;31m    gpu_pred_time = cpu_pred_time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/applying_supervised_learning_algorithms_on_labeled_data_eg_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.6606311798095703,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/applying_unsupervised_learning_techniques_eg_k_means_clustering_on_unlabeled_dat.ipynb",
      "status": "failed",
      "execution_time": 0.8058149814605713,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/cleaning_and_preparing_data_for_ml_tasks_handling_missing_values_encoding_catego.ipynb",
      "status": "failed",
      "execution_time": 0.680150032043457,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/hyperparameter_tuning_using_techniques_like_grid_search_and_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.6286642551422119,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/implementing_ml_models_using_scikit_learn_library_regression_classification.ipynb",
      "status": "failed",
      "execution_time": 0.5263330936431885,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/real_world_problem_solving_using_a_mix_of_supervised_and_unsupervised_learning_a.ipynb",
      "status": "failed",
      "execution_time": 0.6034700870513916,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/working_with_data_using_python_libraries_like_pandas.ipynb",
      "status": "failed",
      "execution_time": 0.6204061508178711,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/14_dask_distributed.ipynb",
      "status": "passed",
      "execution_time": 1.9934589862823486,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/15_rapids_workflows.ipynb",
      "status": "passed",
      "execution_time": 2.160475015640259,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/16_production_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.4361369609832764,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/17_performance_optimization.ipynb",
      "status": "failed",
      "execution_time": 1.0972411632537842,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n3. Memory Optimization\")\nprint(\"-\" * 70)\nprint(\"\\nOriginal memory usage:\")\nprint(f\"Memory: {df.memory_usage(deep=True).sum()\n1024**2:.2f} MB\")\n# Optimize data types\ndf_optimized = df.copy()\ndf_optimized['score'] = df_optimized['score'].astype('int8')\ndf_optimized['category'] = df_optimized['category'].astype('category')\nprint(\"\\nOptimized memory usage:\")\nprint(f\"Memory: {df_optimized.memory_usage(deep=True).sum()\n1024**2:.2f} MB\")\nprint(f\"Reduction: {(1 - df_optimized.memory_usage(deep=True).sum()\ndf.memory_usage(deep=True).sum()) * 100:.1f}%\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[7], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Memory: {df.memory_usage(deep=True).sum()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n3. Memory Optimization\")\nprint(\"-\" * 70)\nprint(\"\\nOriginal memory usage:\")\nprint(f\"Memory: {df.memory_usage(deep=True).sum()\n1024**2:.2f} MB\")\n# Optimize data types\ndf_optimized = df.copy()\ndf_optimized['score'] = df_optimized['score'].astype('int8')\ndf_optimized['category'] = df_optimized['category'].astype('category')\nprint(\"\\nOptimized memory usage:\")\nprint(f\"Memory: {df_optimized.memory_usage(deep=True).sum()\n1024**2:.2f} MB\")\nprint(f\"Reduction: {(1 - df_optimized.memory_usage(deep=True).sum()\ndf.memory_usage(deep=True).sum()) * 100:.1f}%\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[7], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Memory: {df.memory_usage(deep=True).sum()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/18_large_datasets.ipynb",
      "status": "failed",
      "execution_time": 2.4036312103271484,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n3. Memory Efficient Processing\")\nprint(\"-\" * 70)\n# Use iterator to process without loading all into memory\ntotal_sum = 0\ntotal_count = 0\nprint(\"Processing with iterator (memory-efficient)...\")\nstart_time = time.time()\n\nchunk_reader = pd.read_csv(large_file, chunksize=chunk_size)\nchunk_num = 0\nfor chunk_df in chunk_reader:\n    chunk_num += 1\n    # Verify columns exist\n    chunk_df.columns = chunk_df.columns.str.strip()  # Remove any whitespace\n    if 'score' not in chunk_df.columns:\n        print(f\"Warning: Chunk {chunk_num} missing 'score' column. Available: {list(chunk_df.columns)}\")\n        continue\n    \n    chunk_sum = chunk_df['score'].sum()\n    chunk_count = len(chunk_df)\n    total_sum += chunk_sum\n    total_count += chunk_count\n\nif total_count > 0:\n    avg_score = total_sum\ntotal_count\n    iterator_time = time.time() - start_time\n    print(f\"Average score (computed incrementally): {avg_score:.2f}\")\n    print(f\"Processing time: {iterator_time:.4f} seconds\")\n    print(f\"Memory used: Minimal (one chunk at a time)\")\n    print(f\"Processed {chunk_num} chunks\")\nelse:\n    print(\"Error: No valid chunks were processed. Please check the CSV file structure.\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[7], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    iterator_time = time.time() - start_time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n3. Memory Efficient Processing\")\nprint(\"-\" * 70)\n# Use iterator to process without loading all into memory\ntotal_sum = 0\ntotal_count = 0\nprint(\"Processing with iterator (memory-efficient)...\")\nstart_time = time.time()\n\nchunk_reader = pd.read_csv(large_file, chunksize=chunk_size)\nchunk_num = 0\nfor chunk_df in chunk_reader:\n    chunk_num += 1\n    # Verify columns exist\n    chunk_df.columns = chunk_df.columns.str.strip()  # Remove any whitespace\n    if 'score' not in chunk_df.columns:\n        print(f\"Warning: Chunk {chunk_num} missing 'score' column. Available: {list(chunk_df.columns)}\")\n        continue\n    \n    chunk_sum = chunk_df['score'].sum()\n    chunk_count = len(chunk_df)\n    total_sum += chunk_sum\n    total_count += chunk_count\n\nif total_count > 0:\n    avg_score = total_sum\ntotal_count\n    iterator_time = time.time() - start_time\n    print(f\"Average score (computed incrementally): {avg_score:.2f}\")\n    print(f\"Processing time: {iterator_time:.4f} seconds\")\n    print(f\"Memory used: Minimal (one chunk at a time)\")\n    print(f\"Processed {chunk_num} chunks\")\nelse:\n    print(\"Error: No valid chunks were processed. Please check the CSV file structure.\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[7], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    iterator_time = time.time() - start_time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/19_deployment.ipynb",
      "status": "failed",
      "execution_time": 1.5513300895690918,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n4. Monitoring Setup\")\nprint(\"-\" * 70)\nclass ModelMonitor:\n    \"\"\"Simple model monitoring class\"\"\"\n    def__init__(self):\n        self.predictions_log = []\n        self.errors_log = []\n    \n    def log_prediction(self, features, prediction, actual=None):\n        \"\"\"Log prediction for monitoring\"\"\"\n        log_entry = {\n            'timestamp': datetime.now().isoformat(), 'features': features.tolist() if isinstance(features, np.ndarray) else features,\n            'prediction': float(prediction) if np.isscalar(prediction) else prediction.tolist(), 'actual': float(actual) if actual is not None and np.isscalar(actual) else None\n        }\n        self.predictions_log.append(log_entry)\n        logger.info(f\"Logged prediction: {log_entry['prediction']}\")\n    \n    def log_error(self, error_message):\n        \"\"\"Log error for monitoring\"\"\"\n        error_entry = {\n            'timestamp': datetime.now().isoformat(), 'error': error_message\n        }\n        self.errors_log.append(error_entry)\n        logger.error(f\"Logged error: {error_message}\")\n    \n    def get_stats(self):\n        \"\"\"Get monitoring statistics\"\"\"\n        return {\n            'total_predictions': len(self.predictions_log), 'total_errors': len(self.errors_log),\n            'latest_prediction': self.predictions_log[-1] if self.predictions_log else None\n        }\n\nmonitor = ModelMonitor()\n# Simulate monitoring\nfor i in range(5):\n    features = X_test[i:i+1]\n    pred = model.predict(features)[0]\n    actual = y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i]\n    monitor.log_prediction(features[0], pred, actual)\n\nstats = monitor.get_stats()\nprint(f\"\\nMonitoring Statistics:\")\nprint(f\"  Total predictions: {stats['total_predictions']}\")\nprint(f\"  Total errors: {stats['total_errors']}\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[6], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\\n4. Monitoring Setup\")\nprint(\"-\" * 70)\nclass ModelMonitor:\n    \"\"\"Simple model monitoring class\"\"\"\n    def__init__(self):\n        self.predictions_log = []\n        self.errors_log = []\n    \n    def log_prediction(self, features, prediction, actual=None):\n        \"\"\"Log prediction for monitoring\"\"\"\n        log_entry = {\n            'timestamp': datetime.now().isoformat(), 'features': features.tolist() if isinstance(features, np.ndarray) else features,\n            'prediction': float(prediction) if np.isscalar(prediction) else prediction.tolist(), 'actual': float(actual) if actual is not None and np.isscalar(actual) else None\n        }\n        self.predictions_log.append(log_entry)\n        logger.info(f\"Logged prediction: {log_entry['prediction']}\")\n    \n    def log_error(self, error_message):\n        \"\"\"Log error for monitoring\"\"\"\n        error_entry = {\n            'timestamp': datetime.now().isoformat(), 'error': error_message\n        }\n        self.errors_log.append(error_entry)\n        logger.error(f\"Logged error: {error_message}\")\n    \n    def get_stats(self):\n        \"\"\"Get monitoring statistics\"\"\"\n        return {\n            'total_predictions': len(self.predictions_log), 'total_errors': len(self.errors_log),\n            'latest_prediction': self.predictions_log[-1] if self.predictions_log else None\n        }\n\nmonitor = ModelMonitor()\n# Simulate monitoring\nfor i in range(5):\n    features = X_test[i:i+1]\n    pred = model.predict(features)[0]\n    actual = y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i]\n    monitor.log_prediction(features[0], pred, actual)\n\nstats = monitor.get_stats()\nprint(f\"\\nMonitoring Statistics:\")\nprint(f\"  Total predictions: {stats['total_predictions']}\")\nprint(f\"  Total errors: {stats['total_errors']}\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[6], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/accelerated_data_with_gpu_using_rapids_using_rapids_libraries_like_cudf_data_fra.ipynb",
      "status": "failed",
      "execution_time": 0.5351569652557373,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/01_ethical_frameworks.ipynb",
      "status": "passed",
      "execution_time": 1.4470112323760986,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/02_ethical_decision_making.ipynb",
      "status": "failed",
      "execution_time": 0.8105909824371338,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 2: Create the Ethical Decision-Making Framework class\n# This class implements a 6-step process for making ethical decisions in AI\n\n# BEFORE: No structured decision-making process\n# AFTER: We'll have a complete framework with 6 steps, each with questions to guide us\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udccb CREATING ETHICAL DECISION-MAKING FRAMEWORK\")\nprint(\"=\"*80)\nprint(\"\\nThis framework has 6 steps:\")\nprint(\"  1. Identify the Problem\")\nprint(\"  2. Gather Information\")\nprint(\"  3. Identify Stakeholders\")\nprint(\"  4. Apply Ethical Frameworks\")\nprint(\"  5. Evaluate Options\")\nprint(\"  6. Make Decision\\n\")\n\nclass EthicalDecisionFramework:\n    \"\"\"\n    A framework for making ethical decisions in AI development.\n    \n    HOW IT WORKS:\n    1. Defines 6 steps for ethical decision-making\n    2. Each step has questions to guide thinking\n    3. Provides structure for systematic ethical analysis\n    4. Can be applied to any AI ethical dilemma\n    \n    \u23f0 WHEN to use: When facing an ethical decision in AI development\n    \ud83d\udca1 WHY use: Ensures thorough, consistent, and justifiable ethical decisions\n    \"\"\"\n    def__init__(self):\n        # Initialize framework: Set up the 6-step decision-making process\n        # Why a class? It organizes the framework and allows us to reuse it for different scenarios\n        # Define framework steps: Create list of 6 steps with questions for each\n        # Why a list of dictionaries? Each step has multiple attributes (name, description, questions)\n        self.steps = [\n            {\n                'step': 1,  # Step number: First step in the process\n                'name_en': 'Identify the Problem',  # Step name: English name for this step\n                'name_ar': '\u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0645\u0634\u0643\u0644\u0629',  # Step name: Arabic translation\n                'description_en': 'Clearly define the ethical issue or dilemma',  # Description: What this step does\n                'description_ar': '\u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0645\u0634\u0643\u0644\u0629 \u0627\u0644\u0623\u062e\u0644\u0627\u0642\u064a\u0629 \u0623\u0648 \u0627\u0644\u0645\u0639\u0636\u0644\u0629 \u0628\u0648\u0636\u0648\u062d',  # Description: Arabic translation\n                'questions': [  # Guiding questions: Questions to help think through this step\n                    'What is the AI system supposed to do?',  # Question 1: Understand the system's purpose\n                    'What ethical concerns might arise?',  # Question 2: Identify potential ethical issues\n                    'Who are the stakeholders?'  # Question 3: Identify affected parties\n                ]\n            },\n            {\n                'step': 2,  # Step number: Second step\n                'name_en': 'Gather Information',  # Step name: Information gathering\n                'name_ar': '\u062c\u0645\u0639 \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0627\u062a',  # Arabic name\n                'description_en': 'Collect relevant facts and context',  # Description: What this step does\n                'description_ar': '\u062c\u0645\u0639 \u0627\u0644\u062d\u0642\u0627\u0626\u0642 \u0648\u0627\u0644\u0633\u064a\u0627\u0642 \u0630\u0627\u062a \u0627\u0644\u0635\u0644\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to gather information\n                    'What data will be used?',  # Question 1: Understand data requirements\n                    'How will the system be deployed?',  # Question 2: Understand deployment context\n                    'What are the potential impacts?'  # Question 3: Understand consequences\n                ]\n            },\n            {\n                'step': 3,  # Step number: Third step\n                'name_en': 'Identify Stakeholders',  # Step name: Stakeholder identification\n                'name_ar': '\u062a\u062d\u062f\u064a\u062f \u0623\u0635\u062d\u0627\u0628 \u0627\u0644\u0645\u0635\u0644\u062d\u0629',  # Arabic name\n                'description_en': 'List all affected parties',  # Description: What this step does\n                'description_ar': '\u0633\u0631\u062f \u062c\u0645\u064a\u0639 \u0627\u0644\u0623\u0637\u0631\u0627\u0641 \u0627\u0644\u0645\u062a\u0623\u062b\u0631\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to identify stakeholders\n                    'Who will use the system?',  # Question 1: Identify users\n                    'Who might be affected?',  # Question 2: Identify those impacted\n                    'Who has decision-making power?'  # Question 3: Identify decision-makers\n                ]\n            },\n            {\n                'step': 4,  # Step number: Fourth step\n                'name_en': 'Apply Ethical Frameworks',  # Step name: Framework application\n                'name_ar': '\u062a\u0637\u0628\u064a\u0642 \u0627\u0644\u0623\u0637\u0631 \u0627\u0644\u0623\u062e\u0644\u0627\u0642\u064a\u0629',  # Arabic name\n                'description_en': 'Analyze using multiple ethical perspectives',  # Description: What this step does\n                'description_ar': '\u0627\u0644\u062a\u062d\u0644\u064a\u0644 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0648\u062c\u0647\u0627\u062a \u0646\u0638\u0631 \u0623\u062e\u0644\u0627\u0642\u064a\u0629 \u0645\u062a\u0639\u062f\u062f\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to apply frameworks\n                    'What would utilitarianism suggest?',  # Question 1: Utilitarian perspective\n                    'What would deontology require?',  # Question 2: Deontological perspective\n                    'What rights are at stake?'  # Question 3: Rights-based perspective\n                ]\n            },\n            {\n                'step': 5,  # Step number: Fifth step\n                'name_en': 'Evaluate Options',  # Step name: Option evaluation\n                'name_ar': '\u062a\u0642\u064a\u064a\u0645 \u0627\u0644\u062e\u064a\u0627\u0631\u0627\u062a',  # Arabic name\n                'description_en': 'Consider different approaches and their consequences',  # Description: What this step does\n                'description_ar': '\u0627\u0644\u0646\u0638\u0631 \u0641\u064a \u0627\u0644\u0623\u0633\u0627\u0644\u064a\u0628 \u0627\u0644\u0645\u062e\u062a\u0644\u0641\u0629 \u0648\u0639\u0648\u0627\u0642\u0628\u0647\u0627',  # Arabic description\n                'questions': [  # Guiding questions: Questions to evaluate options\n                    'What are the alternative approaches?',  # Question 1: Identify alternatives\n                    'What are the trade-offs?',  # Question 2: Understand trade-offs\n                    'What are the risks and benefits?'  # Question 3: Assess risks and benefits\n                ]\n            },\n            {\n                'step': 6,  # Step number: Sixth step (final decision step)\n                'name_en': 'Make Decision',  # Step name: Decision making\n                'name_ar': '\u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631',  # Arabic name\n                'description_en': 'Choose the most ethical course of action',  # Description: What this step does\n                'description_ar': '\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0645\u0633\u0627\u0631 \u0627\u0644\u0623\u0643\u062b\u0631 \u0623\u062e\u0644\u0627\u0642\u064a\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to make decision\n                    'Which option best balances ethical considerations?',  # Question 1: Find best balance\n                    'Can the decision be justified?',  # Question 2: Ensure justifiability\n                    'Is it transparent and accountable?'  # Question 3: Ensure transparency\n                ]\n            }\n        ]\n        \n        print(\" Framework created with 6 steps!\")\n        print(\"   Each step has guiding questions to help you think through ethical decisions\")\n    \n    def analyze_scenario(self, scenario_name, scenario_data):\n        \"\"\"\n        Analyze an AI scenario using the framework.\n        \n        HOW IT WORKS:\n        1. Takes a scenario name and data dictionary\n        2. Goes through each step of the framework\n        3. Prints step information and guiding questions\n        4. Applies scenario-specific analysis if provided\n        \n        \u23f0 WHEN to use: When you have a specific AI scenario to analyze\n        \ud83d\udca1 WHY use: Ensures systematic analysis following all 6 steps\n        \"\"\"\n        # Print header: Show what scenario we're analyzing\n        print(f\"\\n{'='*80}\")  # Separator: Visual divider\n        print(f\"ETHICAL ANALYSIS: {scenario_name}\")  # Title: Show scenario name\n        print(f\"{'='*80}\\n\")  # Separator: Visual divider\n        \n        # Process each step: Go through framework systematically\n        for step in self.steps:  # Loop through steps: Process each of the 6 steps\n            # Print step information: Show step number, name, and description\n            print(f\"\\nStep {step['step']}: {step['name_en']} ({step['name_ar']})\")  # Step header: Number and name\n            print(\"-\" * 60)  # Separator: Visual divider\n            print(f\"Description: {step['description_en']} ({step['description_ar']})\")  # Description: What this step does\n            \n            # Print guiding questions: Show questions to help think through this step\n            print(f\"\\nKey Questions:\")  # Section header: Questions section\n            for i, question in enumerate(step['questions'], 1):  # Loop through questions: Number each question\n                print(f\"  {i}. {question}\")  # Print question: Show numbered question\n            \n            # Apply scenario analysis: If scenario data provided for this step\n            if scenario_data and step['step'] in scenario_data:  # Check if data exists: Only print if analysis provided\n                print(f\"\\nAnalysis:\")  # Section header: Analysis section\n                print(f\"  {scenario_data[step['step']]}\")  # Print analysis: Show scenario-specific analysis\n\n# Create framework instance to demonstrate\nprint(\"\\nCreating framework instance...\")\nframework = EthicalDecisionFramework()\nprint(\" Framework ready to use!\")\n\n    \n    # Analyze scenario: Apply framework to the hiring system scenario\n\n# Run example analysis\n# ============================================================================\n# STAKEHOLDER ANALYSIS VISUALIZATION\n# ============================================================================\ndef create_stakeholder_analysis():\n    \"\"\"Create a stakeholder impact matrix\"\"\"\n    stakeholders = ['Users', 'Developers', 'Company', 'Society', 'Regulators']\n    impact_levels = [9, 7, 8, 6, 7]  # High impact scores\n    influence_levels = [5, 8, 9, 4, 9]  # Influence scores\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n    # Impact chart\n    colors = plt.cm.viridis(np.linspace(0, 1, len(stakeholders)))\n    bars1 = ax1.barh(stakeholders, impact_levels, color=colors, alpha=0.8)\n    ax1.set_xlabel('Impact Level (1-10)', fontsize=11)\n    ax1.set_title('Stakeholder Impact', fontsize=12, fontweight='bold')\n    ax1.set_xlim(0, 10)\n    ax1.grid(axis='x', alpha=0.3)\n    for i, (bar, value) in enumerate(zip(bars1, impact_levels)):\n        ax1.text(value + 0.2, i, f'{value}', va='center', fontweight='bold')\n    # Influence chart\n    bars2 = ax2.barh(stakeholders, influence_levels, color=colors, alpha=0.8)\n    ax2.set_xlabel('Influence Level (1-10)', fontsize=11)\n    ax2.set_title('Stakeholder Influence', fontsize=12, fontweight='bold')\n    ax2.set_xlim(0, 10)\n    ax2.grid(axis='x', alpha=0.3)\n    for i, (bar, value) in enumerate(zip(bars2, influence_levels)):\n        ax2.text(value + 0.2, i, f'{value}', va='center', fontweight='bold')\n    plt.tight_layout()\n    # Get the directory where this script is located\n    script_dir = os.getcwd()\n    output_path = os.path.join(script_dir, 'stakeholder_analysis.png')\n    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n    print(\" Saved: stakeholder_analysis.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 1 - Example 2: Ethical Decision-Making Framework\")\n    print(\"\")\n    print(\"=\"*80)\n    # Create framework\n    framework = EthicalDecisionFramework()\n    # Print framework steps\n    print(\"\\nETHICAL DECISION-MAKING FRAMEWORK\")\n    print(\"\")\n    print(\"=\"*80)\n    for step in framework.steps:\n        print(f\"\\nStep {step['step']}: {step['name_en']} ({step['name_ar']})\")\n        print(f\"  {step['description_en']} ({step['description_ar']})\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"=\"*80)\n    create_stakeholder_analysis()\n    # Example scenario\n    print(\"\\n\" + \"=\"*80)\n    print(\"Example Scenario Analysis\")\n    print(\"=\"*80)\n    print(\"\\n\" + \"=\"*80)\n    print(\" Example completed successfully!\")\n    print(\"\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways\")\n    print(\"1. Structured frameworks help ensure comprehensive ethical analysis\")\n    print(\"\")\n    print(\"2. Multiple perspectives lead to better decisions\")\n    print(\"\")\n    print(\"3. Continuous monitoring is essential for ethical AI\")\n    print(\"\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 2: Create the Ethical Decision-Making Framework class\n# This class implements a 6-step process for making ethical decisions in AI\n\n# BEFORE: No structured decision-making process\n# AFTER: We'll have a complete framework with 6 steps, each with questions to guide us\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udccb CREATING ETHICAL DECISION-MAKING FRAMEWORK\")\nprint(\"=\"*80)\nprint(\"\\nThis framework has 6 steps:\")\nprint(\"  1. Identify the Problem\")\nprint(\"  2. Gather Information\")\nprint(\"  3. Identify Stakeholders\")\nprint(\"  4. Apply Ethical Frameworks\")\nprint(\"  5. Evaluate Options\")\nprint(\"  6. Make Decision\\n\")\n\nclass EthicalDecisionFramework:\n    \"\"\"\n    A framework for making ethical decisions in AI development.\n    \n    HOW IT WORKS:\n    1. Defines 6 steps for ethical decision-making\n    2. Each step has questions to guide thinking\n    3. Provides structure for systematic ethical analysis\n    4. Can be applied to any AI ethical dilemma\n    \n    \u23f0 WHEN to use: When facing an ethical decision in AI development\n    \ud83d\udca1 WHY use: Ensures thorough, consistent, and justifiable ethical decisions\n    \"\"\"\n    def__init__(self):\n        # Initialize framework: Set up the 6-step decision-making process\n        # Why a class? It organizes the framework and allows us to reuse it for different scenarios\n        # Define framework steps: Create list of 6 steps with questions for each\n        # Why a list of dictionaries? Each step has multiple attributes (name, description, questions)\n        self.steps = [\n            {\n                'step': 1,  # Step number: First step in the process\n                'name_en': 'Identify the Problem',  # Step name: English name for this step\n                'name_ar': '\u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0645\u0634\u0643\u0644\u0629',  # Step name: Arabic translation\n                'description_en': 'Clearly define the ethical issue or dilemma',  # Description: What this step does\n                'description_ar': '\u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0645\u0634\u0643\u0644\u0629 \u0627\u0644\u0623\u062e\u0644\u0627\u0642\u064a\u0629 \u0623\u0648 \u0627\u0644\u0645\u0639\u0636\u0644\u0629 \u0628\u0648\u0636\u0648\u062d',  # Description: Arabic translation\n                'questions': [  # Guiding questions: Questions to help think through this step\n                    'What is the AI system supposed to do?',  # Question 1: Understand the system's purpose\n                    'What ethical concerns might arise?',  # Question 2: Identify potential ethical issues\n                    'Who are the stakeholders?'  # Question 3: Identify affected parties\n                ]\n            },\n            {\n                'step': 2,  # Step number: Second step\n                'name_en': 'Gather Information',  # Step name: Information gathering\n                'name_ar': '\u062c\u0645\u0639 \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0627\u062a',  # Arabic name\n                'description_en': 'Collect relevant facts and context',  # Description: What this step does\n                'description_ar': '\u062c\u0645\u0639 \u0627\u0644\u062d\u0642\u0627\u0626\u0642 \u0648\u0627\u0644\u0633\u064a\u0627\u0642 \u0630\u0627\u062a \u0627\u0644\u0635\u0644\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to gather information\n                    'What data will be used?',  # Question 1: Understand data requirements\n                    'How will the system be deployed?',  # Question 2: Understand deployment context\n                    'What are the potential impacts?'  # Question 3: Understand consequences\n                ]\n            },\n            {\n                'step': 3,  # Step number: Third step\n                'name_en': 'Identify Stakeholders',  # Step name: Stakeholder identification\n                'name_ar': '\u062a\u062d\u062f\u064a\u062f \u0623\u0635\u062d\u0627\u0628 \u0627\u0644\u0645\u0635\u0644\u062d\u0629',  # Arabic name\n                'description_en': 'List all affected parties',  # Description: What this step does\n                'description_ar': '\u0633\u0631\u062f \u062c\u0645\u064a\u0639 \u0627\u0644\u0623\u0637\u0631\u0627\u0641 \u0627\u0644\u0645\u062a\u0623\u062b\u0631\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to identify stakeholders\n                    'Who will use the system?',  # Question 1: Identify users\n                    'Who might be affected?',  # Question 2: Identify those impacted\n                    'Who has decision-making power?'  # Question 3: Identify decision-makers\n                ]\n            },\n            {\n                'step': 4,  # Step number: Fourth step\n                'name_en': 'Apply Ethical Frameworks',  # Step name: Framework application\n                'name_ar': '\u062a\u0637\u0628\u064a\u0642 \u0627\u0644\u0623\u0637\u0631 \u0627\u0644\u0623\u062e\u0644\u0627\u0642\u064a\u0629',  # Arabic name\n                'description_en': 'Analyze using multiple ethical perspectives',  # Description: What this step does\n                'description_ar': '\u0627\u0644\u062a\u062d\u0644\u064a\u0644 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0648\u062c\u0647\u0627\u062a \u0646\u0638\u0631 \u0623\u062e\u0644\u0627\u0642\u064a\u0629 \u0645\u062a\u0639\u062f\u062f\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to apply frameworks\n                    'What would utilitarianism suggest?',  # Question 1: Utilitarian perspective\n                    'What would deontology require?',  # Question 2: Deontological perspective\n                    'What rights are at stake?'  # Question 3: Rights-based perspective\n                ]\n            },\n            {\n                'step': 5,  # Step number: Fifth step\n                'name_en': 'Evaluate Options',  # Step name: Option evaluation\n                'name_ar': '\u062a\u0642\u064a\u064a\u0645 \u0627\u0644\u062e\u064a\u0627\u0631\u0627\u062a',  # Arabic name\n                'description_en': 'Consider different approaches and their consequences',  # Description: What this step does\n                'description_ar': '\u0627\u0644\u0646\u0638\u0631 \u0641\u064a \u0627\u0644\u0623\u0633\u0627\u0644\u064a\u0628 \u0627\u0644\u0645\u062e\u062a\u0644\u0641\u0629 \u0648\u0639\u0648\u0627\u0642\u0628\u0647\u0627',  # Arabic description\n                'questions': [  # Guiding questions: Questions to evaluate options\n                    'What are the alternative approaches?',  # Question 1: Identify alternatives\n                    'What are the trade-offs?',  # Question 2: Understand trade-offs\n                    'What are the risks and benefits?'  # Question 3: Assess risks and benefits\n                ]\n            },\n            {\n                'step': 6,  # Step number: Sixth step (final decision step)\n                'name_en': 'Make Decision',  # Step name: Decision making\n                'name_ar': '\u0627\u062a\u062e\u0627\u0630 \u0627\u0644\u0642\u0631\u0627\u0631',  # Arabic name\n                'description_en': 'Choose the most ethical course of action',  # Description: What this step does\n                'description_ar': '\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0645\u0633\u0627\u0631 \u0627\u0644\u0623\u0643\u062b\u0631 \u0623\u062e\u0644\u0627\u0642\u064a\u0629',  # Arabic description\n                'questions': [  # Guiding questions: Questions to make decision\n                    'Which option best balances ethical considerations?',  # Question 1: Find best balance\n                    'Can the decision be justified?',  # Question 2: Ensure justifiability\n                    'Is it transparent and accountable?'  # Question 3: Ensure transparency\n                ]\n            }\n        ]\n        \n        print(\" Framework created with 6 steps!\")\n        print(\"   Each step has guiding questions to help you think through ethical decisions\")\n    \n    def analyze_scenario(self, scenario_name, scenario_data):\n        \"\"\"\n        Analyze an AI scenario using the framework.\n        \n        HOW IT WORKS:\n        1. Takes a scenario name and data dictionary\n        2. Goes through each step of the framework\n        3. Prints step information and guiding questions\n        4. Applies scenario-specific analysis if provided\n        \n        \u23f0 WHEN to use: When you have a specific AI scenario to analyze\n        \ud83d\udca1 WHY use: Ensures systematic analysis following all 6 steps\n        \"\"\"\n        # Print header: Show what scenario we're analyzing\n        print(f\"\\n{'='*80}\")  # Separator: Visual divider\n        print(f\"ETHICAL ANALYSIS: {scenario_name}\")  # Title: Show scenario name\n        print(f\"{'='*80}\\n\")  # Separator: Visual divider\n        \n        # Process each step: Go through framework systematically\n        for step in self.steps:  # Loop through steps: Process each of the 6 steps\n            # Print step information: Show step number, name, and description\n            print(f\"\\nStep {step['step']}: {step['name_en']} ({step['name_ar']})\")  # Step header: Number and name\n            print(\"-\" * 60)  # Separator: Visual divider\n            print(f\"Description: {step['description_en']} ({step['description_ar']})\")  # Description: What this step does\n            \n            # Print guiding questions: Show questions to help think through this step\n            print(f\"\\nKey Questions:\")  # Section header: Questions section\n            for i, question in enumerate(step['questions'], 1):  # Loop through questions: Number each question\n                print(f\"  {i}. {question}\")  # Print question: Show numbered question\n            \n            # Apply scenario analysis: If scenario data provided for this step\n            if scenario_data and step['step'] in scenario_data:  # Check if data exists: Only print if analysis provided\n                print(f\"\\nAnalysis:\")  # Section header: Analysis section\n                print(f\"  {scenario_data[step['step']]}\")  # Print analysis: Show scenario-specific analysis\n\n# Create framework instance to demonstrate\nprint(\"\\nCreating framework instance...\")\nframework = EthicalDecisionFramework()\nprint(\" Framework ready to use!\")\n\n    \n    # Analyze scenario: Apply framework to the hiring system scenario\n\n# Run example analysis\n# ============================================================================\n# STAKEHOLDER ANALYSIS VISUALIZATION\n# ============================================================================\ndef create_stakeholder_analysis():\n    \"\"\"Create a stakeholder impact matrix\"\"\"\n    stakeholders = ['Users', 'Developers', 'Company', 'Society', 'Regulators']\n    impact_levels = [9, 7, 8, 6, 7]  # High impact scores\n    influence_levels = [5, 8, 9, 4, 9]  # Influence scores\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n    # Impact chart\n    colors = plt.cm.viridis(np.linspace(0, 1, len(stakeholders)))\n    bars1 = ax1.barh(stakeholders, impact_levels, color=colors, alpha=0.8)\n    ax1.set_xlabel('Impact Level (1-10)', fontsize=11)\n    ax1.set_title('Stakeholder Impact', fontsize=12, fontweight='bold')\n    ax1.set_xlim(0, 10)\n    ax1.grid(axis='x', alpha=0.3)\n    for i, (bar, value) in enumerate(zip(bars1, impact_levels)):\n        ax1.text(value + 0.2, i, f'{value}', va='center', fontweight='bold')\n    # Influence chart\n    bars2 = ax2.barh(stakeholders, influence_levels, color=colors, alpha=0.8)\n    ax2.set_xlabel('Influence Level (1-10)', fontsize=11)\n    ax2.set_title('Stakeholder Influence', fontsize=12, fontweight='bold')\n    ax2.set_xlim(0, 10)\n    ax2.grid(axis='x', alpha=0.3)\n    for i, (bar, value) in enumerate(zip(bars2, influence_levels)):\n        ax2.text(value + 0.2, i, f'{value}', va='center', fontweight='bold')\n    plt.tight_layout()\n    # Get the directory where this script is located\n    script_dir = os.getcwd()\n    output_path = os.path.join(script_dir, 'stakeholder_analysis.png')\n    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n    print(\" Saved: stakeholder_analysis.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 1 - Example 2: Ethical Decision-Making Framework\")\n    print(\"\")\n    print(\"=\"*80)\n    # Create framework\n    framework = EthicalDecisionFramework()\n    # Print framework steps\n    print(\"\\nETHICAL DECISION-MAKING FRAMEWORK\")\n    print(\"\")\n    print(\"=\"*80)\n    for step in framework.steps:\n        print(f\"\\nStep {step['step']}: {step['name_en']} ({step['name_ar']})\")\n        print(f\"  {step['description_en']} ({step['description_ar']})\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"=\"*80)\n    create_stakeholder_analysis()\n    # Example scenario\n    print(\"\\n\" + \"=\"*80)\n    print(\"Example Scenario Analysis\")\n    print(\"=\"*80)\n    print(\"\\n\" + \"=\"*80)\n    print(\" Example completed successfully!\")\n    print(\"\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways\")\n    print(\"1. Structured frameworks help ensure comprehensive ethical analysis\")\n    print(\"\")\n    print(\"2. Multiple perspectives lead to better decisions\")\n    print(\"\")\n    print(\"3. Continuous monitoring is essential for ethical AI\")\n    print(\"\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/03_case_study_analysis.ipynb",
      "status": "failed",
      "execution_time": 0.6364490985870361,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us analyze and visualize the case stud\ny\n\nimport matplotlib.pyplot as plt # For creating visualizations: Charts, graphs, bar charts\nimport matplotlib.patches as mpatches # For drawing shapes: Legends, patche\nsi\nmport numpy as np # For numerical operations: Arrays, calculations\nimport pandas as pd # For data manipulation: DataFrames, data analysis\nimport os # For file operations: Saving images\n\n# Configure matplotlib settings: Set default figure size and font size for better visualizations\nplt.rcParams['font.size'] = 10 # Font size: Make text readable (10\npt is good for most displays)\nplt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda What each library does:\")\nprint(\" - matplotlib: Create visualizations (charts, graphs)\")\nprint(\" - numpy: Numerical operations (arrays, calculations)\")\nprint(\" - pandas: Data manipulation (DataFrames, analysis)\")\nprint(\" - os: File operations (saving images)\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    pt is good for most displays)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us analyze and visualize the case stud\ny\n\nimport matplotlib.pyplot as plt # For creating visualizations: Charts, graphs, bar charts\nimport matplotlib.patches as mpatches # For drawing shapes: Legends, patche\nsi\nmport numpy as np # For numerical operations: Arrays, calculations\nimport pandas as pd # For data manipulation: DataFrames, data analysis\nimport os # For file operations: Saving images\n\n# Configure matplotlib settings: Set default figure size and font size for better visualizations\nplt.rcParams['font.size'] = 10 # Font size: Make text readable (10\npt is good for most displays)\nplt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda What each library does:\")\nprint(\" - matplotlib: Create visualizations (charts, graphs)\")\nprint(\" - numpy: Numerical operations (arrays, calculations)\")\nprint(\" - pandas: Data manipulation (DataFrames, analysis)\")\nprint(\" - os: File operations (saving images)\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    pt is good for most displays)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/algorithmic_fairness_testing_applying_fairness_metrics_and_interpreting_ai_decis.ipynb",
      "status": "passed",
      "execution_time": 1.4400818347930908,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/case_studies_analysis_investigating_real_ethical_failures_in_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.6505961418151855,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/detecting_bias_in_ai_models_identifying_biases_in_datasets_and_algorithms_and_ap.ipynb",
      "status": "passed",
      "execution_time": 1.6121058464050293,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/privacy_simulation_assessing_privacy_risks_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.501878023147583,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6560051441192627,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI Ethics\nExercise 1: Ethical Framework Application\nThis exercise helps you practice applying ethical frameworks to AI scenarios.\n\"\"\"\n# ============================================================================\n# EXERCISE INSTRUCTIONS\n# ============================================================================\n\"\"\"\nEXERCISE 1: Ethical Framework Analysis\nScenario: A company wants to develop an AI system that monitors employee\nproductivity by analyzing computer usage patterns, email content, and\nkeystroke dynamics.\nTASKS\n1. Identify the ethical issues in this scenario\n2. Apply at least THREE different ethical frameworks to analyze this scenario:\n   - Utilitarianism\n   - Deontology\n   - Rights-Based Ethics\n3. Identify all stakeholders and their interests\n4. Provide recommendations for ethical AI development\n5. Create a visualization showing:\n   - Stakeholder impact matrix\n   - Ethical issues severity chart\n\"\"\"\n# ============================================================================\n# TODO: Complete the following sections\n# ============================================================================\n# TASK 1: Identify Ethical Issues\ndef identify_ethical_issues():\n    \"\"\"\n    TODO: List at least 3 ethical issues in this scenario\n    Returns:\n        list: List of ethical issues with descriptions\n    \"\"\"\n    ethical_issues = [\n        # TODO: Add your analysis here\n        # Example format:\n        # {\n        #     'issue': 'Privacy violation', #     'severity': 9,\n        #     'description': 'Monitoring employees violates their privacy rights'\n        # }\n    ]\n    return ethical_issues\n# TASK 2: Apply Ethical Frameworks\ndef apply_utilitarianism():\n    \"\"\"\n    TODO: Analyze the scenario from a Utilitarian perspective\n    Consider:\n    - What are the benefits?\n    - What are the harms?\n    - Who is affected?\n    - Overall utility calculation\n    Returns:\n        dict: Analysis with benefits, harms, and conclusion\n    \"\"\"\n    analysis = {\n        'benefits': [],  # TODO: List benefits\n        'harms': [],     # TODO: List harms\n        'overall_utility': None,  # TODO: Calculate overall utility\n        'conclusion': ''  # TODO: Is it ethical from utilitarian perspective?\n    }\n    return analysis\ndef apply_deontology():\n    \"\"\"\n    TODO: Analyze the scenario from a Deontological perspective\n    Consider:\n    - What moral rules/duties apply?\n    - Are any rules violated?\n    - What would a deontologist say?\n    Returns:\n        dict: Analysis with rules, violations, and conclusion\n    \"\"\"\n    analysis = {\n        'moral_rules': [],  # TODO: List relevant moral rules\n        'violations': [],    # TODO: List any rule violations\n        'conclusion': ''     # TODO: Is it ethical from deontological perspective?\n    }\n    return analysis\ndef apply_rights_based():\n    \"\"\"\n    TODO: Analyze the scenario from a Rights-Based perspective\n    Consider:\n    - What rights are at stake?\n    - Are any rights violated?\n    - How can rights be protected?\n    Returns:\n        dict: Analysis with rights, violations, and conclusion\n    \"\"\"\n    analysis = {\n        'rights_at_stake': [],  # TODO: List relevant rights\n        'violations': [],        # TODO: List any rights violations\n        'conclusion': ''         # TODO: Is it ethical from rights-based perspective?\n    }\n    return analysis\n# TASK 3: Identify Stakeholders\ndef identify_stakeholders():\n    \"\"\"\n    TODO: List all stakeholders and their interests\n    Returns:\n        dict: Stakeholders with their interests, impact, and influence\n    \"\"\"\n    stakeholders = {\n        # TODO: Add stakeholders\n        # Example format:\n        # 'Employees': {\n        #     'interests': ['Privacy', 'Autonomy'],\n        #     'impact': 9,  # How much are they affected (1-10)\n        #     'influence': 5  # How much influence do they have (1-10)\n        # }\n    }\n    return stakeholders\n# TASK 4: Provide Recommendations\ndef provide_recommendations():\n    \"\"\"\n    TODO: Provide ethical recommendations for this AI system\n    Consider:\n    - How to address ethical issues\n    - How to protect stakeholder rights\n    - How to ensure transparency and accountability\n    Returns:\n        list: List of recommendations\n    \"\"\"\n    recommendations = [\n        # TODO: Add your recommendations\n        # Example: \"Obtain explicit consent from employees before monitoring\"\n    ]\n    return recommendations\n# TASK 5: Create Visualizations\ndef create_visualizations():\n    \"\"\"\n    TODO: Create visualizations for:\n    1. Stakeholder impact matrix\n    2. Ethical issues severity chart\n    Use matplotlib to create the visualizations.\n    Save them as PNG files.\n    \"\"\"\n    # TODO: Import matplotlib\n    # TODO: Create stakeholder impact matrix\n    # TODO: Create ethical issues severity chart\n    # TODO: Save visualizations\n    pass\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 1 - Exercise 1: Ethical Framework Application\")\n    print(\"\")\n    print(\"=\"*80)\n    print(\"\\n\ud83d\udccb Instructions:\")\n    print(\"Complete all TODO sections in this file.\")\n    print(\"Run each function and verify your analysis.\")\n    print(\"Create visualizations as specified.\")\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    # Run your completed functions here\n    # ethical_issues = identify_ethical_issues()\n    # utilitarianism = apply_utilitarianism()\n    # deontology = apply_deontology()\n    # rights_based = apply_rights_based()\n    # stakeholders = identify_stakeholders()\n    # recommendations = provide_recommendations()\n    # create_visualizations()\n    print(\"\\n\u2705 Exercise template ready. Complete the TODO sections!\")\n    print(\"\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 146\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI Ethics\nExercise 1: Ethical Framework Application\nThis exercise helps you practice applying ethical frameworks to AI scenarios.\n\"\"\"\n# ============================================================================\n# EXERCISE INSTRUCTIONS\n# ============================================================================\n\"\"\"\nEXERCISE 1: Ethical Framework Analysis\nScenario: A company wants to develop an AI system that monitors employee\nproductivity by analyzing computer usage patterns, email content, and\nkeystroke dynamics.\nTASKS\n1. Identify the ethical issues in this scenario\n2. Apply at least THREE different ethical frameworks to analyze this scenario:\n   - Utilitarianism\n   - Deontology\n   - Rights-Based Ethics\n3. Identify all stakeholders and their interests\n4. Provide recommendations for ethical AI development\n5. Create a visualization showing:\n   - Stakeholder impact matrix\n   - Ethical issues severity chart\n\"\"\"\n# ============================================================================\n# TODO: Complete the following sections\n# ============================================================================\n# TASK 1: Identify Ethical Issues\ndef identify_ethical_issues():\n    \"\"\"\n    TODO: List at least 3 ethical issues in this scenario\n    Returns:\n        list: List of ethical issues with descriptions\n    \"\"\"\n    ethical_issues = [\n        # TODO: Add your analysis here\n        # Example format:\n        # {\n        #     'issue': 'Privacy violation', #     'severity': 9,\n        #     'description': 'Monitoring employees violates their privacy rights'\n        # }\n    ]\n    return ethical_issues\n# TASK 2: Apply Ethical Frameworks\ndef apply_utilitarianism():\n    \"\"\"\n    TODO: Analyze the scenario from a Utilitarian perspective\n    Consider:\n    - What are the benefits?\n    - What are the harms?\n    - Who is affected?\n    - Overall utility calculation\n    Returns:\n        dict: Analysis with benefits, harms, and conclusion\n    \"\"\"\n    analysis = {\n        'benefits': [],  # TODO: List benefits\n        'harms': [],     # TODO: List harms\n        'overall_utility': None,  # TODO: Calculate overall utility\n        'conclusion': ''  # TODO: Is it ethical from utilitarian perspective?\n    }\n    return analysis\ndef apply_deontology():\n    \"\"\"\n    TODO: Analyze the scenario from a Deontological perspective\n    Consider:\n    - What moral rules/duties apply?\n    - Are any rules violated?\n    - What would a deontologist say?\n    Returns:\n        dict: Analysis with rules, violations, and conclusion\n    \"\"\"\n    analysis = {\n        'moral_rules': [],  # TODO: List relevant moral rules\n        'violations': [],    # TODO: List any rule violations\n        'conclusion': ''     # TODO: Is it ethical from deontological perspective?\n    }\n    return analysis\ndef apply_rights_based():\n    \"\"\"\n    TODO: Analyze the scenario from a Rights-Based perspective\n    Consider:\n    - What rights are at stake?\n    - Are any rights violated?\n    - How can rights be protected?\n    Returns:\n        dict: Analysis with rights, violations, and conclusion\n    \"\"\"\n    analysis = {\n        'rights_at_stake': [],  # TODO: List relevant rights\n        'violations': [],        # TODO: List any rights violations\n        'conclusion': ''         # TODO: Is it ethical from rights-based perspective?\n    }\n    return analysis\n# TASK 3: Identify Stakeholders\ndef identify_stakeholders():\n    \"\"\"\n    TODO: List all stakeholders and their interests\n    Returns:\n        dict: Stakeholders with their interests, impact, and influence\n    \"\"\"\n    stakeholders = {\n        # TODO: Add stakeholders\n        # Example format:\n        # 'Employees': {\n        #     'interests': ['Privacy', 'Autonomy'],\n        #     'impact': 9,  # How much are they affected (1-10)\n        #     'influence': 5  # How much influence do they have (1-10)\n        # }\n    }\n    return stakeholders\n# TASK 4: Provide Recommendations\ndef provide_recommendations():\n    \"\"\"\n    TODO: Provide ethical recommendations for this AI system\n    Consider:\n    - How to address ethical issues\n    - How to protect stakeholder rights\n    - How to ensure transparency and accountability\n    Returns:\n        list: List of recommendations\n    \"\"\"\n    recommendations = [\n        # TODO: Add your recommendations\n        # Example: \"Obtain explicit consent from employees before monitoring\"\n    ]\n    return recommendations\n# TASK 5: Create Visualizations\ndef create_visualizations():\n    \"\"\"\n    TODO: Create visualizations for:\n    1. Stakeholder impact matrix\n    2. Ethical issues severity chart\n    Use matplotlib to create the visualizations.\n    Save them as PNG files.\n    \"\"\"\n    # TODO: Import matplotlib\n    # TODO: Create stakeholder impact matrix\n    # TODO: Create ethical issues severity chart\n    # TODO: Save visualizations\n    pass\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 1 - Exercise 1: Ethical Framework Application\")\n    print(\"\")\n    print(\"=\"*80)\n    print(\"\\n\ud83d\udccb Instructions:\")\n    print(\"Complete all TODO sections in this file.\")\n    print(\"Run each function and verify your analysis.\")\n    print(\"Create visualizations as specified.\")\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    # Run your completed functions here\n    # ethical_issues = identify_ethical_issues()\n    # utilitarianism = apply_utilitarianism()\n    # deontology = apply_deontology()\n    # rights_based = apply_rights_based()\n    # stakeholders = identify_stakeholders()\n    # recommendations = provide_recommendations()\n    # create_visualizations()\n    print(\"\\n\u2705 Exercise template ready. Complete the TODO sections!\")\n    print(\"\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 146\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7556531429290771,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "other"
    },
    {
      "path": "Course 06/unit2-bias-fairness/examples/06_detecting_bias_ai_models.ipynb",
      "status": "passed",
      "execution_time": 1.3711211681365967,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-fairness",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-fairness/examples/07_fairness_testing_metrics.ipynb",
      "status": "passed",
      "execution_time": 0.8389990329742432,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-fairness",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/01_bias_detection.ipynb",
      "status": "failed",
      "execution_time": 1.790889024734497,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 2: Generate synthetic data with intentional bias\n# This creates a dataset where we know bias exists, so we can practice detecting it\n\n# BEFORE: No data with known bias to practice on\n# AFTER: We'll have a synthetic hiring dataset with intentional bias\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udcca GENERATING SYNTHETIC DATA WITH BIAS\")\nprint(\"=\"*80)\nprint(\"\\nWe'll create a hiring dataset where:\")\nprint(\"  - Group_B has lower hiring rates even with similar qualifications\")\nprint(\"  - This simulates real-world bias we need to detect\")\nprint(\"  - We'll use this to practice bias detection methods\\n\")\n\ndef generate_biased_data(n_samples=2000):\n    \"\"\"\n    Generate synthetic hiring data with inherent bias.\n    \n    HOW IT WORKS:\n    1. Creates synthetic features (age, experience, education, skills)\n    2. Introduces intentional bias: Group_B has lower hiring rates\n    3. Calculates hiring probability with bias factor\n    4. Creates binary hiring outcome\n    \n    \u23f0 WHEN to use: To create test data with known bias for practice\n    \ud83d\udca1 WHY use: Allows us to practice bias detection on data where we know bias exists\n    \"\"\"\n    # Set random seed: Ensure reproducible results\n    np.random.seed(42)  # Seed value: Makes random numbers predictable for consistency\n    \n    # Create synthetic dataset: Generate features for hiring simulation\n    # Why synthetic? Allows us to control bias and practice detection safely\n    data = {\n        'age': np.random.randint(22, 65, n_samples),  # Age: Random ages between 22-65\n        'experience_years': np.random.randint(0, 20, n_samples),  # Experience: Years of work experience\n        'education_level': np.random.choice([1, 2, 3, 4], n_samples, \n                                           p=[0.2, 0.3, 0.3, 0.2]),  # Education: 1-4 scale with probabilities\n        'skill_score': np.random.normal(70, 15, n_samples),  # Skills: Normal distribution, mean=70, std=15\n        'group': np.random.choice(['Group_A', 'Group_B'], n_samples, p=[0.5, 0.5])  # Group: Two groups, equal probability\n    }\n    df = pd.DataFrame(data)  # Create DataFrame: Convert dictionary to pandas DataFrame\n    \n    # Introduce bias: Group_B has lower success rates even with similar qualifications\n    # Why introduce bias? To simulate real-world discrimination we need to detect\n    bias_factor = np.where(df['group'] == 'Group_B', -0.15, 0)  # Bias: -0.15 penalty for Group_B\n    \n    # Calculate hiring probability: Base probability with bias factor\n    # Why this formula? Combines qualifications (skills, experience, education) with bias\n    base_prob = (df['skill_score']\n100 +  # Skills component: Normalize to 0-1\n                 df['experience_years']\n20 +  # Experience component: Normalize to 0-1\n                 df['education_level']\n4)\n3 + bias_factor  # Education component: Average all three, add bias\n    \n    # Add noise: Real-world randomness\n    base_prob += np.random.normal(0, 0.1, n_samples)  # Noise: Small random variation\n    base_prob = np.clip(base_prob, 0, 1)  # Clip: Ensure probability stays between 0 and 1\n    \n    # Create binary outcome: Hired (1) or not hired (0)\n    df['hired'] = (base_prob > 0.5).astype(int)  # Binary: 1 if probability > 0.5, else 0\n    \n    return df  # Return: DataFrame with features and biased hiring outcome\n\n# Generate the biased dataset\nprint(\"Generating synthetic hiring data with bias...\")\ndf = generate_biased_data(n_samples=2000)\nprint(f\" Generated dataset with {len(df)} samples\")\nprint(f\"   Group_A hiring rate: {df[df['group']=='Group_A']['hired'].mean():.2%}\")\nprint(f\"   Group_B hiring rate: {df[df['group']=='Group_B']['hired'].mean():.2%}\")\nprint(\"   (Notice the difference - this is the bias we'll detect!)\")\n\ndef calculate_demographic_parity(df):\n    \"\"\"Calculate demographic parity (overall positive rate by group).\"\"\"\n    parity_rates = {}\n    for group in df['group'].unique():\n        group_df = df[df['group'] == group]\n        positive_rate = group_df['predicted'].mean()\n        parity_rates[group] = positive_rate\n    disparity = abs(parity_rates.get('Group_A', 0) - parity_rates.get('Group_B', 0))\n    return parity_rates, disparity\ndef calculate_equalized_odds(df):\n    \"\"\"Calculate equalized odds (TPR and FPR by group).\"\"\"\n    equalized_odds = {}\n    for group in df['group'].unique():\n        group_df = df[df['group'] == group]\n        tp = ((group_df['predicted'] == 1) & (group_df['hired'] == 1)).sum()\n        fn = ((group_df['predicted'] == 0) & (group_df['hired'] == 1)).sum()\n        fp = ((group_df['predicted'] == 1) & (group_df['hired'] == 0)).sum()\n        tn = ((group_df['predicted'] == 0) & (group_df['hired'] == 0)).sum()\n        tpr = tp\n(tp + fn) if (tp + fn) > 0 else 0\n        fpr = fp\n(fp + tn) if (fp + tn) > 0 else 0\n        equalized_odds[group] = {'TPR': tpr, 'FPR': fpr}\n    tpr_disparity = abs(equalized_odds.get('Group_A', {}).get('TPR', 0) - equalized_odds.get('Group_B', {}).get('TPR', 0))\n    fpr_disparity = abs(equalized_odds.get('Group_A', {}).get('FPR', 0) - equalized_odds.get('Group_B', {}).get('FPR', 0))\n    return equalized_odds, tpr_disparity, fpr_disparity\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:97\u001b[0;36m\u001b[0m\n\u001b[0;31m    tpr_disparity = abs(equalized_odds.get('Group_A', {}).get('TPR', 0) - equalized_odds.get('Group_B', {}).get('TPR', 0))\u001b[0m\n\u001b[0m                                                                                                                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 2: Generate synthetic data with intentional bias\n# This creates a dataset where we know bias exists, so we can practice detecting it\n\n# BEFORE: No data with known bias to practice on\n# AFTER: We'll have a synthetic hiring dataset with intentional bias\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udcca GENERATING SYNTHETIC DATA WITH BIAS\")\nprint(\"=\"*80)\nprint(\"\\nWe'll create a hiring dataset where:\")\nprint(\"  - Group_B has lower hiring rates even with similar qualifications\")\nprint(\"  - This simulates real-world bias we need to detect\")\nprint(\"  - We'll use this to practice bias detection methods\\n\")\n\ndef generate_biased_data(n_samples=2000):\n    \"\"\"\n    Generate synthetic hiring data with inherent bias.\n    \n    HOW IT WORKS:\n    1. Creates synthetic features (age, experience, education, skills)\n    2. Introduces intentional bias: Group_B has lower hiring rates\n    3. Calculates hiring probability with bias factor\n    4. Creates binary hiring outcome\n    \n    \u23f0 WHEN to use: To create test data with known bias for practice\n    \ud83d\udca1 WHY use: Allows us to practice bias detection on data where we know bias exists\n    \"\"\"\n    # Set random seed: Ensure reproducible results\n    np.random.seed(42)  # Seed value: Makes random numbers predictable for consistency\n    \n    # Create synthetic dataset: Generate features for hiring simulation\n    # Why synthetic? Allows us to control bias and practice detection safely\n    data = {\n        'age': np.random.randint(22, 65, n_samples),  # Age: Random ages between 22-65\n        'experience_years': np.random.randint(0, 20, n_samples),  # Experience: Years of work experience\n        'education_level': np.random.choice([1, 2, 3, 4], n_samples, \n                                           p=[0.2, 0.3, 0.3, 0.2]),  # Education: 1-4 scale with probabilities\n        'skill_score': np.random.normal(70, 15, n_samples),  # Skills: Normal distribution, mean=70, std=15\n        'group': np.random.choice(['Group_A', 'Group_B'], n_samples, p=[0.5, 0.5])  # Group: Two groups, equal probability\n    }\n    df = pd.DataFrame(data)  # Create DataFrame: Convert dictionary to pandas DataFrame\n    \n    # Introduce bias: Group_B has lower success rates even with similar qualifications\n    # Why introduce bias? To simulate real-world discrimination we need to detect\n    bias_factor = np.where(df['group'] == 'Group_B', -0.15, 0)  # Bias: -0.15 penalty for Group_B\n    \n    # Calculate hiring probability: Base probability with bias factor\n    # Why this formula? Combines qualifications (skills, experience, education) with bias\n    base_prob = (df['skill_score']\n100 +  # Skills component: Normalize to 0-1\n                 df['experience_years']\n20 +  # Experience component: Normalize to 0-1\n                 df['education_level']\n4)\n3 + bias_factor  # Education component: Average all three, add bias\n    \n    # Add noise: Real-world randomness\n    base_prob += np.random.normal(0, 0.1, n_samples)  # Noise: Small random variation\n    base_prob = np.clip(base_prob, 0, 1)  # Clip: Ensure probability stays between 0 and 1\n    \n    # Create binary outcome: Hired (1) or not hired (0)\n    df['hired'] = (base_prob > 0.5).astype(int)  # Binary: 1 if probability > 0.5, else 0\n    \n    return df  # Return: DataFrame with features and biased hiring outcome\n\n# Generate the biased dataset\nprint(\"Generating synthetic hiring data with bias...\")\ndf = generate_biased_data(n_samples=2000)\nprint(f\" Generated dataset with {len(df)} samples\")\nprint(f\"   Group_A hiring rate: {df[df['group']=='Group_A']['hired'].mean():.2%}\")\nprint(f\"   Group_B hiring rate: {df[df['group']=='Group_B']['hired'].mean():.2%}\")\nprint(\"   (Notice the difference - this is the bias we'll detect!)\")\n\ndef calculate_demographic_parity(df):\n    \"\"\"Calculate demographic parity (overall positive rate by group).\"\"\"\n    parity_rates = {}\n    for group in df['group'].unique():\n        group_df = df[df['group'] == group]\n        positive_rate = group_df['predicted'].mean()\n        parity_rates[group] = positive_rate\n    disparity = abs(parity_rates.get('Group_A', 0) - parity_rates.get('Group_B', 0))\n    return parity_rates, disparity\ndef calculate_equalized_odds(df):\n    \"\"\"Calculate equalized odds (TPR and FPR by group).\"\"\"\n    equalized_odds = {}\n    for group in df['group'].unique():\n        group_df = df[df['group'] == group]\n        tp = ((group_df['predicted'] == 1) & (group_df['hired'] == 1)).sum()\n        fn = ((group_df['predicted'] == 0) & (group_df['hired'] == 1)).sum()\n        fp = ((group_df['predicted'] == 1) & (group_df['hired'] == 0)).sum()\n        tn = ((group_df['predicted'] == 0) & (group_df['hired'] == 0)).sum()\n        tpr = tp\n(tp + fn) if (tp + fn) > 0 else 0\n        fpr = fp\n(fp + tn) if (fp + tn) > 0 else 0\n        equalized_odds[group] = {'TPR': tpr, 'FPR': fpr}\n    tpr_disparity = abs(equalized_odds.get('Group_A', {}).get('TPR', 0) - equalized_odds.get('Group_B', {}).get('TPR', 0))\n    fpr_disparity = abs(equalized_odds.get('Group_A', {}).get('FPR', 0) - equalized_odds.get('Group_B', {}).get('FPR', 0))\n    return equalized_odds, tpr_disparity, fpr_disparity\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:97\u001b[0;36m\u001b[0m\n\u001b[0;31m    tpr_disparity = abs(equalized_odds.get('Group_A', {}).get('TPR', 0) - equalized_odds.get('Group_B', {}).get('TPR', 0))\u001b[0m\n\u001b[0m                                                                                                                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/02_bias_mitigation.ipynb",
      "status": "passed",
      "execution_time": 1.8157868385314941,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/03_fair_representation.ipynb",
      "status": "passed",
      "execution_time": 1.8578400611877441,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/04_bias_case_studies.ipynb",
      "status": "passed",
      "execution_time": 1.9793379306793213,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/05_fair_ai_development.ipynb",
      "status": "failed",
      "execution_time": 1.7897531986236572,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 2: Demonstrate inclusive data collection strategies\n# This shows how different data collection approaches affect representation\n\n# BEFORE: We collect data without considering representation\n# AFTER: We'll see how different strategies affect group representation\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udcca INCLUSIVE DATA COLLECTION STRATEGIES\")\nprint(\"=\"*80)\nprint(\"\\nDifferent data collection strategies:\")\nprint(\"  - Unbalanced: Majority group over-represented\")\nprint(\"  - Balanced: Equal representation across groups\")\nprint(\"  - Oversampled Minority: Minority groups over-represented (for fairness)\\n\")\n\ndef inclusive_data_collection():\n    \"\"\"\n    Demonstrate inclusive data collection strategies.\n    \n    HOW IT WORKS:\n    1. Defines three data collection scenarios (Unbalanced, Balanced, Oversampled)\n    2. Shows sample counts for each group in each scenario\n    3. Calculates percentages to show representation\n    4. Compares strategies to highlight importance of inclusive collection\n    \n    \u23f0 WHEN to use: To understand how data collection affects representation\n    \ud83d\udca1 WHY use: Shows that data collection strategy matters for fairness\n    \"\"\"\n    # Define scenarios: Three different data collection approaches\n    # Why three scenarios? Shows progression from biased to fair collection\n    scenarios = {\n        'Unbalanced': {  # Unbalanced: Majority group over-represented (common problem)\n            'Group_A': 800,  # Group A: 80% of data (majority)\n            'Group_B': 200,  # Group B: 20% of data (minority)\n            'Group_C': 0  # Group C: 0% of data (completely missing!)\n        },\n        'Balanced': {  # Balanced: More equal representation\n            'Group_A': 400,  # Group A: 40% of data\n            'Group_B': 400,  # Group B: 40% of data\n            'Group_C': 200  # Group C: 20% of data (still underrepresented but present)\n        },\n        'Oversampled_Minority': {  # Oversampled: Minority groups over-represented (for fairness)\n            'Group_A': 400,  # Group A: 33.3% of data\n            'Group_B': 400,  # Group B: 33.3% of data\n            'Group_C': 400  # Group C: 33.3% of data (equal representation)\n        }\n    }\n    \n    # Display scenarios: Show each strategy and its group representation\n    print(\"\\nData Collection Strategies:\")\n    for scenario, counts in scenarios.items():  # Loop through scenarios: Process each strategy\n        total = sum(counts.values())  # Total: Sum of all samples\n        print(f\"\\n{scenario}:\")  # Print: Scenario name\n        for group, count in counts.items():  # Loop through groups: Process each group\n            percentage = count\ntotal * 100 if total > 0 else 0  # Percentage: Calculate representation percentage\n            print(f\"  {group}: {count} samples ({percentage:.1f}%)\")  # Print: Group name, count, percentage\n    \n    return scenarios  # Return: Dictionary of scenarios for analysis\n\n# Run the data collection demonstration\nprint(\"Analyzing data collection strategies...\")\nscenarios = inclusive_data_collection()\nprint(\"\\n\u2705 Data collection analysis complete!\")\nprint(\"\\nKey Insight: Inclusive data collection is the foundation of fair AI!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:58\u001b[0;36m\u001b[0m\n\u001b[0;31m    return scenarios  # Return: Dictionary of scenarios for analysis\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 2: Demonstrate inclusive data collection strategies\n# This shows how different data collection approaches affect representation\n\n# BEFORE: We collect data without considering representation\n# AFTER: We'll see how different strategies affect group representation\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udcca INCLUSIVE DATA COLLECTION STRATEGIES\")\nprint(\"=\"*80)\nprint(\"\\nDifferent data collection strategies:\")\nprint(\"  - Unbalanced: Majority group over-represented\")\nprint(\"  - Balanced: Equal representation across groups\")\nprint(\"  - Oversampled Minority: Minority groups over-represented (for fairness)\\n\")\n\ndef inclusive_data_collection():\n    \"\"\"\n    Demonstrate inclusive data collection strategies.\n    \n    HOW IT WORKS:\n    1. Defines three data collection scenarios (Unbalanced, Balanced, Oversampled)\n    2. Shows sample counts for each group in each scenario\n    3. Calculates percentages to show representation\n    4. Compares strategies to highlight importance of inclusive collection\n    \n    \u23f0 WHEN to use: To understand how data collection affects representation\n    \ud83d\udca1 WHY use: Shows that data collection strategy matters for fairness\n    \"\"\"\n    # Define scenarios: Three different data collection approaches\n    # Why three scenarios? Shows progression from biased to fair collection\n    scenarios = {\n        'Unbalanced': {  # Unbalanced: Majority group over-represented (common problem)\n            'Group_A': 800,  # Group A: 80% of data (majority)\n            'Group_B': 200,  # Group B: 20% of data (minority)\n            'Group_C': 0  # Group C: 0% of data (completely missing!)\n        },\n        'Balanced': {  # Balanced: More equal representation\n            'Group_A': 400,  # Group A: 40% of data\n            'Group_B': 400,  # Group B: 40% of data\n            'Group_C': 200  # Group C: 20% of data (still underrepresented but present)\n        },\n        'Oversampled_Minority': {  # Oversampled: Minority groups over-represented (for fairness)\n            'Group_A': 400,  # Group A: 33.3% of data\n            'Group_B': 400,  # Group B: 33.3% of data\n            'Group_C': 400  # Group C: 33.3% of data (equal representation)\n        }\n    }\n    \n    # Display scenarios: Show each strategy and its group representation\n    print(\"\\nData Collection Strategies:\")\n    for scenario, counts in scenarios.items():  # Loop through scenarios: Process each strategy\n        total = sum(counts.values())  # Total: Sum of all samples\n        print(f\"\\n{scenario}:\")  # Print: Scenario name\n        for group, count in counts.items():  # Loop through groups: Process each group\n            percentage = count\ntotal * 100 if total > 0 else 0  # Percentage: Calculate representation percentage\n            print(f\"  {group}: {count} samples ({percentage:.1f}%)\")  # Print: Group name, count, percentage\n    \n    return scenarios  # Return: Dictionary of scenarios for analysis\n\n# Run the data collection demonstration\nprint(\"Analyzing data collection strategies...\")\nscenarios = inclusive_data_collection()\nprint(\"\\n\u2705 Data collection analysis complete!\")\nprint(\"\\nKey Insight: Inclusive data collection is the foundation of fair AI!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:58\u001b[0;36m\u001b[0m\n\u001b[0;31m    return scenarios  # Return: Dictionary of scenarios for analysis\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/ai_fairness_auditing_evaluating_and_improving_ethical_compliance_in_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.55377197265625,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/case_studies_analysis_investigating_bias_incidents_in_ai_in_real_world.ipynb",
      "status": "passed",
      "execution_time": 1.5499260425567627,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/detecting_bias_in_ai_models_identifying_biases_in_datasets_and_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.6655333042144775,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/developing_ai_ethics_policies_formulating_guidelines_for_responsible_ai_use.ipynb",
      "status": "passed",
      "execution_time": 1.5713562965393066,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/fairness_testing_using_fairness_metrics_to_evaluate_ai_decisions.ipynb",
      "status": "passed",
      "execution_time": 1.5281400680541992,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/implementing_bias_mitigation_techniques_applying_correction_techniques_and_evalu.ipynb",
      "status": "passed",
      "execution_time": 1.7687208652496338,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.7495079040527344,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI\nExercise 2: Bias Mitigation TechniquesThis exercise requires you to implement and compare different bias mitigation techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# TASK 1: Generate Biased Datase\nt\n# ============================================================================\ndef generate_biased_dataset(n_samples=2000):\n \n    \n    \"\"\"\n TODO: Generate a synthetic dataset with bias.\n Requirements:\n - Create a dataset with features and a sensitive attribute (e.g., gender: 0 or 1)\n - Introduce bias such that one group has lower probability of positive outcome\n - Return a DataFrame with columns: feature1, feature2, sensitive, target\n \"\"\"\n np.random.seed(42)\n # TODO: Your code here\n # Hint: Use np.random functions to generate features\n # Hint: Make the target depend on features but add bias based on sensitive attribut\nepass\n# ============================================================================\n# TASK 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Implement reweighing technique.\n Requirements:\n - Calculate weights to balance representation across groups\n - Return array of weights for each training sample\n \"\"\"\n # TODO: Your code here\n # Hint: Calculate weights inversely proportional to group size\n pass\n# ============================================================================\n# TASK 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \"\"\"\n TODO: Train a baseline model without any bias mitigation.\n \"\"\"\n # TODO: Your code here\n # Hint: Use RandomForestClassifier\n pass\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Train a model using reweighing technique.\n \"\"\"\n # TODO: Your code here\n # Hint: Use the preprocess_reweighing function and pass weights to fi\nt()\n pass\n# ============================================================================\n# TASK 4: Evaluate Fairness Metric\ns\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \"\"\"\n TODO: Evaluate fairness metrics.\n Requirements:\n - Calculate demographic parity difference\n - Calculate equalized odds difference\n - Calculate accuracy\n - Return a dictionary with these metrics\n \"\"\"\n # TODO: Your code here\n # Hint: Use fairlearn.metrics function\nspass\n# ============================================================================\n# TASK 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \"\"\"\n TODO: Compare baseline vs reweighing techniques.\n Requirements:\n - Split data into train/test\n - Train baseline and reweighed models\n - Evaluate fairness metrics for both\n - Print comparison results\n \"\"\"\n # TODO: Your code here\n pass\n# ============================================================================\n# MAIN EXECUTIO\nN\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate datase\nt\n print(\"\\nTask 1: Generating biased dataset...\")\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"Sensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n # Compare techniques\n print(\"\\nTask 5: Comparing mitigation techniques...\")\n compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Exercise completed! Check your results against the solution.\")\n print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI\nExercise 2: Bias Mitigation TechniquesThis exercise requires you to implement and compare different bias mitigation techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# TASK 1: Generate Biased Datase\nt\n# ============================================================================\ndef generate_biased_dataset(n_samples=2000):\n \n    \n    \"\"\"\n TODO: Generate a synthetic dataset with bias.\n Requirements:\n - Create a dataset with features and a sensitive attribute (e.g., gender: 0 or 1)\n - Introduce bias such that one group has lower probability of positive outcome\n - Return a DataFrame with columns: feature1, feature2, sensitive, target\n \"\"\"\n np.random.seed(42)\n # TODO: Your code here\n # Hint: Use np.random functions to generate features\n # Hint: Make the target depend on features but add bias based on sensitive attribut\nepass\n# ============================================================================\n# TASK 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Implement reweighing technique.\n Requirements:\n - Calculate weights to balance representation across groups\n - Return array of weights for each training sample\n \"\"\"\n # TODO: Your code here\n # Hint: Calculate weights inversely proportional to group size\n pass\n# ============================================================================\n# TASK 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \"\"\"\n TODO: Train a baseline model without any bias mitigation.\n \"\"\"\n # TODO: Your code here\n # Hint: Use RandomForestClassifier\n pass\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Train a model using reweighing technique.\n \"\"\"\n # TODO: Your code here\n # Hint: Use the preprocess_reweighing function and pass weights to fi\nt()\n pass\n# ============================================================================\n# TASK 4: Evaluate Fairness Metric\ns\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \"\"\"\n TODO: Evaluate fairness metrics.\n Requirements:\n - Calculate demographic parity difference\n - Calculate equalized odds difference\n - Calculate accuracy\n - Return a dictionary with these metrics\n \"\"\"\n # TODO: Your code here\n # Hint: Use fairlearn.metrics function\nspass\n# ============================================================================\n# TASK 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \"\"\"\n TODO: Compare baseline vs reweighing techniques.\n Requirements:\n - Split data into train/test\n - Train baseline and reweighed models\n - Evaluate fairness metrics for both\n - Print comparison results\n \"\"\"\n # TODO: Your code here\n pass\n# ============================================================================\n# MAIN EXECUTIO\nN\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate datase\nt\n print(\"\\nTask 1: Generating biased dataset...\")\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"Sensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n # Compare techniques\n print(\"\\nTask 5: Comparing mitigation techniques...\")\n compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Exercise completed! Check your results against the solution.\")\n print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit2-bias-justice/solutions/solution_02.ipynb",
      "status": "passed",
      "execution_time": 0.7404091358184814,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "other"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/01_data_protection.ipynb",
      "status": "failed",
      "execution_time": 1.649522304534912,
      "error": "An error occurred while executing the following cell:\n------------------\n# Part 3: Anonymization and Pseudonymization Techniques\n# This shows how to anonymize and pseudonymize data\n\n# BEFORE: We have identifying information in our data\n# AFTER: We'll remove or mask identifying information\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udd12 ANONYMIZATION AND PSEUDONYMIZATION TECHNIQUES\")\nprint(\"=\"*80)\nprint(\"\\nWe'll implement:\")\nprint(\"  1. Anonymization: Remove identifying information\")\nprint(\"  2. Pseudonymization: Replace with hashed values\\n\")\n\ndef anonymize_data(df, columns_to_anonymize):\n    \"\"\"\n    Anonymize data by removing or masking identifying information.\n    \n    HOW IT WORKS:\n    1. Creates a copy of the DataFrame\n    2. Replaces specified columns with generic identifiers (ID_0, ID_1, etc.)\n    3. Returns anonymized DataFrame\n    \n    \u23f0 WHEN to use: When you need to remove identifying information permanently\n    \ud83d\udca1 WHY use: Anonymization makes it impossible to identify individuals\n    \"\"\"\n    df_anonymized = df.copy()  # Copy: Create copy to avoid modifying original\n    for col in columns_to_anonymize:  # Loop through columns: Process each column to anonymize\n        if col in df_anonymized.columns:  # Check: Ensure column exists\n            # Replace with generic identifiers: ID_0, ID_1, ID_2, etc.\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]  # Anonymize: Replace with generic IDs\n    return df_anonymized  # Return: Anonymized DataFrame\n\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \"\"\"\n    Pseudonymize data by replacing with hashed values.\n    \n    HOW IT WORKS:\n    1. Creates a copy of the DataFrame\n    2. Hashes each value in specified columns using SHA-256\n    3. Uses salt to prevent rainbow table attacks\n    4. Returns pseudonymized DataFrame\n    \n    \u23f0 WHEN to use: When you need reversible pseudonyms (can link back with key)\n    \ud83d\udca1 WHY use: Pseudonymization allows linking while protecting identity\n    \"\"\"\n    df_pseudonymized = df.copy()  # Copy: Create copy to avoid modifying original\n    for col in columns_to_pseudonymize:  # Loop through columns: Process each column to pseudonymize\n        if col in df_pseudonymized.columns:  # Check: Ensure column exists\n            # Create hash-based pseudonyms: Hash each value with salt\n            df_pseudonymized[col] = df_pseudonymized[col].apply(\n                lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]  # Hash: SHA-256 hash, first 16 chars\n            )\n    return df_pseudonymized  # Return: Pseudonymized DataFrame\n# ============================================================================\n# DATA PROTECTION COMPARISON\n# ============================================================================\ndef demonstrate_data_protection():\n    \"\"\"\n    Demonstrate different data protection techniques\n    \"\"\"\n    # Create sample sensitive data\n    np.random.seed(42)\n    n_samples = 100\n    data = {\n        'name': [f'Person_{i}' for i in range(n_samples)], 'email': [f'user{i}@example.com' for i in range(n_samples)],\n        'ssn': [f'{np.random.randint(100,999)}-{np.random.randint(10,99)}-{np.random.randint(1000,9999)}' \n                for _ in range(n_samples)], 'salary': np.random.normal(50000, 15000, n_samples),\n        'age': np.random.randint(25, 65, n_samples)\n    }\n    df = pd.DataFrame(data)\n    print(\"=\"*80)\n    print(\"ORIGINAL DATA (First 5 rows):\")\n    print(\"=\"*80)\n    print(df.head())\n    # 1. Anonymization\n    print(\"\\n\" + \"=\"*80)\n    print(\"1. ANONYMIZATION\")\n    print(\"=\"*80)\n    df_anonymized = anonymize_data(df, ['name', 'email', 'ssn'])\n    print(\"\\nAnonymized Data (First 5 rows):\")\n    print(df_anonymized.head())\n    # 2. Pseudonymization\n    print(\"\\n\" + \"=\"*80)\n    print(\"2. PSEUDONYMIZATION\")\n    print(\"=\"*80)\n    df_pseudonymized = pseudonymize_data(df, ['name', 'email', 'ssn'])\n    print(\"\\nPseudonymized Data (First 5 rows):\")\n    print(df_pseudonymized.head())\n    # 3. Encryption\n    print(\"\\n\" + \"=\"*80)\n    print(\"3. ENCRYPTION\")\n    print(\"=\"*80)\n    key = generate_encryption_key()\n    print(f\"Generated encryption key: {key[:20]}...\")\n    # Encrypt sensitive column\n    sample_email = df['email'].iloc[0]\n    encrypted_email = encrypt_data(sample_email, key)\n    decrypted_email = decrypt_data(encrypted_email, key)\n    print(f\"\\nOriginal email: {sample_email}\")\n    print(f\"Encrypted: {encrypted_email[:50]}...\")\n    print(f\"Decrypted: {decrypted_email}\")\n    return df, df_anonymized, df_pseudonymized\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_data_protection_comparison(df, df_anonymized, df_pseudonymized):\n    \"\"\"\n    Visualize data protection techniques comparison\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    # Original data distribution\n    axes[0, 0].hist(df['salary'], bins=20, color='#e74c3c', alpha=0.7, edgecolor='black')\n    axes[0, 0].set_title('Original Data: Salary Distribution', fontsize=12, fontweight='bold')\n    axes[0, 0].set_xlabel('Salary')\n    axes[0, 0].set_ylabel('Frequency')\n    axes[0, 0].grid(alpha=0.3)\n    # Anonymized data (same distribution, different identifiers)\n    axes[0, 1].hist(df_anonymized['salary'], bins=20, color='#3498db', alpha=0.7, edgecolor='black')\n    axes[0, 1].set_title('Anonymized Data: Salary Distribution', fontsize=12, fontweight='bold')\n    axes[0, 1].set_xlabel('Salary')\n    axes[0, 1].set_ylabel('Frequency')\n    axes[0, 1].grid(alpha=0.3)\n    # Pseudonymized data\n    axes[1, 0].hist(df_pseudonymized['salary'], bins=20, color='#2ecc71', alpha=0.7, edgecolor='black')\n    axes[1, 0].set_title('Pseudonymized Data: Salary Distribution', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xlabel('Salary')\n    axes[1, 0].set_ylabel('Frequency')\n    axes[1, 0].grid(alpha=0.3)\n    # Protection techniques comparison\n    techniques = ['Original', 'Anonymized', 'Pseudonymized', 'Encrypted']\n    privacy_level = [1, 7, 8, 10]  # Privacy level (1-10)\n    utility_level = [10, 9, 8, 7]  # Data utility (1-10)\n    x = np.arange(len(techniques))\n    width = 0.35\n    axes[1, 1].bar(x - width/2, privacy_level, width, label='Privacy Level', alpha=0.8, color='#9b59b6')\n    axes[1, 1].bar(x + width/2, utility_level, width, label='Data Utility', alpha=0.8, color='#f39c12')\n    axes[1, 1].set_xlabel('Protection Technique', fontsize=11, fontweight='bold')\n    axes[1, 1].set_ylabel('Score (1-10)', fontsize=11, fontweight='bold')\n    axes[1, 1].set_title('Privacy vs Utility Trade-off', fontsize=12, fontweight='bold')\n    axes[1, 1].set_xticks(x)\n    axes[1, 1].set_xticklabels(techniques, rotation=15)\n    axes[1, 1].legend()\n    axes[1, 1].grid(axis='y', alpha=0.3)\n    axes[1, 1].set_ylim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: data_protection_comparison.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 1: Data Protection Strategies\")\n    print(\"=\"*80)\n    # Demonstrate data protection techniques\n    df, df_anonymized, df_pseudonymized = demonstrate_data_protection()\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_data_protection_comparison(df, df_anonymized, df_pseudonymized)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Anonymization removes identifying information completely\")\n    print(\"2. Pseudonymization replaces identifiers with reversible hashes\")\n    print(\"3. Encryption protects data at rest and in transit\")\n    print(\"4. Each technique has trade-offs between privacy and utility\")\n    print(\"5. Choose protection technique based on use case requirements\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 152\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Part 3: Anonymization and Pseudonymization Techniques\n# This shows how to anonymize and pseudonymize data\n\n# BEFORE: We have identifying information in our data\n# AFTER: We'll remove or mask identifying information\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udd12 ANONYMIZATION AND PSEUDONYMIZATION TECHNIQUES\")\nprint(\"=\"*80)\nprint(\"\\nWe'll implement:\")\nprint(\"  1. Anonymization: Remove identifying information\")\nprint(\"  2. Pseudonymization: Replace with hashed values\\n\")\n\ndef anonymize_data(df, columns_to_anonymize):\n    \"\"\"\n    Anonymize data by removing or masking identifying information.\n    \n    HOW IT WORKS:\n    1. Creates a copy of the DataFrame\n    2. Replaces specified columns with generic identifiers (ID_0, ID_1, etc.)\n    3. Returns anonymized DataFrame\n    \n    \u23f0 WHEN to use: When you need to remove identifying information permanently\n    \ud83d\udca1 WHY use: Anonymization makes it impossible to identify individuals\n    \"\"\"\n    df_anonymized = df.copy()  # Copy: Create copy to avoid modifying original\n    for col in columns_to_anonymize:  # Loop through columns: Process each column to anonymize\n        if col in df_anonymized.columns:  # Check: Ensure column exists\n            # Replace with generic identifiers: ID_0, ID_1, ID_2, etc.\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]  # Anonymize: Replace with generic IDs\n    return df_anonymized  # Return: Anonymized DataFrame\n\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \"\"\"\n    Pseudonymize data by replacing with hashed values.\n    \n    HOW IT WORKS:\n    1. Creates a copy of the DataFrame\n    2. Hashes each value in specified columns using SHA-256\n    3. Uses salt to prevent rainbow table attacks\n    4. Returns pseudonymized DataFrame\n    \n    \u23f0 WHEN to use: When you need reversible pseudonyms (can link back with key)\n    \ud83d\udca1 WHY use: Pseudonymization allows linking while protecting identity\n    \"\"\"\n    df_pseudonymized = df.copy()  # Copy: Create copy to avoid modifying original\n    for col in columns_to_pseudonymize:  # Loop through columns: Process each column to pseudonymize\n        if col in df_pseudonymized.columns:  # Check: Ensure column exists\n            # Create hash-based pseudonyms: Hash each value with salt\n            df_pseudonymized[col] = df_pseudonymized[col].apply(\n                lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]  # Hash: SHA-256 hash, first 16 chars\n            )\n    return df_pseudonymized  # Return: Pseudonymized DataFrame\n# ============================================================================\n# DATA PROTECTION COMPARISON\n# ============================================================================\ndef demonstrate_data_protection():\n    \"\"\"\n    Demonstrate different data protection techniques\n    \"\"\"\n    # Create sample sensitive data\n    np.random.seed(42)\n    n_samples = 100\n    data = {\n        'name': [f'Person_{i}' for i in range(n_samples)], 'email': [f'user{i}@example.com' for i in range(n_samples)],\n        'ssn': [f'{np.random.randint(100,999)}-{np.random.randint(10,99)}-{np.random.randint(1000,9999)}' \n                for _ in range(n_samples)], 'salary': np.random.normal(50000, 15000, n_samples),\n        'age': np.random.randint(25, 65, n_samples)\n    }\n    df = pd.DataFrame(data)\n    print(\"=\"*80)\n    print(\"ORIGINAL DATA (First 5 rows):\")\n    print(\"=\"*80)\n    print(df.head())\n    # 1. Anonymization\n    print(\"\\n\" + \"=\"*80)\n    print(\"1. ANONYMIZATION\")\n    print(\"=\"*80)\n    df_anonymized = anonymize_data(df, ['name', 'email', 'ssn'])\n    print(\"\\nAnonymized Data (First 5 rows):\")\n    print(df_anonymized.head())\n    # 2. Pseudonymization\n    print(\"\\n\" + \"=\"*80)\n    print(\"2. PSEUDONYMIZATION\")\n    print(\"=\"*80)\n    df_pseudonymized = pseudonymize_data(df, ['name', 'email', 'ssn'])\n    print(\"\\nPseudonymized Data (First 5 rows):\")\n    print(df_pseudonymized.head())\n    # 3. Encryption\n    print(\"\\n\" + \"=\"*80)\n    print(\"3. ENCRYPTION\")\n    print(\"=\"*80)\n    key = generate_encryption_key()\n    print(f\"Generated encryption key: {key[:20]}...\")\n    # Encrypt sensitive column\n    sample_email = df['email'].iloc[0]\n    encrypted_email = encrypt_data(sample_email, key)\n    decrypted_email = decrypt_data(encrypted_email, key)\n    print(f\"\\nOriginal email: {sample_email}\")\n    print(f\"Encrypted: {encrypted_email[:50]}...\")\n    print(f\"Decrypted: {decrypted_email}\")\n    return df, df_anonymized, df_pseudonymized\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_data_protection_comparison(df, df_anonymized, df_pseudonymized):\n    \"\"\"\n    Visualize data protection techniques comparison\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    # Original data distribution\n    axes[0, 0].hist(df['salary'], bins=20, color='#e74c3c', alpha=0.7, edgecolor='black')\n    axes[0, 0].set_title('Original Data: Salary Distribution', fontsize=12, fontweight='bold')\n    axes[0, 0].set_xlabel('Salary')\n    axes[0, 0].set_ylabel('Frequency')\n    axes[0, 0].grid(alpha=0.3)\n    # Anonymized data (same distribution, different identifiers)\n    axes[0, 1].hist(df_anonymized['salary'], bins=20, color='#3498db', alpha=0.7, edgecolor='black')\n    axes[0, 1].set_title('Anonymized Data: Salary Distribution', fontsize=12, fontweight='bold')\n    axes[0, 1].set_xlabel('Salary')\n    axes[0, 1].set_ylabel('Frequency')\n    axes[0, 1].grid(alpha=0.3)\n    # Pseudonymized data\n    axes[1, 0].hist(df_pseudonymized['salary'], bins=20, color='#2ecc71', alpha=0.7, edgecolor='black')\n    axes[1, 0].set_title('Pseudonymized Data: Salary Distribution', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xlabel('Salary')\n    axes[1, 0].set_ylabel('Frequency')\n    axes[1, 0].grid(alpha=0.3)\n    # Protection techniques comparison\n    techniques = ['Original', 'Anonymized', 'Pseudonymized', 'Encrypted']\n    privacy_level = [1, 7, 8, 10]  # Privacy level (1-10)\n    utility_level = [10, 9, 8, 7]  # Data utility (1-10)\n    x = np.arange(len(techniques))\n    width = 0.35\n    axes[1, 1].bar(x - width/2, privacy_level, width, label='Privacy Level', alpha=0.8, color='#9b59b6')\n    axes[1, 1].bar(x + width/2, utility_level, width, label='Data Utility', alpha=0.8, color='#f39c12')\n    axes[1, 1].set_xlabel('Protection Technique', fontsize=11, fontweight='bold')\n    axes[1, 1].set_ylabel('Score (1-10)', fontsize=11, fontweight='bold')\n    axes[1, 1].set_title('Privacy vs Utility Trade-off', fontsize=12, fontweight='bold')\n    axes[1, 1].set_xticks(x)\n    axes[1, 1].set_xticklabels(techniques, rotation=15)\n    axes[1, 1].legend()\n    axes[1, 1].grid(axis='y', alpha=0.3)\n    axes[1, 1].set_ylim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: data_protection_comparison.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 1: Data Protection Strategies\")\n    print(\"=\"*80)\n    # Demonstrate data protection techniques\n    df, df_anonymized, df_pseudonymized = demonstrate_data_protection()\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_data_protection_comparison(df, df_anonymized, df_pseudonymized)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Anonymization removes identifying information completely\")\n    print(\"2. Pseudonymization replaces identifiers with reversible hashes\")\n    print(\"3. Encryption protects data at rest and in transit\")\n    print(\"4. Each technique has trade-offs between privacy and utility\")\n    print(\"5. Choose protection technique based on use case requirements\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 152\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/02_privacy_technologies.ipynb",
      "status": "failed",
      "execution_time": 0.5951390266418457,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 2: Privacy-Enhancing Technologies (PETs)\nThis example demonstrates privacy-enhancing technologies:\n- Secure Multi-Party Computation (SMPC) concepts\n- Homomorphic encryption concepts\n- Privacy-utility trade-offs\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SECURE MULTI-PARTY COMPUTATION (SMPC) SIMULATION\n# ============================================================================\ndef smpc_sum_simulation(parties_data, n_parties=3):\n    \"\"\"\n    Simulate Secure Multi-Party Computation for computing sum\n    without revealing individual values\n    \"\"\"\n    # Each party adds random noise to their data\n    noise = [np.random.normal(0, 100) for _ in range(n_parties)]\n    noisy_data = [data + noise[i] for i, data in enumerate(parties_data)]\n    # Sum of noisy data\n    noisy_sum = sum(noisy_data)\n    # Remove noise to get actual sum (in real SMPC, this is done securely)\n    actual_sum = noisy_sum - sum(noise)\n    return {\n        'parties_data': parties_data, 'noisy_data': noisy_data,\n        'noisy_sum': noisy_sum,\n        'actual_sum': actual_sum,\n        'privacy_preserved': True\n    }\n# ============================================================================\n# HOMOMORPHIC ENCRYPTION CONCEPTS\n# ============================================================================\ndef homomorphic_encryption_demo():\n    \"\"\"\n    Demonstrate concept of homomorphic encryption\n    (simplified - real implementation is much more complex)\n    \"\"\"\n    # Simulate encrypted values (in reality, these would be encrypted)\n    encrypted_a = 100  # Encrypted value of 50\n    encrypted_b = 200  # Encrypted value of 75\n    # Homomorphic addition (can compute on encrypted data)\n    encrypted_sum = encrypted_a + encrypted_b  # Result: 300 (represents 125)\n    # In real homomorphic encryption, you can compute without decrypting\n    return {\n        'encrypted_a': encrypted_a,\n        'encrypted_b': encrypted_b,\n        'encrypted_sum': encrypted_sum,\n        'actual_a': 50,\n        'actual_b': 75,\n        'actual_sum': 125\n    }\n# ============================================================================\n# PRIVACY-UTILITY TRADE-OFF ANALYSIS\n# ============================================================================\ndef analyze_privacy_utility_tradeoff():\n    \"\"\"\n    Analyze trade-offs between privacy and utility for different PETs\n    \"\"\"\n    technologies = {\n        'No Protection': {'privacy': 1, 'utility': 10, 'cost': 1, 'performance': 10},\n        'Anonymization': {'privacy': 6, 'utility': 8, 'cost': 2, 'performance': 9},\n        'Pseudonymization': {'privacy': 7, 'utility': 7, 'cost': 3, 'performance': 8},\n        'Differential Privacy': {'privacy': 9, 'utility': 6, 'cost': 4, 'performance': 7},\n        'SMPC': {'privacy': 10, 'utility': 5, 'cost': 9, 'performance': 4},\n        'Homomorphic Encryption': {'privacy': 10, 'utility': 4, 'cost': 10, 'performance': 3}\n    }\n    return technologies\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_pet_comparison(technologies):\n    \"\"\"\n    Plot comparison of Privacy-Enhancing Technologies\n    \"\"\"\n    tech_names = list(technologies.keys())\n    privacy_scores = [tech['privacy'] for tech in technologies.values()]\n    utility_scores = [tech['utility'] for tech in technologies.values()]\n    cost_scores = [tech['cost'] for tech in technologies.values()]\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n    # Privacy scores\n    axes[0].barh(tech_names, privacy_scores, color='#9b59b6', alpha=0.8)\n    axes[0].set_title('Privacy Level (Higher is Better)', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Privacy Score (1-10)')\n    axes[0].grid(axis='x', alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    # Utility scores\n    axes[1].barh(tech_names, utility_scores, color='#2ecc71', alpha=0.8)\n    axes[1].set_title('Data Utility (Higher is Better)', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Utility Score (1-10)')\n    axes[1].grid(axis='x', alpha=0.3)\n    axes[1].set_xlim([0, 11])\n    # Cost scores\n    axes[2].barh(tech_names, cost_scores, color='#e74c3c', alpha=0.8)\n    axes[2].set_title('Implementation Cost (Lower is Better)', fontsize=12, fontweight='bold')\n    axes[2].set_xlabel('Cost Score (1-10)')\n    axes[2].grid(axis='x', alpha=0.3)\n    axes[2].set_xlim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: pet_comparison.png\")\n    plt.close()\ndef plot_privacy_utility_tradeoff(technologies):\n    \"\"\"\n    Plot privacy-utility trade-off curve\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(10, 8))\n    tech_names = list(technologies.keys())\n    privacy = [tech['privacy'] for tech in technologies.values()]\n    utility = [tech['utility'] for tech in technologies.values()]\n    scatter = ax.scatter(privacy, utility, s=200, alpha=0.7, c=range(len(tech_names)), cmap='viridis', edgecolors='black', linewidth=2)\n    for i, name in enumerate(tech_names):\n        ax.annotate(name, (privacy[i], utility[i]), \n                   xytext=(5, 5), textcoords='offset points', fontsize=9)\n    ax.set_xlabel('Privacy Level (1-10)', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Data Utility (1-10)', fontsize=11, fontweight='bold')\n    ax.set_title('Privacy-Utility Trade-off for Different PETs', fontsize=12, fontweight='bold')\n    ax.grid(alpha=0.3)\n    ax.set_xlim([0, 11])\n    ax.set_ylim([0, 11])\n    plt.colorbar(scatter, ax=ax, label='Technology Index')\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: privacy_utility_tradeoff.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 2: Privacy-Enhancing Technologies (PETs)\")\n    print(\"=\"*80)\n    # SMPC demonstration\n    print(\"\\n1. Secure Multi-Party Computation (SMPC):\")\n    parties_data = [1000, 2000, 1500]  # Three parties' private data\n    smpc_result = smpc_sum_simulation(parties_data, n_parties=3)\n    print(f\"  Party 1 data: {smpc_result['parties_data'][0]}\")  # Party 1: First party's data\n    print(f\"  Party 2 data: {smpc_result['parties_data'][1]}\")  # Party 2: Second party's data\n    print(f\"  Party 3 data: {smpc_result['parties_data'][2]}\")  # Party 3: Third party's data\n    print(f\"  Computed sum: {smpc_result['actual_sum']}\")  # Sum: Computed sum without revealing individual values\n    print(f\"  Privacy preserved: {smpc_result['privacy_preserved']}\")  # Privacy: Whether privacy was preserved\n    \n    # Homomorphic encryption demonstration\n    print(\"\\n2. Homomorphic Encryption:\")\n    he_result = homomorphic_encryption_demo()  # Demo: Demonstrate homomorphic encryption concepts\n    print(f\"  Encrypted value A: {he_result['encrypted_a']}\")  # Encrypted A: First encrypted value\n    print(f\"  Encrypted value B: {he_result['encrypted_b']}\")  # Encrypted B: Second encrypted value\n    print(f\"  Encrypted sum (computed on encrypted data): {he_result['encrypted_sum']}\")  # Encrypted sum: Sum computed on encrypted data\n    print(f\"  Actual sum: {he_result['actual_sum']}\")  # Actual sum: Real sum of decrypted values\n    \n    # Privacy-utility trade-off\n    print(\"\\n3. Privacy-Utility Trade-off Analysis:\")\n    technologies = analyze_privacy_utility_tradeoff()  # Analyze: Get trade-off metrics for different PETs\n    for tech, metrics in technologies.items():  # Loop through technologies: Process each PET\n        print(f\"\\n{tech}:\")  # Print: Technology name\n        print(f\"  Privacy: {metrics['privacy']}\")  # Privacy: Privacy score (1-10)\n        print(f\"  Utility: {metrics['utility']}\")  # Utility: Data utility score (1-10)\n        print(f\"  Cost: {metrics['cost']}\")  # Cost: Implementation cost score (1-10)\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_pet_comparison(technologies)\n    plot_privacy_utility_tradeoff(technologies)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. SMPC allows computation on data without revealing individual values\")\n    print(\"2. Homomorphic encryption enables computation on encrypted data\")\n    print(\"3. Different PETs have different privacy-utility trade-offs\")\n    print(\"4. Higher privacy often comes at the cost of utility or performance\")\n    print(\"5. Choose PET based on specific privacy and utility requirements\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 137\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 2: Privacy-Enhancing Technologies (PETs)\nThis example demonstrates privacy-enhancing technologies:\n- Secure Multi-Party Computation (SMPC) concepts\n- Homomorphic encryption concepts\n- Privacy-utility trade-offs\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SECURE MULTI-PARTY COMPUTATION (SMPC) SIMULATION\n# ============================================================================\ndef smpc_sum_simulation(parties_data, n_parties=3):\n    \"\"\"\n    Simulate Secure Multi-Party Computation for computing sum\n    without revealing individual values\n    \"\"\"\n    # Each party adds random noise to their data\n    noise = [np.random.normal(0, 100) for _ in range(n_parties)]\n    noisy_data = [data + noise[i] for i, data in enumerate(parties_data)]\n    # Sum of noisy data\n    noisy_sum = sum(noisy_data)\n    # Remove noise to get actual sum (in real SMPC, this is done securely)\n    actual_sum = noisy_sum - sum(noise)\n    return {\n        'parties_data': parties_data, 'noisy_data': noisy_data,\n        'noisy_sum': noisy_sum,\n        'actual_sum': actual_sum,\n        'privacy_preserved': True\n    }\n# ============================================================================\n# HOMOMORPHIC ENCRYPTION CONCEPTS\n# ============================================================================\ndef homomorphic_encryption_demo():\n    \"\"\"\n    Demonstrate concept of homomorphic encryption\n    (simplified - real implementation is much more complex)\n    \"\"\"\n    # Simulate encrypted values (in reality, these would be encrypted)\n    encrypted_a = 100  # Encrypted value of 50\n    encrypted_b = 200  # Encrypted value of 75\n    # Homomorphic addition (can compute on encrypted data)\n    encrypted_sum = encrypted_a + encrypted_b  # Result: 300 (represents 125)\n    # In real homomorphic encryption, you can compute without decrypting\n    return {\n        'encrypted_a': encrypted_a,\n        'encrypted_b': encrypted_b,\n        'encrypted_sum': encrypted_sum,\n        'actual_a': 50,\n        'actual_b': 75,\n        'actual_sum': 125\n    }\n# ============================================================================\n# PRIVACY-UTILITY TRADE-OFF ANALYSIS\n# ============================================================================\ndef analyze_privacy_utility_tradeoff():\n    \"\"\"\n    Analyze trade-offs between privacy and utility for different PETs\n    \"\"\"\n    technologies = {\n        'No Protection': {'privacy': 1, 'utility': 10, 'cost': 1, 'performance': 10},\n        'Anonymization': {'privacy': 6, 'utility': 8, 'cost': 2, 'performance': 9},\n        'Pseudonymization': {'privacy': 7, 'utility': 7, 'cost': 3, 'performance': 8},\n        'Differential Privacy': {'privacy': 9, 'utility': 6, 'cost': 4, 'performance': 7},\n        'SMPC': {'privacy': 10, 'utility': 5, 'cost': 9, 'performance': 4},\n        'Homomorphic Encryption': {'privacy': 10, 'utility': 4, 'cost': 10, 'performance': 3}\n    }\n    return technologies\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_pet_comparison(technologies):\n    \"\"\"\n    Plot comparison of Privacy-Enhancing Technologies\n    \"\"\"\n    tech_names = list(technologies.keys())\n    privacy_scores = [tech['privacy'] for tech in technologies.values()]\n    utility_scores = [tech['utility'] for tech in technologies.values()]\n    cost_scores = [tech['cost'] for tech in technologies.values()]\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n    # Privacy scores\n    axes[0].barh(tech_names, privacy_scores, color='#9b59b6', alpha=0.8)\n    axes[0].set_title('Privacy Level (Higher is Better)', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Privacy Score (1-10)')\n    axes[0].grid(axis='x', alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    # Utility scores\n    axes[1].barh(tech_names, utility_scores, color='#2ecc71', alpha=0.8)\n    axes[1].set_title('Data Utility (Higher is Better)', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Utility Score (1-10)')\n    axes[1].grid(axis='x', alpha=0.3)\n    axes[1].set_xlim([0, 11])\n    # Cost scores\n    axes[2].barh(tech_names, cost_scores, color='#e74c3c', alpha=0.8)\n    axes[2].set_title('Implementation Cost (Lower is Better)', fontsize=12, fontweight='bold')\n    axes[2].set_xlabel('Cost Score (1-10)')\n    axes[2].grid(axis='x', alpha=0.3)\n    axes[2].set_xlim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: pet_comparison.png\")\n    plt.close()\ndef plot_privacy_utility_tradeoff(technologies):\n    \"\"\"\n    Plot privacy-utility trade-off curve\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(10, 8))\n    tech_names = list(technologies.keys())\n    privacy = [tech['privacy'] for tech in technologies.values()]\n    utility = [tech['utility'] for tech in technologies.values()]\n    scatter = ax.scatter(privacy, utility, s=200, alpha=0.7, c=range(len(tech_names)), cmap='viridis', edgecolors='black', linewidth=2)\n    for i, name in enumerate(tech_names):\n        ax.annotate(name, (privacy[i], utility[i]), \n                   xytext=(5, 5), textcoords='offset points', fontsize=9)\n    ax.set_xlabel('Privacy Level (1-10)', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Data Utility (1-10)', fontsize=11, fontweight='bold')\n    ax.set_title('Privacy-Utility Trade-off for Different PETs', fontsize=12, fontweight='bold')\n    ax.grid(alpha=0.3)\n    ax.set_xlim([0, 11])\n    ax.set_ylim([0, 11])\n    plt.colorbar(scatter, ax=ax, label='Technology Index')\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: privacy_utility_tradeoff.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 2: Privacy-Enhancing Technologies (PETs)\")\n    print(\"=\"*80)\n    # SMPC demonstration\n    print(\"\\n1. Secure Multi-Party Computation (SMPC):\")\n    parties_data = [1000, 2000, 1500]  # Three parties' private data\n    smpc_result = smpc_sum_simulation(parties_data, n_parties=3)\n    print(f\"  Party 1 data: {smpc_result['parties_data'][0]}\")  # Party 1: First party's data\n    print(f\"  Party 2 data: {smpc_result['parties_data'][1]}\")  # Party 2: Second party's data\n    print(f\"  Party 3 data: {smpc_result['parties_data'][2]}\")  # Party 3: Third party's data\n    print(f\"  Computed sum: {smpc_result['actual_sum']}\")  # Sum: Computed sum without revealing individual values\n    print(f\"  Privacy preserved: {smpc_result['privacy_preserved']}\")  # Privacy: Whether privacy was preserved\n    \n    # Homomorphic encryption demonstration\n    print(\"\\n2. Homomorphic Encryption:\")\n    he_result = homomorphic_encryption_demo()  # Demo: Demonstrate homomorphic encryption concepts\n    print(f\"  Encrypted value A: {he_result['encrypted_a']}\")  # Encrypted A: First encrypted value\n    print(f\"  Encrypted value B: {he_result['encrypted_b']}\")  # Encrypted B: Second encrypted value\n    print(f\"  Encrypted sum (computed on encrypted data): {he_result['encrypted_sum']}\")  # Encrypted sum: Sum computed on encrypted data\n    print(f\"  Actual sum: {he_result['actual_sum']}\")  # Actual sum: Real sum of decrypted values\n    \n    # Privacy-utility trade-off\n    print(\"\\n3. Privacy-Utility Trade-off Analysis:\")\n    technologies = analyze_privacy_utility_tradeoff()  # Analyze: Get trade-off metrics for different PETs\n    for tech, metrics in technologies.items():  # Loop through technologies: Process each PET\n        print(f\"\\n{tech}:\")  # Print: Technology name\n        print(f\"  Privacy: {metrics['privacy']}\")  # Privacy: Privacy score (1-10)\n        print(f\"  Utility: {metrics['utility']}\")  # Utility: Data utility score (1-10)\n        print(f\"  Cost: {metrics['cost']}\")  # Cost: Implementation cost score (1-10)\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_pet_comparison(technologies)\n    plot_privacy_utility_tradeoff(technologies)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. SMPC allows computation on data without revealing individual values\")\n    print(\"2. Homomorphic encryption enables computation on encrypted data\")\n    print(\"3. Different PETs have different privacy-utility trade-offs\")\n    print(\"4. Higher privacy often comes at the cost of utility or performance\")\n    print(\"5. Choose PET based on specific privacy and utility requirements\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 137\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/03_differential_privacy.ipynb",
      "status": "failed",
      "execution_time": 0.5441429615020752,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 3: Differential Privacy\nThis example demonstrates differential privacy concepts:\n- Adding noise for privacy\n- Privacy-utility trade-offs\n- Epsilon (\u03b5) parameter\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# DIFFERENTIAL PRIVACY IMPLEMENTATION\n# ============================================================================\ndef add_laplace_noise(value, epsilon=1.0, sensitivity=1.0):\n    \"\"\"\n    Add Laplace noise for differential privacy\n    epsilon (\u03b5): privacy parameter (smaller = more private)\n    sensitivity: maximum change in output from changing one record\n    \"\"\"\n    scale = sensitivity\nepsilon\n    noise = np.random.laplace(0, scale)\n    return value + noise\ndef differentially_private_mean(data, epsilon=1.0):\n    \"\"\"\n    Compute differentially private mean\n    \"\"\"\n    true_mean = np.mean(data)\n    sensitivity = (data.max() - data.min())\nlen(data)\n    noisy_mean = add_laplace_noise(true_mean, epsilon, sensitivity)\n    return true_mean, noisy_mean\ndef differentially_private_count(data, epsilon=1.0):\n    \"\"\"\n    Compute differentially private count\n    \"\"\"\n    true_count = len(data)\n    sensitivity = 1.0  # Adding\n    noisy_count = add_laplace_noise(true_count, epsilon, sensitivity)\n    return true_count, max(0, int(noisy_count))  # Ensure non-negative\n# ============================================================================\n# PRIVACY-UTILITY TRADE-OFF\n# ============================================================================\ndef analyze_epsilon_impact(data, epsilon_values):\n    \"\"\"\n    Analyze how different epsilon values affect privacy and utility\n    \"\"\"\n    results = []\n    true_mean = np.mean(data)\n    true_count = len(data)\n    for epsilon in epsilon_values:\n        # Compute multiple times to show variance\n        noisy_means = []\n        noisy_counts = []\n        for _ in range(10):\n            _, noisy_mean = differentially_private_mean(data, epsilon)\n            _, noisy_count = differentially_private_count(data, epsilon)\n            noisy_means.append(noisy_mean)\n            noisy_counts.append(noisy_count)\n        mean_error = np.mean([abs(m - true_mean) for m in noisy_means])\n        count_error = np.mean([abs(c - true_count) for c in noisy_counts])\n        results.append({\n            'epsilon': epsilon, 'privacy_level': 1.0\nepsilon,  # Higher epsilon = less private\n            'mean_error': mean_error,\n            'count_error': count_error,\n            'noisy_mean_avg': np.mean(noisy_means),\n            'noisy_count_avg': np.mean(noisy_counts)\n        })\n    return results\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_differential_privacy_comparison(data, epsilon_values):\n    \"\"\"\n    Plot comparison of differential privacy with different epsilon values\n    \"\"\"\n    results = analyze_epsilon_impact(data, epsilon_values)\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    epsilons = [r['epsilon'] for r in results]\n    mean_errors = [r['mean_error'] for r in results]\n    count_errors = [r['count_error'] for r in results]\n    privacy_levels = [r['privacy_level'] for r in results]\n    # Mean error vs epsilon\n    axes[0, 0].plot(epsilons, mean_errors, marker='o', linewidth=2, markersize=8, color='#e74c3c')\n    axes[0, 0].set_xlabel('Epsilon (\u03b5)', fontsize=11, fontweight='bold')\n    axes[0, 0].set_ylabel('Mean Error', fontsize=11, fontweight='bold')\n    axes[0, 0].set_title('Privacy vs Accuracy: Mean Estimation', fontsize=12, fontweight='bold')\n    axes[0, 0].grid(alpha=0.3)\n    axes[0, 0].set_xscale('log')\n    # Count error vs epsilon\n    axes[0, 1].plot(epsilons, count_errors, marker='s', linewidth=2, markersize=8, color='#3498db')\n    axes[0, 1].set_xlabel('Epsilon (\u03b5)', fontsize=11, fontweight='bold')\n    axes[0, 1].set_ylabel('Count Error', fontsize=11, fontweight='bold')\n    axes[0, 1].set_title('Privacy vs Accuracy: Count Estimation', fontsize=12, fontweight='bold')\n    axes[0, 1].grid(alpha=0.3)\n    axes[0, 1].set_xscale('log')\n    # Privacy level\n    axes[1, 0].bar(range(len(epsilons)), privacy_levels, color='#9b59b6', alpha=0.8)\n    axes[1, 0].set_xlabel('Epsilon Value Index', fontsize=11, fontweight='bold')\n    axes[1, 0].set_ylabel('Privacy Level (Higher is Better)', fontsize=11, fontweight='bold')\n    axes[1, 0].set_title('Privacy Level by Epsilon', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xticks(range(len(epsilons)))\n    axes[1, 0].set_xticklabels([f'\u03b5={e:.2f}' for e in epsilons], rotation=15)\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    # Privacy-utility trade-off\n    axes[1, 1].scatter(privacy_levels, mean_errors, s=200, alpha=0.7, \n                      c=epsilons, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n    axes[1, 1].set_xlabel('Privacy Level', fontsize=11, fontweight='bold')\n    axes[1, 1].set_ylabel('Mean Error (Lower is Better)', fontsize=11, fontweight='bold')\n    axes[1, 1].set_title('Privacy-Utility Trade-off', fontsize=12, fontweight='bold')\n    axes[1, 1].grid(alpha=0.3)\n    cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n    cbar.set_label('Epsilon (\u03b5)', fontsize=10)\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: differential_privacy_analysis.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 3: Differential Privacy\")\n    print(\"=\"*80)\n    # Generate sample data\n    np.random.seed(42)\n    data = np.random.normal(50000, 15000, 1000)  # Salary data\n    print(f\"\\nDataset: {len(data)} samples\")\n    print(f\"True mean: ${np.mean(data):,.2f}\")\n    print(f\"True count: {len(data)}\")\n    # Demonstrate differential privacy\n    print(\"\\n\" + \"=\"*80)\n    print(\"Differential Privacy Demonstration\")\n    print(\"=\"*80)\n    epsilon_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n    for epsilon in epsilon_values:\n        true_mean, noisy_mean = differentially_private_mean(data, epsilon)\n        true_count, noisy_count = differentially_private_count(data, epsilon)\n        print(f\"\\nEpsilon (\u03b5) = {epsilon}:\")\n        print(f\"  True mean: ${true_mean:,.2f}, Noisy mean: ${noisy_mean:,.2f}\")\n        print(f\"  Error: ${abs(noisy_mean - true_mean):,.2f}\")\n        print(f\"  True count: {true_count}, Noisy count: {noisy_count}\")\n        print(f\"  Privacy level: {1.0\nepsilon:.2f} (higher = more private)\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_differential_privacy_comparison(data, epsilon_values)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Differential privacy adds controlled noise to protect individual privacy\")\n    print(\"2. Epsilon (\u03b5) controls privacy level: smaller \u03b5 = more private\")\n    print(\"3. There is a trade-off between privacy and data utility\")\n    print(\"4. Differential privacy provides mathematical privacy guarantees\")\n    print(\"5. Choose epsilon based on privacy requirements and acceptable error\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    noise = np.random.laplace(0, scale)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 3: Differential Privacy\nThis example demonstrates differential privacy concepts:\n- Adding noise for privacy\n- Privacy-utility trade-offs\n- Epsilon (\u03b5) parameter\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# DIFFERENTIAL PRIVACY IMPLEMENTATION\n# ============================================================================\ndef add_laplace_noise(value, epsilon=1.0, sensitivity=1.0):\n    \"\"\"\n    Add Laplace noise for differential privacy\n    epsilon (\u03b5): privacy parameter (smaller = more private)\n    sensitivity: maximum change in output from changing one record\n    \"\"\"\n    scale = sensitivity\nepsilon\n    noise = np.random.laplace(0, scale)\n    return value + noise\ndef differentially_private_mean(data, epsilon=1.0):\n    \"\"\"\n    Compute differentially private mean\n    \"\"\"\n    true_mean = np.mean(data)\n    sensitivity = (data.max() - data.min())\nlen(data)\n    noisy_mean = add_laplace_noise(true_mean, epsilon, sensitivity)\n    return true_mean, noisy_mean\ndef differentially_private_count(data, epsilon=1.0):\n    \"\"\"\n    Compute differentially private count\n    \"\"\"\n    true_count = len(data)\n    sensitivity = 1.0  # Adding\n    noisy_count = add_laplace_noise(true_count, epsilon, sensitivity)\n    return true_count, max(0, int(noisy_count))  # Ensure non-negative\n# ============================================================================\n# PRIVACY-UTILITY TRADE-OFF\n# ============================================================================\ndef analyze_epsilon_impact(data, epsilon_values):\n    \"\"\"\n    Analyze how different epsilon values affect privacy and utility\n    \"\"\"\n    results = []\n    true_mean = np.mean(data)\n    true_count = len(data)\n    for epsilon in epsilon_values:\n        # Compute multiple times to show variance\n        noisy_means = []\n        noisy_counts = []\n        for _ in range(10):\n            _, noisy_mean = differentially_private_mean(data, epsilon)\n            _, noisy_count = differentially_private_count(data, epsilon)\n            noisy_means.append(noisy_mean)\n            noisy_counts.append(noisy_count)\n        mean_error = np.mean([abs(m - true_mean) for m in noisy_means])\n        count_error = np.mean([abs(c - true_count) for c in noisy_counts])\n        results.append({\n            'epsilon': epsilon, 'privacy_level': 1.0\nepsilon,  # Higher epsilon = less private\n            'mean_error': mean_error,\n            'count_error': count_error,\n            'noisy_mean_avg': np.mean(noisy_means),\n            'noisy_count_avg': np.mean(noisy_counts)\n        })\n    return results\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_differential_privacy_comparison(data, epsilon_values):\n    \"\"\"\n    Plot comparison of differential privacy with different epsilon values\n    \"\"\"\n    results = analyze_epsilon_impact(data, epsilon_values)\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    epsilons = [r['epsilon'] for r in results]\n    mean_errors = [r['mean_error'] for r in results]\n    count_errors = [r['count_error'] for r in results]\n    privacy_levels = [r['privacy_level'] for r in results]\n    # Mean error vs epsilon\n    axes[0, 0].plot(epsilons, mean_errors, marker='o', linewidth=2, markersize=8, color='#e74c3c')\n    axes[0, 0].set_xlabel('Epsilon (\u03b5)', fontsize=11, fontweight='bold')\n    axes[0, 0].set_ylabel('Mean Error', fontsize=11, fontweight='bold')\n    axes[0, 0].set_title('Privacy vs Accuracy: Mean Estimation', fontsize=12, fontweight='bold')\n    axes[0, 0].grid(alpha=0.3)\n    axes[0, 0].set_xscale('log')\n    # Count error vs epsilon\n    axes[0, 1].plot(epsilons, count_errors, marker='s', linewidth=2, markersize=8, color='#3498db')\n    axes[0, 1].set_xlabel('Epsilon (\u03b5)', fontsize=11, fontweight='bold')\n    axes[0, 1].set_ylabel('Count Error', fontsize=11, fontweight='bold')\n    axes[0, 1].set_title('Privacy vs Accuracy: Count Estimation', fontsize=12, fontweight='bold')\n    axes[0, 1].grid(alpha=0.3)\n    axes[0, 1].set_xscale('log')\n    # Privacy level\n    axes[1, 0].bar(range(len(epsilons)), privacy_levels, color='#9b59b6', alpha=0.8)\n    axes[1, 0].set_xlabel('Epsilon Value Index', fontsize=11, fontweight='bold')\n    axes[1, 0].set_ylabel('Privacy Level (Higher is Better)', fontsize=11, fontweight='bold')\n    axes[1, 0].set_title('Privacy Level by Epsilon', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xticks(range(len(epsilons)))\n    axes[1, 0].set_xticklabels([f'\u03b5={e:.2f}' for e in epsilons], rotation=15)\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    # Privacy-utility trade-off\n    axes[1, 1].scatter(privacy_levels, mean_errors, s=200, alpha=0.7, \n                      c=epsilons, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n    axes[1, 1].set_xlabel('Privacy Level', fontsize=11, fontweight='bold')\n    axes[1, 1].set_ylabel('Mean Error (Lower is Better)', fontsize=11, fontweight='bold')\n    axes[1, 1].set_title('Privacy-Utility Trade-off', fontsize=12, fontweight='bold')\n    axes[1, 1].grid(alpha=0.3)\n    cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n    cbar.set_label('Epsilon (\u03b5)', fontsize=10)\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: differential_privacy_analysis.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 3: Differential Privacy\")\n    print(\"=\"*80)\n    # Generate sample data\n    np.random.seed(42)\n    data = np.random.normal(50000, 15000, 1000)  # Salary data\n    print(f\"\\nDataset: {len(data)} samples\")\n    print(f\"True mean: ${np.mean(data):,.2f}\")\n    print(f\"True count: {len(data)}\")\n    # Demonstrate differential privacy\n    print(\"\\n\" + \"=\"*80)\n    print(\"Differential Privacy Demonstration\")\n    print(\"=\"*80)\n    epsilon_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n    for epsilon in epsilon_values:\n        true_mean, noisy_mean = differentially_private_mean(data, epsilon)\n        true_count, noisy_count = differentially_private_count(data, epsilon)\n        print(f\"\\nEpsilon (\u03b5) = {epsilon}:\")\n        print(f\"  True mean: ${true_mean:,.2f}, Noisy mean: ${noisy_mean:,.2f}\")\n        print(f\"  Error: ${abs(noisy_mean - true_mean):,.2f}\")\n        print(f\"  True count: {true_count}, Noisy count: {noisy_count}\")\n        print(f\"  Privacy level: {1.0\nepsilon:.2f} (higher = more private)\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_differential_privacy_comparison(data, epsilon_values)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Differential privacy adds controlled noise to protect individual privacy\")\n    print(\"2. Epsilon (\u03b5) controls privacy level: smaller \u03b5 = more private\")\n    print(\"3. There is a trade-off between privacy and data utility\")\n    print(\"4. Differential privacy provides mathematical privacy guarantees\")\n    print(\"5. Choose epsilon based on privacy requirements and acceptable error\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    noise = np.random.laplace(0, scale)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/04_gdpr_compliance.ipynb",
      "status": "failed",
      "execution_time": 0.547382116317749,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 4: GDPR Compliance\nThis example demonstrates GDPR compliance requirements:\n- Key GDPR principles\n- Data subject rights\n- Compliance checklist\n- Privacy by design\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# GDPR PRINCIPLES\n# ============================================================================\ndef gdpr_principles():\n    \"\"\"\n    Define key GDPR principles\n    \"\"\"\n    principles = {\n        'Lawfulness, Fairness, Transparency': {\n            'description': 'Process data lawfully, fairly, and transparently',\n            'importance': 10,\n            'compliance_level': 0.85\n        },\n        'Purpose Limitation': {\n            'description': 'Collect data for specified, explicit, legitimate purposes',\n            'importance': 9,\n            'compliance_level': 0.80\n        },\n        'Data Minimization': {\n            'description': 'Collect only data that is necessary',\n            'importance': 9,\n            'compliance_level': 0.75\n        },\n        'Accuracy': {\n            'description': 'Keep data accurate and up-to-date',\n            'importance': 8,\n            'compliance_level': 0.90\n        },\n        'Storage Limitation': {\n            'description': 'Retain data only as long as necessary',\n            'importance': 8,\n            'compliance_level': 0.70\n        },\n        'Integrity and Confidentiality': {\n            'description': 'Ensure appropriate security of personal data',\n            'importance': 10,\n            'compliance_level': 0.85\n        },\n        'Accountability': {\n            'description': 'Demonstrate compliance with GDPR principles',\n            'importance': 9,\n            'compliance_level': 0.75\n        }\n    }\n    return principles\n# ============================================================================\n# DATA SUBJECT RIGHTS\n# ============================================================================\ndef data_subject_rights():\n    \"\"\"\n    Define data subject rights under GDPR\n    \"\"\"\n    rights = {\n        'Right to Access': {\n            'description': 'Access personal data held by organization', 'response_time_days': 30,\n            'complexity': 'Medium'\n        },\n        'Right to Rectification': {\n            'description': 'Correct inaccurate personal data',\n            'response_time_days': 30,\n            'complexity': 'Low'\n        },\n        'Right to Erasure': {\n            'description': 'Request deletion of personal data',\n            'response_time_days': 30,\n            'complexity': 'High'\n        },\n        'Right to Restrict Processing': {\n            'description': 'Limit how data is processed',\n            'response_time_days': 30,\n            'complexity': 'Medium'\n        },\n        'Right to Data Portability': {\n            'description': 'Receive data in machine-readable format',\n            'response_time_days': 30,\n            'complexity': 'Medium'\n        },\n        'Right to Object': {\n            'description': 'Object to processing of personal data',\n            'response_time_days': 30,\n            'complexity': 'Low'\n        }\n    }\n    return rights\n# ============================================================================\n# GDPR COMPLIANCE CHECKLIST\n# ============================================================================\ndef gdpr_compliance_checklist():\n    \"\"\"\n    Create GDPR compliance checklist\n    \"\"\"\n    checklist = {\n        'Data Inventory': {\n            'status': 'Complete',\n            'items': [\n                'Document all personal data collected',\n                'Identify data sources and purposes',\n                'Map data flows',\n                'Identify data processors'\n            ]\n        },\n        'Legal Basis': {\n            'status': 'Complete',\n            'items': [\n                'Identify legal basis for processing',\n                'Document consent mechanisms',\n                'Review legitimate interests',\n                'Update privacy notices'\n            ]\n        },\n        'Data Protection': {\n            'status': 'In Progress',\n            'items': [\n                'Implement encryption',\n                'Access controls',\n                'Data anonymization',\n                'Security monitoring'\n            ]\n        },\n        'Data Subject Rights': {\n            'status': 'In Progress',\n            'items': [\n                'Request handling procedures',\n                'Response time tracking',\n                'Data export functionality',\n                'Deletion procedures'\n            ]\n        },\n        'Privacy by Design': {\n            'status': 'In Progress',\n            'items': [\n                'Privacy impact assessments',\n                'Default privacy settings',\n                'Minimal data collection',\n                'Data retention policies'\n            ]\n        }\n    }\n    return checklist\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_gdpr_principles(principles):\n    \"\"\"\n    Plot GDPR principles importance and compliance\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    principle_names = list(principles.keys())\n    importance = [p['importance'] for p in principles.values()]\n    compliance = [p['compliance_level'] * 10 for p in principles.values()]\n    y_pos = np.arange(len(principle_names))\n    axes[0].barh(y_pos, importance, color='#3498db', alpha=0.8)\n    axes[0].set_yticks(y_pos)\n    axes[0].set_yticklabels(principle_names, fontsize=9)\n    axes[0].set_xlabel('Importance (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_title('GDPR Principles Importance', fontsize=12, fontweight='bold')\n    axes[0].grid(axis='x', alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    axes[1].barh(y_pos, compliance, color='#2ecc71', alpha=0.8)\n    axes[1].set_yticks(y_pos)\n    axes[1].set_yticklabels(principle_names, fontsize=9)\n    axes[1].set_xlabel('Compliance Level (1-10)', fontsize=11, fontweight='bold')\n    axes[1].set_title('Current Compliance Level', fontsize=12, fontweight='bold')\n    axes[1].grid(axis='x', alpha=0.3)\n    axes[1].set_xlim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: gdpr_principles.png\")\n    plt.close()\ndef plot_data_subject_rights(rights):\n    \"\"\"\n    Plot data subject rights analysis\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    right_names = list(rights.keys())\n    response_times = [r['response_time_days'] for r in rights.values()]\n    complexities = {'Low': 1, 'Medium': 2, 'High': 3}\n    complexity_scores = [complexities[r['complexity']] for r in rights.values()]\n    axes[0].bar(right_names, response_times, color='#f39c12', alpha=0.8)\n    axes[0].set_title('Response Time Requirements', fontsize=12, fontweight='bold')\n    axes[0].set_ylabel('Days')\n    axes[0].tick_params(axis='x', rotation=15)\n    axes[0].axhline(y=30, color='red', linestyle='--', linewidth=2, label='GDPR Limit (30 days)')\n    axes[0].legend()\n    axes[0].grid(axis='y', alpha=0.3)\n    axes[1].bar(right_names, complexity_scores, color='#e74c3c', alpha=0.8)\n    axes[1].set_title('Implementation Complexity', fontsize=12, fontweight='bold')\n    axes[1].set_ylabel('Complexity (1=Low, 2=Medium, 3=High)')\n    axes[1].tick_params(axis='x', rotation=15)\n    axes[1].grid(axis='y', alpha=0.3)\n    axes[1].set_ylim([0, 4])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: data_subject_rights.png\")\n    plt.close()\ndef plot_compliance_checklist(checklist):\n    \"\"\"\n    Plot GDPR compliance checklist status\n    \"\"\"\n    categories = list(checklist.keys())\n    status_counts = {'Complete': 0, 'In Progress': 0, 'Not Started': 0}\n    for cat, info in checklist.items():\n        if info['status'] in status_counts:\n            status_counts[info['status']] += 1\n    fig, ax = plt.subplots(figsize=(10, 6))\n    colors = {'Complete': '#2ecc71', 'In Progress': '#f39c12', 'Not Started': '#e74c3c'}\n    bars = ax.bar(status_counts.keys(), status_counts.values(), color=[colors[s] for s in status_counts.keys()], alpha=0.8)\n    for bar, count in zip(bars, status_counts.values()):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n               f'{int(count)}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Number of Categories', fontsize=11, fontweight='bold')\n    ax.set_title('GDPR Compliance Checklist Status', fontsize=12, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: gdpr_compliance_status.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 4: GDPR Compliance\")\n    print(\"=\"*80)\n    # GDPR Principles\n    print(\"\\n1. GDPR Principles:\")\n    principles = gdpr_principles()\n    for principle, info in principles.items():\n        print(f\"\\n{principle}:\")\n        print(f\"  Description: {info['description']}\")\n        print(f\"  Importance: {info['importance']}\")\n        print(f\"  Compliance Level: {info['compliance_level']*100:.0f}%\")\n    # Data Subject Rights\n    print(\"\\n\" + \"=\"*80)\n    print(\"2. Data Subject Rights:\")\n    print(\"=\"*80)\n    rights = data_subject_rights()\n    for right, info in rights.items():\n        print(f\"\\n{right}:\")\n        print(f\"  Description: {info['description']}\")\n        print(f\"  Response Time: {info['response_time_days']} days\")\n        print(f\"  Complexity: {info['complexity']}\")\n    # Compliance Checklist\n    print(\"\\n\" + \"=\"*80)\n    print(\"3. GDPR Compliance Checklist:\")\n    print(\"=\"*80)\n    checklist = gdpr_compliance_checklist()\n    for category, info in checklist.items():\n        print(f\"\\n{category} ({info['status']}):\")\n        for item in info['items']:\n            print(f\"  - {item}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_gdpr_principles(principles)\n    plot_data_subject_rights(rights)\n    plot_compliance_checklist(checklist)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. GDPR has 7 key principles for data processing\")\n    print(\"2. Data subjects have 6 fundamental rights\")\n    print(\"3. Organizations must respond to requests within 30 days\")\n    print(\"4. Privacy by design is a core requirement\")\n    print(\"5. Compliance requires ongoing monitoring and documentation\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 241\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 4: GDPR Compliance\nThis example demonstrates GDPR compliance requirements:\n- Key GDPR principles\n- Data subject rights\n- Compliance checklist\n- Privacy by design\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# GDPR PRINCIPLES\n# ============================================================================\ndef gdpr_principles():\n    \"\"\"\n    Define key GDPR principles\n    \"\"\"\n    principles = {\n        'Lawfulness, Fairness, Transparency': {\n            'description': 'Process data lawfully, fairly, and transparently',\n            'importance': 10,\n            'compliance_level': 0.85\n        },\n        'Purpose Limitation': {\n            'description': 'Collect data for specified, explicit, legitimate purposes',\n            'importance': 9,\n            'compliance_level': 0.80\n        },\n        'Data Minimization': {\n            'description': 'Collect only data that is necessary',\n            'importance': 9,\n            'compliance_level': 0.75\n        },\n        'Accuracy': {\n            'description': 'Keep data accurate and up-to-date',\n            'importance': 8,\n            'compliance_level': 0.90\n        },\n        'Storage Limitation': {\n            'description': 'Retain data only as long as necessary',\n            'importance': 8,\n            'compliance_level': 0.70\n        },\n        'Integrity and Confidentiality': {\n            'description': 'Ensure appropriate security of personal data',\n            'importance': 10,\n            'compliance_level': 0.85\n        },\n        'Accountability': {\n            'description': 'Demonstrate compliance with GDPR principles',\n            'importance': 9,\n            'compliance_level': 0.75\n        }\n    }\n    return principles\n# ============================================================================\n# DATA SUBJECT RIGHTS\n# ============================================================================\ndef data_subject_rights():\n    \"\"\"\n    Define data subject rights under GDPR\n    \"\"\"\n    rights = {\n        'Right to Access': {\n            'description': 'Access personal data held by organization', 'response_time_days': 30,\n            'complexity': 'Medium'\n        },\n        'Right to Rectification': {\n            'description': 'Correct inaccurate personal data',\n            'response_time_days': 30,\n            'complexity': 'Low'\n        },\n        'Right to Erasure': {\n            'description': 'Request deletion of personal data',\n            'response_time_days': 30,\n            'complexity': 'High'\n        },\n        'Right to Restrict Processing': {\n            'description': 'Limit how data is processed',\n            'response_time_days': 30,\n            'complexity': 'Medium'\n        },\n        'Right to Data Portability': {\n            'description': 'Receive data in machine-readable format',\n            'response_time_days': 30,\n            'complexity': 'Medium'\n        },\n        'Right to Object': {\n            'description': 'Object to processing of personal data',\n            'response_time_days': 30,\n            'complexity': 'Low'\n        }\n    }\n    return rights\n# ============================================================================\n# GDPR COMPLIANCE CHECKLIST\n# ============================================================================\ndef gdpr_compliance_checklist():\n    \"\"\"\n    Create GDPR compliance checklist\n    \"\"\"\n    checklist = {\n        'Data Inventory': {\n            'status': 'Complete',\n            'items': [\n                'Document all personal data collected',\n                'Identify data sources and purposes',\n                'Map data flows',\n                'Identify data processors'\n            ]\n        },\n        'Legal Basis': {\n            'status': 'Complete',\n            'items': [\n                'Identify legal basis for processing',\n                'Document consent mechanisms',\n                'Review legitimate interests',\n                'Update privacy notices'\n            ]\n        },\n        'Data Protection': {\n            'status': 'In Progress',\n            'items': [\n                'Implement encryption',\n                'Access controls',\n                'Data anonymization',\n                'Security monitoring'\n            ]\n        },\n        'Data Subject Rights': {\n            'status': 'In Progress',\n            'items': [\n                'Request handling procedures',\n                'Response time tracking',\n                'Data export functionality',\n                'Deletion procedures'\n            ]\n        },\n        'Privacy by Design': {\n            'status': 'In Progress',\n            'items': [\n                'Privacy impact assessments',\n                'Default privacy settings',\n                'Minimal data collection',\n                'Data retention policies'\n            ]\n        }\n    }\n    return checklist\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_gdpr_principles(principles):\n    \"\"\"\n    Plot GDPR principles importance and compliance\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    principle_names = list(principles.keys())\n    importance = [p['importance'] for p in principles.values()]\n    compliance = [p['compliance_level'] * 10 for p in principles.values()]\n    y_pos = np.arange(len(principle_names))\n    axes[0].barh(y_pos, importance, color='#3498db', alpha=0.8)\n    axes[0].set_yticks(y_pos)\n    axes[0].set_yticklabels(principle_names, fontsize=9)\n    axes[0].set_xlabel('Importance (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_title('GDPR Principles Importance', fontsize=12, fontweight='bold')\n    axes[0].grid(axis='x', alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    axes[1].barh(y_pos, compliance, color='#2ecc71', alpha=0.8)\n    axes[1].set_yticks(y_pos)\n    axes[1].set_yticklabels(principle_names, fontsize=9)\n    axes[1].set_xlabel('Compliance Level (1-10)', fontsize=11, fontweight='bold')\n    axes[1].set_title('Current Compliance Level', fontsize=12, fontweight='bold')\n    axes[1].grid(axis='x', alpha=0.3)\n    axes[1].set_xlim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: gdpr_principles.png\")\n    plt.close()\ndef plot_data_subject_rights(rights):\n    \"\"\"\n    Plot data subject rights analysis\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    right_names = list(rights.keys())\n    response_times = [r['response_time_days'] for r in rights.values()]\n    complexities = {'Low': 1, 'Medium': 2, 'High': 3}\n    complexity_scores = [complexities[r['complexity']] for r in rights.values()]\n    axes[0].bar(right_names, response_times, color='#f39c12', alpha=0.8)\n    axes[0].set_title('Response Time Requirements', fontsize=12, fontweight='bold')\n    axes[0].set_ylabel('Days')\n    axes[0].tick_params(axis='x', rotation=15)\n    axes[0].axhline(y=30, color='red', linestyle='--', linewidth=2, label='GDPR Limit (30 days)')\n    axes[0].legend()\n    axes[0].grid(axis='y', alpha=0.3)\n    axes[1].bar(right_names, complexity_scores, color='#e74c3c', alpha=0.8)\n    axes[1].set_title('Implementation Complexity', fontsize=12, fontweight='bold')\n    axes[1].set_ylabel('Complexity (1=Low, 2=Medium, 3=High)')\n    axes[1].tick_params(axis='x', rotation=15)\n    axes[1].grid(axis='y', alpha=0.3)\n    axes[1].set_ylim([0, 4])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: data_subject_rights.png\")\n    plt.close()\ndef plot_compliance_checklist(checklist):\n    \"\"\"\n    Plot GDPR compliance checklist status\n    \"\"\"\n    categories = list(checklist.keys())\n    status_counts = {'Complete': 0, 'In Progress': 0, 'Not Started': 0}\n    for cat, info in checklist.items():\n        if info['status'] in status_counts:\n            status_counts[info['status']] += 1\n    fig, ax = plt.subplots(figsize=(10, 6))\n    colors = {'Complete': '#2ecc71', 'In Progress': '#f39c12', 'Not Started': '#e74c3c'}\n    bars = ax.bar(status_counts.keys(), status_counts.values(), color=[colors[s] for s in status_counts.keys()], alpha=0.8)\n    for bar, count in zip(bars, status_counts.values()):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n               f'{int(count)}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Number of Categories', fontsize=11, fontweight='bold')\n    ax.set_title('GDPR Compliance Checklist Status', fontsize=12, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: gdpr_compliance_status.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 4: GDPR Compliance\")\n    print(\"=\"*80)\n    # GDPR Principles\n    print(\"\\n1. GDPR Principles:\")\n    principles = gdpr_principles()\n    for principle, info in principles.items():\n        print(f\"\\n{principle}:\")\n        print(f\"  Description: {info['description']}\")\n        print(f\"  Importance: {info['importance']}\")\n        print(f\"  Compliance Level: {info['compliance_level']*100:.0f}%\")\n    # Data Subject Rights\n    print(\"\\n\" + \"=\"*80)\n    print(\"2. Data Subject Rights:\")\n    print(\"=\"*80)\n    rights = data_subject_rights()\n    for right, info in rights.items():\n        print(f\"\\n{right}:\")\n        print(f\"  Description: {info['description']}\")\n        print(f\"  Response Time: {info['response_time_days']} days\")\n        print(f\"  Complexity: {info['complexity']}\")\n    # Compliance Checklist\n    print(\"\\n\" + \"=\"*80)\n    print(\"3. GDPR Compliance Checklist:\")\n    print(\"=\"*80)\n    checklist = gdpr_compliance_checklist()\n    for category, info in checklist.items():\n        print(f\"\\n{category} ({info['status']}):\")\n        for item in info['items']:\n            print(f\"  - {item}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_gdpr_principles(principles)\n    plot_data_subject_rights(rights)\n    plot_compliance_checklist(checklist)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. GDPR has 7 key principles for data processing\")\n    print(\"2. Data subjects have 6 fundamental rights\")\n    print(\"3. Organizations must respond to requests within 30 days\")\n    print(\"4. Privacy by design is a core requirement\")\n    print(\"5. Compliance requires ongoing monitoring and documentation\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 241\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/05_secure_development.ipynb",
      "status": "failed",
      "execution_time": 0.6947710514068604,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 5: Secure AI Development Practices\nThis example demonstrates secure AI development practices:\n- Security vulnerabilities in AI systems\n- Secure coding practices\n- Security testing\n- Incident response\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SECURITY VULNERABILITIES\n# ============================================================================\ndef identify_security_vulnerabilities():\n    \"\"\"\n    Identify common security vulnerabilities in AI systems\n    \"\"\"\n    vulnerabilities = {\n        'Adversarial Attacks': {\n            'severity': 'High', 'impact': 9,\n            'likelihood': 7,\n            'description': 'Malicious inputs designed to fool AI models'\n        },\n        'Model Inversion': {\n            'severity': 'High',\n            'impact': 8,\n            'likelihood': 6,\n            'description': 'Reconstructing training data from model outputs'\n        },\n        'Membership Inference': {\n            'severity': 'Medium',\n            'impact': 7,\n            'likelihood': 7,\n            'description': 'Determining if specific data was in training set'\n        },\n        'Data Poisoning': {\n            'severity': 'High',\n            'impact': 9,\n            'likelihood': 5,\n            'description': 'Injecting malicious data into training set'\n        },\n        'Model Theft': {\n            'severity': 'Medium',\n            'impact': 6,\n            'likelihood': 6,\n            'description': 'Stealing model architecture and parameters'\n        },\n        'Insufficient Access Controls': {\n            'severity': 'High',\n            'impact': 8,\n            'likelihood': 8,\n            'description': 'Unauthorized access to models or data'\n        }\n    }\n    return vulnerabilities\n# ============================================================================\n# SECURE DEVELOPMENT PRACTICES\n# ============================================================================\ndef secure_development_practices():\n    \"\"\"\n    Define secure AI development practices\n    \"\"\"\n    practices = {\n        'Input Validation': {\n            'phase': 'Development',\n            'importance': 10,\n            'implementation': 'Validate and sanitize all inputs'\n        },\n        'Output Sanitization': {\n            'phase': 'Development',\n            'importance': 9,\n            'implementation': 'Sanitize model outputs before use'\n        },\n        'Access Control': {\n            'phase': 'Deployment',\n            'importance': 10,\n            'implementation': 'Implement role-based access control'\n        },\n        'Encryption': {\n            'phase': 'All Phases',\n            'importance': 10,\n            'implementation': 'Encrypt data at rest and in transit'\n        },\n        'Security Testing': {\n            'phase': 'Testing',\n            'importance': 9,\n            'implementation': 'Regular security audits and penetration testing'\n        },\n        'Monitoring': {\n            'phase': 'Operations',\n            'importance': 9,\n            'implementation': 'Monitor for anomalies and attacks'\n        },\n        'Incident Response': {\n            'phase': 'Operations',\n            'importance': 8,\n            'implementation': 'Have response plan for security incidents'\n        }\n    }\n    return practices\n# ============================================================================\n# SECURITY RISK MATRIX\n# ============================================================================\ndef create_risk_matrix(vulnerabilities):\n    \"\"\"\n    Create risk matrix for security vulnerabilities\n    \"\"\"\n    risk_matrix = []\n    for vuln, info in vulnerabilities.items():\n        risk_score = info['impact'] * info['likelihood']\n        risk_matrix.append({\n            'vulnerability': vuln, 'impact': info['impact'],\n            'likelihood': info['likelihood'],\n            'risk_score': risk_score,\n            'severity': info['severity']\n        })\n    return risk_matrix\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_security_vulnerabilities(vulnerabilities):\n    \"\"\"\n    Plot security vulnerabilities analysis\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    vuln_names = list(vulnerabilities.keys())\n    impacts = [v['impact'] for v in vulnerabilities.values()]\n    likelihoods = [v['likelihood'] for v in vulnerabilities.values()]\n    # Risk matrix\n    scatter = axes[0].scatter(likelihoods, impacts, s=300, alpha=0.7, \n                             c=impacts, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n    for i, name in enumerate(vuln_names):\n        axes[0].annotate(name, (likelihoods[i], impacts[i]), \n                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n    axes[0].set_xlabel('Likelihood (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_ylabel('Impact (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_title('Security Risk Matrix', fontsize=12, fontweight='bold')\n    axes[0].grid(alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    axes[0].set_ylim([0, 11])\n    plt.colorbar(scatter, ax=axes[0], label='Impact')\n    # Severity distribution\n    severity_counts = {}\n    for v in vulnerabilities.values():\n        sev = v['severity']\n        severity_counts[sev] = severity_counts.get(sev, 0) + 1\n    colors = {'High': '#e74c3c', 'Medium': '#f39c12', 'Low': '#2ecc71'}\n    axes[1].bar(severity_counts.keys(), severity_counts.values(), color=[colors[s] for s in severity_counts.keys()], alpha=0.8)\n    axes[1].set_title('Vulnerability Severity Distribution', fontsize=12, fontweight='bold')\n    axes[1].set_ylabel('Count')\n    axes[1].grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: security_vulnerabilities.png\")\n    plt.close()\ndef plot_secure_practices(practices):\n    \"\"\"\n    Plot secure development practices by phase\n    \"\"\"\n    phases = {}\n    for practice, info in practices.items():\n        phase = info['phase']\n        if phase not in phases:\n            phases[phase] = []\n        phases[phase].append((practice, info['importance']))\n    fig, ax = plt.subplots(figsize=(12, 8))\n    y_pos = 0\n    colors = ['#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n    color_idx = 0\n    for phase, items in phases.items():\n        practices_list = [item[0] for item in items]\n        importance_list = [item[1] for item in items]\n        x_start = y_pos\n        for i, (practice, importance) in enumerate(items):\n            ax.barh(y_pos, importance, left=0, color=colors[color_idx % len(colors)], alpha=0.7, edgecolor='black')\n            ax.text(importance/2, y_pos, practice, ha='center', va='center', \n                   fontsize=9, fontweight='bold')\n            y_pos += 1\n        # Add phase label\n        ax.text(-0.5, (x_start + y_pos - 1)\n2, phase, ha='right', va='center',\n               fontsize=10, fontweight='bold', rotation=0)\n        y_pos += 0.5\n        color_idx += 1\n    ax.set_xlabel('Importance (1-10)', fontsize=11, fontweight='bold')\n    ax.set_title('Secure Development Practices by Phase', fontsize=12, fontweight='bold')\n    ax.set_xlim([0, 11])\n    ax.grid(axis='x', alpha=0.3)\n    ax.set_yticks([])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: secure_practices.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 5: Secure AI Development Practices\")\n    print(\"=\"*80)\n    # Security Vulnerabilities\n    print(\"\\n1. Security Vulnerabilities in AI Systems:\")\n    vulnerabilities = identify_security_vulnerabilities()\n    for vuln, info in vulnerabilities.items():\n        print(f\"\\n{vuln}:\")\n        print(f\"  Severity: {info['severity']}\")\n        print(f\"  Impact: {info['impact']}\")\n        print(f\"  Likelihood: {info['likelihood']}\")\n        print(f\"  Description: {info['description']}\")\n    # Secure Practices\n    print(\"\\n\" + \"=\"*80)\n    print(\"2. Secure Development Practices:\")\n    print(\"=\"*80)\n    practices = secure_development_practices()\n    for practice, info in practices.items():\n        print(f\"\\n{practice} ({info['phase']}):\")\n        print(f\"  Importance: {info['importance']}\")\n        print(f\"  Implementation: {info['implementation']}\")\n    # Risk Matrix\n    print(\"\\n\" + \"=\"*80)\n    print(\"3. Security Risk Matrix:\")\n    print(\"=\"*80)\n    risk_matrix = create_risk_matrix(vulnerabilities)\n    for risk in sorted(risk_matrix, key=lambda x: x['risk_score'], reverse=True):\n        print(f\"\\n{risk['vulnerability']}:\")\n        print(f\"  Risk Score: {risk['risk_score']}\")\n        print(f\"  Impact: {risk['impact']}, Likelihood: {risk['likelihood']}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_security_vulnerabilities(vulnerabilities)\n    plot_secure_practices(practices)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. AI systems face unique security vulnerabilities\")\n    print(\"2. Secure development practices should be applied throughout the lifecycle\")\n    print(\"3. Risk assessment helps prioritize security measures\")\n    print(\"4. Security testing and monitoring are essential\")\n    print(\"5. Incident response plans should be prepared in advance\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 188\u001b[0;36m\u001b[0m\n\u001b[0;31m    ax.text(-0.5, (x_start + y_pos - 1)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExample 5: Secure AI Development Practices\nThis example demonstrates secure AI development practices:\n- Security vulnerabilities in AI systems\n- Secure coding practices\n- Security testing\n- Incident response\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SECURITY VULNERABILITIES\n# ============================================================================\ndef identify_security_vulnerabilities():\n    \"\"\"\n    Identify common security vulnerabilities in AI systems\n    \"\"\"\n    vulnerabilities = {\n        'Adversarial Attacks': {\n            'severity': 'High', 'impact': 9,\n            'likelihood': 7,\n            'description': 'Malicious inputs designed to fool AI models'\n        },\n        'Model Inversion': {\n            'severity': 'High',\n            'impact': 8,\n            'likelihood': 6,\n            'description': 'Reconstructing training data from model outputs'\n        },\n        'Membership Inference': {\n            'severity': 'Medium',\n            'impact': 7,\n            'likelihood': 7,\n            'description': 'Determining if specific data was in training set'\n        },\n        'Data Poisoning': {\n            'severity': 'High',\n            'impact': 9,\n            'likelihood': 5,\n            'description': 'Injecting malicious data into training set'\n        },\n        'Model Theft': {\n            'severity': 'Medium',\n            'impact': 6,\n            'likelihood': 6,\n            'description': 'Stealing model architecture and parameters'\n        },\n        'Insufficient Access Controls': {\n            'severity': 'High',\n            'impact': 8,\n            'likelihood': 8,\n            'description': 'Unauthorized access to models or data'\n        }\n    }\n    return vulnerabilities\n# ============================================================================\n# SECURE DEVELOPMENT PRACTICES\n# ============================================================================\ndef secure_development_practices():\n    \"\"\"\n    Define secure AI development practices\n    \"\"\"\n    practices = {\n        'Input Validation': {\n            'phase': 'Development',\n            'importance': 10,\n            'implementation': 'Validate and sanitize all inputs'\n        },\n        'Output Sanitization': {\n            'phase': 'Development',\n            'importance': 9,\n            'implementation': 'Sanitize model outputs before use'\n        },\n        'Access Control': {\n            'phase': 'Deployment',\n            'importance': 10,\n            'implementation': 'Implement role-based access control'\n        },\n        'Encryption': {\n            'phase': 'All Phases',\n            'importance': 10,\n            'implementation': 'Encrypt data at rest and in transit'\n        },\n        'Security Testing': {\n            'phase': 'Testing',\n            'importance': 9,\n            'implementation': 'Regular security audits and penetration testing'\n        },\n        'Monitoring': {\n            'phase': 'Operations',\n            'importance': 9,\n            'implementation': 'Monitor for anomalies and attacks'\n        },\n        'Incident Response': {\n            'phase': 'Operations',\n            'importance': 8,\n            'implementation': 'Have response plan for security incidents'\n        }\n    }\n    return practices\n# ============================================================================\n# SECURITY RISK MATRIX\n# ============================================================================\ndef create_risk_matrix(vulnerabilities):\n    \"\"\"\n    Create risk matrix for security vulnerabilities\n    \"\"\"\n    risk_matrix = []\n    for vuln, info in vulnerabilities.items():\n        risk_score = info['impact'] * info['likelihood']\n        risk_matrix.append({\n            'vulnerability': vuln, 'impact': info['impact'],\n            'likelihood': info['likelihood'],\n            'risk_score': risk_score,\n            'severity': info['severity']\n        })\n    return risk_matrix\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_security_vulnerabilities(vulnerabilities):\n    \"\"\"\n    Plot security vulnerabilities analysis\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    vuln_names = list(vulnerabilities.keys())\n    impacts = [v['impact'] for v in vulnerabilities.values()]\n    likelihoods = [v['likelihood'] for v in vulnerabilities.values()]\n    # Risk matrix\n    scatter = axes[0].scatter(likelihoods, impacts, s=300, alpha=0.7, \n                             c=impacts, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n    for i, name in enumerate(vuln_names):\n        axes[0].annotate(name, (likelihoods[i], impacts[i]), \n                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n    axes[0].set_xlabel('Likelihood (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_ylabel('Impact (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_title('Security Risk Matrix', fontsize=12, fontweight='bold')\n    axes[0].grid(alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    axes[0].set_ylim([0, 11])\n    plt.colorbar(scatter, ax=axes[0], label='Impact')\n    # Severity distribution\n    severity_counts = {}\n    for v in vulnerabilities.values():\n        sev = v['severity']\n        severity_counts[sev] = severity_counts.get(sev, 0) + 1\n    colors = {'High': '#e74c3c', 'Medium': '#f39c12', 'Low': '#2ecc71'}\n    axes[1].bar(severity_counts.keys(), severity_counts.values(), color=[colors[s] for s in severity_counts.keys()], alpha=0.8)\n    axes[1].set_title('Vulnerability Severity Distribution', fontsize=12, fontweight='bold')\n    axes[1].set_ylabel('Count')\n    axes[1].grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: security_vulnerabilities.png\")\n    plt.close()\ndef plot_secure_practices(practices):\n    \"\"\"\n    Plot secure development practices by phase\n    \"\"\"\n    phases = {}\n    for practice, info in practices.items():\n        phase = info['phase']\n        if phase not in phases:\n            phases[phase] = []\n        phases[phase].append((practice, info['importance']))\n    fig, ax = plt.subplots(figsize=(12, 8))\n    y_pos = 0\n    colors = ['#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n    color_idx = 0\n    for phase, items in phases.items():\n        practices_list = [item[0] for item in items]\n        importance_list = [item[1] for item in items]\n        x_start = y_pos\n        for i, (practice, importance) in enumerate(items):\n            ax.barh(y_pos, importance, left=0, color=colors[color_idx % len(colors)], alpha=0.7, edgecolor='black')\n            ax.text(importance/2, y_pos, practice, ha='center', va='center', \n                   fontsize=9, fontweight='bold')\n            y_pos += 1\n        # Add phase label\n        ax.text(-0.5, (x_start + y_pos - 1)\n2, phase, ha='right', va='center',\n               fontsize=10, fontweight='bold', rotation=0)\n        y_pos += 0.5\n        color_idx += 1\n    ax.set_xlabel('Importance (1-10)', fontsize=11, fontweight='bold')\n    ax.set_title('Secure Development Practices by Phase', fontsize=12, fontweight='bold')\n    ax.set_xlim([0, 11])\n    ax.grid(axis='x', alpha=0.3)\n    ax.set_yticks([])\n    plt.tight_layout()\n    plt.savefig('unit3-privacy-security', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: secure_practices.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Example 5: Secure AI Development Practices\")\n    print(\"=\"*80)\n    # Security Vulnerabilities\n    print(\"\\n1. Security Vulnerabilities in AI Systems:\")\n    vulnerabilities = identify_security_vulnerabilities()\n    for vuln, info in vulnerabilities.items():\n        print(f\"\\n{vuln}:\")\n        print(f\"  Severity: {info['severity']}\")\n        print(f\"  Impact: {info['impact']}\")\n        print(f\"  Likelihood: {info['likelihood']}\")\n        print(f\"  Description: {info['description']}\")\n    # Secure Practices\n    print(\"\\n\" + \"=\"*80)\n    print(\"2. Secure Development Practices:\")\n    print(\"=\"*80)\n    practices = secure_development_practices()\n    for practice, info in practices.items():\n        print(f\"\\n{practice} ({info['phase']}):\")\n        print(f\"  Importance: {info['importance']}\")\n        print(f\"  Implementation: {info['implementation']}\")\n    # Risk Matrix\n    print(\"\\n\" + \"=\"*80)\n    print(\"3. Security Risk Matrix:\")\n    print(\"=\"*80)\n    risk_matrix = create_risk_matrix(vulnerabilities)\n    for risk in sorted(risk_matrix, key=lambda x: x['risk_score'], reverse=True):\n        print(f\"\\n{risk['vulnerability']}:\")\n        print(f\"  Risk Score: {risk['risk_score']}\")\n        print(f\"  Impact: {risk['impact']}, Likelihood: {risk['likelihood']}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_security_vulnerabilities(vulnerabilities)\n    plot_secure_practices(practices)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. AI systems face unique security vulnerabilities\")\n    print(\"2. Secure development practices should be applied throughout the lifecycle\")\n    print(\"3. Risk assessment helps prioritize security measures\")\n    print(\"4. Security testing and monitoring are essential\")\n    print(\"5. Incident response plans should be prepared in advance\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 188\u001b[0;36m\u001b[0m\n\u001b[0;31m    ax.text(-0.5, (x_start + y_pos - 1)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/06_data_encryption_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.757415771484375,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/07_anonymization_pseudonymization.ipynb",
      "status": "passed",
      "execution_time": 0.7942278385162354,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/anonymization_techniques_applying_anonymization_and_pseudonymization_methods.ipynb",
      "status": "passed",
      "execution_time": 1.7055890560150146,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/case_study_analysis_investigating_real_world_privacy_breaches_and_security_failu.ipynb",
      "status": "passed",
      "execution_time": 1.5927011966705322,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/compliance_testing_ensuring_ai_systems_comply_with_gdpr_and_other_regulations.ipynb",
      "status": "passed",
      "execution_time": 1.5099091529846191,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/data_encryption_implementing_encryption_techniques_for_data_protection.ipynb",
      "status": "passed",
      "execution_time": 1.6241919994354248,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/privacy_risk_assessment_evaluating_privacy_risks_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.547170877456665,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/security_auditing_conducting_security_audits_on_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.4738872051239014,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7399537563323975,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1: Privacy Techniques\nThis exercise requires you to implement privacy-preserving techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\n# ============================================================================\n# TASK 1: Implement Anonymization\n# ============================================================================\ndef anonymize_data(df, columns_to_anonymize):\n    \"\"\"\n    TODO: Implement data anonymization.\n    Requirements:\n    - Replace identifying columns with generic identifiers\n    - Return anonymized DataFrame\n    \"\"\"\n    # TODO: Your code here\n    pass\n# ============================================================================\n# TASK 2: Implement Pseudonymization\n# ============================================================================\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \"\"\"\n    TODO: Implement data pseudonymization using hashing.\n    Requirements:\n    - Use hash function to create pseudonyms\n    - Return pseudonymized DataFrame\n    \"\"\"\n    # TODO: Your code here\n    # Hint: Use hashlib.sha256()\n    pass\n# ============================================================================\n# TASK 3: Implement Differential Privacy\n# ============================================================================\ndef add_differential_privacy_noise(value, epsilon=1.0):\n    \"\"\"\n    TODO: Add Laplace noise for differential privacy.\n    Requirements:\n    - Use Laplace distribution\n    - Scale noise based on epsilon\n    - Return noisy value\n    \"\"\"\n    # TODO: Your code here\n    # Hint: Use np.random.laplace()\n    pass\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Exercise 1: Privacy Techniques\")\n    print(\"=\"*80)\n    print(\"\\nComplete the TODO sections in this file.\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 50\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1: Privacy Techniques\nThis exercise requires you to implement privacy-preserving techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\n# ============================================================================\n# TASK 1: Implement Anonymization\n# ============================================================================\ndef anonymize_data(df, columns_to_anonymize):\n    \"\"\"\n    TODO: Implement data anonymization.\n    Requirements:\n    - Replace identifying columns with generic identifiers\n    - Return anonymized DataFrame\n    \"\"\"\n    # TODO: Your code here\n    pass\n# ============================================================================\n# TASK 2: Implement Pseudonymization\n# ============================================================================\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \"\"\"\n    TODO: Implement data pseudonymization using hashing.\n    Requirements:\n    - Use hash function to create pseudonyms\n    - Return pseudonymized DataFrame\n    \"\"\"\n    # TODO: Your code here\n    # Hint: Use hashlib.sha256()\n    pass\n# ============================================================================\n# TASK 3: Implement Differential Privacy\n# ============================================================================\ndef add_differential_privacy_noise(value, epsilon=1.0):\n    \"\"\"\n    TODO: Add Laplace noise for differential privacy.\n    Requirements:\n    - Use Laplace distribution\n    - Scale noise based on epsilon\n    - Return noisy value\n    \"\"\"\n    # TODO: Your code here\n    # Hint: Use np.random.laplace()\n    pass\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 3 - Exercise 1: Privacy Techniques\")\n    print(\"=\"*80)\n    print(\"\\nComplete the TODO sections in this file.\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 50\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit3-privacy-security/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.8478119373321533,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "other"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/01_shap_explanations.ipynb",
      "status": "failed",
      "execution_time": 0.739022970199585,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 1: SHAP Explanations\nThis example demonstrates SHAP (SHapley Additive exPlanations) for model interpretability:\n- SHAP values calculation\n- Global and local explanations\n- Feature importance visualization\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n# Try to import SHAP, use simplified version if not available\ntry:\n    import shap\n    SHAP_AVAILABLE = True\nexcept ImportError:\n    SHAP_AVAILABLE = False\n    print(\"Note: SHAP library not available. Using simplified SHAP implementation.\")\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SIMPLIFIED SHAP IMPLEMENTATION (if SHAP not available)\n# ============================================================================\ndef calculate_shap_values_simple(model, X, feature_names):\n    \"\"\"\n    Simplified SHAP value calculation using permutation importance\n    \"\"\"\n    baseline_pred = model.predict_proba(X)[:, 1].mean()\n    shap_values = []\n    for i in range(len(X)):\n        sample = X[i:i+1]\n        base_pred = model.predict_proba(sample)[0, 1]\n        sample_shap = []\n        for j in range(X.shape[1]):\n            # Permute feature j\n            X_permuted = X.copy()\n            X_permuted[:, j] = sample[0, j]\n            perm_pred = model.predict_proba(X_permuted)[:, 1].mean()\n            # SHAP value approximation\n            shap_val = base_pred - perm_pred\n            sample_shap.append(shap_val)\n        shap_values.append(sample_shap)\n    return np.array(shap_values)\n# ============================================================================\n# GENERATE DATASET\n# ============================================================================\ndef generate_dataset(n_samples=1000):\n    \"\"\"\n    Generate synthetic dataset for SHAP demonstration\n    \"\"\"\n    np.random.seed(42)\n    # Features\n    age = np.random.randint(18, 80, n_samples)\n    income = np.random.normal(50000, 20000, n_samples)\n    credit_score = np.random.normal(650, 100, n_samples)\n    debt_ratio = np.random.uniform(0.1, 0.6, n_samples)\n    # Target (loan approval)\n    approval_prob = (credit_score\n850 * 0.4 +\n                     (income\n100000) * 0.3 +\n                     (1 - debt_ratio) * 0.2 +\n                     (age\n80) * 0.1 +\n                     np.random.normal(0, 0.05, n_samples))\n    approval = (approval_prob > 0.5).astype(int)\n    df = pd.DataFrame({\n        'age': age, 'income': income,\n        'credit_score': credit_score,\n        'debt_ratio': debt_ratio,\n        'approved': approval\n    })\n    return df\n# ============================================================================\n# SHAP EXPLANATIONS\n# ============================================================================\ndef explain_with_shap(model, X, feature_names, use_library=True):\n    \"\"\"\n    Generate SHAP explanations for the model\n    \"\"\"\n    if SHAP_AVAILABLE and use_library:\n        # Use actual SHAP library\n        explainer = shap.TreeExplainer(model)\n        shap_values = explainer.shap_values(X)\n        if isinstance(shap_values, list):\n            shap_values = shap_values[1]  # For binary classification, use positive class\n        return shap_values, explainer\n    else:\n        # Use simplified implementation\n        shap_values = calculate_shap_values_simple(model, X, feature_names)\n        return shap_values, None\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_shap_summary(shap_values, X, feature_names):\n    \"\"\"\n    Plot SHAP summary plot\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))\n    # Calculate mean absolute SHAP values for feature importance\n    mean_shap = np.abs(shap_values).mean(axis=0)\n    # Sort by importance\n    indices = np.argsort(mean_shap)\n    y_pos = np.arange(len(feature_names))\n    colors = plt.cm.RdYlGn(mean_shap\nmean_shap.max())\n    ax.barh(y_pos, mean_shap[indices], color=colors[indices])\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.set_xlabel('Mean |SHAP Value|', fontsize=11, fontweight='bold')\n    ax.set_title('SHAP Feature Importance Summary', fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: shap_summary.png\")\n    plt.close()\ndef plot_shap_waterfall(shap_values, X, feature_names, sample_idx=0):\n    \"\"\"\n    Plot SHAP waterfall plot for a single prediction\n    \"\"\"\n    sample_shap = shap_values[sample_idx]\n    sample_values = X[sample_idx]\n    # Sort by absolute SHAP value\n    indices = np.argsort(np.abs(sample_shap))[::-1]\n    fig, ax = plt.subplots(figsize=(12, 8))\n    # Calculate cumulative SHAP values\n    cumulative = np.cumsum([0] + list(sample_shap[indices]))\n    # Plot waterfall\n    for i in range(len(indices)):\n        idx = indices[i]\n        color = 'red' if sample_shap[idx] < 0 else 'green'\n        ax.barh(i, sample_shap[idx], left=cumulative[i], color=color, alpha=0.7)\n        ax.text(cumulative[i] + sample_shap[idx]/2, i, \n               f'{feature_names[idx]}\\n={sample_values[idx]:.2f}',\n               ha='center', va='center', fontsize=9)\n    ax.set_yticks(range(len(indices)))\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.set_xlabel('SHAP Value', fontsize=11, fontweight='bold')\n    ax.set_title(f'SHAP Waterfall Plot (Sample {sample_idx})', fontsize=12, fontweight='bold')\n    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n    ax.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: shap_waterfall.png\")\n    plt.close()\ndef plot_shap_dependence(shap_values, X, feature_names, feature_idx=0):\n    \"\"\"\n    Plot SHAP dependence plot for a specific feature\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(10, 6))\n    feature_values = X[:, feature_idx]\n    feature_shap = shap_values[:, feature_idx]\n    scatter = ax.scatter(feature_values, feature_shap, alpha=0.5, c=feature_shap, \n                        cmap='RdBu_r', s=30)\n    ax.set_xlabel(feature_names[feature_idx], fontsize=11, fontweight='bold')\n    ax.set_ylabel('SHAP Value', fontsize=11, fontweight='bold')\n    ax.set_title(f'SHAP Dependence Plot: {feature_names[feature_idx]}', fontsize=12, fontweight='bold')\n    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n    ax.grid(alpha=0.3)\n    plt.colorbar(scatter, ax=ax, label='SHAP Value')\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: shap_dependence.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 1: SHAP Explanations\")\n    print(\"=\"*80)\n    # Generate dataset\n    print(\"\\nGenerating dataset...\")\n    df = generate_dataset(n_samples=1000)\n    print(f\"Dataset shape: {df.shape}\")\n    # Prepare data\n    feature_names = ['age', 'income', 'credit_score', 'debt_ratio']\n    X = df[feature_names].values\n    y = df['approved'].values\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Train model\n    print(\"\\nTraining Random Forest model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    train_acc = accuracy_score(y_train, model.predict(X_train_scaled))\n    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n    print(f\"Training Accuracy: {train_acc:.4f}\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    # Calculate SHAP values\n    print(\"\\nCalculating SHAP values...\")\n    shap_values, explainer = explain_with_shap(\n        model, X_test_scaled[:100], feature_names, use_library=SHAP_AVAILABLE\n    )\n    print(f\"SHAP values shape: {shap_values.shape}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_shap_summary(shap_values, X_test_scaled[:100], feature_names)\n    plot_shap_waterfall(shap_values, X_test_scaled[:100], feature_names, sample_idx=0)\n    plot_shap_dependence(shap_values, X_test_scaled[:100], feature_names, feature_idx=2)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. SHAP values explain individual predictions\")\n    print(\"2. SHAP summary shows global feature importance\")\n    print(\"3. Waterfall plots show how features contribute to a specific prediction\")\n    print(\"4. Dependence plots show how SHAP values vary with feature values\")\n    print(\"5. SHAP provides model-agnostic explanations\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    approval_prob = (credit_score\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 1: SHAP Explanations\nThis example demonstrates SHAP (SHapley Additive exPlanations) for model interpretability:\n- SHAP values calculation\n- Global and local explanations\n- Feature importance visualization\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n# Try to import SHAP, use simplified version if not available\ntry:\n    import shap\n    SHAP_AVAILABLE = True\nexcept ImportError:\n    SHAP_AVAILABLE = False\n    print(\"Note: SHAP library not available. Using simplified SHAP implementation.\")\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SIMPLIFIED SHAP IMPLEMENTATION (if SHAP not available)\n# ============================================================================\ndef calculate_shap_values_simple(model, X, feature_names):\n    \"\"\"\n    Simplified SHAP value calculation using permutation importance\n    \"\"\"\n    baseline_pred = model.predict_proba(X)[:, 1].mean()\n    shap_values = []\n    for i in range(len(X)):\n        sample = X[i:i+1]\n        base_pred = model.predict_proba(sample)[0, 1]\n        sample_shap = []\n        for j in range(X.shape[1]):\n            # Permute feature j\n            X_permuted = X.copy()\n            X_permuted[:, j] = sample[0, j]\n            perm_pred = model.predict_proba(X_permuted)[:, 1].mean()\n            # SHAP value approximation\n            shap_val = base_pred - perm_pred\n            sample_shap.append(shap_val)\n        shap_values.append(sample_shap)\n    return np.array(shap_values)\n# ============================================================================\n# GENERATE DATASET\n# ============================================================================\ndef generate_dataset(n_samples=1000):\n    \"\"\"\n    Generate synthetic dataset for SHAP demonstration\n    \"\"\"\n    np.random.seed(42)\n    # Features\n    age = np.random.randint(18, 80, n_samples)\n    income = np.random.normal(50000, 20000, n_samples)\n    credit_score = np.random.normal(650, 100, n_samples)\n    debt_ratio = np.random.uniform(0.1, 0.6, n_samples)\n    # Target (loan approval)\n    approval_prob = (credit_score\n850 * 0.4 +\n                     (income\n100000) * 0.3 +\n                     (1 - debt_ratio) * 0.2 +\n                     (age\n80) * 0.1 +\n                     np.random.normal(0, 0.05, n_samples))\n    approval = (approval_prob > 0.5).astype(int)\n    df = pd.DataFrame({\n        'age': age, 'income': income,\n        'credit_score': credit_score,\n        'debt_ratio': debt_ratio,\n        'approved': approval\n    })\n    return df\n# ============================================================================\n# SHAP EXPLANATIONS\n# ============================================================================\ndef explain_with_shap(model, X, feature_names, use_library=True):\n    \"\"\"\n    Generate SHAP explanations for the model\n    \"\"\"\n    if SHAP_AVAILABLE and use_library:\n        # Use actual SHAP library\n        explainer = shap.TreeExplainer(model)\n        shap_values = explainer.shap_values(X)\n        if isinstance(shap_values, list):\n            shap_values = shap_values[1]  # For binary classification, use positive class\n        return shap_values, explainer\n    else:\n        # Use simplified implementation\n        shap_values = calculate_shap_values_simple(model, X, feature_names)\n        return shap_values, None\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_shap_summary(shap_values, X, feature_names):\n    \"\"\"\n    Plot SHAP summary plot\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))\n    # Calculate mean absolute SHAP values for feature importance\n    mean_shap = np.abs(shap_values).mean(axis=0)\n    # Sort by importance\n    indices = np.argsort(mean_shap)\n    y_pos = np.arange(len(feature_names))\n    colors = plt.cm.RdYlGn(mean_shap\nmean_shap.max())\n    ax.barh(y_pos, mean_shap[indices], color=colors[indices])\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.set_xlabel('Mean |SHAP Value|', fontsize=11, fontweight='bold')\n    ax.set_title('SHAP Feature Importance Summary', fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: shap_summary.png\")\n    plt.close()\ndef plot_shap_waterfall(shap_values, X, feature_names, sample_idx=0):\n    \"\"\"\n    Plot SHAP waterfall plot for a single prediction\n    \"\"\"\n    sample_shap = shap_values[sample_idx]\n    sample_values = X[sample_idx]\n    # Sort by absolute SHAP value\n    indices = np.argsort(np.abs(sample_shap))[::-1]\n    fig, ax = plt.subplots(figsize=(12, 8))\n    # Calculate cumulative SHAP values\n    cumulative = np.cumsum([0] + list(sample_shap[indices]))\n    # Plot waterfall\n    for i in range(len(indices)):\n        idx = indices[i]\n        color = 'red' if sample_shap[idx] < 0 else 'green'\n        ax.barh(i, sample_shap[idx], left=cumulative[i], color=color, alpha=0.7)\n        ax.text(cumulative[i] + sample_shap[idx]/2, i, \n               f'{feature_names[idx]}\\n={sample_values[idx]:.2f}',\n               ha='center', va='center', fontsize=9)\n    ax.set_yticks(range(len(indices)))\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.set_xlabel('SHAP Value', fontsize=11, fontweight='bold')\n    ax.set_title(f'SHAP Waterfall Plot (Sample {sample_idx})', fontsize=12, fontweight='bold')\n    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n    ax.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: shap_waterfall.png\")\n    plt.close()\ndef plot_shap_dependence(shap_values, X, feature_names, feature_idx=0):\n    \"\"\"\n    Plot SHAP dependence plot for a specific feature\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(10, 6))\n    feature_values = X[:, feature_idx]\n    feature_shap = shap_values[:, feature_idx]\n    scatter = ax.scatter(feature_values, feature_shap, alpha=0.5, c=feature_shap, \n                        cmap='RdBu_r', s=30)\n    ax.set_xlabel(feature_names[feature_idx], fontsize=11, fontweight='bold')\n    ax.set_ylabel('SHAP Value', fontsize=11, fontweight='bold')\n    ax.set_title(f'SHAP Dependence Plot: {feature_names[feature_idx]}', fontsize=12, fontweight='bold')\n    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n    ax.grid(alpha=0.3)\n    plt.colorbar(scatter, ax=ax, label='SHAP Value')\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: shap_dependence.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 1: SHAP Explanations\")\n    print(\"=\"*80)\n    # Generate dataset\n    print(\"\\nGenerating dataset...\")\n    df = generate_dataset(n_samples=1000)\n    print(f\"Dataset shape: {df.shape}\")\n    # Prepare data\n    feature_names = ['age', 'income', 'credit_score', 'debt_ratio']\n    X = df[feature_names].values\n    y = df['approved'].values\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Train model\n    print(\"\\nTraining Random Forest model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    train_acc = accuracy_score(y_train, model.predict(X_train_scaled))\n    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n    print(f\"Training Accuracy: {train_acc:.4f}\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    # Calculate SHAP values\n    print(\"\\nCalculating SHAP values...\")\n    shap_values, explainer = explain_with_shap(\n        model, X_test_scaled[:100], feature_names, use_library=SHAP_AVAILABLE\n    )\n    print(f\"SHAP values shape: {shap_values.shape}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_shap_summary(shap_values, X_test_scaled[:100], feature_names)\n    plot_shap_waterfall(shap_values, X_test_scaled[:100], feature_names, sample_idx=0)\n    plot_shap_dependence(shap_values, X_test_scaled[:100], feature_names, feature_idx=2)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. SHAP values explain individual predictions\")\n    print(\"2. SHAP summary shows global feature importance\")\n    print(\"3. Waterfall plots show how features contribute to a specific prediction\")\n    print(\"4. Dependence plots show how SHAP values vary with feature values\")\n    print(\"5. SHAP provides model-agnostic explanations\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    approval_prob = (credit_score\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/02_lime_explanations.ipynb",
      "status": "failed",
      "execution_time": 0.7419838905334473,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 2: LIME Explanations\nThis example demonstrates LIME (Local Interpretable Model-agnostic Explanations):\n- LIME for tabular data\n- LIME for text data (simplified)\n- Local interpretability\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n# Try to import LIME, use simplified version if not available\ntry:\n    import lime\n    import lime.lime_tabular\n    LIME_AVAILABLE = True\nexcept ImportError:\n    LIME_AVAILABLE = False\n    print(\"Note: LIME library not available. Using simplified LIME implementation.\")\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SIMPLIFIED LIME IMPLEMENTATION\n# ============================================================================\ndef lime_explanation_simple(model, X_sample, X_train, feature_names, n_samples=5000):\n    \"\"\"\n    Simplified LIME implementation using local linear approximation\n    \"\"\"\n    # Generate perturbed samples around the instance\n    np.random.seed(42)\n    perturbations = np.random.normal(0, 0.1, (n_samples, X_sample.shape[1]))\n    X_perturbed = X_sample + perturbations\n    # Get predictions for perturbed samples\n    y_perturbed = model.predict_proba(X_perturbed)[:, 1]\n    # Calculate distances (weights)\n    distances = np.exp(-np.sum((X_perturbed - X_sample) ** 2, axis=1))\n    # Fit linear model to approximate local behavior\n    linear_model = Ridge(alpha=0.1)\n    linear_model.fit(X_perturbed, y_perturbed, sample_weight=distances)\n    # Get feature importance (coefficients)\n    feature_importance = linear_model.coef_\n    return feature_importance, linear_model\n# ============================================================================\n# GENERATE DATASET\n# ============================================================================\ndef generate_dataset(n_samples=1000):\n    \"\"\"\n    Generate synthetic dataset for LIME demonstration\n    \"\"\"\n    np.random.seed(42)\n    # Features\n    age = np.random.randint(25, 70, n_samples)\n    income = np.random.normal(60000, 25000, n_samples)\n    credit_history = np.random.choice([0, 1, 2, 3], n_samples)  # 0=bad, 3=excellent\n    loan_amount = np.random.uniform(10000, 200000, n_samples)\n    # Target (loan approval)\n    approval_prob = (credit_history\n3 * 0.5 +\n                     (income\n100000) * 0.3 +\n                     (1 - loan_amount\n200000) * 0.15 +\n                     (age\n70) * 0.05 +\n                     np.random.normal(0, 0.05, n_samples))\n    approval = (approval_prob > 0.5).astype(int)\n    df = pd.DataFrame({\n        'age': age, 'income': income,\n        'credit_history': credit_history,\n        'loan_amount': loan_amount,\n        'approved': approval\n    })\n    return df\n# ============================================================================\n# LIME EXPLANATIONS\n# ============================================================================\ndef explain_with_lime(model, X_sample, X_train, feature_names, use_library=True):\n    \"\"\"\n    Generate LIME explanations for a single instance\n    \"\"\"\n    if LIME_AVAILABLE and use_library:\n        # Use actual LIME library\n        explainer = lime.lime_tabular.LimeTabularExplainer(\n            X_train, feature_names=feature_names, mode='classification'\n        )\n        explanation = explainer.explain_instance(\n            X_sample[0], model.predict_proba, num_features=len(feature_names)\n        )\n        return explanation, explainer\n    else:\n        # Use simplified implementation\n        feature_importance, linear_model = lime_explanation_simple(\n            model, X_sample, X_train, feature_names\n        )\n        return feature_importance, linear_model\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_lime_explanation(feature_importance, feature_names, X_sample, sample_idx=0):\n    \"\"\"\n    Plot LIME explanation for a single instance\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))\n    # Sort by absolute importance\n    indices = np.argsort(np.abs(feature_importance))[::-1]\n    colors = ['red' if feature_importance[i] < 0 else 'green' for i in indices]\n    bars = ax.barh(range(len(feature_names)), [feature_importance[i] for i in indices],\n                   color=colors, alpha=0.7)\n    # Add value labels\n    for i, (bar, idx) in enumerate(zip(bars, indices)):\n        height = bar.get_height()\n        width = bar.get_width()\n        label = f'{feature_names[idx]}\\n={X_sample[0, idx]:.2f}'\n        ax.text(width/2 if width > 0 else width/2, i, label,\n               ha='center' if width > 0 else 'right', va='center', fontsize=9)\n    ax.set_yticks(range(len(feature_names)))\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.set_xlabel('LIME Feature Importance', fontsize=11, fontweight='bold')\n    ax.set_title(f'LIME Explanation (Sample {sample_idx})', fontsize=12, fontweight='bold')\n    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n    ax.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: lime_explanation.png\")\n    plt.close()\ndef plot_lime_comparison(explanations, feature_names, n_samples=5):\n    \"\"\"\n    Plot LIME explanations for multiple samples\n    \"\"\"\n    fig, axes = plt.subplots(1, n_samples, figsize=(20, 6))\n    for idx, (importance, X_sample) in enumerate(explanations[:n_samples]):\n        if idx >= len(axes):\n            break\n        # Sort by absolute importance\n        indices = np.argsort(np.abs(importance))[::-1]\n        top_k = min(4, len(indices))\n        top_indices = indices[:top_k]\n        top_importance = importance[top_indices]\n        top_names = [feature_names[i] for i in top_indices]\n        colors = ['red' if imp < 0 else 'green' for imp in top_importance]\n        axes[idx].barh(range(len(top_names)), top_importance, color=colors, alpha=0.7)\n        axes[idx].set_yticks(range(len(top_names)))\n        axes[idx].set_yticklabels(top_names, fontsize=8)\n        axes[idx].set_title(f'Sample {idx}', fontsize=10, fontweight='bold')\n        axes[idx].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n        axes[idx].grid(axis='x', alpha=0.3)\n    plt.suptitle('LIME Explanations for Multiple Samples', fontsize=12, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: lime_comparison.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 2: LIME Explanations\")\n    print(\"=\"*80)\n    # Generate dataset\n    print(\"\\nGenerating dataset...\")\n    df = generate_dataset(n_samples=1000)\n    print(f\"Dataset shape: {df.shape}\")\n    # Prepare data\n    feature_names = ['age', 'income', 'credit_history', 'loan_amount']\n    X = df[feature_names].values\n    y = df['approved'].values\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Train model\n    print(\"\\nTraining Random Forest model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    train_acc = accuracy_score(y_train, model.predict(X_train_scaled))\n    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n    print(f\"Training Accuracy: {train_acc:.4f}\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    # Generate LIME explanations for multiple samples\n    print(\"\\nGenerating LIME explanations...\")\n    explanations = []\n    for i in range(min(10, len(X_test_scaled))):\n        X_sample = X_test_scaled[i:i+1]\n        explanation, _ = explain_with_lime(\n            model, X_sample, X_train_scaled, feature_names, use_library=LIME_AVAILABLE\n        )\n        if isinstance(explanation, np.ndarray):\n            explanations.append((explanation, X_test[i:i+1]))\n        else:\n            # If using LIME library, extract feature importance\n            exp_list = explanation.as_list()\n            importance = np.zeros(len(feature_names))\n            for feature_name, value in exp_list:\n                idx = feature_names.index(feature_name)\n                importance[idx] = value\n            explanations.append((importance, X_test[i:i+1]))\n    print(f\"Generated {len(explanations)} LIME explanations\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_lime_explanation(explanations[0][0], feature_names, explanations[0][1], sample_idx=0)\n    plot_lime_comparison(explanations, feature_names, n_samples=5)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. LIME provides local, interpretable explanations\")\n    print(\"2. LIME approximates complex models with simple linear models locally\")\n    print(\"3. LIME works for any black-box model\")\n    print(\"4. LIME explanations are instance-specific\")\n    print(\"5. LIME helps understand individual predictions\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    approval_prob = (credit_history\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 2: LIME Explanations\nThis example demonstrates LIME (Local Interpretable Model-agnostic Explanations):\n- LIME for tabular data\n- LIME for text data (simplified)\n- Local interpretability\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n# Try to import LIME, use simplified version if not available\ntry:\n    import lime\n    import lime.lime_tabular\n    LIME_AVAILABLE = True\nexcept ImportError:\n    LIME_AVAILABLE = False\n    print(\"Note: LIME library not available. Using simplified LIME implementation.\")\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# SIMPLIFIED LIME IMPLEMENTATION\n# ============================================================================\ndef lime_explanation_simple(model, X_sample, X_train, feature_names, n_samples=5000):\n    \"\"\"\n    Simplified LIME implementation using local linear approximation\n    \"\"\"\n    # Generate perturbed samples around the instance\n    np.random.seed(42)\n    perturbations = np.random.normal(0, 0.1, (n_samples, X_sample.shape[1]))\n    X_perturbed = X_sample + perturbations\n    # Get predictions for perturbed samples\n    y_perturbed = model.predict_proba(X_perturbed)[:, 1]\n    # Calculate distances (weights)\n    distances = np.exp(-np.sum((X_perturbed - X_sample) ** 2, axis=1))\n    # Fit linear model to approximate local behavior\n    linear_model = Ridge(alpha=0.1)\n    linear_model.fit(X_perturbed, y_perturbed, sample_weight=distances)\n    # Get feature importance (coefficients)\n    feature_importance = linear_model.coef_\n    return feature_importance, linear_model\n# ============================================================================\n# GENERATE DATASET\n# ============================================================================\ndef generate_dataset(n_samples=1000):\n    \"\"\"\n    Generate synthetic dataset for LIME demonstration\n    \"\"\"\n    np.random.seed(42)\n    # Features\n    age = np.random.randint(25, 70, n_samples)\n    income = np.random.normal(60000, 25000, n_samples)\n    credit_history = np.random.choice([0, 1, 2, 3], n_samples)  # 0=bad, 3=excellent\n    loan_amount = np.random.uniform(10000, 200000, n_samples)\n    # Target (loan approval)\n    approval_prob = (credit_history\n3 * 0.5 +\n                     (income\n100000) * 0.3 +\n                     (1 - loan_amount\n200000) * 0.15 +\n                     (age\n70) * 0.05 +\n                     np.random.normal(0, 0.05, n_samples))\n    approval = (approval_prob > 0.5).astype(int)\n    df = pd.DataFrame({\n        'age': age, 'income': income,\n        'credit_history': credit_history,\n        'loan_amount': loan_amount,\n        'approved': approval\n    })\n    return df\n# ============================================================================\n# LIME EXPLANATIONS\n# ============================================================================\ndef explain_with_lime(model, X_sample, X_train, feature_names, use_library=True):\n    \"\"\"\n    Generate LIME explanations for a single instance\n    \"\"\"\n    if LIME_AVAILABLE and use_library:\n        # Use actual LIME library\n        explainer = lime.lime_tabular.LimeTabularExplainer(\n            X_train, feature_names=feature_names, mode='classification'\n        )\n        explanation = explainer.explain_instance(\n            X_sample[0], model.predict_proba, num_features=len(feature_names)\n        )\n        return explanation, explainer\n    else:\n        # Use simplified implementation\n        feature_importance, linear_model = lime_explanation_simple(\n            model, X_sample, X_train, feature_names\n        )\n        return feature_importance, linear_model\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_lime_explanation(feature_importance, feature_names, X_sample, sample_idx=0):\n    \"\"\"\n    Plot LIME explanation for a single instance\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))\n    # Sort by absolute importance\n    indices = np.argsort(np.abs(feature_importance))[::-1]\n    colors = ['red' if feature_importance[i] < 0 else 'green' for i in indices]\n    bars = ax.barh(range(len(feature_names)), [feature_importance[i] for i in indices],\n                   color=colors, alpha=0.7)\n    # Add value labels\n    for i, (bar, idx) in enumerate(zip(bars, indices)):\n        height = bar.get_height()\n        width = bar.get_width()\n        label = f'{feature_names[idx]}\\n={X_sample[0, idx]:.2f}'\n        ax.text(width/2 if width > 0 else width/2, i, label,\n               ha='center' if width > 0 else 'right', va='center', fontsize=9)\n    ax.set_yticks(range(len(feature_names)))\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.set_xlabel('LIME Feature Importance', fontsize=11, fontweight='bold')\n    ax.set_title(f'LIME Explanation (Sample {sample_idx})', fontsize=12, fontweight='bold')\n    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n    ax.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: lime_explanation.png\")\n    plt.close()\ndef plot_lime_comparison(explanations, feature_names, n_samples=5):\n    \"\"\"\n    Plot LIME explanations for multiple samples\n    \"\"\"\n    fig, axes = plt.subplots(1, n_samples, figsize=(20, 6))\n    for idx, (importance, X_sample) in enumerate(explanations[:n_samples]):\n        if idx >= len(axes):\n            break\n        # Sort by absolute importance\n        indices = np.argsort(np.abs(importance))[::-1]\n        top_k = min(4, len(indices))\n        top_indices = indices[:top_k]\n        top_importance = importance[top_indices]\n        top_names = [feature_names[i] for i in top_indices]\n        colors = ['red' if imp < 0 else 'green' for imp in top_importance]\n        axes[idx].barh(range(len(top_names)), top_importance, color=colors, alpha=0.7)\n        axes[idx].set_yticks(range(len(top_names)))\n        axes[idx].set_yticklabels(top_names, fontsize=8)\n        axes[idx].set_title(f'Sample {idx}', fontsize=10, fontweight='bold')\n        axes[idx].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n        axes[idx].grid(axis='x', alpha=0.3)\n    plt.suptitle('LIME Explanations for Multiple Samples', fontsize=12, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: lime_comparison.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 2: LIME Explanations\")\n    print(\"=\"*80)\n    # Generate dataset\n    print(\"\\nGenerating dataset...\")\n    df = generate_dataset(n_samples=1000)\n    print(f\"Dataset shape: {df.shape}\")\n    # Prepare data\n    feature_names = ['age', 'income', 'credit_history', 'loan_amount']\n    X = df[feature_names].values\n    y = df['approved'].values\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Train model\n    print(\"\\nTraining Random Forest model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    train_acc = accuracy_score(y_train, model.predict(X_train_scaled))\n    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n    print(f\"Training Accuracy: {train_acc:.4f}\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    # Generate LIME explanations for multiple samples\n    print(\"\\nGenerating LIME explanations...\")\n    explanations = []\n    for i in range(min(10, len(X_test_scaled))):\n        X_sample = X_test_scaled[i:i+1]\n        explanation, _ = explain_with_lime(\n            model, X_sample, X_train_scaled, feature_names, use_library=LIME_AVAILABLE\n        )\n        if isinstance(explanation, np.ndarray):\n            explanations.append((explanation, X_test[i:i+1]))\n        else:\n            # If using LIME library, extract feature importance\n            exp_list = explanation.as_list()\n            importance = np.zeros(len(feature_names))\n            for feature_name, value in exp_list:\n                idx = feature_names.index(feature_name)\n                importance[idx] = value\n            explanations.append((importance, X_test[i:i+1]))\n    print(f\"Generated {len(explanations)} LIME explanations\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_lime_explanation(explanations[0][0], feature_names, explanations[0][1], sample_idx=0)\n    plot_lime_comparison(explanations, feature_names, n_samples=5)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. LIME provides local, interpretable explanations\")\n    print(\"2. LIME approximates complex models with simple linear models locally\")\n    print(\"3. LIME works for any black-box model\")\n    print(\"4. LIME explanations are instance-specific\")\n    print(\"5. LIME helps understand individual predictions\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    approval_prob = (credit_history\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/03_counterfactual_analysis.ipynb",
      "status": "failed",
      "execution_time": 0.5406911373138428,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 3: Counterfactual Analysis\nThis example demonstrates counterfactual analysis for model interpretability:\n- Generating counterfactual examples\n- What-if analysis\n- Model decision explanations\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# COUNTERFACTUAL GENERATION\n# ============================================================================\ndef generate_counterfactual(model, X_instance, X_train, feature_names, target_class=1, max_iterations=100):\n    \"\"\"\n    Generate counterfactual example by perturbing features\n    \"\"\"\n    # Get original prediction\n    original_pred = model.predict_proba(X_instance)[0, 1]\n    original_class = model.predict(X_instance)[0]\n    if original_class == target_class:\n        return X_instance.copy(), 0, \"Already in target class\"\n    # Initialize counterfactual\n    counterfactual = X_instance.copy()\n    # Feature ranges from training data\n    feature_ranges = {\n        i: (X_train[:, i].min(), X_train[:, i].max())\n        for i in range(X_train.shape[1])\n    }\n    # Iteratively modify features\n    for iteration in range(max_iterations):\n        # Try modifying each feature\n        best_change = None\n        best_score = original_pred\n        for feature_idx in range(X_instance.shape[1]):\n            # Try increasing feature\n            test_cf = counterfactual.copy()\n            step = (feature_ranges[feature_idx][1] - feature_ranges[feature_idx][0]) * 0.1\n            test_cf[0, feature_idx] = min(\n                test_cf[0, feature_idx] + step,\n                feature_ranges[feature_idx][1]\n            )\n            new_pred = model.predict_proba(test_cf)[0, 1]\n            # Check if we're moving toward target class\n            if target_class == 1 and new_pred > best_score:\n                best_score = new_pred\n                best_change = (feature_idx, step)\n            elif target_class == 0 and new_pred < best_score:\n                best_score = new_pred\n                best_change = (feature_idx, -step)\n        if best_change is None:\n            break\n        # Apply best change\n        feature_idx, change = best_change\n        counterfactual[0, feature_idx] += change\n        counterfactual[0, feature_idx] = np.clip(\n            counterfactual[0, feature_idx],\n            feature_ranges[feature_idx][0],\n            feature_ranges[feature_idx][1]\n        )\n        # Check if we've reached target class\n        new_pred = model.predict_proba(counterfactual)[0, 1]\n        new_class = model.predict(counterfactual)[0]\n        if new_class == target_class:\n            return counterfactual, iteration + 1, \"Target class reached\"\n    return counterfactual, max_iterations, \"Max iterations reached\"\n# ============================================================================\n# WHAT-IF ANALYSIS\n# ============================================================================\ndef what_if_analysis(model, X_instance, feature_names, feature_to_change, values_to_test):\n    \"\"\"\n    Perform what-if analysis by changing a single feature\n    \"\"\"\n    results = []\n    for value in values_to_test:\n        X_test = X_instance.copy()\n        feature_idx = feature_names.index(feature_to_change)\n        X_test[0, feature_idx] = value\n        pred_proba = model.predict_proba(X_test)[0, 1]\n        pred_class = model.predict(X_test)[0]\n        results.append({\n            'value': value, 'prediction_probability': pred_proba,\n            'prediction_class': pred_class\n        })\n    return pd.DataFrame(results)\n# ============================================================================\n# GENERATE DATASET\n# ============================================================================\ndef generate_dataset(n_samples=1000):\n    \"\"\"\n    Generate synthetic dataset for counterfactual analysis\n    \"\"\"\n    np.random.seed(42)\n    age = np.random.randint(25, 70, n_samples)\n    income = np.random.normal(60000, 25000, n_samples)\n    credit_score = np.random.normal(650, 100, n_samples)\n    debt_ratio = np.random.uniform(0.1, 0.6, n_samples)\n    approval_prob = (credit_score\n850 * 0.4 +\n                     (income\n100000) * 0.3 +\n                     (1 - debt_ratio) * 0.2 +\n                     (age\n70) * 0.1 +\n                     np.random.normal(0, 0.05, n_samples))\n    approval = (approval_prob > 0.5).astype(int)\n    df = pd.DataFrame({\n        'age': age, 'income': income,\n        'credit_score': credit_score,\n        'debt_ratio': debt_ratio,\n        'approved': approval\n    })\n    return df\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_counterfactual_comparison(X_original, X_counterfactual, feature_names, original_pred, cf_pred):\n    \"\"\"\n    Plot comparison between original and counterfactual\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    # Feature comparison\n    features = feature_names\n    original_values = X_original[0]\n    cf_values = X_counterfactual[0]\n    changes = cf_values - original_values\n    x = np.arange(len(features))\n    width = 0.35\n    axes[0].bar(x - width/2, original_values, width, label='Original', alpha=0.8, color='#e74c3c')\n    axes[0].bar(x + width/2, cf_values, width, label='Counterfactual', alpha=0.8, color='#2ecc71')\n    axes[0].set_xlabel('Features', fontsize=11, fontweight='bold')\n    axes[0].set_ylabel('Feature Values', fontsize=11, fontweight='bold')\n    axes[0].set_title('Original vs Counterfactual Feature Values', fontsize=12, fontweight='bold')\n    axes[0].set_xticks(x)\n    axes[0].set_xticklabels(features, rotation=15)\n    axes[0].legend()\n    axes[0].grid(axis='y', alpha=0.3)\n    # Feature changes\n    colors = ['green' if c > 0 else 'red' for c in changes]\n    axes[1].barh(features, changes, color=colors, alpha=0.7)\n    axes[1].set_xlabel('Change in Feature Value', fontsize=11, fontweight='bold')\n    axes[1].set_title('Feature Changes to Achieve Counterfactual', fontsize=12, fontweight='bold')\n    axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n    axes[1].grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: counterfactual_comparison.png\")\n    plt.close()\ndef plot_what_if_analysis(what_if_df, feature_name):\n    \"\"\"\n    Plot what-if analysis results\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(what_if_df['value'], what_if_df['prediction_probability'], \n           marker='o', linewidth=2, markersize=8, color='#3498db')\n    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Decision Threshold')\n    ax.set_xlabel(feature_name, fontsize=11, fontweight='bold')\n    ax.set_ylabel('Prediction Probability', fontsize=11, fontweight='bold')\n    ax.set_title(f'What-If Analysis: {feature_name}', fontsize=12, fontweight='bold')\n    ax.grid(alpha=0.3)\n    ax.legend()\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: what_if_analysis.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 3: Counterfactual Analysis\")\n    print(\"=\"*80)\n    # Generate dataset\n    print(\"\\nGenerating dataset...\")\n    df = generate_dataset(n_samples=1000)\n    print(f\"Dataset shape: {df.shape}\")\n    # Prepare data\n    feature_names = ['age', 'income', 'credit_score', 'debt_ratio']\n    X = df[feature_names].values\n    y = df['approved'].values\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Train model\n    print(\"\\nTraining Random Forest model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    # Find a rejected instance to generate counterfactual\n    rejected_indices = np.where(model.predict(X_test_scaled) == 0)[0]\n    if len(rejected_indices) > 0:\n        sample_idx = rejected_indices[0]\n        X_instance = X_test_scaled[sample_idx:sample_idx+1]\n        print(f\"\\nOriginal instance (rejected):\")\n        print(f\"  Features: {dict(zip(feature_names, X_test[sample_idx]))}\")\n        print(f\"  Prediction probability: {model.predict_proba(X_instance)[0, 1]:.4f}\")\n        print(f\"  Prediction: {model.predict(X_instance)[0]}\")\n        # Generate counterfactual\n        print(\"\\nGenerating counterfactual (to get approved)...\")\n        X_counterfactual, iterations, status = generate_counterfactual(\n            model, X_instance, X_train_scaled, feature_names, target_class=1\n        )\n        print(f\"Counterfactual found after {iterations} iterations: {status}\")\n        print(f\"  Prediction probability: {model.predict_proba(X_counterfactual)[0, 1]:.4f}\")\n        print(f\"  Prediction: {model.predict(X_counterfactual)[0]}\")\n        # What-if analysis\n        print(\"\\nPerforming what-if analysis on credit_score...\")\n        credit_scores = np.linspace(500, 800, 50)\n        what_if_df = what_if_analysis(\n            model, X_instance, feature_names, 'credit_score', credit_scores\n        )\n        # Create visualizations\n        print(\"\\n\" + \"=\"*80)\n        print(\"Creating Visualizations...\")\n        print(\"=\"*80)\n        original_pred = model.predict_proba(X_instance)[0, 1]\n        cf_pred = model.predict_proba(X_counterfactual)[0, 1]\n        plot_counterfactual_comparison(X_instance, X_counterfactual, feature_names, \n                                      original_pred, cf_pred)\n        plot_what_if_analysis(what_if_df, 'credit_score')\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Counterfactuals show what needs to change to get a different outcome\")\n    print(\"2. What-if analysis explores how changes in features affect predictions\")\n    print(\"3. Counterfactuals help explain model decisions\")\n    print(\"4. Counterfactuals are useful for actionable insights\")\n    print(\"5. Counterfactual analysis improves model transparency\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 109\u001b[0;36m\u001b[0m\n\u001b[0;31m    approval_prob = (credit_score\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 3: Counterfactual Analysis\nThis example demonstrates counterfactual analysis for model interpretability:\n- Generating counterfactual examples\n- What-if analysis\n- Model decision explanations\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# COUNTERFACTUAL GENERATION\n# ============================================================================\ndef generate_counterfactual(model, X_instance, X_train, feature_names, target_class=1, max_iterations=100):\n    \"\"\"\n    Generate counterfactual example by perturbing features\n    \"\"\"\n    # Get original prediction\n    original_pred = model.predict_proba(X_instance)[0, 1]\n    original_class = model.predict(X_instance)[0]\n    if original_class == target_class:\n        return X_instance.copy(), 0, \"Already in target class\"\n    # Initialize counterfactual\n    counterfactual = X_instance.copy()\n    # Feature ranges from training data\n    feature_ranges = {\n        i: (X_train[:, i].min(), X_train[:, i].max())\n        for i in range(X_train.shape[1])\n    }\n    # Iteratively modify features\n    for iteration in range(max_iterations):\n        # Try modifying each feature\n        best_change = None\n        best_score = original_pred\n        for feature_idx in range(X_instance.shape[1]):\n            # Try increasing feature\n            test_cf = counterfactual.copy()\n            step = (feature_ranges[feature_idx][1] - feature_ranges[feature_idx][0]) * 0.1\n            test_cf[0, feature_idx] = min(\n                test_cf[0, feature_idx] + step,\n                feature_ranges[feature_idx][1]\n            )\n            new_pred = model.predict_proba(test_cf)[0, 1]\n            # Check if we're moving toward target class\n            if target_class == 1 and new_pred > best_score:\n                best_score = new_pred\n                best_change = (feature_idx, step)\n            elif target_class == 0 and new_pred < best_score:\n                best_score = new_pred\n                best_change = (feature_idx, -step)\n        if best_change is None:\n            break\n        # Apply best change\n        feature_idx, change = best_change\n        counterfactual[0, feature_idx] += change\n        counterfactual[0, feature_idx] = np.clip(\n            counterfactual[0, feature_idx],\n            feature_ranges[feature_idx][0],\n            feature_ranges[feature_idx][1]\n        )\n        # Check if we've reached target class\n        new_pred = model.predict_proba(counterfactual)[0, 1]\n        new_class = model.predict(counterfactual)[0]\n        if new_class == target_class:\n            return counterfactual, iteration + 1, \"Target class reached\"\n    return counterfactual, max_iterations, \"Max iterations reached\"\n# ============================================================================\n# WHAT-IF ANALYSIS\n# ============================================================================\ndef what_if_analysis(model, X_instance, feature_names, feature_to_change, values_to_test):\n    \"\"\"\n    Perform what-if analysis by changing a single feature\n    \"\"\"\n    results = []\n    for value in values_to_test:\n        X_test = X_instance.copy()\n        feature_idx = feature_names.index(feature_to_change)\n        X_test[0, feature_idx] = value\n        pred_proba = model.predict_proba(X_test)[0, 1]\n        pred_class = model.predict(X_test)[0]\n        results.append({\n            'value': value, 'prediction_probability': pred_proba,\n            'prediction_class': pred_class\n        })\n    return pd.DataFrame(results)\n# ============================================================================\n# GENERATE DATASET\n# ============================================================================\ndef generate_dataset(n_samples=1000):\n    \"\"\"\n    Generate synthetic dataset for counterfactual analysis\n    \"\"\"\n    np.random.seed(42)\n    age = np.random.randint(25, 70, n_samples)\n    income = np.random.normal(60000, 25000, n_samples)\n    credit_score = np.random.normal(650, 100, n_samples)\n    debt_ratio = np.random.uniform(0.1, 0.6, n_samples)\n    approval_prob = (credit_score\n850 * 0.4 +\n                     (income\n100000) * 0.3 +\n                     (1 - debt_ratio) * 0.2 +\n                     (age\n70) * 0.1 +\n                     np.random.normal(0, 0.05, n_samples))\n    approval = (approval_prob > 0.5).astype(int)\n    df = pd.DataFrame({\n        'age': age, 'income': income,\n        'credit_score': credit_score,\n        'debt_ratio': debt_ratio,\n        'approved': approval\n    })\n    return df\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_counterfactual_comparison(X_original, X_counterfactual, feature_names, original_pred, cf_pred):\n    \"\"\"\n    Plot comparison between original and counterfactual\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    # Feature comparison\n    features = feature_names\n    original_values = X_original[0]\n    cf_values = X_counterfactual[0]\n    changes = cf_values - original_values\n    x = np.arange(len(features))\n    width = 0.35\n    axes[0].bar(x - width/2, original_values, width, label='Original', alpha=0.8, color='#e74c3c')\n    axes[0].bar(x + width/2, cf_values, width, label='Counterfactual', alpha=0.8, color='#2ecc71')\n    axes[0].set_xlabel('Features', fontsize=11, fontweight='bold')\n    axes[0].set_ylabel('Feature Values', fontsize=11, fontweight='bold')\n    axes[0].set_title('Original vs Counterfactual Feature Values', fontsize=12, fontweight='bold')\n    axes[0].set_xticks(x)\n    axes[0].set_xticklabels(features, rotation=15)\n    axes[0].legend()\n    axes[0].grid(axis='y', alpha=0.3)\n    # Feature changes\n    colors = ['green' if c > 0 else 'red' for c in changes]\n    axes[1].barh(features, changes, color=colors, alpha=0.7)\n    axes[1].set_xlabel('Change in Feature Value', fontsize=11, fontweight='bold')\n    axes[1].set_title('Feature Changes to Achieve Counterfactual', fontsize=12, fontweight='bold')\n    axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n    axes[1].grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: counterfactual_comparison.png\")\n    plt.close()\ndef plot_what_if_analysis(what_if_df, feature_name):\n    \"\"\"\n    Plot what-if analysis results\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(what_if_df['value'], what_if_df['prediction_probability'], \n           marker='o', linewidth=2, markersize=8, color='#3498db')\n    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Decision Threshold')\n    ax.set_xlabel(feature_name, fontsize=11, fontweight='bold')\n    ax.set_ylabel('Prediction Probability', fontsize=11, fontweight='bold')\n    ax.set_title(f'What-If Analysis: {feature_name}', fontsize=12, fontweight='bold')\n    ax.grid(alpha=0.3)\n    ax.legend()\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: what_if_analysis.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 3: Counterfactual Analysis\")\n    print(\"=\"*80)\n    # Generate dataset\n    print(\"\\nGenerating dataset...\")\n    df = generate_dataset(n_samples=1000)\n    print(f\"Dataset shape: {df.shape}\")\n    # Prepare data\n    feature_names = ['age', 'income', 'credit_score', 'debt_ratio']\n    X = df[feature_names].values\n    y = df['approved'].values\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Train model\n    print(\"\\nTraining Random Forest model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    # Find a rejected instance to generate counterfactual\n    rejected_indices = np.where(model.predict(X_test_scaled) == 0)[0]\n    if len(rejected_indices) > 0:\n        sample_idx = rejected_indices[0]\n        X_instance = X_test_scaled[sample_idx:sample_idx+1]\n        print(f\"\\nOriginal instance (rejected):\")\n        print(f\"  Features: {dict(zip(feature_names, X_test[sample_idx]))}\")\n        print(f\"  Prediction probability: {model.predict_proba(X_instance)[0, 1]:.4f}\")\n        print(f\"  Prediction: {model.predict(X_instance)[0]}\")\n        # Generate counterfactual\n        print(\"\\nGenerating counterfactual (to get approved)...\")\n        X_counterfactual, iterations, status = generate_counterfactual(\n            model, X_instance, X_train_scaled, feature_names, target_class=1\n        )\n        print(f\"Counterfactual found after {iterations} iterations: {status}\")\n        print(f\"  Prediction probability: {model.predict_proba(X_counterfactual)[0, 1]:.4f}\")\n        print(f\"  Prediction: {model.predict(X_counterfactual)[0]}\")\n        # What-if analysis\n        print(\"\\nPerforming what-if analysis on credit_score...\")\n        credit_scores = np.linspace(500, 800, 50)\n        what_if_df = what_if_analysis(\n            model, X_instance, feature_names, 'credit_score', credit_scores\n        )\n        # Create visualizations\n        print(\"\\n\" + \"=\"*80)\n        print(\"Creating Visualizations...\")\n        print(\"=\"*80)\n        original_pred = model.predict_proba(X_instance)[0, 1]\n        cf_pred = model.predict_proba(X_counterfactual)[0, 1]\n        plot_counterfactual_comparison(X_instance, X_counterfactual, feature_names, \n                                      original_pred, cf_pred)\n        plot_what_if_analysis(what_if_df, 'credit_score')\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Counterfactuals show what needs to change to get a different outcome\")\n    print(\"2. What-if analysis explores how changes in features affect predictions\")\n    print(\"3. Counterfactuals help explain model decisions\")\n    print(\"4. Counterfactuals are useful for actionable insights\")\n    print(\"5. Counterfactual analysis improves model transparency\")\n    print(\"=\"*80 + \"\\n\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 109\u001b[0;36m\u001b[0m\n\u001b[0;31m    approval_prob = (credit_score\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/04_accountability_frameworks.ipynb",
      "status": "failed",
      "execution_time": 0.555535078048706,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 4: Accountability Frameworks\nThis example demonstrates accountability frameworks for AI systems:\n- Key stakeholders and responsibilities\n- Mechanisms for tracking and auditing\n- Model cards and data sheets\n- Audit trails\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# STAKEHOLDER RESPONSIBILITIES\n# ============================================================================\ndef define_stakeholder_responsibilities():\n    \"\"\"\n    Define key stakeholders and their responsibilities in AI accountability\n    \"\"\"\n    stakeholders = {\n        'Developers': {\n            'responsibilities': [\n                'Design fair and transparent algorithms', 'Document model decisions and limitations',\n                'Implement bias detection and mitigation',\n                'Create model cards and documentation'\n            ],\n            'accountability_level': 9\n        },\n        'Data Scientists': {\n            'responsibilities': [\n                'Ensure data quality and representativeness',\n                'Document data sources and preprocessing',\n                'Identify potential biases in data',\n                'Maintain data lineage'\n            ],\n            'accountability_level': 8\n        },\n        'Product Managers': {\n            'responsibilities': [\n                'Define ethical requirements',\n                'Oversee deployment and monitoring',\n                'Ensure compliance with regulations',\n                'Manage stakeholder communication'\n            ],\n            'accountability_level': 7\n        },\n        'Legal': {\n            'responsibilities': [\n                'Ensure regulatory compliance',\n                'Review model for legal risks',\n                'Handle liability issues',\n                'Manage data privacy requirements'\n            ],\n            'accountability_level': 9\n        },\n        'End Users': {\n            'responsibilities': [\n                'Use AI system responsibly',\n                'Report issues and biases',\n                'Provide feedback',\n                'Understand system limitations'\n            ],\n            'accountability_level': 5\n        }\n    }\n    return stakeholders\n# ============================================================================\n# MODEL CARD TEMPLATE\n# ============================================================================\ndef create_model_card(model_name, model_type, performance_metrics, training_data_info, \n                     limitations, use_cases):\n    \"\"\"\n    Create a model card documenting key information about an AI model\n    \"\"\"\n    model_card = {\n        'model_name': model_name,\n        'model_type': model_type,\n        'date_created': datetime.now().strftime('%Y-%m-%d'), 'performance_metrics': performance_metrics,\n        'training_data': training_data_info,\n        'limitations': limitations,\n        'intended_use_cases': use_cases,\n        'ethical_considerations': {\n            'bias_mitigation': 'Applied reweighing and fairness constraints',\n            'transparency': 'SHAP and LIME explanations available',\n            'accountability': 'Full audit trail maintained'\n        }\n    }\n    return model_card\n# ============================================================================\n# AUDIT TRAIL\n# ============================================================================\ndef create_audit_trail():\n    \"\"\"\n    Create an audit trail for AI system decisions\n    \"\"\"\n    audit_entries = []\n    # Simulate audit trail entries\n    base_time = datetime.now() - timedelta(days=30)\n    events = [\n        {'timestamp': base_time, 'event': 'Model trained', 'user': 'Data Scientist', 'details': 'Initial model training'},\n        {'timestamp': base_time + timedelta(days=1), 'event': 'Bias check performed', 'user': 'Developer', 'details': 'Demographic parity: 0.05'},\n        {'timestamp': base_time + timedelta(days=2), 'event': 'Model deployed', 'user': 'Product Manager', 'details': 'Production deployment'},\n        {'timestamp': base_time + timedelta(days=5), 'event': 'Performance monitoring', 'user': 'System', 'details': 'Accuracy: 0.87'},\n        {'timestamp': base_time + timedelta(days=10), 'event': 'Bias detected', 'user': 'Monitoring System', 'details': 'Fairness metric degraded'},\n        {'timestamp': base_time + timedelta(days=11), 'event': 'Model retrained', 'user': 'Data Scientist', 'details': 'Retraining with fairness constraints'},\n        {'timestamp': base_time + timedelta(days=12), 'event': 'Model updated', 'user': 'Product Manager', 'details': 'New version deployed'},\n    ]\n    for event in events:\n        audit_entries.append({\n            'timestamp': event['timestamp'], 'event_type': event['event'],\n            'user': event['user'],\n            'details': event['details']\n        })\n    return pd.DataFrame(audit_entries)\n# ============================================================================\n# ACCOUNTABILITY FRAMEWORK\n# ============================================================================\ndef accountability_framework_checklist():\n    \"\"\"\n    Create accountability framework checklist\n    \"\"\"\n    checklist = {\n        'Pre-deployment': [\n            'Model documentation complete', 'Bias assessment performed',\n            'Fairness metrics calculated',\n            'Stakeholder review completed',\n            'Legal compliance verified'\n        ],\n        'Deployment': [\n            'Monitoring systems in place',\n            'Audit trail enabled',\n            'User notifications configured',\n            'Rollback plan prepared'\n        ],\n        'Post-deployment': [\n            'Regular performance monitoring',\n            'Fairness metrics tracking',\n            'User feedback collection',\n            'Periodic model audits',\n            'Incident response plan'\n        ]\n    }\n    return checklist\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_stakeholder_responsibilities(stakeholders):\n    \"\"\"\n    Plot stakeholder responsibility matrix\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))\n    names = list(stakeholders.keys())\n    accountability = [stakeholders[name]['accountability_level'] for name in names]\n    num_responsibilities = [len(stakeholders[name]['responsibilities']) for name in names]\n    scatter = ax.scatter(num_responsibilities, accountability, s=200, alpha=0.6, c=accountability, \n                        cmap='RdYlGn', edgecolors='black', linewidth=2)\n    for i, name in enumerate(names):\n        ax.annotate(name, (num_responsibilities[i], accountability[i]), \n                   xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n    ax.set_xlabel('Number of Responsibilities', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Accountability Level (1-10)', fontsize=11, fontweight='bold')\n    ax.set_title('Stakeholder Accountability Matrix', fontsize=12, fontweight='bold')\n    ax.grid(alpha=0.3)\n    plt.colorbar(scatter, ax=ax, label='Accountability Level')\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: stakeholder_accountability.png\")\n    plt.close()\ndef plot_audit_timeline(audit_df):\n    \"\"\"\n    Plot audit trail timeline\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(14, 8))\n    # Convert timestamps to days since first event\n    first_time = audit_df['timestamp'].min()\n    audit_df['days_since_start'] = (audit_df['timestamp'] - first_time).dt.days\n    # Plot events\n    event_types = audit_df['event_type'].unique()\n    colors = plt.cm.Set3(np.linspace(0, 1, len(event_types)))\n    color_map = dict(zip(event_types, colors))\n    for idx, row in audit_df.iterrows():\n        ax.scatter(row['days_since_start'], idx, s=200, \n                 c=color_map[row['event_type']], alpha=0.7, edgecolors='black')\n        ax.text(row['days_since_start'], idx, f\"  {row['event_type']}\", \n               va='center', fontsize=9)\n    ax.set_xlabel('Days Since First Event', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Event Index', fontsize=11, fontweight='bold')\n    ax.set_title('AI System Audit Trail Timeline', fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    # Legend\n    from matplotlib.patches import Patch\n    legend_elements = [Patch(facecolor=color_map[et], label=et) for et in event_types]\n    ax.legend(handles=legend_elements, loc='upper left', fontsize=9)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: audit_timeline.png\")\n    plt.close()\ndef plot_accountability_checklist(checklist):\n    \"\"\"\n    Plot accountability checklist status\n    \"\"\"\n    phases = list(checklist.keys())\n    items_per_phase = [len(items) for items in checklist.values()]\n    fig, ax = plt.subplots(figsize=(12, 6))\n    bars = ax.bar(phases, items_per_phase, color=['#3498db', '#2ecc71', '#f39c12'], alpha=0.8)\n    # Add value labels\n    for bar, count in zip(bars, items_per_phase):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n               f'{int(count)} items', ha='center', va='bottom', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Number of Checklist Items', fontsize=11, fontweight='bold')\n    ax.set_title('Accountability Framework Checklist by Phase', fontsize=12, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: accountability_checklist.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 4: Accountability Frameworks\")\n    print(\"=\"*80)\n    # Define stakeholders\n    print(\"\\n1. Stakeholder Responsibilities:\")\n    stakeholders = define_stakeholder_responsibilities()\n    for name, info in stakeholders.items():\n        print(f\"\\n{name}:\")\n        print(f\"  Accountability Level: {info['accountability_level']}\")\n        print(f\"  Responsibilities:\")\n        for resp in info['responsibilities']:\n            print(f\"    - {resp}\")\n    # Create model card\n    print(\"\\n2. Model Card:\")\n    model_card = create_model_card(\n        model_name='Loan Approval Classifier', model_type='Random Forest',\n        performance_metrics={'accuracy': 0.87, 'fairness_score': 0.92},\n        training_data_info={'samples': 10000, 'features': 10, 'date_range': '2023-01 to 2023-12'},\n        limitations=['May have bias for certain demographic groups', 'Requires periodic retraining'],\n        use_cases=['Loan approval decisions', 'Credit risk assessment']\n    )\n    print(f\"  Model: {model_card['model_name']}\")\n    print(f\"  Created: {model_card['date_created']}\")\n    print(f\"  Performance: {model_card['performance_metrics']}\")\n    # Create audit trail\n    print(\"\\n3. Audit Trail:\")\n    audit_df = create_audit_trail()\n    print(f\"  Total audit entries: {len(audit_df)}\")\n    print(f\"  Date range: {audit_df['timestamp'].min()} to {audit_df['timestamp'].max()}\")\n    # Accountability checklist\n    print(\"\\n4. Accountability Checklist:\")\n    checklist = accountability_framework_checklist()\n    for phase, items in checklist.items():\n        print(f\"\\n{phase}:\")\n        for item in items:\n            print(f\"  [ ] {item}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_stakeholder_responsibilities(stakeholders)\n    plot_audit_timeline(audit_df)\n    plot_accountability_checklist(checklist)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Clear stakeholder responsibilities ensure accountability\")\n    print(\"2. Model cards document model characteristics and limitations\")\n    print(\"3. Audit trails track all system decisions and changes\")\n    print(\"4. Accountability checklists ensure comprehensive coverage\")\n    print(\"5. Accountability frameworks are essential for trustworthy AI\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 228\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 4: Accountability Frameworks\nThis example demonstrates accountability frameworks for AI systems:\n- Key stakeholders and responsibilities\n- Mechanisms for tracking and auditing\n- Model cards and data sheets\n- Audit trails\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# STAKEHOLDER RESPONSIBILITIES\n# ============================================================================\ndef define_stakeholder_responsibilities():\n    \"\"\"\n    Define key stakeholders and their responsibilities in AI accountability\n    \"\"\"\n    stakeholders = {\n        'Developers': {\n            'responsibilities': [\n                'Design fair and transparent algorithms', 'Document model decisions and limitations',\n                'Implement bias detection and mitigation',\n                'Create model cards and documentation'\n            ],\n            'accountability_level': 9\n        },\n        'Data Scientists': {\n            'responsibilities': [\n                'Ensure data quality and representativeness',\n                'Document data sources and preprocessing',\n                'Identify potential biases in data',\n                'Maintain data lineage'\n            ],\n            'accountability_level': 8\n        },\n        'Product Managers': {\n            'responsibilities': [\n                'Define ethical requirements',\n                'Oversee deployment and monitoring',\n                'Ensure compliance with regulations',\n                'Manage stakeholder communication'\n            ],\n            'accountability_level': 7\n        },\n        'Legal': {\n            'responsibilities': [\n                'Ensure regulatory compliance',\n                'Review model for legal risks',\n                'Handle liability issues',\n                'Manage data privacy requirements'\n            ],\n            'accountability_level': 9\n        },\n        'End Users': {\n            'responsibilities': [\n                'Use AI system responsibly',\n                'Report issues and biases',\n                'Provide feedback',\n                'Understand system limitations'\n            ],\n            'accountability_level': 5\n        }\n    }\n    return stakeholders\n# ============================================================================\n# MODEL CARD TEMPLATE\n# ============================================================================\ndef create_model_card(model_name, model_type, performance_metrics, training_data_info, \n                     limitations, use_cases):\n    \"\"\"\n    Create a model card documenting key information about an AI model\n    \"\"\"\n    model_card = {\n        'model_name': model_name,\n        'model_type': model_type,\n        'date_created': datetime.now().strftime('%Y-%m-%d'), 'performance_metrics': performance_metrics,\n        'training_data': training_data_info,\n        'limitations': limitations,\n        'intended_use_cases': use_cases,\n        'ethical_considerations': {\n            'bias_mitigation': 'Applied reweighing and fairness constraints',\n            'transparency': 'SHAP and LIME explanations available',\n            'accountability': 'Full audit trail maintained'\n        }\n    }\n    return model_card\n# ============================================================================\n# AUDIT TRAIL\n# ============================================================================\ndef create_audit_trail():\n    \"\"\"\n    Create an audit trail for AI system decisions\n    \"\"\"\n    audit_entries = []\n    # Simulate audit trail entries\n    base_time = datetime.now() - timedelta(days=30)\n    events = [\n        {'timestamp': base_time, 'event': 'Model trained', 'user': 'Data Scientist', 'details': 'Initial model training'},\n        {'timestamp': base_time + timedelta(days=1), 'event': 'Bias check performed', 'user': 'Developer', 'details': 'Demographic parity: 0.05'},\n        {'timestamp': base_time + timedelta(days=2), 'event': 'Model deployed', 'user': 'Product Manager', 'details': 'Production deployment'},\n        {'timestamp': base_time + timedelta(days=5), 'event': 'Performance monitoring', 'user': 'System', 'details': 'Accuracy: 0.87'},\n        {'timestamp': base_time + timedelta(days=10), 'event': 'Bias detected', 'user': 'Monitoring System', 'details': 'Fairness metric degraded'},\n        {'timestamp': base_time + timedelta(days=11), 'event': 'Model retrained', 'user': 'Data Scientist', 'details': 'Retraining with fairness constraints'},\n        {'timestamp': base_time + timedelta(days=12), 'event': 'Model updated', 'user': 'Product Manager', 'details': 'New version deployed'},\n    ]\n    for event in events:\n        audit_entries.append({\n            'timestamp': event['timestamp'], 'event_type': event['event'],\n            'user': event['user'],\n            'details': event['details']\n        })\n    return pd.DataFrame(audit_entries)\n# ============================================================================\n# ACCOUNTABILITY FRAMEWORK\n# ============================================================================\ndef accountability_framework_checklist():\n    \"\"\"\n    Create accountability framework checklist\n    \"\"\"\n    checklist = {\n        'Pre-deployment': [\n            'Model documentation complete', 'Bias assessment performed',\n            'Fairness metrics calculated',\n            'Stakeholder review completed',\n            'Legal compliance verified'\n        ],\n        'Deployment': [\n            'Monitoring systems in place',\n            'Audit trail enabled',\n            'User notifications configured',\n            'Rollback plan prepared'\n        ],\n        'Post-deployment': [\n            'Regular performance monitoring',\n            'Fairness metrics tracking',\n            'User feedback collection',\n            'Periodic model audits',\n            'Incident response plan'\n        ]\n    }\n    return checklist\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_stakeholder_responsibilities(stakeholders):\n    \"\"\"\n    Plot stakeholder responsibility matrix\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 8))\n    names = list(stakeholders.keys())\n    accountability = [stakeholders[name]['accountability_level'] for name in names]\n    num_responsibilities = [len(stakeholders[name]['responsibilities']) for name in names]\n    scatter = ax.scatter(num_responsibilities, accountability, s=200, alpha=0.6, c=accountability, \n                        cmap='RdYlGn', edgecolors='black', linewidth=2)\n    for i, name in enumerate(names):\n        ax.annotate(name, (num_responsibilities[i], accountability[i]), \n                   xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n    ax.set_xlabel('Number of Responsibilities', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Accountability Level (1-10)', fontsize=11, fontweight='bold')\n    ax.set_title('Stakeholder Accountability Matrix', fontsize=12, fontweight='bold')\n    ax.grid(alpha=0.3)\n    plt.colorbar(scatter, ax=ax, label='Accountability Level')\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: stakeholder_accountability.png\")\n    plt.close()\ndef plot_audit_timeline(audit_df):\n    \"\"\"\n    Plot audit trail timeline\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(14, 8))\n    # Convert timestamps to days since first event\n    first_time = audit_df['timestamp'].min()\n    audit_df['days_since_start'] = (audit_df['timestamp'] - first_time).dt.days\n    # Plot events\n    event_types = audit_df['event_type'].unique()\n    colors = plt.cm.Set3(np.linspace(0, 1, len(event_types)))\n    color_map = dict(zip(event_types, colors))\n    for idx, row in audit_df.iterrows():\n        ax.scatter(row['days_since_start'], idx, s=200, \n                 c=color_map[row['event_type']], alpha=0.7, edgecolors='black')\n        ax.text(row['days_since_start'], idx, f\"  {row['event_type']}\", \n               va='center', fontsize=9)\n    ax.set_xlabel('Days Since First Event', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Event Index', fontsize=11, fontweight='bold')\n    ax.set_title('AI System Audit Trail Timeline', fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    # Legend\n    from matplotlib.patches import Patch\n    legend_elements = [Patch(facecolor=color_map[et], label=et) for et in event_types]\n    ax.legend(handles=legend_elements, loc='upper left', fontsize=9)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: audit_timeline.png\")\n    plt.close()\ndef plot_accountability_checklist(checklist):\n    \"\"\"\n    Plot accountability checklist status\n    \"\"\"\n    phases = list(checklist.keys())\n    items_per_phase = [len(items) for items in checklist.values()]\n    fig, ax = plt.subplots(figsize=(12, 6))\n    bars = ax.bar(phases, items_per_phase, color=['#3498db', '#2ecc71', '#f39c12'], alpha=0.8)\n    # Add value labels\n    for bar, count in zip(bars, items_per_phase):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n               f'{int(count)} items', ha='center', va='bottom', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Number of Checklist Items', fontsize=11, fontweight='bold')\n    ax.set_title('Accountability Framework Checklist by Phase', fontsize=12, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: accountability_checklist.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 4: Accountability Frameworks\")\n    print(\"=\"*80)\n    # Define stakeholders\n    print(\"\\n1. Stakeholder Responsibilities:\")\n    stakeholders = define_stakeholder_responsibilities()\n    for name, info in stakeholders.items():\n        print(f\"\\n{name}:\")\n        print(f\"  Accountability Level: {info['accountability_level']}\")\n        print(f\"  Responsibilities:\")\n        for resp in info['responsibilities']:\n            print(f\"    - {resp}\")\n    # Create model card\n    print(\"\\n2. Model Card:\")\n    model_card = create_model_card(\n        model_name='Loan Approval Classifier', model_type='Random Forest',\n        performance_metrics={'accuracy': 0.87, 'fairness_score': 0.92},\n        training_data_info={'samples': 10000, 'features': 10, 'date_range': '2023-01 to 2023-12'},\n        limitations=['May have bias for certain demographic groups', 'Requires periodic retraining'],\n        use_cases=['Loan approval decisions', 'Credit risk assessment']\n    )\n    print(f\"  Model: {model_card['model_name']}\")\n    print(f\"  Created: {model_card['date_created']}\")\n    print(f\"  Performance: {model_card['performance_metrics']}\")\n    # Create audit trail\n    print(\"\\n3. Audit Trail:\")\n    audit_df = create_audit_trail()\n    print(f\"  Total audit entries: {len(audit_df)}\")\n    print(f\"  Date range: {audit_df['timestamp'].min()} to {audit_df['timestamp'].max()}\")\n    # Accountability checklist\n    print(\"\\n4. Accountability Checklist:\")\n    checklist = accountability_framework_checklist()\n    for phase, items in checklist.items():\n        print(f\"\\n{phase}:\")\n        for item in items:\n            print(f\"  [ ] {item}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_stakeholder_responsibilities(stakeholders)\n    plot_audit_timeline(audit_df)\n    plot_accountability_checklist(checklist)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Clear stakeholder responsibilities ensure accountability\")\n    print(\"2. Model cards document model characteristics and limitations\")\n    print(\"3. Audit trails track all system decisions and changes\")\n    print(\"4. Accountability checklists ensure comprehensive coverage\")\n    print(\"5. Accountability frameworks are essential for trustworthy AI\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 228\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/05_hitl_approaches.ipynb",
      "status": "failed",
      "execution_time": 0.6601121425628662,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 5: Human-in-the-Loop (HITL) Approaches\nThis example demonstrates human-in-the-loop approaches for AI fairness evaluation.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)\n    sensitive = np.random.choice([0, 1], n_samples, p=[0.6, 0.4])\n    X1 = np.random.normal(0, 1, n_samples)\n    X2 = np.random.normal(0, 1, n_samples)\n    y = (0.4 * X1 + 0.3 * X2 + np.random.normal(0, 0.1, n_samples) > 0).astype(int)\n    return pd.DataFrame({'feature1': X1, 'feature2': X2, 'sensitive': sensitive, 'target': y})\ndef hitl_fairness_evaluation(model, X_test, y_test, sensitive_test, uncertainty_threshold=0.1):\n    y_pred_proba = model.predict_proba(X_test)[:, 1]\n    y_pred = (y_pred_proba > 0.5).astype(int)\n    uncertainty = np.abs(y_pred_proba - 0.5)\n    uncertain_mask = uncertainty < uncertainty_threshold\n    human_reviewed = y_pred.copy()\n    if uncertain_mask.sum() > 0:\n        human_predictions = y_test[uncertain_mask].copy()\n        human_reviewed[uncertain_mask] = human_predictions\n    return {\n        'automated': y_pred, 'hitl': human_reviewed,\n        'uncertain_count': uncertain_mask.sum(),\n        'uncertain_mask': uncertain_mask\n    }\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 5: Human-in-the-Loop Approaches\")\n    print(\"=\"*80)\n    df = generate_dataset()\n    X = df[['feature1', 'feature2']].values\n    y = df['target'].values\n    sensitive = df['sensitive'].values\n    X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n        X, y, sensitive, test_size=0.3, random_state=42, stratify=y\n    )\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    results = hitl_fairness_evaluation(model, X_test_scaled, y_test, sensitive_test)\n    auto_acc = accuracy_score(y_test, results['automated'])\n    hitl_acc = accuracy_score(y_test, results['hitl'])\n    auto_dp = abs(demographic_parity_difference(y_test, results['automated'], sensitive_features=sensitive_test))\n    hitl_dp = abs(demographic_parity_difference(y_test, results['hitl'], sensitive_features=sensitive_test))\n    print(f\"\\nAutomated Model:\")\n    print(f\"  Accuracy: {auto_acc:.4f}\")\n    print(f\"  Demographic Parity Difference: {auto_dp:.4f}\")\n    print(f\"\\nHITL Model:\")\n    print(f\"  Accuracy: {hitl_acc:.4f}\")\n    print(f\"  Demographic Parity Difference: {hitl_dp:.4f}\")\n    print(f\"  Human Reviews: {results['uncertain_count']}\")\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n    axes[0].bar(['Automated', 'HITL'], [auto_acc, hitl_acc], color=['#e74c3c', '#2ecc71'])\n    axes[0].set_title('Accuracy Comparison', fontweight='bold')\n    axes[0].set_ylabel('Accuracy')\n    axes[1].bar(['Automated', 'HITL'], [auto_dp, hitl_dp], color=['#e74c3c', '#2ecc71'])\n    axes[1].set_title('Fairness Comparison', fontweight='bold')\n    axes[1].set_ylabel('Demographic Parity Difference')\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: hitl_comparison.png\")\n    plt.close()\n    print(\"\\n\u2705 Example completed!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 41\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 5: Human-in-the-Loop (HITL) Approaches\nThis example demonstrates human-in-the-loop approaches for AI fairness evaluation.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)\n    sensitive = np.random.choice([0, 1], n_samples, p=[0.6, 0.4])\n    X1 = np.random.normal(0, 1, n_samples)\n    X2 = np.random.normal(0, 1, n_samples)\n    y = (0.4 * X1 + 0.3 * X2 + np.random.normal(0, 0.1, n_samples) > 0).astype(int)\n    return pd.DataFrame({'feature1': X1, 'feature2': X2, 'sensitive': sensitive, 'target': y})\ndef hitl_fairness_evaluation(model, X_test, y_test, sensitive_test, uncertainty_threshold=0.1):\n    y_pred_proba = model.predict_proba(X_test)[:, 1]\n    y_pred = (y_pred_proba > 0.5).astype(int)\n    uncertainty = np.abs(y_pred_proba - 0.5)\n    uncertain_mask = uncertainty < uncertainty_threshold\n    human_reviewed = y_pred.copy()\n    if uncertain_mask.sum() > 0:\n        human_predictions = y_test[uncertain_mask].copy()\n        human_reviewed[uncertain_mask] = human_predictions\n    return {\n        'automated': y_pred, 'hitl': human_reviewed,\n        'uncertain_count': uncertain_mask.sum(),\n        'uncertain_mask': uncertain_mask\n    }\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 5: Human-in-the-Loop Approaches\")\n    print(\"=\"*80)\n    df = generate_dataset()\n    X = df[['feature1', 'feature2']].values\n    y = df['target'].values\n    sensitive = df['sensitive'].values\n    X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n        X, y, sensitive, test_size=0.3, random_state=42, stratify=y\n    )\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    results = hitl_fairness_evaluation(model, X_test_scaled, y_test, sensitive_test)\n    auto_acc = accuracy_score(y_test, results['automated'])\n    hitl_acc = accuracy_score(y_test, results['hitl'])\n    auto_dp = abs(demographic_parity_difference(y_test, results['automated'], sensitive_features=sensitive_test))\n    hitl_dp = abs(demographic_parity_difference(y_test, results['hitl'], sensitive_features=sensitive_test))\n    print(f\"\\nAutomated Model:\")\n    print(f\"  Accuracy: {auto_acc:.4f}\")\n    print(f\"  Demographic Parity Difference: {auto_dp:.4f}\")\n    print(f\"\\nHITL Model:\")\n    print(f\"  Accuracy: {hitl_acc:.4f}\")\n    print(f\"  Demographic Parity Difference: {hitl_dp:.4f}\")\n    print(f\"  Human Reviews: {results['uncertain_count']}\")\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n    axes[0].bar(['Automated', 'HITL'], [auto_acc, hitl_acc], color=['#e74c3c', '#2ecc71'])\n    axes[0].set_title('Accuracy Comparison', fontweight='bold')\n    axes[0].set_ylabel('Accuracy')\n    axes[1].bar(['Automated', 'HITL'], [auto_dp, hitl_dp], color=['#e74c3c', '#2ecc71'])\n    axes[1].set_title('Fairness Comparison', fontweight='bold')\n    axes[1].set_ylabel('Demographic Parity Difference')\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: hitl_comparison.png\")\n    plt.close()\n    print(\"\\n\u2705 Example completed!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 41\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/06_transparency_tools.ipynb",
      "status": "failed",
      "execution_time": 0.799144983291626,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 6: Transparency Tools\nThis example demonstrates transparency tools and frameworks for AI systems.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\ndef compare_transparency_tools():\n    tools = {\n        'SHAP': {'interpretability': 9, 'ease_of_use': 8, 'model_agnostic': True, 'local_explanations': True},\n        'LIME': {'interpretability': 8, 'ease_of_use': 9, 'model_agnostic': True, 'local_explanations': True},\n        'Partial Dependence': {'interpretability': 7, 'ease_of_use': 7, 'model_agnostic': False, 'local_explanations': False},\n        'Feature Importance': {'interpretability': 6, 'ease_of_use': 9, 'model_agnostic': False, 'local_explanations': False},\n        'Counterfactuals': {'interpretability': 9, 'ease_of_use': 6, 'model_agnostic': True, 'local_explanations': True}\n    }\n    return tools\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 6: Transparency Tools\")\n    print(\"=\"*80)\n    tools = compare_transparency_tools()\n    print(\"\\nTransparency Tools Comparison:\")\n    for tool, metrics in tools.items():\n        print(f\"\\n{tool}:\")\n        print(f\"  Interpretability: {metrics['interpretability']}\")\n        print(f\"  Ease of Use: {metrics['ease_of_use']}\")\n        print(f\"  Model Agnostic: {metrics['model_agnostic']}\")\n        print(f\"  Local Explanations: {metrics['local_explanations']}\")\n    tools_list = list(tools.keys())\n    interpretability = [tools[t]['interpretability'] for t in tools_list]\n    ease_of_use = [tools[t]['ease_of_use'] for t in tools_list]\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    axes[0].bar(tools_list, interpretability, color='#3498db')\n    axes[0].set_title('Interpretability Score', fontweight='bold')\n    axes[0].set_ylabel('Score (1-10)')\n    axes[0].tick_params(axis='x', rotation=15)\n    axes[1].bar(tools_list, ease_of_use, color='#2ecc71')\n    axes[1].set_title('Ease of Use Score', fontweight='bold')\n    axes[1].set_ylabel('Score (1-10)')\n    axes[1].tick_params(axis='x', rotation=15)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: transparency_tools_comparison.png\")\n    plt.close()\n    print(\"\\n\u2705 Example completed!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 24\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExample 6: Transparency Tools\nThis example demonstrates transparency tools and frameworks for AI systems.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\ndef compare_transparency_tools():\n    tools = {\n        'SHAP': {'interpretability': 9, 'ease_of_use': 8, 'model_agnostic': True, 'local_explanations': True},\n        'LIME': {'interpretability': 8, 'ease_of_use': 9, 'model_agnostic': True, 'local_explanations': True},\n        'Partial Dependence': {'interpretability': 7, 'ease_of_use': 7, 'model_agnostic': False, 'local_explanations': False},\n        'Feature Importance': {'interpretability': 6, 'ease_of_use': 9, 'model_agnostic': False, 'local_explanations': False},\n        'Counterfactuals': {'interpretability': 9, 'ease_of_use': 6, 'model_agnostic': True, 'local_explanations': True}\n    }\n    return tools\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Example 6: Transparency Tools\")\n    print(\"=\"*80)\n    tools = compare_transparency_tools()\n    print(\"\\nTransparency Tools Comparison:\")\n    for tool, metrics in tools.items():\n        print(f\"\\n{tool}:\")\n        print(f\"  Interpretability: {metrics['interpretability']}\")\n        print(f\"  Ease of Use: {metrics['ease_of_use']}\")\n        print(f\"  Model Agnostic: {metrics['model_agnostic']}\")\n        print(f\"  Local Explanations: {metrics['local_explanations']}\")\n    tools_list = list(tools.keys())\n    interpretability = [tools[t]['interpretability'] for t in tools_list]\n    ease_of_use = [tools[t]['ease_of_use'] for t in tools_list]\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    axes[0].bar(tools_list, interpretability, color='#3498db')\n    axes[0].set_title('Interpretability Score', fontweight='bold')\n    axes[0].set_ylabel('Score (1-10)')\n    axes[0].tick_params(axis='x', rotation=15)\n    axes[1].bar(tools_list, ease_of_use, color='#2ecc71')\n    axes[1].set_title('Ease of Use Score', fontweight='bold')\n    axes[1].set_ylabel('Score (1-10)')\n    axes[1].tick_params(axis='x', rotation=15)\n    plt.tight_layout()\n    plt.savefig('unit4-transparency-accountability', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: transparency_tools_comparison.png\")\n    plt.close()\n    print(\"\\n\u2705 Example completed!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 24\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/07_explainable_ai_techniques.ipynb",
      "status": "failed",
      "execution_time": 0.6969878673553467,
      "error": "An error occurred while executing the following cell:\n------------------\nimport shap\nimport lime\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nExplainable AI Techniques\")\nprint(\"=\" * 60)\n\nprint(\"\\nSHAP (SHapley Additive exPlanations):\")\nprint(\" - Game theory-based\")\nprint(\" - Feature importance\")\nprint(\" - Global and local explanations\")\nprint(\" - Consistent explanations\")\n\nprint(\"\\nLIME (Local Interpretable Model-agnostic Explanations):\")\nprint(\" - Local explanations\")\nprint(\" - Model-agnostic\")\nprint(\" - Perturbation-based\")\nprint(\" - Interpretable models\")\n\nprint(\"\\nApplications:\")\nprint(\" - Model debugging\")\nprint(\" - Feature importance\")\nprint(\" - Regulatory compliance\")\nprint(\" - User trust\")\n\nprint(\"\\n\u2705 Explainable AI concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport shap\nimport lime\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nExplainable AI Techniques\")\nprint(\"=\" * 60)\n\nprint(\"\\nSHAP (SHapley Additive exPlanations):\")\nprint(\" - Game theory-based\")\nprint(\" - Feature importance\")\nprint(\" - Global and local explanations\")\nprint(\" - Consistent explanations\")\n\nprint(\"\\nLIME (Local Interpretable Model-agnostic Explanations):\")\nprint(\" - Local explanations\")\nprint(\" - Model-agnostic\")\nprint(\" - Perturbation-based\")\nprint(\" - Interpretable models\")\n\nprint(\"\\nApplications:\")\nprint(\" - Model debugging\")\nprint(\" - Feature importance\")\nprint(\" - Regulatory compliance\")\nprint(\" - User trust\")\n\nprint(\"\\n\u2705 Explainable AI concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/case_studies_analysis_analyzing_success_and_failure_in_transparency_and_accounta.ipynb",
      "status": "passed",
      "execution_time": 1.697317123413086,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/implementing_xai_techniques_applying_techniques_like_lime_and_shap_to_interpret_.ipynb",
      "status": "passed",
      "execution_time": 1.491161823272705,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6901729106903076,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1: SHAP and LIME Explanations\nThis exercise requires you to implement SHAP and LIME explanations.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\ndef generate_dataset(n_samples=1000):\n    \"\"\"TODO: Generate a dataset for explanation exercises\"\"\"\n    pass\ndef calculate_shap_values(model, X_sample, X_train, feature_names):\n    \"\"\"TODO: Calculate SHAP values for a sample\"\"\"\n    pass\ndef calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    \"\"\"TODO: Calculate LIME explanation for a sample\"\"\"\n    pass\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Exercise 1: SHAP and LIME Explanations\")\n    print(\"=\"*80)\n    print(\"\\nComplete the TODO sections in this file.\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1: SHAP and LIME Explanations\nThis exercise requires you to implement SHAP and LIME explanations.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\ndef generate_dataset(n_samples=1000):\n    \"\"\"TODO: Generate a dataset for explanation exercises\"\"\"\n    pass\ndef calculate_shap_values(model, X_sample, X_train, feature_names):\n    \"\"\"TODO: Calculate SHAP values for a sample\"\"\"\n    pass\ndef calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    \"\"\"TODO: Calculate LIME explanation for a sample\"\"\"\n    pass\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 4 - Exercise 1: SHAP and LIME Explanations\")\n    print(\"=\"*80)\n    print(\"\\nComplete the TODO sections in this file.\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6426711082458496,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "other"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/01_global_regulations.ipynb",
      "status": "failed",
      "execution_time": 0.8176710605621338,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 1: Global AI Regulations\nThis example demonstrates global AI regulations:\n- EU AI Act\n- US Executive Orders and Initiatives\n- China, Canada, OECD regulations\n- Comparison of approaches\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# GLOBAL AI REGULATIONS\n# ============================================================================\ndef global_ai_regulations():\n    \"\"\"\n    Define global AI regulations and their key features\n    \"\"\"\n    regulations = {\n        'EU AI Act': {\n            'region': 'European Union', 'status': 'Enacted',\n            'risk_based': True,\n            'strictness': 9,\n            'key_features': [\n                'Risk-based classification (Unacceptable, High, Limited, Minimal)',\n                'Prohibited AI practices',\n                'Requirements for high-risk AI systems',\n                'Transparency obligations',\n                'Market surveillance'\n            ],\n            'enforcement': 'Strong',\n            'penalties': 'Up to 7% of global revenue'\n        },\n        'US Executive Orders': {\n            'region': 'United States',\n            'status': 'Active',\n            'risk_based': False,\n            'strictness': 6,\n            'key_features': [\n                'AI Safety and Security Standards',\n                'Privacy protections',\n                'Equity and civil rights',\n                'Consumer protections',\n                'Worker support'\n            ],\n            'enforcement': 'Moderate',\n            'penalties': 'Varies by agency'\n        },\n        'China AI Regulations': {\n            'region': 'China',\n            'status': 'Active',\n            'risk_based': True,\n            'strictness': 8,\n            'key_features': [\n                'Algorithmic recommendation rules',\n                'Deep synthesis regulations',\n                'Data security law',\n                'Personal information protection law',\n                'Content moderation requirements'\n            ],\n            'enforcement': 'Strong',\n            'penalties': 'Fines and business restrictions'\n        },\n        'Canada AI Regulations': {\n            'region': 'Canada',\n            'status': 'Proposed',\n            'risk_based': True,\n            'strictness': 7,\n            'key_features': [\n                'AIDA (Artificial Intelligence and Data Act)',\n                'High-impact AI system requirements',\n                'Harm prevention',\n                'Transparency and accountability',\n                'Human oversight'\n            ],\n            'enforcement': 'Moderate',\n            'penalties': 'Up to $25M or 5% of revenue'\n        },\n        'OECD AI Principles': {\n            'region': 'International',\n            'status': 'Adopted',\n            'risk_based': False,\n            'strictness': 5,\n            'key_features': [\n                'Inclusive growth and human-centered values',\n                'Transparency and explainability',\n                'Robustness and security',\n                'Accountability',\n                'International cooperation'\n            ],\n            'enforcement': 'Voluntary',\n            'penalties': 'None (guidelines)'\n        }\n    }\n    return regulations\n# ============================================================================\n# REGULATION COMPARISON\n# ============================================================================\ndef compare_regulations(regulations):\n    \"\"\"\n    Compare different regulatory approaches\n    \"\"\"\n    comparison = pd.DataFrame({\n        'Region': [r['region'] for r in regulations.values()], 'Status': [r['status'] for r in regulations.values()],\n        'Strictness': [r['strictness'] for r in regulations.values()], 'Risk-Based': [r['risk_based'] for r in regulations.values()],\n        'Enforcement': [r['enforcement'] for r in regulations.values()]\n    })\n    return comparison\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_regulation_comparison(regulations):\n    \"\"\"\n    Plot comparison of global AI regulations\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    regions = list(regulations.keys())\n    strictness = [r['strictness'] for r in regulations.values()]\n    risk_based = [1 if r['risk_based'] else 0 for r in regulations.values()]\n    # Strictness comparison\n    colors = ['#e74c3c' if s >= 8 else '#f39c12' if s >= 6 else '#2ecc71' \n              for s in strictness]\n    axes[0, 0].barh(regions, strictness, color=colors, alpha=0.8)\n    axes[0, 0].set_title('Regulatory Strictness (1-10)', fontsize=12, fontweight='bold')\n    axes[0, 0].set_xlabel('Strictness Score')\n    axes[0, 0].grid(axis='x', alpha=0.3)\n    axes[0, 0].set_xlim([0, 11])\n    # Risk-based approach\n    axes[0, 1].bar(regions, risk_based, color='#3498db', alpha=0.8)\n    axes[0, 1].set_title('Risk-Based Approach (1=Yes, 0=No)', fontsize=12, fontweight='bold')\n    axes[0, 1].set_ylabel('Risk-Based')\n    axes[0, 1].tick_params(axis='x', rotation=15)\n    axes[0, 1].grid(axis='y', alpha=0.3)\n    axes[0, 1].set_ylim([0, 1.2])\n    # Enforcement levels\n    enforcement_map = {'Strong': 3, 'Moderate': 2, 'Voluntary': 1}\n    enforcement_scores = [enforcement_map[r['enforcement']] for r in regulations.values()]\n    axes[1, 0].barh(regions, enforcement_scores, color='#9b59b6', alpha=0.8)\n    axes[1, 0].set_title('Enforcement Level', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xlabel('Enforcement (1=Voluntary, 2=Moderate, 3=Strong)')\n    axes[1, 0].grid(axis='x', alpha=0.3)\n    axes[1, 0].set_xlim([0, 4])\n    # Status\n    status_map = {'Enacted': 3, 'Active': 2, 'Proposed': 1, 'Adopted': 2}\n    status_scores = [status_map.get(r['status'], 0) for r in regulations.values()]\n    axes[1, 1].bar(regions, status_scores, color='#2ecc71', alpha=0.8)\n    axes[1, 1].set_title('Regulatory Status', fontsize=12, fontweight='bold')\n    axes[1, 1].set_ylabel('Status (1=Proposed, 2=Active')\n    axes[1, 1].tick_params(axis='x', rotation=15)\n    axes[1, 1].grid(axis='y', alpha=0.3)\n    axes[1, 1].set_ylim([0, 4])\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: global_regulations_comparison.png\")\n    plt.close()\ndef plot_regulatory_timeline(regulations):\n    \"\"\"\n    Plot regulatory timeline\n    \"\"\"\n    timeline_data = {\n        'OECD AI Principles': 2019, 'China AI Regulations': 2021,\n        'EU AI Act': 2024,\n        'US Executive Orders': 2023,\n        'Canada AI Regulations': 2025  # Proposed\n    }\n    fig, ax = plt.subplots(figsize=(12, 8))\n    regions = list(timeline_data.keys())\n    years = list(timeline_data.values())\n    colors = plt.cm.viridis(np.linspace(0, 1, len(regions)))\n    for i, (region, year) in enumerate(timeline_data.items()):\n        ax.scatter(year, i, s=300, c=[colors[i]], alpha=0.7, edgecolors='black', linewidth=2)\n        ax.text(year, i, f'  {region}', va='center', fontsize=10, fontweight='bold')\n    ax.set_xlabel('Year', fontsize=11, fontweight='bold')\n    ax.set_yticks(range(len(regions)))\n    ax.set_yticklabels([])\n    ax.set_title('Global AI Regulations Timeline', fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    ax.set_xlim([2018, 2026])\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: regulatory_timeline.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 1: Global AI Regulations\")\n    print(\"=\"*80)\n    # Global regulations\n    regulations = global_ai_regulations()\n    print(\"\\nGlobal AI Regulations Overview:\")\n    for region, info in regulations.items():\n        print(f\"\\n{region} ({info['region']}):\")\n        print(f\"  Status: {info['status']}\")\n        print(f\"  Strictness: {info['strictness']}\")\n        print(f\"  Risk-Based: {info['risk_based']}\")\n        print(f\"  Enforcement: {info['enforcement']}\")\n        print(f\"  Key Features:\")\n        for feature in info['key_features'][:3]:\n            print(f\"    - {feature}\")\n    # Comparison\n    print(\"\\n\" + \"=\"*80)\n    print(\"Regulation Comparison:\")\n    print(\"=\"*80)\n    comparison = compare_regulations(regulations)\n    print(comparison.to_string(index=False))\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_regulation_comparison(regulations)\n    plot_regulatory_timeline(regulations)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Different regions have different regulatory approaches\")\n    print(\"2. EU AI Act is the most comprehensive risk-based framework\")\n    print(\"3. US focuses on executive orders and agency-specific rules\")\n    print(\"4. China has strict content and data regulations\")\n    print(\"5. International cooperation is needed for global AI governance\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 193\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 1: Global AI Regulations\nThis example demonstrates global AI regulations:\n- EU AI Act\n- US Executive Orders and Initiatives\n- China, Canada, OECD regulations\n- Comparison of approaches\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# GLOBAL AI REGULATIONS\n# ============================================================================\ndef global_ai_regulations():\n    \"\"\"\n    Define global AI regulations and their key features\n    \"\"\"\n    regulations = {\n        'EU AI Act': {\n            'region': 'European Union', 'status': 'Enacted',\n            'risk_based': True,\n            'strictness': 9,\n            'key_features': [\n                'Risk-based classification (Unacceptable, High, Limited, Minimal)',\n                'Prohibited AI practices',\n                'Requirements for high-risk AI systems',\n                'Transparency obligations',\n                'Market surveillance'\n            ],\n            'enforcement': 'Strong',\n            'penalties': 'Up to 7% of global revenue'\n        },\n        'US Executive Orders': {\n            'region': 'United States',\n            'status': 'Active',\n            'risk_based': False,\n            'strictness': 6,\n            'key_features': [\n                'AI Safety and Security Standards',\n                'Privacy protections',\n                'Equity and civil rights',\n                'Consumer protections',\n                'Worker support'\n            ],\n            'enforcement': 'Moderate',\n            'penalties': 'Varies by agency'\n        },\n        'China AI Regulations': {\n            'region': 'China',\n            'status': 'Active',\n            'risk_based': True,\n            'strictness': 8,\n            'key_features': [\n                'Algorithmic recommendation rules',\n                'Deep synthesis regulations',\n                'Data security law',\n                'Personal information protection law',\n                'Content moderation requirements'\n            ],\n            'enforcement': 'Strong',\n            'penalties': 'Fines and business restrictions'\n        },\n        'Canada AI Regulations': {\n            'region': 'Canada',\n            'status': 'Proposed',\n            'risk_based': True,\n            'strictness': 7,\n            'key_features': [\n                'AIDA (Artificial Intelligence and Data Act)',\n                'High-impact AI system requirements',\n                'Harm prevention',\n                'Transparency and accountability',\n                'Human oversight'\n            ],\n            'enforcement': 'Moderate',\n            'penalties': 'Up to $25M or 5% of revenue'\n        },\n        'OECD AI Principles': {\n            'region': 'International',\n            'status': 'Adopted',\n            'risk_based': False,\n            'strictness': 5,\n            'key_features': [\n                'Inclusive growth and human-centered values',\n                'Transparency and explainability',\n                'Robustness and security',\n                'Accountability',\n                'International cooperation'\n            ],\n            'enforcement': 'Voluntary',\n            'penalties': 'None (guidelines)'\n        }\n    }\n    return regulations\n# ============================================================================\n# REGULATION COMPARISON\n# ============================================================================\ndef compare_regulations(regulations):\n    \"\"\"\n    Compare different regulatory approaches\n    \"\"\"\n    comparison = pd.DataFrame({\n        'Region': [r['region'] for r in regulations.values()], 'Status': [r['status'] for r in regulations.values()],\n        'Strictness': [r['strictness'] for r in regulations.values()], 'Risk-Based': [r['risk_based'] for r in regulations.values()],\n        'Enforcement': [r['enforcement'] for r in regulations.values()]\n    })\n    return comparison\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_regulation_comparison(regulations):\n    \"\"\"\n    Plot comparison of global AI regulations\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    regions = list(regulations.keys())\n    strictness = [r['strictness'] for r in regulations.values()]\n    risk_based = [1 if r['risk_based'] else 0 for r in regulations.values()]\n    # Strictness comparison\n    colors = ['#e74c3c' if s >= 8 else '#f39c12' if s >= 6 else '#2ecc71' \n              for s in strictness]\n    axes[0, 0].barh(regions, strictness, color=colors, alpha=0.8)\n    axes[0, 0].set_title('Regulatory Strictness (1-10)', fontsize=12, fontweight='bold')\n    axes[0, 0].set_xlabel('Strictness Score')\n    axes[0, 0].grid(axis='x', alpha=0.3)\n    axes[0, 0].set_xlim([0, 11])\n    # Risk-based approach\n    axes[0, 1].bar(regions, risk_based, color='#3498db', alpha=0.8)\n    axes[0, 1].set_title('Risk-Based Approach (1=Yes, 0=No)', fontsize=12, fontweight='bold')\n    axes[0, 1].set_ylabel('Risk-Based')\n    axes[0, 1].tick_params(axis='x', rotation=15)\n    axes[0, 1].grid(axis='y', alpha=0.3)\n    axes[0, 1].set_ylim([0, 1.2])\n    # Enforcement levels\n    enforcement_map = {'Strong': 3, 'Moderate': 2, 'Voluntary': 1}\n    enforcement_scores = [enforcement_map[r['enforcement']] for r in regulations.values()]\n    axes[1, 0].barh(regions, enforcement_scores, color='#9b59b6', alpha=0.8)\n    axes[1, 0].set_title('Enforcement Level', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xlabel('Enforcement (1=Voluntary, 2=Moderate, 3=Strong)')\n    axes[1, 0].grid(axis='x', alpha=0.3)\n    axes[1, 0].set_xlim([0, 4])\n    # Status\n    status_map = {'Enacted': 3, 'Active': 2, 'Proposed': 1, 'Adopted': 2}\n    status_scores = [status_map.get(r['status'], 0) for r in regulations.values()]\n    axes[1, 1].bar(regions, status_scores, color='#2ecc71', alpha=0.8)\n    axes[1, 1].set_title('Regulatory Status', fontsize=12, fontweight='bold')\n    axes[1, 1].set_ylabel('Status (1=Proposed, 2=Active')\n    axes[1, 1].tick_params(axis='x', rotation=15)\n    axes[1, 1].grid(axis='y', alpha=0.3)\n    axes[1, 1].set_ylim([0, 4])\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: global_regulations_comparison.png\")\n    plt.close()\ndef plot_regulatory_timeline(regulations):\n    \"\"\"\n    Plot regulatory timeline\n    \"\"\"\n    timeline_data = {\n        'OECD AI Principles': 2019, 'China AI Regulations': 2021,\n        'EU AI Act': 2024,\n        'US Executive Orders': 2023,\n        'Canada AI Regulations': 2025  # Proposed\n    }\n    fig, ax = plt.subplots(figsize=(12, 8))\n    regions = list(timeline_data.keys())\n    years = list(timeline_data.values())\n    colors = plt.cm.viridis(np.linspace(0, 1, len(regions)))\n    for i, (region, year) in enumerate(timeline_data.items()):\n        ax.scatter(year, i, s=300, c=[colors[i]], alpha=0.7, edgecolors='black', linewidth=2)\n        ax.text(year, i, f'  {region}', va='center', fontsize=10, fontweight='bold')\n    ax.set_xlabel('Year', fontsize=11, fontweight='bold')\n    ax.set_yticks(range(len(regions)))\n    ax.set_yticklabels([])\n    ax.set_title('Global AI Regulations Timeline', fontsize=12, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    ax.set_xlim([2018, 2026])\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: regulatory_timeline.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 1: Global AI Regulations\")\n    print(\"=\"*80)\n    # Global regulations\n    regulations = global_ai_regulations()\n    print(\"\\nGlobal AI Regulations Overview:\")\n    for region, info in regulations.items():\n        print(f\"\\n{region} ({info['region']}):\")\n        print(f\"  Status: {info['status']}\")\n        print(f\"  Strictness: {info['strictness']}\")\n        print(f\"  Risk-Based: {info['risk_based']}\")\n        print(f\"  Enforcement: {info['enforcement']}\")\n        print(f\"  Key Features:\")\n        for feature in info['key_features'][:3]:\n            print(f\"    - {feature}\")\n    # Comparison\n    print(\"\\n\" + \"=\"*80)\n    print(\"Regulation Comparison:\")\n    print(\"=\"*80)\n    comparison = compare_regulations(regulations)\n    print(comparison.to_string(index=False))\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_regulation_comparison(regulations)\n    plot_regulatory_timeline(regulations)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Different regions have different regulatory approaches\")\n    print(\"2. EU AI Act is the most comprehensive risk-based framework\")\n    print(\"3. US focuses on executive orders and agency-specific rules\")\n    print(\"4. China has strict content and data regulations\")\n    print(\"5. International cooperation is needed for global AI governance\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 193\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/02_industry_regulations.ipynb",
      "status": "failed",
      "execution_time": 0.6881148815155029,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 2: Industry-Specific AI Regulations\nThis example demonstrates industry-specific AI regulations:\n- Healthcare AI regulations\n- Finance AI regulations\n- Autonomous Vehicles regulations\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# INDUSTRY-SPECIFIC REGULATIONS\n# ============================================================================\ndef industry_regulations():\n    \"\"\"\n    Define industry-specific AI regulations\n    \"\"\"\n    regulations = {\n        'Healthcare': {\n            'regulatory_bodies': ['FDA (US)', 'EMA (EU)', 'Health Canada'],\n            'key_requirements': [\n                'Clinical validation',\n                'Safety and efficacy proof',\n                'Transparency in decision-making',\n                'Human oversight',\n                'Data privacy (HIPAA compliance)'\n            ],\n            'risk_level': 'Very High',\n            'compliance_complexity': 9,\n            'examples': ['Medical diagnosis AI', 'Drug discovery', 'Treatment recommendations']\n        },\n        'Finance': {\n            'regulatory_bodies': ['SEC (US)', 'FCA (UK)', 'ESMA (EU)'],\n            'key_requirements': [\n                'Fair lending practices',\n                'Anti-discrimination compliance',\n                'Explainability for credit decisions',\n                'Risk management',\n                'Audit trails'\n            ],\n            'risk_level': 'High',\n            'compliance_complexity': 8,\n            'examples': ['Credit scoring', 'Fraud detection', 'Algorithmic trading']\n        },\n        'Autonomous Vehicles': {\n            'regulatory_bodies': ['NHTSA (US)', 'ECE (EU)', 'Transport Canada'],\n            'key_requirements': [\n                'Safety standards',\n                'Testing and validation',\n                'Liability frameworks',\n                'Data recording',\n                'Cybersecurity'\n            ],\n            'risk_level': 'Very High',\n            'compliance_complexity': 9,\n            'examples': ['Self-driving cars', 'Autonomous trucks', 'Delivery robots']\n        }\n    }\n    return regulations\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_industry_regulations(regulations):\n    \"\"\"\n    Plot industry-specific regulations comparison\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    industries = list(regulations.keys())\n    risk_map = {'Very High': 4, 'High': 3, 'Medium': 2, 'Low': 1}\n    risk_scores = [risk_map[r['risk_level']] for r in regulations.values()]\n    complexity = [r['compliance_complexity'] for r in regulations.values()]\n    # Risk levels\n    axes[0, 0].barh(industries, risk_scores, color='#e74c3c', alpha=0.8)\n    axes[0, 0].set_title('Risk Level by Industry', fontsize=12, fontweight='bold')\n    axes[0, 0].set_xlabel('Risk Level (1=Low, 4=Very High)')\n    axes[0, 0].grid(axis='x', alpha=0.3)\n    axes[0, 0].set_xlim([0, 5])\n    # Compliance complexity\n    axes[0, 1].bar(industries, complexity, color='#3498db', alpha=0.8)\n    axes[0, 1].set_title('Compliance Complexity (1-10)', fontsize=12, fontweight='bold')\n    axes[0, 1].set_ylabel('Complexity Score')\n    axes[0, 1].tick_params(axis='x', rotation=15)\n    axes[0, 1].grid(axis='y', alpha=0.3)\n    axes[0, 1].set_ylim([0, 11])\n    # Number of requirements\n    num_requirements = [len(r['key_requirements']) for r in regulations.values()]\n    axes[1, 0].bar(industries, num_requirements, color='#2ecc71', alpha=0.8)\n    axes[1, 0].set_title('Number of Key Requirements', fontsize=12, fontweight='bold')\n    axes[1, 0].set_ylabel('Number of Requirements')\n    axes[1, 0].tick_params(axis='x', rotation=15)\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    # Risk vs Complexity\n    scatter = axes[1, 1].scatter(risk_scores, complexity, s=300, alpha=0.7,\n                               c=complexity, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n    for i, industry in enumerate(industries):\n        axes[1, 1].annotate(industry, (risk_scores[i], complexity[i]),\n                           xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n    axes[1, 1].set_xlabel('Risk Level', fontsize=11, fontweight='bold')\n    axes[1, 1].set_ylabel('Compliance Complexity', fontsize=11, fontweight='bold')\n    axes[1, 1].set_title('Risk vs Compliance Complexity', fontsize=12, fontweight='bold')\n    axes[1, 1].grid(alpha=0.3)\n    plt.colorbar(scatter, ax=axes[1, 1], label='Complexity')\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: industry_regulations.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 2: Industry-Specific AI Regulations\")\n    print(\"=\"*80)\n    regulations = industry_regulations()\n    for industry, info in regulations.items():\n        print(f\"\\n{industry} AI Regulations:\")\n        print(f\"  Regulatory Bodies: {', '.join(info['regulatory_bodies'])}\")\n        print(f\"  Risk Level: {info['risk_level']}\")\n        print(f\"  Compliance Complexity: {info['compliance_complexity']}\")\n        print(f\"  Key Requirements:\")\n        for req in info['key_requirements']:\n            print(f\"    - {req}\")\n        print(f\"  Examples: {', '.join(info['examples'])}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_industry_regulations(regulations)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Different industries have specific regulatory requirements\")\n    print(\"2. Healthcare and autonomous vehicles have highest risk levels\")\n    print(\"3. Finance requires strong explainability and fairness\")\n    print(\"4. Compliance complexity varies by industry\")\n    print(\"5. Industry-specific regulations complement general AI regulations\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 117\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 2: Industry-Specific AI Regulations\nThis example demonstrates industry-specific AI regulations:\n- Healthcare AI regulations\n- Finance AI regulations\n- Autonomous Vehicles regulations\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# INDUSTRY-SPECIFIC REGULATIONS\n# ============================================================================\ndef industry_regulations():\n    \"\"\"\n    Define industry-specific AI regulations\n    \"\"\"\n    regulations = {\n        'Healthcare': {\n            'regulatory_bodies': ['FDA (US)', 'EMA (EU)', 'Health Canada'],\n            'key_requirements': [\n                'Clinical validation',\n                'Safety and efficacy proof',\n                'Transparency in decision-making',\n                'Human oversight',\n                'Data privacy (HIPAA compliance)'\n            ],\n            'risk_level': 'Very High',\n            'compliance_complexity': 9,\n            'examples': ['Medical diagnosis AI', 'Drug discovery', 'Treatment recommendations']\n        },\n        'Finance': {\n            'regulatory_bodies': ['SEC (US)', 'FCA (UK)', 'ESMA (EU)'],\n            'key_requirements': [\n                'Fair lending practices',\n                'Anti-discrimination compliance',\n                'Explainability for credit decisions',\n                'Risk management',\n                'Audit trails'\n            ],\n            'risk_level': 'High',\n            'compliance_complexity': 8,\n            'examples': ['Credit scoring', 'Fraud detection', 'Algorithmic trading']\n        },\n        'Autonomous Vehicles': {\n            'regulatory_bodies': ['NHTSA (US)', 'ECE (EU)', 'Transport Canada'],\n            'key_requirements': [\n                'Safety standards',\n                'Testing and validation',\n                'Liability frameworks',\n                'Data recording',\n                'Cybersecurity'\n            ],\n            'risk_level': 'Very High',\n            'compliance_complexity': 9,\n            'examples': ['Self-driving cars', 'Autonomous trucks', 'Delivery robots']\n        }\n    }\n    return regulations\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_industry_regulations(regulations):\n    \"\"\"\n    Plot industry-specific regulations comparison\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    industries = list(regulations.keys())\n    risk_map = {'Very High': 4, 'High': 3, 'Medium': 2, 'Low': 1}\n    risk_scores = [risk_map[r['risk_level']] for r in regulations.values()]\n    complexity = [r['compliance_complexity'] for r in regulations.values()]\n    # Risk levels\n    axes[0, 0].barh(industries, risk_scores, color='#e74c3c', alpha=0.8)\n    axes[0, 0].set_title('Risk Level by Industry', fontsize=12, fontweight='bold')\n    axes[0, 0].set_xlabel('Risk Level (1=Low, 4=Very High)')\n    axes[0, 0].grid(axis='x', alpha=0.3)\n    axes[0, 0].set_xlim([0, 5])\n    # Compliance complexity\n    axes[0, 1].bar(industries, complexity, color='#3498db', alpha=0.8)\n    axes[0, 1].set_title('Compliance Complexity (1-10)', fontsize=12, fontweight='bold')\n    axes[0, 1].set_ylabel('Complexity Score')\n    axes[0, 1].tick_params(axis='x', rotation=15)\n    axes[0, 1].grid(axis='y', alpha=0.3)\n    axes[0, 1].set_ylim([0, 11])\n    # Number of requirements\n    num_requirements = [len(r['key_requirements']) for r in regulations.values()]\n    axes[1, 0].bar(industries, num_requirements, color='#2ecc71', alpha=0.8)\n    axes[1, 0].set_title('Number of Key Requirements', fontsize=12, fontweight='bold')\n    axes[1, 0].set_ylabel('Number of Requirements')\n    axes[1, 0].tick_params(axis='x', rotation=15)\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    # Risk vs Complexity\n    scatter = axes[1, 1].scatter(risk_scores, complexity, s=300, alpha=0.7,\n                               c=complexity, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n    for i, industry in enumerate(industries):\n        axes[1, 1].annotate(industry, (risk_scores[i], complexity[i]),\n                           xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n    axes[1, 1].set_xlabel('Risk Level', fontsize=11, fontweight='bold')\n    axes[1, 1].set_ylabel('Compliance Complexity', fontsize=11, fontweight='bold')\n    axes[1, 1].set_title('Risk vs Compliance Complexity', fontsize=12, fontweight='bold')\n    axes[1, 1].grid(alpha=0.3)\n    plt.colorbar(scatter, ax=axes[1, 1], label='Complexity')\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: industry_regulations.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 2: Industry-Specific AI Regulations\")\n    print(\"=\"*80)\n    regulations = industry_regulations()\n    for industry, info in regulations.items():\n        print(f\"\\n{industry} AI Regulations:\")\n        print(f\"  Regulatory Bodies: {', '.join(info['regulatory_bodies'])}\")\n        print(f\"  Risk Level: {info['risk_level']}\")\n        print(f\"  Compliance Complexity: {info['compliance_complexity']}\")\n        print(f\"  Key Requirements:\")\n        for req in info['key_requirements']:\n            print(f\"    - {req}\")\n        print(f\"  Examples: {', '.join(info['examples'])}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_industry_regulations(regulations)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Different industries have specific regulatory requirements\")\n    print(\"2. Healthcare and autonomous vehicles have highest risk levels\")\n    print(\"3. Finance requires strong explainability and fairness\")\n    print(\"4. Compliance complexity varies by industry\")\n    print(\"5. Industry-specific regulations complement general AI regulations\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 117\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/03_governance_frameworks.ipynb",
      "status": "failed",
      "execution_time": 0.7388801574707031,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 3: AI Governance Frameworks\nThis example demonstrates AI governance frameworks:\n- Governance models\n- Key components\n- Implementation strategies\n- Future trends\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# GOVERNANCE FRAMEWORKS\n# ============================================================================\ndef governance_frameworks():\n    \"\"\"\n    Define different AI governance frameworks\n    \"\"\"\n    frameworks = {\n        'Ethics Board': {\n            'type': 'Organizational', 'scope': 'Internal',\n            'components': [\n                'Ethics review committee',\n                'AI ethics guidelines',\n                'Case review process',\n                'Stakeholder representation'\n            ],\n            'effectiveness': 7,\n            'implementation_cost': 5\n        },\n        'Regulatory Compliance': {\n            'type': 'Legal',\n            'scope': 'External',\n            'components': [\n                'Legal compliance team',\n                'Regulatory monitoring',\n                'Audit processes',\n                'Documentation requirements'\n            ],\n            'effectiveness': 8,\n            'implementation_cost': 7\n        },\n        'Technical Governance': {\n            'type': 'Technical',\n            'scope': 'Internal',\n            'components': [\n                'Model monitoring',\n                'Bias detection systems',\n                'Explainability tools',\n                'Performance tracking'\n            ],\n            'effectiveness': 9,\n            'implementation_cost': 8\n        },\n        'Multi-Stakeholder': {\n            'type': 'Collaborative',\n            'scope': 'Mixed',\n            'components': [\n                'Industry partnerships',\n                'Academic collaboration',\n                'Civil society engagement',\n                'Government coordination'\n            ],\n            'effectiveness': 8,\n            'implementation_cost': 6\n        }\n    }\n    return frameworks\n# ============================================================================\n# GOVERNANCE COMPONENTS\n# ============================================================================\ndef governance_components():\n    \"\"\"\n    Define key components of AI governance\n    \"\"\"\n    components = {\n        'Policy Development': {\n            'importance': 10,\n            'complexity': 7,\n            'stakeholders': ['Legal', 'Ethics', 'Management']\n        },\n        'Risk Assessment': {\n            'importance': 9,\n            'complexity': 8,\n            'stakeholders': ['Technical', 'Legal', 'Business']\n        },\n        'Monitoring and Auditing': {\n            'importance': 9,\n            'complexity': 7,\n            'stakeholders': ['Technical', 'Compliance', 'Quality']\n        },\n        'Training and Awareness': {\n            'importance': 8,\n            'complexity': 5,\n            'stakeholders': ['HR', 'Training', 'All Employees']\n        },\n        'Incident Response': {\n            'importance': 9,\n            'complexity': 6,\n            'stakeholders': ['Security', 'Legal', 'Management']\n        }\n    }\n    return components\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_governance_frameworks(frameworks):\n    \"\"\"\n    Plot governance frameworks comparison\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    framework_names = list(frameworks.keys())\n    effectiveness = [f['effectiveness'] for f in frameworks.values()]\n    cost = [f['implementation_cost'] for f in frameworks.values()]\n    # Effectiveness vs Cost\n    scatter = axes[0].scatter(cost, effectiveness, s=300, alpha=0.7,\n                             c=effectiveness, cmap='RdYlGn', edgecolors='black', linewidth=2)\n    for i, name in enumerate(framework_names):\n        axes[0].annotate(name, (cost[i], effectiveness[i]),\n                        xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n    axes[0].set_xlabel('Implementation Cost (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_ylabel('Effectiveness (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_title('Governance Framework: Effectiveness vs Cost', fontsize=12, fontweight='bold')\n    axes[0].grid(alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    axes[0].set_ylim([0, 11])\n    plt.colorbar(scatter, ax=axes[0], label='Effectiveness')\n    # Number of components\n    num_components = [len(f['components']) for f in frameworks.values()]\n    axes[1].bar(framework_names, num_components, color='#3498db', alpha=0.8)\n    axes[1].set_title('Number of Framework Components', fontsize=12, fontweight='bold')\n    axes[1].set_ylabel('Number of Components')\n    axes[1].tick_params(axis='x', rotation=15)\n    axes[1].grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: governance_frameworks.png\")\n    plt.close()\ndef plot_governance_components(components):\n    \"\"\"\n    Plot governance components analysis\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    component_names = list(components.keys())\n    importance = [c['importance'] for c in components.values()]\n    complexity = [c['complexity'] for c in components.values()]\n    # Importance\n    axes[0].barh(component_names, importance, color='#2ecc71', alpha=0.8)\n    axes[0].set_title('Component Importance (1-10)', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Importance Score')\n    axes[0].grid(axis='x', alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    # Complexity\n    axes[1].barh(component_names, complexity, color='#f39c12', alpha=0.8)\n    axes[1].set_title('Implementation Complexity (1-10)', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Complexity Score')\n    axes[1].grid(axis='x', alpha=0.3)\n    axes[1].set_xlim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: governance_components.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 3: AI Governance Frameworks\")\n    print(\"=\"*80)\n    # Governance frameworks\n    frameworks = governance_frameworks()\n    print(\"\\nAI Governance Frameworks:\")\n    for framework, info in frameworks.items():\n        print(f\"\\n{framework} ({info['type']}):\")\n        print(f\"  Scope: {info['scope']}\")\n        print(f\"  Effectiveness: {info['effectiveness']}\")\n        print(f\"  Implementation Cost: {info['implementation_cost']}\")\n        print(f\"  Components:\")\n        for component in info['components']:\n            print(f\"    - {component}\")\n    # Governance components\n    print(\"\\n\" + \"=\"*80)\n    print(\"Key Governance Components:\")\n    print(\"=\"*80)\n    components = governance_components()\n    for component, info in components.items():\n        print(f\"\\n{component}:\")\n        print(f\"  Importance: {info['importance']}\")\n        print(f\"  Complexity: {info['complexity']}\")\n        print(f\"  Key Stakeholders: {', '.join(info['stakeholders'])}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_governance_frameworks(frameworks)\n    plot_governance_components(components)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Multiple governance frameworks can be combined\")\n    print(\"2. Technical governance is highly effective but costly\")\n    print(\"3. Ethics boards provide internal oversight\")\n    print(\"4. Regulatory compliance ensures legal adherence\")\n    print(\"5. Effective governance requires multiple components working together\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 173\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 3: AI Governance Frameworks\nThis example demonstrates AI governance frameworks:\n- Governance models\n- Key components\n- Implementation strategies\n- Future trends\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\n# ============================================================================\n# GOVERNANCE FRAMEWORKS\n# ============================================================================\ndef governance_frameworks():\n    \"\"\"\n    Define different AI governance frameworks\n    \"\"\"\n    frameworks = {\n        'Ethics Board': {\n            'type': 'Organizational', 'scope': 'Internal',\n            'components': [\n                'Ethics review committee',\n                'AI ethics guidelines',\n                'Case review process',\n                'Stakeholder representation'\n            ],\n            'effectiveness': 7,\n            'implementation_cost': 5\n        },\n        'Regulatory Compliance': {\n            'type': 'Legal',\n            'scope': 'External',\n            'components': [\n                'Legal compliance team',\n                'Regulatory monitoring',\n                'Audit processes',\n                'Documentation requirements'\n            ],\n            'effectiveness': 8,\n            'implementation_cost': 7\n        },\n        'Technical Governance': {\n            'type': 'Technical',\n            'scope': 'Internal',\n            'components': [\n                'Model monitoring',\n                'Bias detection systems',\n                'Explainability tools',\n                'Performance tracking'\n            ],\n            'effectiveness': 9,\n            'implementation_cost': 8\n        },\n        'Multi-Stakeholder': {\n            'type': 'Collaborative',\n            'scope': 'Mixed',\n            'components': [\n                'Industry partnerships',\n                'Academic collaboration',\n                'Civil society engagement',\n                'Government coordination'\n            ],\n            'effectiveness': 8,\n            'implementation_cost': 6\n        }\n    }\n    return frameworks\n# ============================================================================\n# GOVERNANCE COMPONENTS\n# ============================================================================\ndef governance_components():\n    \"\"\"\n    Define key components of AI governance\n    \"\"\"\n    components = {\n        'Policy Development': {\n            'importance': 10,\n            'complexity': 7,\n            'stakeholders': ['Legal', 'Ethics', 'Management']\n        },\n        'Risk Assessment': {\n            'importance': 9,\n            'complexity': 8,\n            'stakeholders': ['Technical', 'Legal', 'Business']\n        },\n        'Monitoring and Auditing': {\n            'importance': 9,\n            'complexity': 7,\n            'stakeholders': ['Technical', 'Compliance', 'Quality']\n        },\n        'Training and Awareness': {\n            'importance': 8,\n            'complexity': 5,\n            'stakeholders': ['HR', 'Training', 'All Employees']\n        },\n        'Incident Response': {\n            'importance': 9,\n            'complexity': 6,\n            'stakeholders': ['Security', 'Legal', 'Management']\n        }\n    }\n    return components\n# ============================================================================\n# VISUALIZATIONS\n# ============================================================================\ndef plot_governance_frameworks(frameworks):\n    \"\"\"\n    Plot governance frameworks comparison\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    framework_names = list(frameworks.keys())\n    effectiveness = [f['effectiveness'] for f in frameworks.values()]\n    cost = [f['implementation_cost'] for f in frameworks.values()]\n    # Effectiveness vs Cost\n    scatter = axes[0].scatter(cost, effectiveness, s=300, alpha=0.7,\n                             c=effectiveness, cmap='RdYlGn', edgecolors='black', linewidth=2)\n    for i, name in enumerate(framework_names):\n        axes[0].annotate(name, (cost[i], effectiveness[i]),\n                        xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n    axes[0].set_xlabel('Implementation Cost (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_ylabel('Effectiveness (1-10)', fontsize=11, fontweight='bold')\n    axes[0].set_title('Governance Framework: Effectiveness vs Cost', fontsize=12, fontweight='bold')\n    axes[0].grid(alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    axes[0].set_ylim([0, 11])\n    plt.colorbar(scatter, ax=axes[0], label='Effectiveness')\n    # Number of components\n    num_components = [len(f['components']) for f in frameworks.values()]\n    axes[1].bar(framework_names, num_components, color='#3498db', alpha=0.8)\n    axes[1].set_title('Number of Framework Components', fontsize=12, fontweight='bold')\n    axes[1].set_ylabel('Number of Components')\n    axes[1].tick_params(axis='x', rotation=15)\n    axes[1].grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: governance_frameworks.png\")\n    plt.close()\ndef plot_governance_components(components):\n    \"\"\"\n    Plot governance components analysis\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    component_names = list(components.keys())\n    importance = [c['importance'] for c in components.values()]\n    complexity = [c['complexity'] for c in components.values()]\n    # Importance\n    axes[0].barh(component_names, importance, color='#2ecc71', alpha=0.8)\n    axes[0].set_title('Component Importance (1-10)', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Importance Score')\n    axes[0].grid(axis='x', alpha=0.3)\n    axes[0].set_xlim([0, 11])\n    # Complexity\n    axes[1].barh(component_names, complexity, color='#f39c12', alpha=0.8)\n    axes[1].set_title('Implementation Complexity (1-10)', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Complexity Score')\n    axes[1].grid(axis='x', alpha=0.3)\n    axes[1].set_xlim([0, 11])\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\u2705 Saved: governance_components.png\")\n    plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 3: AI Governance Frameworks\")\n    print(\"=\"*80)\n    # Governance frameworks\n    frameworks = governance_frameworks()\n    print(\"\\nAI Governance Frameworks:\")\n    for framework, info in frameworks.items():\n        print(f\"\\n{framework} ({info['type']}):\")\n        print(f\"  Scope: {info['scope']}\")\n        print(f\"  Effectiveness: {info['effectiveness']}\")\n        print(f\"  Implementation Cost: {info['implementation_cost']}\")\n        print(f\"  Components:\")\n        for component in info['components']:\n            print(f\"    - {component}\")\n    # Governance components\n    print(\"\\n\" + \"=\"*80)\n    print(\"Key Governance Components:\")\n    print(\"=\"*80)\n    components = governance_components()\n    for component, info in components.items():\n        print(f\"\\n{component}:\")\n        print(f\"  Importance: {info['importance']}\")\n        print(f\"  Complexity: {info['complexity']}\")\n        print(f\"  Key Stakeholders: {', '.join(info['stakeholders'])}\")\n    # Create visualizations\n    print(\"\\n\" + \"=\"*80)\n    print(\"Creating Visualizations...\")\n    print(\"=\"*80)\n    plot_governance_frameworks(frameworks)\n    plot_governance_components(components)\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY\")\n    print(\"=\"*80)\n    print(\"\\nKey Takeaways:\")\n    print(\"1. Multiple governance frameworks can be combined\")\n    print(\"2. Technical governance is highly effective but costly\")\n    print(\"3. Ethics boards provide internal oversight\")\n    print(\"4. Regulatory compliance ensures legal adherence\")\n    print(\"5. Effective governance requires multiple components working together\")\n    print(\"=\"*80 + \"\\n\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 173\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/04_legal_challenges.ipynb",
      "status": "failed",
      "execution_time": 0.587590217590332,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 4: Legal Challenges in AI Governance\nThis example demonstrates legal challenges in AI governance:\n- AI and Legal Liability\n- Ethical AI vs. Business Profits\n- Regulatory Approaches by Region\n- Global vs. Local AI Laws\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\ndef legal_challenges():\n    challenges = {\n        'Liability Attribution': {'complexity': 9, 'urgency': 8, 'stakeholders': ['Legal', 'Business', 'Insurance']},\n        'Ethical vs. Profit': {'complexity': 8, 'urgency': 9, 'stakeholders': ['Business', 'Ethics', 'Compliance']},\n        'Regulatory Conflicts': {'complexity': 7, 'urgency': 7, 'stakeholders': ['Legal', 'Compliance', 'International']},\n        'Data Ownership': {'complexity': 8, 'urgency': 8, 'stakeholders': ['Legal', 'Data', 'Privacy']},\n        'Cross-Border Issues': {'complexity': 9, 'urgency': 7, 'stakeholders': ['Legal', 'International', 'Compliance']}\n    }\n    return challenges\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 4: Legal Challenges in AI Governance\")\n    print(\"=\"*80)\n    challenges = legal_challenges()\n    for challenge, info in challenges.items():\n        print(f\"\\n{challenge}:\")\n        print(f\"  Complexity: {info['complexity']}\")\n        print(f\"  Urgency: {info['urgency']}\")\n        print(f\"  Stakeholders: {', '.join(info['stakeholders'])}\")\n    # Visualization\n    fig, ax = plt.subplots(figsize=(12, 6))\n    challenge_names = list(challenges.keys())\n    complexity = [c['complexity'] for c in challenges.values()]\n    urgency = [c['urgency'] for c in challenges.values()]\n    x = np.arange(len(challenge_names))\n    width = 0.35\n    ax.bar(x - width/2, complexity, width, label='Complexity', alpha=0.8, color='#e74c3c')\n    ax.bar(x + width/2, urgency, width, label='Urgency', alpha=0.8, color='#3498db')\n    ax.set_xlabel('Legal Challenge', fontweight='bold')\n    ax.set_ylabel('Score (1-10)', fontweight='bold')\n    ax.set_title('Legal Challenges: Complexity vs Urgency', fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(challenge_names, rotation=15)\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: legal_challenges.png\")\n    plt.close()\n    print(\"\\n\u2705 Example completed!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExample 4: Legal Challenges in AI Governance\nThis example demonstrates legal challenges in AI governance:\n- AI and Legal Liability\n- Ethical AI vs. Business Profits\n- Regulatory Approaches by Region\n- Global vs. Local AI Laws\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (14, 8)\nsns.set_style(\"whitegrid\")\ndef legal_challenges():\n    challenges = {\n        'Liability Attribution': {'complexity': 9, 'urgency': 8, 'stakeholders': ['Legal', 'Business', 'Insurance']},\n        'Ethical vs. Profit': {'complexity': 8, 'urgency': 9, 'stakeholders': ['Business', 'Ethics', 'Compliance']},\n        'Regulatory Conflicts': {'complexity': 7, 'urgency': 7, 'stakeholders': ['Legal', 'Compliance', 'International']},\n        'Data Ownership': {'complexity': 8, 'urgency': 8, 'stakeholders': ['Legal', 'Data', 'Privacy']},\n        'Cross-Border Issues': {'complexity': 9, 'urgency': 7, 'stakeholders': ['Legal', 'International', 'Compliance']}\n    }\n    return challenges\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Example 4: Legal Challenges in AI Governance\")\n    print(\"=\"*80)\n    challenges = legal_challenges()\n    for challenge, info in challenges.items():\n        print(f\"\\n{challenge}:\")\n        print(f\"  Complexity: {info['complexity']}\")\n        print(f\"  Urgency: {info['urgency']}\")\n        print(f\"  Stakeholders: {', '.join(info['stakeholders'])}\")\n    # Visualization\n    fig, ax = plt.subplots(figsize=(12, 6))\n    challenge_names = list(challenges.keys())\n    complexity = [c['complexity'] for c in challenges.values()]\n    urgency = [c['urgency'] for c in challenges.values()]\n    x = np.arange(len(challenge_names))\n    width = 0.35\n    ax.bar(x - width/2, complexity, width, label='Complexity', alpha=0.8, color='#e74c3c')\n    ax.bar(x + width/2, urgency, width, label='Urgency', alpha=0.8, color='#3498db')\n    ax.set_xlabel('Legal Challenge', fontweight='bold')\n    ax.set_ylabel('Score (1-10)', fontweight='bold')\n    ax.set_title('Legal Challenges: Complexity vs Urgency', fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(challenge_names, rotation=15)\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('unit5-governance-regulations', dpi=300, bbox_inches='tight')\n    print(\"\\n\u2705 Saved: legal_challenges.png\")\n    plt.close()\n    print(\"\\n\u2705 Example completed!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/06_ai_governance_frameworks.ipynb",
      "status": "passed",
      "execution_time": 0.5360238552093506,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/accountability_practices_in_ai_developing_and_simulating_monitoring_systems_for_.ipynb",
      "status": "passed",
      "execution_time": 1.6314349174499512,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/case_studies_evaluation_evaluating_regulatory_challenges_and_ai_in_real_world.ipynb",
      "status": "passed",
      "execution_time": 1.5066289901733398,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/predictive_analysis_for_future_challenges_identifying_and_predicting_upcoming_ch.ipynb",
      "status": "passed",
      "execution_time": 1.7207820415496826,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/transparency_and_interpretability_tools_implementing_and_testing_interpretabilit.ipynb",
      "status": "passed",
      "execution_time": 1.5130019187927246,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6795179843902588,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExercise 1: Regulations\nThis exercise requires you to analyze AI regulations.\n\"\"\"\n# TODO: Complete the exercise\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Exercise 1: Regulations\")\n    print(\"=\"*80)\n    print(\"\\nComplete the TODO sections in this file.\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExercise 1: Regulations\nThis exercise requires you to analyze AI regulations.\n\"\"\"\n# TODO: Complete the exercise\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Exercise 1: Regulations\")\n    print(\"=\"*80)\n    print(\"\\nComplete the TODO sections in this file.\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit5-governance-regulations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.8138570785522461,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "other"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/01_text_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 1.0598747730255127,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/02_nltk_spacy_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.9120581150054932,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/03_real_world_nlp_applications.ipynb",
      "status": "passed",
      "execution_time": 0.6916790008544922,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/04_text_conversion_script.ipynb",
      "status": "passed",
      "execution_time": 0.733773946762085,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/05_exploring_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.5998289585113525,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/exercises/01_text_preprocessing_exercise.ipynb",
      "status": "failed",
      "execution_time": 0.8218817710876465,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\\n\n%pip install nltk pandas -q\\n\n\\ni\nmport nltk\\ni\nmport pandas as pd\\ni\nmport re\\nf\nrom nltk.corpus import stopwords\\nf\nrom nltk.tokenize import word_tokenize\\nf\nrom nltk.stem import PorterStemmer, WordNetLemmatizer\\n\n\\nn\nltk.download('punkt', quiet=True)\\nn\nltk.download('stopwords', quiet=True)\\nn\nltk.download('wordnet', quiet=True)\\np\nrint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\ni\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\\n\n%pip install nltk pandas -q\\n\n\\ni\nmport nltk\\ni\nmport pandas as pd\\ni\nmport re\\nf\nrom nltk.corpus import stopwords\\nf\nrom nltk.tokenize import word_tokenize\\nf\nrom nltk.stem import PorterStemmer, WordNetLemmatizer\\n\n\\nn\nltk.download('punkt', quiet=True)\\nn\nltk.download('stopwords', quiet=True)\\nn\nltk.download('wordnet', quiet=True)\\np\nrint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\ni\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n\n",
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/solutions/01_text_preprocessing_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6161751747131348,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install nltk pandas -q\nimport nltk\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom collections import Counter_nltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections import Counter_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install nltk pandas -q\nimport nltk\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom collections import Counter_nltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections import Counter_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/01_advanced_tokenization.ipynb",
      "status": "passed",
      "execution_time": 0.9697349071502686,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/02_text_vectorization_bow_tfidf.ipynb",
      "status": "passed",
      "execution_time": 1.001952886581421,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/03_word_embeddings_word2vec.ipynb",
      "status": "passed",
      "execution_time": 1.7665982246398926,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/04_word_embeddings_glove_fasttext.ipynb",
      "status": "failed",
      "execution_time": 0.6892402172088623,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom gensim.models \nimport KeyedVectors\nimport gensim.downloader as api\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained Word Embeddings: GloVe and FastText\")\nprint(\"=\" * 60)\n\nprint(\"\\nGloVe (Global Vectors):\")\nprint(\" - Global co-occurrence statistics\")\nprint(\" - Pre-trained on large corpora\")\nprint(\" - Available in multiple dimensions\")\n\nprint(\"\\nFastText:\")\nprint(\" - Subword information\")\nprint(\" - Handles out-of-vocabulary words\")\nprint(\" - Character n-grams\")\n\nprint(\"\\nApplications:\")\nprint(\" - Word similarity\")\nprint(\" - Text classification\")\nprint(\" - Semantic analysis\")\nprint(\" - Transfer learning\")\n\nprint(\"\\n\u2705 Pre-trained embeddings concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gensim.models\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom gensim.models \nimport KeyedVectors\nimport gensim.downloader as api\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained Word Embeddings: GloVe and FastText\")\nprint(\"=\" * 60)\n\nprint(\"\\nGloVe (Global Vectors):\")\nprint(\" - Global co-occurrence statistics\")\nprint(\" - Pre-trained on large corpora\")\nprint(\" - Available in multiple dimensions\")\n\nprint(\"\\nFastText:\")\nprint(\" - Subword information\")\nprint(\" - Handles out-of-vocabulary words\")\nprint(\" - Character n-grams\")\n\nprint(\"\\nApplications:\")\nprint(\" - Word similarity\")\nprint(\" - Text classification\")\nprint(\" - Semantic analysis\")\nprint(\" - Transfer learning\")\n\nprint(\"\\n\u2705 Pre-trained embeddings concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gensim.models\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/applying_dimensionality_reduction_on_high_dimensional_vectors_and_visualizing_re.ipynb",
      "status": "passed",
      "execution_time": 1.8559601306915283,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/implementing_basic_text_processing_techniques_using_nltk_and_spacy.ipynb",
      "status": "passed",
      "execution_time": 1.5380899906158447,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/implementing_bert_embeddings_using_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.646070957183838,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/performing_tokenization_stemming_and_lemmatization_on_sample_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.654834270477295,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/writing_a_simple_text_conversion_script_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.5262670516967773,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/exercises/01_tokenization_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.8574419021606445,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/solutions/01_tokenization_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6216089725494385,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install nltk -q\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re_nltk.download('punkt', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    import re_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install nltk -q\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re_nltk.download('punkt', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    import re_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "other"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/01_text_classification.ipynb",
      "status": "passed",
      "execution_time": 1.383735179901123,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/02_named_entity_recognition.ipynb",
      "status": "passed",
      "execution_time": 2.287040948867798,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/03_topic_modeling_lda_nmf.ipynb",
      "status": "passed",
      "execution_time": 0.6987383365631104,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/04_model_evaluation_metrics_nlp.ipynb",
      "status": "failed",
      "execution_time": 0.6484549045562744,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nNLP Model Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nPrecision:\")\nprint(\"  - TP\n(TP + FP)\")\nprint(\"  - Accuracy of positive predictions\")\nprint(\"  - Important when false positives costly\")\n\nprint(\"\\nRecall:\")\nprint(\"  - TP\n(TP + FN)\")\nprint(\"  - Ability to find all positives\")\nprint(\"  - Important when false negatives costly\")\n\nprint(\"\\nF1-Score:\")\nprint(\"  - Harmonic mean of precision and recall\")\nprint(\"  - Balanced metric\")\nprint(\"  - Range: 0 to 1\")\n\nprint(\"\\n\u2705 NLP evaluation metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  - TP\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 10)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nNLP Model Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nPrecision:\")\nprint(\"  - TP\n(TP + FP)\")\nprint(\"  - Accuracy of positive predictions\")\nprint(\"  - Important when false positives costly\")\n\nprint(\"\\nRecall:\")\nprint(\"  - TP\n(TP + FN)\")\nprint(\"  - Ability to find all positives\")\nprint(\"  - Important when false negatives costly\")\n\nprint(\"\\nF1-Score:\")\nprint(\"  - Harmonic mean of precision and recall\")\nprint(\"  - Balanced metric\")\nprint(\"  - Range: 0 to 1\")\n\nprint(\"\\n\u2705 NLP evaluation metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"  - TP\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 10)\n\n\n",
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/exercises/01_sentiment_classification_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.0105509757995605,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/solutions/01_sentiment_classification_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6199817657470703,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pandas scikit-learn nltk -q\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk_nltk.download('stopwords', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nltk_nltk.download('stopwords', quiet=True)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pandas scikit-learn nltk -q\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk_nltk.download('stopwords', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nltk_nltk.download('stopwords', quiet=True)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "other"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/01_rnn_lstm_nlp.ipynb",
      "status": "passed",
      "execution_time": 0.8358421325683594,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/02_lstm_text_generation.ipynb",
      "status": "passed",
      "execution_time": 0.893740177154541,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/03_bert_advanced_usage.ipynb",
      "status": "passed",
      "execution_time": 5.102966070175171,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/04_seq2seq_attention_translation.ipynb",
      "status": "passed",
      "execution_time": 1.349910020828247,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/05_gpt_openai_text_generation.ipynb",
      "status": "passed",
      "execution_time": 0.6242120265960693,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/06_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 0.6779308319091797,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/07_building_simple_chatbot.ipynb",
      "status": "passed",
      "execution_time": 0.7443830966949463,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/building_a_simple_chatbot.ipynb",
      "status": "passed",
      "execution_time": 1.5103719234466553,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/building_an_lstm_based_text_classifier_using_tensorflowkeras.ipynb",
      "status": "passed",
      "execution_time": 1.6671900749206543,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/fine_tuning_bert_model_for_text_classification_using_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.5758652687072754,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/implementing_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 1.5575499534606934,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/exercises/01_ner_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.077517032623291,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/solutions/01_ner_solution.ipynb",
      "status": "failed",
      "execution_time": 1.3637382984161377,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install spacy -q\n# Note: Requires: python -m spacy download en_core_web_sm\nimport spacy_\nprint('\ud83d\udcdd NER Solution Concept:')\nprint('\\n1. Load spaCy model: nlp = spacy.load(\"en_core_web_sm\")')\nprint('2. Process text: doc = nlp(text)')\nprint('3. Extract entities: doc.ents')\nprint('4. Classify: entity.label_')\nprint('\\n\u2705 NER solution understood!')\nprint('\\nReal-world: Extract key information from news articles')\n------------------\n\n----- stdout -----\nNote: you may need to restart the kernel to use updated packages.\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall spacy -q\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: Requires: python -m spacy download en_core_web_sm\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy_\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\ud83d\udcdd NER Solution Concept:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. Load spaCy model: nlp = spacy.load(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy_'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install spacy -q\n# Note: Requires: python -m spacy download en_core_web_sm\nimport spacy_\nprint('\ud83d\udcdd NER Solution Concept:')\nprint('\\n1. Load spaCy model: nlp = spacy.load(\"en_core_web_sm\")')\nprint('2. Process text: doc = nlp(text)')\nprint('3. Extract entities: doc.ents')\nprint('4. Classify: entity.label_')\nprint('\\n\u2705 NER solution understood!')\nprint('\\nReal-world: Extract key information from news articles')\n------------------\n\n----- stdout -----\nNote: you may need to restart the kernel to use updated packages.\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall spacy -q\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: Requires: python -m spacy download en_core_web_sm\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy_\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\ud83d\udcdd NER Solution Concept:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. Load spaCy model: nlp = spacy.load(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy_'\n\n",
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "other"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/01_bias_detection.ipynb",
      "status": "passed",
      "execution_time": 0.6262860298156738,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/02_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 0.8953619003295898,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/03_chatbot_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.8008708953857422,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/exercises/01_nlp_applications_ethics_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.0632898807525635,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit5-applications-ethics/solutions/01_nlp_applications_ethics_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5327968597412109,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\n%pip install nltk transformers torch pandas numpy matplotlib seaborn -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections \nimport Counter_\nprint('\u2705 Setup complete!')\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\n%pip install nltk transformers torch pandas numpy matplotlib seaborn -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections \nimport Counter_\nprint('\u2705 Setup complete!')\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "other"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/01_simple_neural_network.ipynb",
      "status": "failed",
      "execution_time": 0.821087121963501,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 1 - Example 1: Simple Neural Network with Keras\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\n\nThis example demonstrates:\n1. Building a simple neural network2. Training on a dataset3. Making predictions4. Evaluating the model\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Simple Neural Network with Keras\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\")\nprint(\"=\" * 60)\n\n# Note: This example shows the structure. Actual implementation requires TensorFlow.\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u0627\u0644\u0647\u064a\u0643\u0644. \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a \u064a\u062a\u0637\u0644\u0628 TensorFlow. print(\"\\nNeural Network Structure:\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629:\")\nprint(\"-\" * 60)\nnetwork_structure = \"\"\"\nModel: Sequential\n\u251c\u2500\u2500 Input Layer: 784 neurons (for 28\nx28 images)\n\u251c\u2500\u2500 Hidden Layer 1: 128 neurons, ReLU activation\n\u251c\u2500\u2500 Hidden Layer 2: 64 neurons, ReLU activation\n\u2514\u2500\u2500 Output Layer: 10 neurons, Softmax activation (for 10 classes)\n\"\"\"\n\nprint(network_structure)\nprint(\"\\nCode Structure (using Keras):\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0643\u0648\u062f (\u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras):\")\nprint(\"-\" * 60)\ncode_example = \"\"\"\nfrom tensorflow \nimport kerasf\nrom tensorflow.keras import layers\n\n# Create mode\nlm\nodel = keras.Sequential([\n layers.Dense(128, activation='relu', input_shape=(784,)),\n layers.Dense(64, activation='relu'),\n layers.Dense(10, activation='softmax')\n])\n\n# Compile mode\nlm\nodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n metrics=['accuracy']\n)\n\n# Train mode\nlm\nodel.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n# Evaluate\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test accuracy: {accuracy}')\n\"\"\"\n\nprint(code_example)\nprint(\"\\nKey Concepts:\")\nprint(\"\u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629:\")\nprint(\"-\" * 60)\nconcepts = {\n \"Dense Layer\": \"Fully connected layer where each neuron connects to all neurons in next layer\", \"ReLU\": \"Rectified Linear Unit - activation function that outputs max(0, x)\",\n \"Softmax\": \"Activation function for multi-class classification\",\n \"Adam Optimizer\": \"Adaptive learning rate optimization algorithm\",\n \"Epochs\": \"Number of times the model sees the entire training dataset\"\n}\n\nfor concept, explanation in concepts.items():\n print(f\"\\n{concept}:\")\nprint(f\" {explanation}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: Install TensorFlow to run actual code:\")\nprint(\"pip install tensorflow\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 1 - Example 1: Simple Neural Network with Keras\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\n\nThis example demonstrates:\n1. Building a simple neural network2. Training on a dataset3. Making predictions4. Evaluating the model\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Simple Neural Network with Keras\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\")\nprint(\"=\" * 60)\n\n# Note: This example shows the structure. Actual implementation requires TensorFlow.\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u0627\u0644\u0647\u064a\u0643\u0644. \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a \u064a\u062a\u0637\u0644\u0628 TensorFlow. print(\"\\nNeural Network Structure:\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629:\")\nprint(\"-\" * 60)\nnetwork_structure = \"\"\"\nModel: Sequential\n\u251c\u2500\u2500 Input Layer: 784 neurons (for 28\nx28 images)\n\u251c\u2500\u2500 Hidden Layer 1: 128 neurons, ReLU activation\n\u251c\u2500\u2500 Hidden Layer 2: 64 neurons, ReLU activation\n\u2514\u2500\u2500 Output Layer: 10 neurons, Softmax activation (for 10 classes)\n\"\"\"\n\nprint(network_structure)\nprint(\"\\nCode Structure (using Keras):\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0643\u0648\u062f (\u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras):\")\nprint(\"-\" * 60)\ncode_example = \"\"\"\nfrom tensorflow \nimport kerasf\nrom tensorflow.keras import layers\n\n# Create mode\nlm\nodel = keras.Sequential([\n layers.Dense(128, activation='relu', input_shape=(784,)),\n layers.Dense(64, activation='relu'),\n layers.Dense(10, activation='softmax')\n])\n\n# Compile mode\nlm\nodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n metrics=['accuracy']\n)\n\n# Train mode\nlm\nodel.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n# Evaluate\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test accuracy: {accuracy}')\n\"\"\"\n\nprint(code_example)\nprint(\"\\nKey Concepts:\")\nprint(\"\u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629:\")\nprint(\"-\" * 60)\nconcepts = {\n \"Dense Layer\": \"Fully connected layer where each neuron connects to all neurons in next layer\", \"ReLU\": \"Rectified Linear Unit - activation function that outputs max(0, x)\",\n \"Softmax\": \"Activation function for multi-class classification\",\n \"Adam Optimizer\": \"Adaptive learning rate optimization algorithm\",\n \"Epochs\": \"Number of times the model sees the entire training dataset\"\n}\n\nfor concept, explanation in concepts.items():\n print(f\"\\n{concept}:\")\nprint(f\" {explanation}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: Install TensorFlow to run actual code:\")\nprint(\"pip install tensorflow\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n\n",
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/02_backpropagation_detailed.ipynb",
      "status": "passed",
      "execution_time": 0.8985660076141357,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/03_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.960378885269165,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/04_perceptron_mlp_tensorflow_pytorch_setup.ipynb",
      "status": "failed",
      "execution_time": 2.016901969909668,
      "error": "An error occurred while executing the following cell:\n------------------\nclass Perceptron:\n    \"\"\"Simple Perceptron implementation from scratch\"\"\"\n    \n    def__init__(self, learning_rate=0.1, n_iterations=100):\n        self.learning_rate = learning_rate\n        self.n_iterations = n_iterations\n        self.weights = None\n        self.bias = None\n    \n    def fit(self, X, y):\n        \"\"\"Train the perceptron\"\"\"\n        n_samples, n_features = X.shape\n        \n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        \n        # Training loop\n        for _ in range(self.n_iterations):\n            for idx, x_i in enumerate(X):\n                # Forward pass\n                linear_output = np.dot(x_i, self.weights) + self.bias\n                y_predicted = self.activate(linear_output)\n                \n                # Update weights and bias\n                update = self.learning_rate * (y[idx] - y_predicted)\n                self.weights += update * x_i\n                self.bias += update\n    \n    def activate(self, x):\n        \"\"\"Step activation function\"\"\"\n        return np.where(x >= 0, 1, 0)\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        linear_output = np.dot(X, self.weights) + self.bias\n        return self.activate(linear_output)\n\n# Example: Simple AND gate\nprint(\"=\" * 60)\nprint(\"Perceptron: Learning AND Gate\")\nprint(\"=\" * 60)\n\n# AND gate truth table\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([0, 0, 0, 1])\n\n# Train perceptron\nperceptron = Perceptron(learning_rate=0.1, n_iterations=100)\nperceptron.fit(X, y)\n\n# Test\npredictions = perceptron.predict(X)\nprint(\"\\nPredictions:\")\nprint(f\"Input [0,0]: {predictions[0]} (expected 0)\")\nprint(f\"Input [0,1]: {predictions[1]} (expected 0)\")\nprint(f\"Input [1,0]: {predictions[2]} (expected 0)\")\nprint(f\"Input [1,1]: {predictions[3]} (expected 1)\")\nprint(f\"\\nAccuracy: {np.mean(predictions == y) * 100:.0f}%\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.1, n_iterations=100):\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass Perceptron:\n    \"\"\"Simple Perceptron implementation from scratch\"\"\"\n    \n    def__init__(self, learning_rate=0.1, n_iterations=100):\n        self.learning_rate = learning_rate\n        self.n_iterations = n_iterations\n        self.weights = None\n        self.bias = None\n    \n    def fit(self, X, y):\n        \"\"\"Train the perceptron\"\"\"\n        n_samples, n_features = X.shape\n        \n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        \n        # Training loop\n        for _ in range(self.n_iterations):\n            for idx, x_i in enumerate(X):\n                # Forward pass\n                linear_output = np.dot(x_i, self.weights) + self.bias\n                y_predicted = self.activate(linear_output)\n                \n                # Update weights and bias\n                update = self.learning_rate * (y[idx] - y_predicted)\n                self.weights += update * x_i\n                self.bias += update\n    \n    def activate(self, x):\n        \"\"\"Step activation function\"\"\"\n        return np.where(x >= 0, 1, 0)\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        linear_output = np.dot(X, self.weights) + self.bias\n        return self.activate(linear_output)\n\n# Example: Simple AND gate\nprint(\"=\" * 60)\nprint(\"Perceptron: Learning AND Gate\")\nprint(\"=\" * 60)\n\n# AND gate truth table\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([0, 0, 0, 1])\n\n# Train perceptron\nperceptron = Perceptron(learning_rate=0.1, n_iterations=100)\nperceptron.fit(X, y)\n\n# Test\npredictions = perceptron.predict(X)\nprint(\"\\nPredictions:\")\nprint(f\"Input [0,0]: {predictions[0]} (expected 0)\")\nprint(f\"Input [0,1]: {predictions[1]} (expected 0)\")\nprint(f\"Input [1,0]: {predictions[2]} (expected 0)\")\nprint(f\"Input [1,1]: {predictions[3]} (expected 1)\")\nprint(f\"\\nAccuracy: {np.mean(predictions == y) * 100:.0f}%\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, learning_rate=0.1, n_iterations=100):\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/05_image_processing_feature_extraction.ipynb",
      "status": "passed",
      "execution_time": 0.8796930313110352,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/activation_functions_and_optimization_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.6276040077209473,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/deep_learning_fundamentals_compared_to_traditional_ml.ipynb",
      "status": "passed",
      "execution_time": 1.4479081630706787,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/ethical_concerns_in_ai_bias_fairness_interpretability.ipynb",
      "status": "passed",
      "execution_time": 1.5669279098510742,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/forward_and_backward_propagation.ipynb",
      "status": "passed",
      "execution_time": 1.4133291244506836,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/gans_and_autoencoders_vaes.ipynb",
      "status": "passed",
      "execution_time": 1.5541610717773438,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/implementing_a_vae_variational_autoencoder_for_anomaly_detection.ipynb",
      "status": "passed",
      "execution_time": 1.5185210704803467,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/reinforcement_learning_fundamentals_deep_q_networks_policy_gradients.ipynb",
      "status": "passed",
      "execution_time": 1.6571249961853027,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/exercises/01_neural_network_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.091796875,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/solutions/01_neural_network_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6861569881439209,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision -q\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass MedicalImageClassifier(nn.Module):\n    def__init__(self, num_classes=2):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(), nn.Linear(256 * 32 * 32, 512),\n            nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x_\nprint('\u2705 Model architecture defined')\nprint('\\nTeaching Notes: CNN architecture with dropout for regularization')\nprint('Grading: Task 1 (25pts), Task 2 (30pts), Task 3 (45pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, num_classes=2):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision -q\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass MedicalImageClassifier(nn.Module):\n    def__init__(self, num_classes=2):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(), nn.Linear(256 * 32 * 32, 512),\n            nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x_\nprint('\u2705 Model architecture defined')\nprint('\\nTeaching Notes: CNN architecture with dropout for regularization')\nprint('Grading: Task 1 (25pts), Task 2 (30pts), Task 3 (45pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, num_classes=2):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "other"
    },
    {
      "path": "Course 08/unit2-cnns/examples/01_cnn_architecture.ipynb",
      "status": "failed",
      "execution_time": 0.7463641166687012,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 2 - Example 1: CNN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\n\nThis example demonstrates:\n1. CNN architecture components2. Convolution and pooling operations\n3. Building a simple CNN\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: CNN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\n\n# 1. CNN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a CN\nNp\nrint(\"\\n1. CNN Architecture Components\")\nprint(\"\u0645\u0643\u0648\u0646\u0627\u062a \u0647\u064a\u0643\u0644 CNN\")\nprint(\"-\" * 60)\ncnn_components = \"\"\"\nCNN Architecture:\n1. Convolutional Layers - Detect features (edges, shapes)\n2. Pooling Layers - Reduce dimensionality (Max, Average)\n3. Fully Connected Layers - Classification4. Activation Functions - ReLU, Softmax\n\n\u0647\u064a\u0643\u0644 CNN:\n1. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 - \u0627\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0645\u064a\u0632\u0627\u062a (\u0627\u0644\u062d\u0648\u0627\u0641\u060c \u0627\u0644\u0623\u0634\u0643\u0627\u0644)\n2. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 - \u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f (\u0627\u0644\u062d\u062f \u0627\u0644\u0623\u0642\u0635\u0649\u060c \u0627\u0644\u0645\u062a\u0648\u0633\u0637)\n3. \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0628\u0627\u0644\u0643\u0627\u0645\u0644 - \u0627\u0644\u062a\u0635\u0646\u064a\u06414. \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 - ReLU\u060c Softmax\n\"\"\"\n\nprint(cnn_components)\n\n# 2. Convolution Operation\n# \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Convolution Operation\")\nprint(\"\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641\")\nprint(\"=\" * 60)\ndef simple_convolution_example():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Demonstrate convolution concept.\n \u062a\u0648\u0636\u064a\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641.\n \"\"\"\n # Simple 3\nx3 imag\neimage = [\n [1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]\n ]\n \n # 2\nx2 filter (kernel)\nfilter_kernel = [\n [1, 0],\n [0, -1]\n ]\n \n print(\"\\nImage (3\\nx3):\")\n for row in image:\n print(f\" {row}\")\nprint(\"\\nFilter (2\\nx2):\")\n for row in filter_kernel:\n print(f\" {row}\")\n \n # Apply convolution (simplified)\nresult = []\n for i in range(len(image) - 1):\n row_result = []\n for j in range(len(image[0]) - 1):\n # Element-wise multiplication and sum\n conv_value = (image[i][j] * filter_kernel[0][0] +\n image[i][j+1] * filter_kernel[0][1] +\n image[i+1][j] * filter_kernel[1][0] +\n image[i+1][j+1] * filter_kernel[1][1])\nrow_result.append(conv_value)\nresult.append(row_result)\nprint(\"\\nConvolution Result (2\\nx2):\")\n for row in result:\n print(f\" {row}\")\nsimple_convolution_example()\n\n# 3. CNN Architecture Example\n# \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CN\nNp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. CNN Architecture Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\ncnn_architecture = \"\"\"\nSimple CNN for Image Classification:\n\nInput (28\nx28\nx1) # Grayscale image\n \u2193\nConv2\nD (32 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nConv2\nD (64 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nFlatten\n \u2193\nDense (128) + ReLU\n \u2193\nDense (10) + Softmax # 10 classes\n \u2193\nOutput (10 classes)\n\"\"\"\n\nprint(cnn_architecture)\n\n# 4. Transfer Learning Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Transfer Learning\")\nprint(\"\u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644\")\nprint(\"=\" * 60)\ntransfer_learning = \"\"\"\nTransfer Learning Process:\n1. Use pre-trained model (e.g., ResNet, VGG)\n2. Remove final classification layer3. Add new layers for your task\n4. Fine-tune on your dataset5. Much faster than training from scratch!\n\n\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644:\n1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0645\u0648\u0630\u062c \u0645\u062f\u0631\u0628 \u0645\u0633\u0628\u0642\u0627\u064b (\u0645\u062b\u0644 ResNet\u060c VGG)\n2. \u0625\u0632\u0627\u0644\u0629 \u0637\u0628\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0646\u0647\u0627\u0626\u064a\u06293. \u0625\u0636\u0627\u0641\u0629 \u0637\u0628\u0642\u0627\u062a \u062c\u062f\u064a\u062f\u0629 \u0644\u0645\u0647\u0645\u062a\u06434. \u0627\u0644\u0636\u0628\u0637 \u0627\u0644\u062f\u0642\u064a\u0642 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u062a\u06435. \u0623\u0633\u0631\u0639 \u0628\u0643\u062b\u064a\u0631 \u0645\u0646 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631!\n\"\"\"\n\nprint(transfer_learning)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 2 - Example 1: CNN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\n\nThis example demonstrates:\n1. CNN architecture components2. Convolution and pooling operations\n3. Building a simple CNN\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: CNN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\n\n# 1. CNN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a CN\nNp\nrint(\"\\n1. CNN Architecture Components\")\nprint(\"\u0645\u0643\u0648\u0646\u0627\u062a \u0647\u064a\u0643\u0644 CNN\")\nprint(\"-\" * 60)\ncnn_components = \"\"\"\nCNN Architecture:\n1. Convolutional Layers - Detect features (edges, shapes)\n2. Pooling Layers - Reduce dimensionality (Max, Average)\n3. Fully Connected Layers - Classification4. Activation Functions - ReLU, Softmax\n\n\u0647\u064a\u0643\u0644 CNN:\n1. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 - \u0627\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0645\u064a\u0632\u0627\u062a (\u0627\u0644\u062d\u0648\u0627\u0641\u060c \u0627\u0644\u0623\u0634\u0643\u0627\u0644)\n2. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 - \u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f (\u0627\u0644\u062d\u062f \u0627\u0644\u0623\u0642\u0635\u0649\u060c \u0627\u0644\u0645\u062a\u0648\u0633\u0637)\n3. \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0628\u0627\u0644\u0643\u0627\u0645\u0644 - \u0627\u0644\u062a\u0635\u0646\u064a\u06414. \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 - ReLU\u060c Softmax\n\"\"\"\n\nprint(cnn_components)\n\n# 2. Convolution Operation\n# \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Convolution Operation\")\nprint(\"\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641\")\nprint(\"=\" * 60)\ndef simple_convolution_example():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Demonstrate convolution concept.\n \u062a\u0648\u0636\u064a\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641.\n \"\"\"\n # Simple 3\nx3 imag\neimage = [\n [1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]\n ]\n \n # 2\nx2 filter (kernel)\nfilter_kernel = [\n [1, 0],\n [0, -1]\n ]\n \n print(\"\\nImage (3\\nx3):\")\n for row in image:\n print(f\" {row}\")\nprint(\"\\nFilter (2\\nx2):\")\n for row in filter_kernel:\n print(f\" {row}\")\n \n # Apply convolution (simplified)\nresult = []\n for i in range(len(image) - 1):\n row_result = []\n for j in range(len(image[0]) - 1):\n # Element-wise multiplication and sum\n conv_value = (image[i][j] * filter_kernel[0][0] +\n image[i][j+1] * filter_kernel[0][1] +\n image[i+1][j] * filter_kernel[1][0] +\n image[i+1][j+1] * filter_kernel[1][1])\nrow_result.append(conv_value)\nresult.append(row_result)\nprint(\"\\nConvolution Result (2\\nx2):\")\n for row in result:\n print(f\" {row}\")\nsimple_convolution_example()\n\n# 3. CNN Architecture Example\n# \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CN\nNp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. CNN Architecture Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\ncnn_architecture = \"\"\"\nSimple CNN for Image Classification:\n\nInput (28\nx28\nx1) # Grayscale image\n \u2193\nConv2\nD (32 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nConv2\nD (64 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nFlatten\n \u2193\nDense (128) + ReLU\n \u2193\nDense (10) + Softmax # 10 classes\n \u2193\nOutput (10 classes)\n\"\"\"\n\nprint(cnn_architecture)\n\n# 4. Transfer Learning Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Transfer Learning\")\nprint(\"\u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644\")\nprint(\"=\" * 60)\ntransfer_learning = \"\"\"\nTransfer Learning Process:\n1. Use pre-trained model (e.g., ResNet, VGG)\n2. Remove final classification layer3. Add new layers for your task\n4. Fine-tune on your dataset5. Much faster than training from scratch!\n\n\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644:\n1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0645\u0648\u0630\u062c \u0645\u062f\u0631\u0628 \u0645\u0633\u0628\u0642\u0627\u064b (\u0645\u062b\u0644 ResNet\u060c VGG)\n2. \u0625\u0632\u0627\u0644\u0629 \u0637\u0628\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0646\u0647\u0627\u0626\u064a\u06293. \u0625\u0636\u0627\u0641\u0629 \u0637\u0628\u0642\u0627\u062a \u062c\u062f\u064a\u062f\u0629 \u0644\u0645\u0647\u0645\u062a\u06434. \u0627\u0644\u0636\u0628\u0637 \u0627\u0644\u062f\u0642\u064a\u0642 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u062a\u06435. \u0623\u0633\u0631\u0639 \u0628\u0643\u062b\u064a\u0631 \u0645\u0646 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631!\n\"\"\"\n\nprint(transfer_learning)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n\n",
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/02_cnn_advanced_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.9027681350708008,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/03_transfer_learning_cnns.ipynb",
      "status": "passed",
      "execution_time": 0.8124709129333496,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/04_pretrained_cnn_architectures.ipynb",
      "status": "failed",
      "execution_time": 1.793076992034912,
      "error": "An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import ResNet50, VGG16, InceptionV3\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained CNN Architectures\")\nprint(\"=\" * 60)\n\nprint(\"\\nResNet:\")\nprint(\"  - Residual connections\")\nprint(\"  - Very deep networks\")\nprint(\"  - Skip connections\")\n\nprint(\"\\nVGG:\")\nprint(\"  - Simple architecture\")\nprint(\"  - Small filters\")\nprint(\"  - Deep networks\")\n\nprint(\"\\nInception:\")\nprint(\"  - Multiple filter sizes\")\nprint(\"  - Efficient computation\")\nprint(\"  - Inception modules\")\n\nprint(\"\\nBenefits:\")\nprint(\"  - Pre-trained on ImageNet\")\nprint(\"  - Transfer learning\")\nprint(\"  - Feature extraction\")\nprint(\"  - Fine-tuning\")\n\nprint(\"\\n\u2705 Pre-trained CNN concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ResNet50, VGG16, InceptionV3\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import ResNet50, VGG16, InceptionV3\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained CNN Architectures\")\nprint(\"=\" * 60)\n\nprint(\"\\nResNet:\")\nprint(\"  - Residual connections\")\nprint(\"  - Very deep networks\")\nprint(\"  - Skip connections\")\n\nprint(\"\\nVGG:\")\nprint(\"  - Simple architecture\")\nprint(\"  - Small filters\")\nprint(\"  - Deep networks\")\n\nprint(\"\\nInception:\")\nprint(\"  - Multiple filter sizes\")\nprint(\"  - Efficient computation\")\nprint(\"  - Inception modules\")\n\nprint(\"\\nBenefits:\")\nprint(\"  - Pre-trained on ImageNet\")\nprint(\"  - Transfer learning\")\nprint(\"  - Feature extraction\")\nprint(\"  - Fine-tuning\")\n\nprint(\"\\n\u2705 Pre-trained CNN concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ResNet50, VGG16, InceptionV3\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/05_training_cnn_image_datasets.ipynb",
      "status": "failed",
      "execution_time": 1.8104231357574463,
      "error": "An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import cifar10\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nTraining CNN on Image Datasets\")\nprint(\"=\" * 60)\n\nprint(\"\\nDatasets:\")\nprint(\"  - CIFAR-10: 32x32 color images, 10 classes\")\nprint(\"  - ImageNet: Large-scale dataset, 1000 classes\")\nprint(\"  - Custom datasets\")\n\nprint(\"\\nTraining Steps:\")\nprint(\"  1. Load and preprocess data\")\nprint(\"  2. Define CNN architecture\")\nprint(\"  3. Compile model\")\nprint(\"  4. Train model\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\nKey Considerations:\")\nprint(\"  - Data augmentation\")\nprint(\"  - Learning rate scheduling\")\nprint(\"  - Regularization\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 CNN training concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cifar10\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import cifar10\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nTraining CNN on Image Datasets\")\nprint(\"=\" * 60)\n\nprint(\"\\nDatasets:\")\nprint(\"  - CIFAR-10: 32x32 color images, 10 classes\")\nprint(\"  - ImageNet: Large-scale dataset, 1000 classes\")\nprint(\"  - Custom datasets\")\n\nprint(\"\\nTraining Steps:\")\nprint(\"  1. Load and preprocess data\")\nprint(\"  2. Define CNN architecture\")\nprint(\"  3. Compile model\")\nprint(\"  4. Train model\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\nKey Considerations:\")\nprint(\"  - Data augmentation\")\nprint(\"  - Learning rate scheduling\")\nprint(\"  - Regularization\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 CNN training concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cifar10\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/06_transfer_learning_object_detection.ipynb",
      "status": "failed",
      "execution_time": 1.9260761737823486,
      "error": "An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nTransfer Learning for Object Detection\")\nprint(\"=\" * 60)\n\nprint(\"\\nObject Detection:\")\nprint(\"  - Localize objects\")\nprint(\"  - Classify objects\")\nprint(\"  - Bounding boxes\")\nprint(\"  - Multiple objects\")\n\nprint(\"\\nPre-trained Models:\")\nprint(\"  - YOLO\")\nprint(\"  - SSD\")\nprint(\"  - Faster R-CNN\")\nprint(\"  - RetinaNet\")\n\nprint(\"\\nTransfer Learning Approach:\")\nprint(\"  1. Use pre-trained backbone\")\nprint(\"  2. Add detection head\")\nprint(\"  3. Fine-tune on target dataset\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 Object detection concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nTransfer Learning for Object Detection\")\nprint(\"=\" * 60)\n\nprint(\"\\nObject Detection:\")\nprint(\"  - Localize objects\")\nprint(\"  - Classify objects\")\nprint(\"  - Bounding boxes\")\nprint(\"  - Multiple objects\")\n\nprint(\"\\nPre-trained Models:\")\nprint(\"  - YOLO\")\nprint(\"  - SSD\")\nprint(\"  - Faster R-CNN\")\nprint(\"  - RetinaNet\")\n\nprint(\"\\nTransfer Learning Approach:\")\nprint(\"  1. Use pre-trained backbone\")\nprint(\"  2. Add detection head\")\nprint(\"  3. Fine-tune on target dataset\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 Object detection concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/cnn_architecture_convolutional_layers_pooling_layers_fully_connected_layers.ipynb",
      "status": "passed",
      "execution_time": 1.535438060760498,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/image_processing_fundamentals_and_feature_extraction.ipynb",
      "status": "passed",
      "execution_time": 1.5456409454345703,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/implementing_a_cnn_from_scratch_using_tensorflowpytorch.ipynb",
      "status": "passed",
      "execution_time": 1.663233995437622,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/introduction_to_pre_trained_cnn_architectures_resnet_vgg_inception.ipynb",
      "status": "passed",
      "execution_time": 1.4600257873535156,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/training_a_cnn_on_image_datasets_eg_cifar_10_imagenet.ipynb",
      "status": "passed",
      "execution_time": 1.421511173248291,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/exercises/01_cnn_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.7664129734039307,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit2-cnns/solutions/01_cnn_solution.ipynb",
      "status": "passed",
      "execution_time": 1.8767590522766113,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "other"
    },
    {
      "path": "Course 08/unit3-rnns/examples/01_rnn_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8445091247558594,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/02_lstm_advanced.ipynb",
      "status": "passed",
      "execution_time": 0.7797689437866211,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/03_sequence_to_sequence.ipynb",
      "status": "passed",
      "execution_time": 0.6795108318328857,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/04_text_generation_rnn_lstm_gru.ipynb",
      "status": "failed",
      "execution_time": 1.807887077331543,
      "error": "An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRNN, LSTM, and GRU for Text Generation\")\nprint(\"=\" * 60)\n\nprint(\"\\nRNN:\")\nprint(\"  - Simple recurrent units\")\nprint(\"  - Vanishing gradient problem\")\nprint(\"  - Basic sequential modeling\")\n\nprint(\"\\nLSTM:\")\nprint(\"  - Long Short-Term Memory\")\nprint(\"  - Gates (forget, input, output)\")\nprint(\"  - Handles long sequences\")\n\nprint(\"\\nGRU:\")\nprint(\"  - Gated Recurrent Unit\")\nprint(\"  - Simpler than LSTM\")\nprint(\"  - Fewer parameters\")\n\nprint(\"\\nText Generation:\")\nprint(\"  - Character-level\")\nprint(\"  - Word-level\")\nprint(\"  - Sequence prediction\")\nprint(\"  - Sampling strategies\")\n\nprint(\"\\n\u2705 Text generation concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRNN, LSTM, and GRU for Text Generation\")\nprint(\"=\" * 60)\n\nprint(\"\\nRNN:\")\nprint(\"  - Simple recurrent units\")\nprint(\"  - Vanishing gradient problem\")\nprint(\"  - Basic sequential modeling\")\n\nprint(\"\\nLSTM:\")\nprint(\"  - Long Short-Term Memory\")\nprint(\"  - Gates (forget, input, output)\")\nprint(\"  - Handles long sequences\")\n\nprint(\"\\nGRU:\")\nprint(\"  - Gated Recurrent Unit\")\nprint(\"  - Simpler than LSTM\")\nprint(\"  - Fewer parameters\")\n\nprint(\"\\nText Generation:\")\nprint(\"  - Character-level\")\nprint(\"  - Word-level\")\nprint(\"  - Sequence prediction\")\nprint(\"  - Sampling strategies\")\n\nprint(\"\\n\u2705 Text generation concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/05_transformer_models_bert_gpt_nlp.ipynb",
      "status": "failed",
      "execution_time": 5.272710084915161,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nTransformer Models: BERT and GPT\")\nprint(\"=\" * 60)\n\nprint(\"\\nBERT (Bidirectional Encoder Representations):\")\nprint(\"  - Bidirectional context\")\nprint(\"  - Masked language modeling\")\nprint(\"  - Good for understanding tasks\")\n\nprint(\"\\nGPT (Generative Pre-trained Transformer):\")\nprint(\"  - Autoregressive generation\")\nprint(\"  - Left-to-right context\")\nprint(\"  - Good for generation tasks\")\n\nprint(\"\\nNLP Tasks:\")\nprint(\"  - Text classification\")\nprint(\"  - Named entity recognition\")\nprint(\"  - Question answering\")\nprint(\"  - Text generation\")\n\nprint(\"\\n\u2705 Transformer models concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prepare_4d_attention_mask_for_sdpa, _prepare_4d_causal_attention_mask_for_sdpa\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradientCheckpointingLayer\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     35\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_layers.py:28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     BaseModelOutputWithPast,\n\u001b[1;32m     23\u001b[0m     QuestionAnsweringModelOutput,\n\u001b[1;32m     24\u001b[0m     SequenceClassifierOutputWithPast,\n\u001b[1;32m     25\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unpack\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformersKwargs, auto_docstring, can_return_tuple, logging\n\u001b[1;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/processing_utils.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, ImageInput, is_vision_available\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m render_jinja_template\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoInput, VideoMetadata\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PILImageResampling\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/video_utils.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaddingMode, to_channel_dimension_format\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, infer_channel_dimension_format, is_valid_image\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     is_av_available,\n\u001b[1;32m     32\u001b[0m     is_cv2_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     requires_backends,\n\u001b[1;32m     43\u001b[0m )\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/image_transforms.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nTransformer Models: BERT and GPT\")\nprint(\"=\" * 60)\n\nprint(\"\\nBERT (Bidirectional Encoder Representations):\")\nprint(\"  - Bidirectional context\")\nprint(\"  - Masked language modeling\")\nprint(\"  - Good for understanding tasks\")\n\nprint(\"\\nGPT (Generative Pre-trained Transformer):\")\nprint(\"  - Autoregressive generation\")\nprint(\"  - Left-to-right context\")\nprint(\"  - Good for generation tasks\")\n\nprint(\"\\nNLP Tasks:\")\nprint(\"  - Text classification\")\nprint(\"  - Named entity recognition\")\nprint(\"  - Question answering\")\nprint(\"  - Text generation\")\n\nprint(\"\\n\u2705 Transformer models concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prepare_4d_attention_mask_for_sdpa, _prepare_4d_causal_attention_mask_for_sdpa\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradientCheckpointingLayer\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     35\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_layers.py:28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     BaseModelOutputWithPast,\n\u001b[1;32m     23\u001b[0m     QuestionAnsweringModelOutput,\n\u001b[1;32m     24\u001b[0m     SequenceClassifierOutputWithPast,\n\u001b[1;32m     25\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unpack\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformersKwargs, auto_docstring, can_return_tuple, logging\n\u001b[1;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/processing_utils.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, ImageInput, is_vision_available\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m render_jinja_template\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoInput, VideoMetadata\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PILImageResampling\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/video_utils.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaddingMode, to_channel_dimension_format\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, infer_channel_dimension_format, is_valid_image\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     is_av_available,\n\u001b[1;32m     32\u001b[0m     is_cv2_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     requires_backends,\n\u001b[1;32m     43\u001b[0m )\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/image_transforms.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/06_sentiment_analysis_translation_speech.ipynb",
      "status": "failed",
      "execution_time": 3.668335199356079,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers import pipeline\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSentiment Analysis, Translation, and Speech Recognition\")\nprint(\"=\" * 60)\n\nprint(\"\\nSentiment Analysis:\")\nprint(\"  - Classify text sentiment\")\nprint(\"  - Positive/negative/neutral\")\nprint(\"  - Use BERT or LSTM\")\n\nprint(\"\\nMachine Translation:\")\nprint(\"  - Translate between languages\")\nprint(\"  - Seq2seq models\")\nprint(\"  - Attention mechanisms\")\n\nprint(\"\\nSpeech Recognition:\")\nprint(\"  - Convert speech to text\")\nprint(\"  - Audio processing\")\nprint(\"  - CTC or attention models\")\n\nprint(\"\\nModels:\")\nprint(\"  - Pre-trained transformers\")\nprint(\"  - Fine-tuned models\")\nprint(\"  - Task-specific architectures\")\n\nprint(\"\\n\u2705 NLP applications concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/pipelines/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/image_processing_utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, ImageProcessingMixin\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, get_image_size\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/image_transforms.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers import pipeline\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSentiment Analysis, Translation, and Speech Recognition\")\nprint(\"=\" * 60)\n\nprint(\"\\nSentiment Analysis:\")\nprint(\"  - Classify text sentiment\")\nprint(\"  - Positive/negative/neutral\")\nprint(\"  - Use BERT or LSTM\")\n\nprint(\"\\nMachine Translation:\")\nprint(\"  - Translate between languages\")\nprint(\"  - Seq2seq models\")\nprint(\"  - Attention mechanisms\")\n\nprint(\"\\nSpeech Recognition:\")\nprint(\"  - Convert speech to text\")\nprint(\"  - Audio processing\")\nprint(\"  - CTC or attention models\")\n\nprint(\"\\nModels:\")\nprint(\"  - Pre-trained transformers\")\nprint(\"  - Fine-tuned models\")\nprint(\"  - Task-specific architectures\")\n\nprint(\"\\n\u2705 NLP applications concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/pipelines/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/image_processing_utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, ImageProcessingMixin\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, get_image_size\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/image_transforms.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/advanced_architectures_lstm_gru_transformers_attention_mechanism.ipynb",
      "status": "passed",
      "execution_time": 1.3428707122802734,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/applications_in_nlp.ipynb",
      "status": "passed",
      "execution_time": 1.7202661037445068,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/implementing_rnn_lstm_and_gru_for_text_generation.ipynb",
      "status": "passed",
      "execution_time": 1.3893182277679443,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/performing_sentiment_analysis_machine_translation_and_speech_recognition.ipynb",
      "status": "passed",
      "execution_time": 1.3878300189971924,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/rnn_structure_and_challenges_vanishing_gradients_problem.ipynb",
      "status": "passed",
      "execution_time": 1.343592882156372,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/understanding_sequential_data_and_time_series_prediction.ipynb",
      "status": "passed",
      "execution_time": 1.555483102798462,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/using_transformer_models_like_bert_and_gpt_for_nlp_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.442291259765625,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/exercises/01_rnn_exercise.ipynb",
      "status": "failed",
      "execution_time": 2.3393921852111816,
      "error": "An error occurred while executing the following cell:\n------------------\n# TODO: Generate synthetic time series data\n# Hint: Use sine wave + trend + noise\ndef generate_stock_data(n_samples=1000):\n # YOUR CODE HERE\n pass\n\n# Test\ndata = generate_stock_data()\nplt.plot(data[:100])\nplt.title('Stock Price Data')\nplt.show()\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_stock_data()\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Price Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# TODO: Generate synthetic time series data\n# Hint: Use sine wave + trend + noise\ndef generate_stock_data(n_samples=1000):\n # YOUR CODE HERE\n pass\n\n# Test\ndata = generate_stock_data()\nplt.plot(data[:100])\nplt.title('Stock Price Data')\nplt.show()\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_stock_data()\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Price Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit3-rnns/solutions/01_rnn_solution.ipynb",
      "status": "failed",
      "execution_time": 2.1922879219055176,
      "error": "An error occurred while executing the following cell:\n------------------\ndef generate_stock_data(n_samples=1000):\n    \n    \n    \n    \"\"\"Generate synthetic stock price data\"\"\"\n_t =  np.linspace(0, 100, n_samples)\n    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)\n    trend = 0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)_noise =  np.random.normal(0, 2, n_samples)\n    noise = np.random.normal(0, 2, n_samples)\n    return trend + seasonality + noise + 100_data = generate_stock_data()\nplt.figure(figsize=(12, 4))\nplt.plot(data[:200])\nplt.title('Synthetic Stock Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.grid(True)\nplt.show()\nprint(f'\u2705 Generated {len(data)} samples')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\ndef generate_stock_data(n_samples=1000):\n    \n    \n    \n    \"\"\"Generate synthetic stock price data\"\"\"\n_t =  np.linspace(0, 100, n_samples)\n    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)\n    trend = 0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)_noise =  np.random.normal(0, 2, n_samples)\n    noise = np.random.normal(0, 2, n_samples)\n    return trend + seasonality + noise + 100_data = generate_stock_data()\nplt.figure(figsize=(12, 4))\nplt.plot(data[:200])\nplt.title('Synthetic Stock Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.grid(True)\nplt.show()\nprint(f'\u2705 Generated {len(data)} samples')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "other"
    },
    {
      "path": "Course 08/unit4-transformers/examples/01_transformer_attention.ipynb",
      "status": "passed",
      "execution_time": 0.7329950332641602,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/examples/02_bert_finetuning.ipynb",
      "status": "passed",
      "execution_time": 0.73073410987854,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/examples/03_gpt_text_generation.ipynb",
      "status": "failed",
      "execution_time": 0.7460470199584961,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch datasets -q\n\nimport torch\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers \nimport Trainer, TrainingArguments\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch datasets -q\n\nimport torch\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers \nimport Trainer, TrainingArguments\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/exercises/01_transformer_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.8792870044708252,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit4-transformers/solutions/01_transformer_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6140589714050293,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Use pre-trained translation model_model_name = 'Helsinki-NLP/opus-mt-en-de'\ntokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\nprint('\u2705 Translation model loaded')\nprint('\\nTeaching Notes: Use pre-trained transformer models for translation')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Use pre-trained translation model_model_name = 'Helsinki-NLP/opus-mt-en-de'\ntokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\nprint('\u2705 Translation model loaded')\nprint('\\nTeaching Notes: Use pre-trained transformer models for translation')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "other"
    },
    {
      "path": "Course 08/unit5-deployment/examples/01_model_optimization.ipynb",
      "status": "passed",
      "execution_time": 0.7298638820648193,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/02_tensorflow_serving.ipynb",
      "status": "failed",
      "execution_time": 5.753029823303223,
      "error": "An error occurred while executing the following cell:\n------------------\n# Create a simple model for demonstration\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n tf.keras.layers.Dense(32, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Save in SavedModel format\nmodel_path = './saved_model'\nmodel.save(model_path, save_format='tf')\nprint(f'\u2705 Model saved to {model_path}')\n------------------\n\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save in SavedModel format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\u2705 Model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:69\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend removing this argument as it can be inferred \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the file path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\n\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Create a simple model for demonstration\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n tf.keras.layers.Dense(32, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Save in SavedModel format\nmodel_path = './saved_model'\nmodel.save(model_path, save_format='tf')\nprint(f'\u2705 Model saved to {model_path}')\n------------------\n\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save in SavedModel format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\u2705 Model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:69\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend removing this argument as it can be inferred \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the file path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\n\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf\n\n",
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/03_onnx_conversion.ipynb",
      "status": "failed",
      "execution_time": 0.8225729465484619,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch onnx onnxruntime -q\nimport torch\nimport torch.nn as nn\nimport onnx\nimport onnxruntime as ortprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import onnxruntime as ortprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch onnx onnxruntime -q\nimport torch\nimport torch.nn as nn\nimport onnx\nimport onnxruntime as ortprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import onnxruntime as ortprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/04_model_pruning.ipynb",
      "status": "passed",
      "execution_time": 0.7693030834197998,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/05_model_distillation.ipynb",
      "status": "passed",
      "execution_time": 0.9163460731506348,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/06_flask_fastapi_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.8095099925994873,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/07_model_optimization_quantization.ipynb",
      "status": "passed",
      "execution_time": 3.2411508560180664,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/cloud_deployment_of_deep_learning_models.ipynb",
      "status": "passed",
      "execution_time": 1.7052600383758545,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/model_compression_for_edge_devices.ipynb",
      "status": "passed",
      "execution_time": 1.4912440776824951,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/optimizing_deep_learning_models_using_regularization.ipynb",
      "status": "passed",
      "execution_time": 1.6382582187652588,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/regularization_and_hyperparameter_tuning.ipynb",
      "status": "passed",
      "execution_time": 1.6678872108459473,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/regularization_techniques_dropout_batch_normalization.ipynb",
      "status": "passed",
      "execution_time": 1.377467155456543,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/exercises/01_deep_learning_model_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.747636079788208,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit5-deployment/solutions/01_deep_learning_model_deployment_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7418808937072754,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "other"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/01_mdp_example.ipynb",
      "status": "passed",
      "execution_time": 1.0003328323364258,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/02_mdp_solving.ipynb",
      "status": "passed",
      "execution_time": 0.7808129787445068,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/03_value_iteration.ipynb",
      "status": "passed",
      "execution_time": 0.7356479167938232,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/04_openai_gym_setup.ipynb",
      "status": "failed",
      "execution_time": 0.8750870227813721,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Interacting with Gym Environments\")\nprint(\"=\" * 60)\n\n# Create environment\nenv = gym.make('CartPole-v1')\n\n# Reset environment\nobservation, info = env.reset()\nprint(f\"\\nInitial observation: {observation}\")\n\n# Take a few random actions\ntotal_reward = 0\nfor step in range(5):\n # Sample random action\n action = env.action_space.sample()\n \n # Take step\n observation, reward, terminated, truncated, info = env.step(action)\n \n done = terminated or truncated\n total_reward += reward\n \n print(f\"\\nStep {step + 1}:\")\n print(f\" Action: {action}\")\n print(f\" Reward: {reward}\")\n print(f\" Done: {done}\")\n print(f\" Observation: {observation[:2]}...\") # Show first 2 values\n \n if done:\n print(\" Episode ended!\")\n observation, info = env.reset()\n break\n\nprint(f\"\\nTotal reward: {total_reward}\")\nenv.close()\n\nprint(\"\\n\u2705 Environment interaction complete!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" Episode ended!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Interacting with Gym Environments\")\nprint(\"=\" * 60)\n\n# Create environment\nenv = gym.make('CartPole-v1')\n\n# Reset environment\nobservation, info = env.reset()\nprint(f\"\\nInitial observation: {observation}\")\n\n# Take a few random actions\ntotal_reward = 0\nfor step in range(5):\n # Sample random action\n action = env.action_space.sample()\n \n # Take step\n observation, reward, terminated, truncated, info = env.step(action)\n \n done = terminated or truncated\n total_reward += reward\n \n print(f\"\\nStep {step + 1}:\")\n print(f\" Action: {action}\")\n print(f\" Reward: {reward}\")\n print(f\" Done: {done}\")\n print(f\" Observation: {observation[:2]}...\") # Show first 2 values\n \n if done:\n print(\" Episode ended!\")\n observation, info = env.reset()\n break\n\nprint(f\"\\nTotal reward: {total_reward}\")\nenv.close()\n\nprint(\"\\n\u2705 Environment interaction complete!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" Episode ended!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/05_exploration_strategies_epsilon_greedy.ipynb",
      "status": "passed",
      "execution_time": 1.0629692077636719,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/06_solving_rl_problems_states_actions_rewards.ipynb",
      "status": "failed",
      "execution_time": 0.7425971031188965,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Designing Reward Functions\")\nprint(\"=\" * 60)\n\nprint(\"\\nReward Function Design Principles:\")\nprint(\" 1. Provide clear feedback (positive for good, negative for bad)\")\nprint(\" 2. Shape rewards to guide learning (sparse vs dense)\")\nprint(\" 3. Balance immediate vs long-term rewards\")\nprint(\" 4. Avoid reward hacking (unintended behaviors)\")\n\n# Test CartPole rewards\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint(\"\\nCartPole-v1 Reward Function:\")\nprint(\" +1 for each step the pole remains balanced\")\nprint(\" Episode ends when pole falls or cart goes out of bounds\")\nprint(\" Maximum reward: 500 (episode length limit)\")\n\ntotal_reward = 0\nfor step in range(10):\n action = env.action_space.sample()\n obs, reward, terminated, truncated, info = env.step(action)\n done = terminated or truncated\n total_reward += reward\n print(f\" Step {step+1}: Reward = {reward}, Total = {total_reward}\")\n if done:\n break\n\nenv.close()\n\nprint(\"\\n\u2705 Reward functions understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 27\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Designing Reward Functions\")\nprint(\"=\" * 60)\n\nprint(\"\\nReward Function Design Principles:\")\nprint(\" 1. Provide clear feedback (positive for good, negative for bad)\")\nprint(\" 2. Shape rewards to guide learning (sparse vs dense)\")\nprint(\" 3. Balance immediate vs long-term rewards\")\nprint(\" 4. Avoid reward hacking (unintended behaviors)\")\n\n# Test CartPole rewards\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint(\"\\nCartPole-v1 Reward Function:\")\nprint(\" +1 for each step the pole remains balanced\")\nprint(\" Episode ends when pole falls or cart goes out of bounds\")\nprint(\" Maximum reward: 500 (episode length limit)\")\n\ntotal_reward = 0\nfor step in range(10):\n action = env.action_space.sample()\n obs, reward, terminated, truncated, info = env.step(action)\n done = terminated or truncated\n total_reward += reward\n print(f\" Step {step+1}: Reward = {reward}, Total = {total_reward}\")\n if done:\n break\n\nenv.close()\n\nprint(\"\\n\u2705 Reward functions understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 27\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/07_mini_projects_cartpole_frozenlake_qlearning_dqn.ipynb",
      "status": "failed",
      "execution_time": 0.8792047500610352,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Q-Learning Algorithm Implementation\")\nprint(\"=\" * 60)\n\ndef epsilon_greedy_action(q_table, state, epsilon, n_actions):\n \n    \n    \"\"\"Choose action using epsilon-greedy strategy.\"\"\"\n if random.random() < epsilon:\n return random.randint(0, n_actions - 1)\n else:\n return np.argmax(q_table[state])\n\ndef q_learning_update(q_table, state, action, reward, next_state, alpha, gamma):\n \n    \n    \"\"\"\n Q-learning update rule:\n Q(s,a) = Q(s,a) + \u03b1[r + \u03b3 * max(Q(s',a')) - Q(s,a)]\n \"\"\"\n current_q = q_table[state, action]\n max_next_q = np.max(q_table[next_state])\n new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n q_table[state, action] = new_q\n return q_table\n\nprint(\"\\nQ-Learning Algorithm:\")\nprint(\" 1. Initialize Q-table (states \u00d7 actions)\")\nprint(\" 2. For each episode:\")\nprint(\" a. Initialize state\")\nprint(\" b. While not done:\")\nprint(\" - Choose action using epsilon-greedy\")\nprint(\" - Take action, observe reward and next state\")\nprint(\" - Update Q-table: Q(s,a) = Q(s,a) + \u03b1[r + \u03b3*max(Q(s',a')) - Q(s,a)]\")\nprint(\" - Set state = next_state\")\nprint(\" 3. Return Q-table\")\n\nprint(\"\\nKey Parameters:\")\nprint(\" - \u03b1 (alpha): Learning rate (0.0 to 1.0)\")\nprint(\" - \u03b3 (gamma): Discount factor (0.0 to 1.0)\")\nprint(\" - \u03b5 (epsilon): Exploration rate\")\nprint(\" - Q-table: State-action value function\")\n\nprint(\"\\n\u2705 Q-Learning algorithm understood!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    if random.random() < epsilon:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Q-Learning Algorithm Implementation\")\nprint(\"=\" * 60)\n\ndef epsilon_greedy_action(q_table, state, epsilon, n_actions):\n \n    \n    \"\"\"Choose action using epsilon-greedy strategy.\"\"\"\n if random.random() < epsilon:\n return random.randint(0, n_actions - 1)\n else:\n return np.argmax(q_table[state])\n\ndef q_learning_update(q_table, state, action, reward, next_state, alpha, gamma):\n \n    \n    \"\"\"\n Q-learning update rule:\n Q(s,a) = Q(s,a) + \u03b1[r + \u03b3 * max(Q(s',a')) - Q(s,a)]\n \"\"\"\n current_q = q_table[state, action]\n max_next_q = np.max(q_table[next_state])\n new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n q_table[state, action] = new_q\n return q_table\n\nprint(\"\\nQ-Learning Algorithm:\")\nprint(\" 1. Initialize Q-table (states \u00d7 actions)\")\nprint(\" 2. For each episode:\")\nprint(\" a. Initialize state\")\nprint(\" b. While not done:\")\nprint(\" - Choose action using epsilon-greedy\")\nprint(\" - Take action, observe reward and next state\")\nprint(\" - Update Q-table: Q(s,a) = Q(s,a) + \u03b1[r + \u03b3*max(Q(s',a')) - Q(s,a)]\")\nprint(\" - Set state = next_state\")\nprint(\" 3. Return Q-table\")\n\nprint(\"\\nKey Parameters:\")\nprint(\" - \u03b1 (alpha): Learning rate (0.0 to 1.0)\")\nprint(\" - \u03b3 (gamma): Discount factor (0.0 to 1.0)\")\nprint(\" - \u03b5 (epsilon): Exploration rate\")\nprint(\" - Q-table: State-action value function\")\n\nprint(\"\\n\u2705 Q-Learning algorithm understood!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    if random.random() < epsilon:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/exploration_strategies_programming_epsilon_greedy_strategy_and_visualizing_its_i.ipynb",
      "status": "passed",
      "execution_time": 1.3422131538391113,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/mini_projects_applying_rl_in_games_like_cartpole_and_frozenlake_implementing_q_l.ipynb",
      "status": "failed",
      "execution_time": 0.5323939323425293,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/setting_up_rl_environment_installing_openai_gym_and_using_python_based_framework.ipynb",
      "status": "failed",
      "execution_time": 0.7721443176269531,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/solving_rl_problems_defining_states_actions_and_rewards_running_rl_simulations.ipynb",
      "status": "passed",
      "execution_time": 1.4712660312652588,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/exercises/01_rl_fundamentals_and_mdps_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.5383148193359375,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/solutions/01_rl_fundamentals_and_mdps_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5314629077911377,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/01_q_learning.ipynb",
      "status": "failed",
      "execution_time": 0.7405750751495361,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Q-Table Heatmap\n# \u062a\u0635\u0648\u0631: \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q\ntry:\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    # Example Q-table (from training above)\n    q_table_example = np.array([[0.5, 0.8], [0.3, 0.9], [0.2, 0.7], [0.1, 0.6], [0.0, 0.0]])\n    \n    plt.figure(figsize=(8, 6))\n    plt.imshow(q_table_example, cmap='YlOrRd', aspect='auto')\n    plt.colorbar(label='Q-Value | \u0642\u064a\u0645\u0629 Q')\n    plt.xlabel('Actions | \u0627\u0644\u0625\u062c\u0631\u0627\u0621\u0627\u062a (Left, Right)', fontsize=12)\n    plt.ylabel('States | \u0627\u0644\u062d\u0627\u0644\u0627\u062a', fontsize=12)\n    plt.title('Q-Table Visualization | \u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q', fontsize=14, pad=20)\n    plt.xticks([0, 1], ['Left | \u064a\u0633\u0627\u0631', 'Right | \u064a\u0645\u064a\u0646'])\n    plt.yticks(range(5), [f'State {i}' for i in range(5)])\n    plt.tight_layout()\n    plt.show()\n    print(\"\u2705 Q-table heatmap displayed\")\nexcept ImportError:\n    print(\"Note: Install matplotlib and numpy for Q-table visualization\")\n    print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q\")\n\n\"\"\"\nUnit 2 - Example 1: Q-Learning Algorithm\n\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 Q-Learning\n\nThis example demonstrates:\n1. Q-learning algorithm\n2. Q-table initialization\n3. Q-value updates\n4. Policy extraction\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60)\nprint(\"Example 1: Q-Learning Algorithm\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 Q-Learning\")\nprint(\"=\" * 60)\n\n# Simple Grid World Environment\n# \u0628\u064a\u0626\u0629 \u0634\u0628\u0643\u0629 \u0628\u0633\u064a\u0637\u0629\n# States: 0, 1, 2, 3, 4 (4 is goal)\n# Actions: 0=left, 1=right\n\nclass SimpleGridWorld:\n    \"\"\"\n    Simple grid world for Q-learning demonstration.\n    \u0634\u0628\u0643\u0629 \u0628\u0633\u064a\u0637\u0629 \u0644\u0639\u0631\u0636 Q-learning.\n    \"\"\"\n    def__init__(self):\n        self.states = 5\n        self.actions = 2  # left, right\n        self.goal_state = 4\n        \n    def get_reward(self, state, action, next_state):\n        \"\"\"Get reward for transition.\"\"\"\n        if next_state == self.goal_state:\n            return 10.0  # Goal reward\n        return -0.1  # Small negative reward for each step\n    \n    def get_next_state(self, state, action):\n        \"\"\"Get next state after action.\"\"\"\n        if action == 0:  # left\n            return max(0, state - 1)\n        else:  # right\n            return min(self.states - 1, state + 1)\n\n# Initialize Q-table\n# \u062a\u0647\u064a\u0626\u0629 \u062c\u062f\u0648\u0644 Q\nenv = SimpleGridWorld()\nQ = np.zeros((env.states, env.actions))\n\nprint(\"\\nInitial Q-table:\")\nprint(\"\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0623\u0648\u0644\u064a:\")\nprint(Q)\n\n# Visualization: Q-Table Heatmap (After Training)\n# \u062a\u0635\u0648\u0631: \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q (\u0628\u0639\u062f \u0627\u0644\u062a\u062f\u0631\u064a\u0628)\ntry:\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 6))\n    im = plt.imshow(Q, cmap='YlOrRd', aspect='auto', interpolation='nearest')\n    plt.colorbar(im, label='Q-Value | \u0642\u064a\u0645\u0629 Q')\n    plt.xlabel('Actions | \u0627\u0644\u0625\u062c\u0631\u0627\u0621\u0627\u062a', fontsize=12, fontweight='bold')\n    plt.ylabel('States | \u0627\u0644\u062d\u0627\u0644\u0627\u062a', fontsize=12, fontweight='bold')\n    plt.title('Trained Q-Table Heatmap | \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0645\u062f\u0631\u0628', fontsize=14, pad=20, fontweight='bold')\n    plt.xticks([0, 1], ['Left | \u064a\u0633\u0627\u0631', 'Right | \u064a\u0645\u064a\u0646'])\n    plt.yticks(range(env.states), [f'State {i} | \u0627\u0644\u062d\u0627\u0644\u0629 {i}' for i in range(env.states)])\n    \n    # Add text annotations with Q-values\n    for i in range(env.states):\n        for j in range(env.actions):\n            text = plt.text(j, i, f'{Q[i, j]:.2f}', \n                           ha='center', va='center', \n                           color='white' if Q[i, j] > 0.5 else 'black',\n                           fontweight='bold', fontsize=11)\n    \n    plt.tight_layout()\n    plt.show()\n    print(\"\\n\u2705 Q-table heatmap visualization displayed\")\n    print(\"\u062a\u0645 \u0639\u0631\u0636 \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0628\u0646\u062c\u0627\u062d\")\nexcept ImportError:\n    print(\"\\n\u26a0\ufe0f  Install matplotlib for Q-table visualization:\")\n    print(\"   pip install matplotlib\")\n    print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q\")\n\n# Q-Learning parameters\n# \u0645\u0639\u0627\u0645\u0644\u0627\u062a Q-Learning\nalpha = 0.1  # Learning rate\ngamma = 0.9  # Discount factor\nepsilon = 0.1  # Exploration rate\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Q-Learning Training\")\nprint(\"\u062a\u062f\u0631\u064a\u0628 Q-Learning\")\nprint(\"=\" * 60)\n\n# Training loop\n# \u062d\u0644\u0642\u0629 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\nnum_episodes = 100\n\nfor episode in range(num_episodes):\n    state = 0  # Start state\n    \n    while state != env.goal_state:\n        # Epsilon-greedy action selection\n        # \u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0625\u062c\u0631\u0627\u0621 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 epsilon-greedy\n        if np.random.random() < epsilon:\n            action = np.random.randint(env.actions)  # Explore\n        else:\n            action = np.argmax(Q[state])  # Exploit\n        \n        # Take action\n        next_state = env.get_next_state(state, action)\n        reward = env.get_reward(state, action, next_state)\n        \n        # Q-learning update\n        # \u062a\u062d\u062f\u064a\u062b Q-learning\n        Q[state, action] = Q[state, action] + alpha * (\n            reward + gamma * np.max(Q[next_state]) - Q[state, action]\n        )\n        \n        state = next_state\n\nprint(\"\\nTrained Q-table:\")\nprint(\"\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0645\u062f\u0631\u0628:\")\nprint(Q)\n\n# Extract policy\n# \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0644\u0633\u064a\u0627\u0633\u0629\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Extracted Policy\")\nprint(\"\u0627\u0644\u0633\u064a\u0627\u0633\u0629 \u0627\u0644\u0645\u0633\u062a\u062e\u0631\u062c\u0629\")\nprint(\"=\" * 60)\n\npolicy = {}\nfor state in range(env.states):\n    best_action = np.argmax(Q[state])\n    action_name = \"left\" if best_action == 0 else \"right\"\n    policy[state] = action_name\n    print(f\"State {state}: {action_name}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n# Visualize Q-table as heatmap (after training)\n# \u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q \u0643\u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 (\u0628\u0639\u062f \u0627\u0644\u062a\u062f\u0631\u064a\u0628)\ntry:\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 7))\n    im = plt.imshow(Q, cmap='YlOrRd', aspect='auto', interpolation='nearest')\n    plt.colorbar(im, label='Q-Value | \u0642\u064a\u0645\u0629 Q', pad=0.02)\n    plt.xlabel('Actions | \u0627\u0644\u0625\u062c\u0631\u0627\u0621\u0627\u062a (0=Left/\u064a\u0633\u0627\u0631, 1=Right/\u064a\u0645\u064a\u0646)', \n               fontsize=13, fontweight='bold')\n    plt.ylabel('States | \u0627\u0644\u062d\u0627\u0644\u0627\u062a', fontsize=13, fontweight='bold')\n    plt.title('Trained Q-Table Heatmap | \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0645\u062f\u0631\u0628', fontsize=15, pad=20, fontweight='bold')\n    plt.xticks([0, 1], ['Left | \u064a\u0633\u0627\u0631', 'Right | \u064a\u0645\u064a\u0646'], fontsize=11)\n    plt.yticks(range(env.states), [f'State {i} | \u0627\u0644\u062d\u0627\u0644\u0629 {i}' for i in range(env.states)], fontsize=11)\n    \n    # Add Q-value annotations\n    for i in range(env.states):\n        for j in range(env.actions):\n            text = plt.text(j, i, f'{Q[i, j]:.2f}', \n                           ha='center', va='center', \n                           color='white' if Q[i, j] > np.max(Q) * 0.5 else 'black', fontweight='bold', fontsize=12)\n    \n    plt.tight_layout()\n    plt.show()\n    print(\"\\n\u2705 Q-table heatmap visualization displayed!\")\n    print(\"\u062a\u0645 \u0639\u0631\u0636 \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0628\u0646\u062c\u0627\u062d!\")\nexcept ImportError:\n    print(\"\\n\ud83d\udce6 To see Q-table visualization, install:\")\n    print(\"   pip install matplotlib\")\n    print(\"\\n\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0631\u0624\u064a\u0629 \u0627\u0644\u062a\u0635\u0648\u0631\u060c \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a:\")\n    print(\"   pip install matplotlib\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 53\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Q-Table Heatmap\n# \u062a\u0635\u0648\u0631: \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q\ntry:\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    # Example Q-table (from training above)\n    q_table_example = np.array([[0.5, 0.8], [0.3, 0.9], [0.2, 0.7], [0.1, 0.6], [0.0, 0.0]])\n    \n    plt.figure(figsize=(8, 6))\n    plt.imshow(q_table_example, cmap='YlOrRd', aspect='auto')\n    plt.colorbar(label='Q-Value | \u0642\u064a\u0645\u0629 Q')\n    plt.xlabel('Actions | \u0627\u0644\u0625\u062c\u0631\u0627\u0621\u0627\u062a (Left, Right)', fontsize=12)\n    plt.ylabel('States | \u0627\u0644\u062d\u0627\u0644\u0627\u062a', fontsize=12)\n    plt.title('Q-Table Visualization | \u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q', fontsize=14, pad=20)\n    plt.xticks([0, 1], ['Left | \u064a\u0633\u0627\u0631', 'Right | \u064a\u0645\u064a\u0646'])\n    plt.yticks(range(5), [f'State {i}' for i in range(5)])\n    plt.tight_layout()\n    plt.show()\n    print(\"\u2705 Q-table heatmap displayed\")\nexcept ImportError:\n    print(\"Note: Install matplotlib and numpy for Q-table visualization\")\n    print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q\")\n\n\"\"\"\nUnit 2 - Example 1: Q-Learning Algorithm\n\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 Q-Learning\n\nThis example demonstrates:\n1. Q-learning algorithm\n2. Q-table initialization\n3. Q-value updates\n4. Policy extraction\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60)\nprint(\"Example 1: Q-Learning Algorithm\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 Q-Learning\")\nprint(\"=\" * 60)\n\n# Simple Grid World Environment\n# \u0628\u064a\u0626\u0629 \u0634\u0628\u0643\u0629 \u0628\u0633\u064a\u0637\u0629\n# States: 0, 1, 2, 3, 4 (4 is goal)\n# Actions: 0=left, 1=right\n\nclass SimpleGridWorld:\n    \"\"\"\n    Simple grid world for Q-learning demonstration.\n    \u0634\u0628\u0643\u0629 \u0628\u0633\u064a\u0637\u0629 \u0644\u0639\u0631\u0636 Q-learning.\n    \"\"\"\n    def__init__(self):\n        self.states = 5\n        self.actions = 2  # left, right\n        self.goal_state = 4\n        \n    def get_reward(self, state, action, next_state):\n        \"\"\"Get reward for transition.\"\"\"\n        if next_state == self.goal_state:\n            return 10.0  # Goal reward\n        return -0.1  # Small negative reward for each step\n    \n    def get_next_state(self, state, action):\n        \"\"\"Get next state after action.\"\"\"\n        if action == 0:  # left\n            return max(0, state - 1)\n        else:  # right\n            return min(self.states - 1, state + 1)\n\n# Initialize Q-table\n# \u062a\u0647\u064a\u0626\u0629 \u062c\u062f\u0648\u0644 Q\nenv = SimpleGridWorld()\nQ = np.zeros((env.states, env.actions))\n\nprint(\"\\nInitial Q-table:\")\nprint(\"\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0623\u0648\u0644\u064a:\")\nprint(Q)\n\n# Visualization: Q-Table Heatmap (After Training)\n# \u062a\u0635\u0648\u0631: \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q (\u0628\u0639\u062f \u0627\u0644\u062a\u062f\u0631\u064a\u0628)\ntry:\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 6))\n    im = plt.imshow(Q, cmap='YlOrRd', aspect='auto', interpolation='nearest')\n    plt.colorbar(im, label='Q-Value | \u0642\u064a\u0645\u0629 Q')\n    plt.xlabel('Actions | \u0627\u0644\u0625\u062c\u0631\u0627\u0621\u0627\u062a', fontsize=12, fontweight='bold')\n    plt.ylabel('States | \u0627\u0644\u062d\u0627\u0644\u0627\u062a', fontsize=12, fontweight='bold')\n    plt.title('Trained Q-Table Heatmap | \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0645\u062f\u0631\u0628', fontsize=14, pad=20, fontweight='bold')\n    plt.xticks([0, 1], ['Left | \u064a\u0633\u0627\u0631', 'Right | \u064a\u0645\u064a\u0646'])\n    plt.yticks(range(env.states), [f'State {i} | \u0627\u0644\u062d\u0627\u0644\u0629 {i}' for i in range(env.states)])\n    \n    # Add text annotations with Q-values\n    for i in range(env.states):\n        for j in range(env.actions):\n            text = plt.text(j, i, f'{Q[i, j]:.2f}', \n                           ha='center', va='center', \n                           color='white' if Q[i, j] > 0.5 else 'black',\n                           fontweight='bold', fontsize=11)\n    \n    plt.tight_layout()\n    plt.show()\n    print(\"\\n\u2705 Q-table heatmap visualization displayed\")\n    print(\"\u062a\u0645 \u0639\u0631\u0636 \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0628\u0646\u062c\u0627\u062d\")\nexcept ImportError:\n    print(\"\\n\u26a0\ufe0f  Install matplotlib for Q-table visualization:\")\n    print(\"   pip install matplotlib\")\n    print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q\")\n\n# Q-Learning parameters\n# \u0645\u0639\u0627\u0645\u0644\u0627\u062a Q-Learning\nalpha = 0.1  # Learning rate\ngamma = 0.9  # Discount factor\nepsilon = 0.1  # Exploration rate\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Q-Learning Training\")\nprint(\"\u062a\u062f\u0631\u064a\u0628 Q-Learning\")\nprint(\"=\" * 60)\n\n# Training loop\n# \u062d\u0644\u0642\u0629 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\nnum_episodes = 100\n\nfor episode in range(num_episodes):\n    state = 0  # Start state\n    \n    while state != env.goal_state:\n        # Epsilon-greedy action selection\n        # \u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0625\u062c\u0631\u0627\u0621 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 epsilon-greedy\n        if np.random.random() < epsilon:\n            action = np.random.randint(env.actions)  # Explore\n        else:\n            action = np.argmax(Q[state])  # Exploit\n        \n        # Take action\n        next_state = env.get_next_state(state, action)\n        reward = env.get_reward(state, action, next_state)\n        \n        # Q-learning update\n        # \u062a\u062d\u062f\u064a\u062b Q-learning\n        Q[state, action] = Q[state, action] + alpha * (\n            reward + gamma * np.max(Q[next_state]) - Q[state, action]\n        )\n        \n        state = next_state\n\nprint(\"\\nTrained Q-table:\")\nprint(\"\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0645\u062f\u0631\u0628:\")\nprint(Q)\n\n# Extract policy\n# \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0644\u0633\u064a\u0627\u0633\u0629\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Extracted Policy\")\nprint(\"\u0627\u0644\u0633\u064a\u0627\u0633\u0629 \u0627\u0644\u0645\u0633\u062a\u062e\u0631\u062c\u0629\")\nprint(\"=\" * 60)\n\npolicy = {}\nfor state in range(env.states):\n    best_action = np.argmax(Q[state])\n    action_name = \"left\" if best_action == 0 else \"right\"\n    policy[state] = action_name\n    print(f\"State {state}: {action_name}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n# Visualize Q-table as heatmap (after training)\n# \u062a\u0635\u0648\u0631 \u062c\u062f\u0648\u0644 Q \u0643\u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 (\u0628\u0639\u062f \u0627\u0644\u062a\u062f\u0631\u064a\u0628)\ntry:\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 7))\n    im = plt.imshow(Q, cmap='YlOrRd', aspect='auto', interpolation='nearest')\n    plt.colorbar(im, label='Q-Value | \u0642\u064a\u0645\u0629 Q', pad=0.02)\n    plt.xlabel('Actions | \u0627\u0644\u0625\u062c\u0631\u0627\u0621\u0627\u062a (0=Left/\u064a\u0633\u0627\u0631, 1=Right/\u064a\u0645\u064a\u0646)', \n               fontsize=13, fontweight='bold')\n    plt.ylabel('States | \u0627\u0644\u062d\u0627\u0644\u0627\u062a', fontsize=13, fontweight='bold')\n    plt.title('Trained Q-Table Heatmap | \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0627\u0644\u0645\u062f\u0631\u0628', fontsize=15, pad=20, fontweight='bold')\n    plt.xticks([0, 1], ['Left | \u064a\u0633\u0627\u0631', 'Right | \u064a\u0645\u064a\u0646'], fontsize=11)\n    plt.yticks(range(env.states), [f'State {i} | \u0627\u0644\u062d\u0627\u0644\u0629 {i}' for i in range(env.states)], fontsize=11)\n    \n    # Add Q-value annotations\n    for i in range(env.states):\n        for j in range(env.actions):\n            text = plt.text(j, i, f'{Q[i, j]:.2f}', \n                           ha='center', va='center', \n                           color='white' if Q[i, j] > np.max(Q) * 0.5 else 'black', fontweight='bold', fontsize=12)\n    \n    plt.tight_layout()\n    plt.show()\n    print(\"\\n\u2705 Q-table heatmap visualization displayed!\")\n    print(\"\u062a\u0645 \u0639\u0631\u0636 \u062e\u0631\u064a\u0637\u0629 \u062d\u0631\u0627\u0631\u064a\u0629 \u0644\u062c\u062f\u0648\u0644 Q \u0628\u0646\u062c\u0627\u062d!\")\nexcept ImportError:\n    print(\"\\n\ud83d\udce6 To see Q-table visualization, install:\")\n    print(\"   pip install matplotlib\")\n    print(\"\\n\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0631\u0624\u064a\u0629 \u0627\u0644\u062a\u0635\u0648\u0631\u060c \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a:\")\n    print(\"   pip install matplotlib\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 53\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/02_sarsa_algorithm.ipynb",
      "status": "passed",
      "execution_time": 1.0409669876098633,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/03_policy_gradient_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8732700347900391,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/04_monte_carlo_value_estimation.ipynb",
      "status": "failed",
      "execution_time": 0.9021110534667969,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: First-Visit Monte Carlo Implementation\")\nprint(\"=\" * 60)\n\ndef generate_episode(policy, env, max_steps=100):\n \n    \n    \"\"\"Generate an episode following the policy.\"\"\"\n episode = []\n state = env.reset()[0] if hasattr(env.reset(), '__len__') else env.reset()\n \n for step in range(max_steps):\n # Choose action based on policy\n if isinstance(policy, dict):\n action = policy.get(state, random.choice(range(env.action_space.n)))\n else:\n action = policy(state)\n \n # Take action (simplified - assuming env.step returns tuple)\n if hasattr(env, 'step'):\n next_state, reward, done, truncated, info = env.step(action) if hasattr(env.step(action), '__len__') and len(env.step(action)) > 1 else (None, 0, True, False, {})\n if isinstance(env.step(action), tuple) and len(env.step(action)) >= 2:\n next_state, reward = env.step(action)[:2]\n done = env.step(action)[2] if len(env.step(action)) > 2 else Falseelse:\n next_state, reward, done = state, 0, Trueelse:\n next_state, reward, done = state, 0, True\n \n episode.append((state, action, reward))\n state = next_state\n \n if done:\n break\n \n return episode\n\ndef first_visit_mc(policy, env, n_episodes=1000, gamma=0.99):\n \n    \n    \"\"\"\n First-visit Monte Carlo for estimating state values.\n \"\"\"\n returns = defaultdict(list)\n V = defaultdict(float)\n \n for episode_num in range(n_episodes):\n episode = generate_episode(policy, env)\n \n # Calculate returns\n G = 0\n visited_states = set()\n \n # Process episode backwards\n for t in reversed(range(len(episode))):\n state, action, reward = episode[t]\n G = gamma * G + reward\n \n # First-visit: only update if state not visited yet in this episode\n if state not in visited_states:\n visited_states.add(state)\n returns[state].append(G)\n V[state] = np.mean(returns[state])\n \n return V, returns\n\n# Simple example: Random walk\nprint(\"\\nExample: Simple Random Walk\")\nprint(\" States: [0, 1, 2, 3, 4]\")\nprint(\" Actions: Move left (-1) or right (+1)\")\nprint(\" Goal: Estimate state values\")\n\n# Simplified environment simulation\nclass SimpleRandomWalk:\n \ndef__init__(self):\n self.state = 2\n self.n_states = 5\n \n def reset(self):\n self.state = 2\n return self.state\n \n def step(self, action):\n self.state = max(0, min(4, self.state + action))\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state in [0, 4]\n return self.state, reward, done\n \n @property\n def action_space(self):\n class Space:\n n = 2\n return Space()\n\n# Random policy\ndef random_policy(state):\n return random.choice([-1, 1])\n\nenv_simple = SimpleRandomWalk()\nV_mc, returns_mc = first_visit_mc(random_policy, env_simple, n_episodes=100, gamma=1.0)\n\nprint(f\"\\nEstimated State Values (First-Visit MC):\")\nfor state in sorted(V_mc.keys()):\n print(f\" V({state}) = {V_mc[state]:.4f} (from {len(returns_mc[state])} visits)\")\n\nprint(\"\\n\u2705 First-visit Monte Carlo implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    episode = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: First-Visit Monte Carlo Implementation\")\nprint(\"=\" * 60)\n\ndef generate_episode(policy, env, max_steps=100):\n \n    \n    \"\"\"Generate an episode following the policy.\"\"\"\n episode = []\n state = env.reset()[0] if hasattr(env.reset(), '__len__') else env.reset()\n \n for step in range(max_steps):\n # Choose action based on policy\n if isinstance(policy, dict):\n action = policy.get(state, random.choice(range(env.action_space.n)))\n else:\n action = policy(state)\n \n # Take action (simplified - assuming env.step returns tuple)\n if hasattr(env, 'step'):\n next_state, reward, done, truncated, info = env.step(action) if hasattr(env.step(action), '__len__') and len(env.step(action)) > 1 else (None, 0, True, False, {})\n if isinstance(env.step(action), tuple) and len(env.step(action)) >= 2:\n next_state, reward = env.step(action)[:2]\n done = env.step(action)[2] if len(env.step(action)) > 2 else Falseelse:\n next_state, reward, done = state, 0, Trueelse:\n next_state, reward, done = state, 0, True\n \n episode.append((state, action, reward))\n state = next_state\n \n if done:\n break\n \n return episode\n\ndef first_visit_mc(policy, env, n_episodes=1000, gamma=0.99):\n \n    \n    \"\"\"\n First-visit Monte Carlo for estimating state values.\n \"\"\"\n returns = defaultdict(list)\n V = defaultdict(float)\n \n for episode_num in range(n_episodes):\n episode = generate_episode(policy, env)\n \n # Calculate returns\n G = 0\n visited_states = set()\n \n # Process episode backwards\n for t in reversed(range(len(episode))):\n state, action, reward = episode[t]\n G = gamma * G + reward\n \n # First-visit: only update if state not visited yet in this episode\n if state not in visited_states:\n visited_states.add(state)\n returns[state].append(G)\n V[state] = np.mean(returns[state])\n \n return V, returns\n\n# Simple example: Random walk\nprint(\"\\nExample: Simple Random Walk\")\nprint(\" States: [0, 1, 2, 3, 4]\")\nprint(\" Actions: Move left (-1) or right (+1)\")\nprint(\" Goal: Estimate state values\")\n\n# Simplified environment simulation\nclass SimpleRandomWalk:\n \ndef__init__(self):\n self.state = 2\n self.n_states = 5\n \n def reset(self):\n self.state = 2\n return self.state\n \n def step(self, action):\n self.state = max(0, min(4, self.state + action))\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state in [0, 4]\n return self.state, reward, done\n \n @property\n def action_space(self):\n class Space:\n n = 2\n return Space()\n\n# Random policy\ndef random_policy(state):\n return random.choice([-1, 1])\n\nenv_simple = SimpleRandomWalk()\nV_mc, returns_mc = first_visit_mc(random_policy, env_simple, n_episodes=100, gamma=1.0)\n\nprint(f\"\\nEstimated State Values (First-Visit MC):\")\nfor state in sorted(V_mc.keys()):\n print(f\" V({state}) = {V_mc[state]:.4f} (from {len(returns_mc[state])} visits)\")\n\nprint(\"\\n\u2705 First-visit Monte Carlo implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    episode = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/05_td_algorithms_td0_nstep.ipynb",
      "status": "failed",
      "execution_time": 0.6872308254241943,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: TD(0) Implementation\")\nprint(\"=\" * 60)\n\ndef td0(policy, env_simulator, n_episodes=100, alpha=0.1, gamma=0.99):\n \n    \n    \"\"\"\n TD(0) for estimating state values.\n V(S_t) \u2190 V(S_t) + \u03b1[R_{t+1} + \u03b3V(S_{t+1}) - V(S_t)]\n \"\"\"\n V = defaultdict(float)\n \n for episode in range(n_episodes):\n state = env_simulator.reset()\n done = False\n \n while not done:\n # Choose action (simplified)\n action = policy(state) if callable(policy) else policy.get(state, 0)\n \n # Take step (simplified - assuming env interface)\n next_state, reward, done = env_simulator.step(action)\n \n # TD(0) update\n td_target = reward + gamma * V[next_state]\n td_error = td_target - V[state]\n V[state] = V[state] + alpha * td_error\n \n state = next_state\n \n return V\n\n# Simple example\nclass SimpleEnv:\n \ndef__init__(self):\n self.state = 1\n self.n_states = 5\n \n def reset(self):\n self.state = 1\n return self.state\n \n def step(self, action):\n # Simple transition: move towards goal (state 4)\n if self.state < 4:\n self.state += 1\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state == 4\n return self.state, reward, done\n\nenv = SimpleEnv()\ndef simple_policy(state):\n return 1 # Always move forward\n\nV_td0 = td0(simple_policy, env, n_episodes=100, alpha=0.1, gamma=1.0)\n\nprint(\"\\nTD(0) Estimated State Values:\")\nfor state in sorted(V_td0.keys()):\n print(f\" V({state}) = {V_td0[state]:.4f}\")\n\nprint(\"\\n\u2705 TD(0) implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    V = defaultdict(float)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: TD(0) Implementation\")\nprint(\"=\" * 60)\n\ndef td0(policy, env_simulator, n_episodes=100, alpha=0.1, gamma=0.99):\n \n    \n    \"\"\"\n TD(0) for estimating state values.\n V(S_t) \u2190 V(S_t) + \u03b1[R_{t+1} + \u03b3V(S_{t+1}) - V(S_t)]\n \"\"\"\n V = defaultdict(float)\n \n for episode in range(n_episodes):\n state = env_simulator.reset()\n done = False\n \n while not done:\n # Choose action (simplified)\n action = policy(state) if callable(policy) else policy.get(state, 0)\n \n # Take step (simplified - assuming env interface)\n next_state, reward, done = env_simulator.step(action)\n \n # TD(0) update\n td_target = reward + gamma * V[next_state]\n td_error = td_target - V[state]\n V[state] = V[state] + alpha * td_error\n \n state = next_state\n \n return V\n\n# Simple example\nclass SimpleEnv:\n \ndef__init__(self):\n self.state = 1\n self.n_states = 5\n \n def reset(self):\n self.state = 1\n return self.state\n \n def step(self, action):\n # Simple transition: move towards goal (state 4)\n if self.state < 4:\n self.state += 1\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state == 4\n return self.state, reward, done\n\nenv = SimpleEnv()\ndef simple_policy(state):\n return 1 # Always move forward\n\nV_td0 = td0(simple_policy, env, n_episodes=100, alpha=0.1, gamma=1.0)\n\nprint(\"\\nTD(0) Estimated State Values:\")\nfor state in sorted(V_td0.keys()):\n print(f\" V({state}) = {V_td0[state]:.4f}\")\n\nprint(\"\\n\u2705 TD(0) implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    V = defaultdict(float)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/06_policy_vs_value_iteration_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.7800381183624268,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/applying_q_learning_and_sarsa_in_openai_gym_cartpole_frozenlake.ipynb",
      "status": "failed",
      "execution_time": 0.7367839813232422,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/comparing_policy_iteration_vs_value_iteration_through_code_based_experiments.ipynb",
      "status": "passed",
      "execution_time": 1.7430541515350342,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/implementing_monte_carlo_methods_for_estimating_value_functions.ipynb",
      "status": "passed",
      "execution_time": 1.6263008117675781,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/running_td0_and_n_step_td_algorithms_in_simple_rl_environments.ipynb",
      "status": "failed",
      "execution_time": 0.5346620082855225,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/using_python_to_update_q_tables_and_display_agent_learning_progress.ipynb",
      "status": "passed",
      "execution_time": 1.6301031112670898,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/exercises/01_q_learning_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.6871278285980225,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit2-policy-value/solutions/01_q_learning_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5320408344268799,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass GridWorld:\n    \n\ndef__init__(self, size=5):\n        self.size = size_self.start = (0, 0)\n        self.goal = (size-1, size-1)\n        self.agent_pos = self.start\n    \n    def reset(self):\n        self.agent_pos = self.start\n        return self.agent_pos\n    \n    def step(self, action):\n        moves = {0: (-1,0), 1: (1,0), 2: (0,-1), 3: (0,1)}\n        dx, dy = moves[action]_new_pos =  (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        new_pos = (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        \n        if 0 <= new_pos[0] < self.size and 0 <= new_pos[1] < self.size:\n            self.agent_pos = new_pos_reward = 10 if self.agent_pos == self.goal else -1_done = self.agent_pos == self.goal\n        return self.agent_pos, reward, done\n\nclass QLearningAgent:\n    \n\ndef__init__(self, n_states, n_actions, lr=0.1, gamma=0.95, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr_self.gamma = gamma_self.epsilon = epsilon\n    \n    def select_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(4)\n        return np.argmax(self.q_table[state])\n    \n    def update(self, state, action, reward, next_state, done):\n        if done:\n            target = reward\n        else:\n            target = reward + self.gamma * np.max(self.q_table[next_state])\n        self.q_table[state, action] += self.lr * (target - self.q_table[state, action])\n\nprint('\u2705 Q-learning solution implemented')\nprint('\\nTeaching Notes: Q-table updates, epsilon-greedy exploration')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def reset(self):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass GridWorld:\n    \n\ndef__init__(self, size=5):\n        self.size = size_self.start = (0, 0)\n        self.goal = (size-1, size-1)\n        self.agent_pos = self.start\n    \n    def reset(self):\n        self.agent_pos = self.start\n        return self.agent_pos\n    \n    def step(self, action):\n        moves = {0: (-1,0), 1: (1,0), 2: (0,-1), 3: (0,1)}\n        dx, dy = moves[action]_new_pos =  (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        new_pos = (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        \n        if 0 <= new_pos[0] < self.size and 0 <= new_pos[1] < self.size:\n            self.agent_pos = new_pos_reward = 10 if self.agent_pos == self.goal else -1_done = self.agent_pos == self.goal\n        return self.agent_pos, reward, done\n\nclass QLearningAgent:\n    \n\ndef__init__(self, n_states, n_actions, lr=0.1, gamma=0.95, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr_self.gamma = gamma_self.epsilon = epsilon\n    \n    def select_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(4)\n        return np.argmax(self.q_table[state])\n    \n    def update(self, state, action, reward, next_state, done):\n        if done:\n            target = reward\n        else:\n            target = reward + self.gamma * np.max(self.q_table[next_state])\n        self.q_table[state, action] += self.lr * (target - self.q_table[state, action])\n\nprint('\u2705 Q-learning solution implemented')\nprint('\\nTeaching Notes: Q-table updates, epsilon-greedy exploration')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def reset(self):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "other"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/01_dqn_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.7434830665588379,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/02_actor_critic.ipynb",
      "status": "failed",
      "execution_time": 2.0581676959991455,
      "error": "An error occurred while executing the following cell:\n------------------\nclass ActorCritic(nn.Module):\n    \"\"\"\n    Actor-Critic network.\n    Actor: Policy network (outputs action probabilities)\n    Critic: Value network (estimates state values)\n    \"\"\"\n    def__init__(self, state_dim, action_dim, hidden_dim=128):\n        super().__init__()\n        \n        # Shared feature extractor\n        self.shared = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.ReLU(), nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        \n        # Actor (policy)\n        self.actor = nn.Sequential(\n            nn.Linear(hidden_dim, action_dim),\n            nn.Softmax(dim=-1)\n        )\n        \n        # Critic (value)\n        self.critic = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, state):\n        features = self.shared(state)\n        action_probs = self.actor(features)\n        value = self.critic(features)\n        return action_probs, value\n\nprint('\u2705 Actor-Critic architecture defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, state_dim, action_dim, hidden_dim=128):\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass ActorCritic(nn.Module):\n    \"\"\"\n    Actor-Critic network.\n    Actor: Policy network (outputs action probabilities)\n    Critic: Value network (estimates state values)\n    \"\"\"\n    def__init__(self, state_dim, action_dim, hidden_dim=128):\n        super().__init__()\n        \n        # Shared feature extractor\n        self.shared = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.ReLU(), nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        \n        # Actor (policy)\n        self.actor = nn.Sequential(\n            nn.Linear(hidden_dim, action_dim),\n            nn.Softmax(dim=-1)\n        )\n        \n        # Critic (value)\n        self.critic = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, state):\n        features = self.shared(state)\n        action_probs = self.actor(features)\n        value = self.critic(features)\n        return action_probs, value\n\nprint('\u2705 Actor-Critic architecture defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, state_dim, action_dim, hidden_dim=128):\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/03_ppo_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.9750328063964844,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/04_training_evaluation_monitoring.ipynb",
      "status": "failed",
      "execution_time": 0.8021581172943115,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Monitoring Learning Curves\")\nprint(\"=\" * 60)\n\nclass TrainingMonitor:\n    \"\"\"Monitor training progress for Deep RL.\"\"\"\n    \n    def__init__(self, window_size=100):\n        self.episode_rewards = []\n        self.episode_lengths = []\n        self.window_size = window_size\n        self.reward_window = deque(maxlen=window_size)\n    \n    def record_episode(self, reward, length):\n        \"\"\"Record an episode's results.\"\"\"\n        self.episode_rewards.append(reward)\n        self.episode_lengths.append(length)\n        self.reward_window.append(reward)\n    \n    def get_average_reward(self):\n        \"\"\"Get average reward over window.\"\"\"\n        return np.mean(self.reward_window) if self.reward_window else 0.0\n    \n    def plot_learning_curve(self):\n        \"\"\"Plot learning curves.\"\"\"\n        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n        \n        # Plot 1: Episode Rewards\n        axes[0].plot(self.episode_rewards, alpha=0.3, label='Raw rewards', color='blue')\n        if len(self.episode_rewards) >= self.window_size:\n            smoothed = [np.mean(self.episode_rewards[max(0, i-self.window_size):i+1]) \n                       for i in range(len(self.episode_rewards))]\n            axes[0].plot(smoothed, label=f'Smoothed (window={self.window_size})', \n                        color='red', linewidth=2)\n        axes[0].set_xlabel('Episode')\n        axes[0].set_ylabel('Reward')\n        axes[0].set_title('Learning Curve: Episode Rewards')\n        axes[0].legend()\n        axes[0].grid(True, alpha=0.3)\n        \n        # Plot 2: Episode Lengths\n        axes[1].plot(self.episode_lengths, alpha=0.3, label='Episode lengths', color='green')\n        if len(self.episode_lengths) >= self.window_size:\n            smoothed_lengths = [np.mean(self.episode_lengths[max(0, i-self.window_size):i+1]) \n                               for i in range(len(self.episode_lengths))]\n            axes[1].plot(smoothed_lengths, label=f'Smoothed (window={self.window_size})', \n                        color='orange', linewidth=2)\n        axes[1].set_xlabel('Episode')\n        axes[1].set_ylabel('Episode Length')\n        axes[1].set_title('Learning Curve: Episode Lengths')\n        axes[1].legend()\n        axes[1].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n\n# Simulate training data\nmonitor = TrainingMonitor(window_size=50)\n\n# Simulate training progress (improving over time)\nnp.random.seed(42)\nfor episode in range(200):\n    # Simulate improving performance\n    base_reward = 20 + episode * 0.5 + np.random.normal(0, 5)\n    reward = max(0, base_reward)\n    length = int(50 + episode * 0.3 + np.random.normal(0, 10))\n    length = max(1, length)\n    monitor.record_episode(reward, length)\n\nprint(f\"\\nTraining Statistics:\")\nprint(f\"  Total episodes: {len(monitor.episode_rewards)}\")\nprint(f\"  Average reward (final 50 episodes): {monitor.get_average_reward():.2f}\")\nprint(f\"  Best episode reward: {max(monitor.episode_rewards):.2f}\")\nprint(f\"  Average episode length: {np.mean(monitor.episode_lengths):.2f}\")\n\nmonitor.plot_learning_curve()\n\nprint(\"\\n\u2705 Learning curves monitored!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, window_size=100):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Monitoring Learning Curves\")\nprint(\"=\" * 60)\n\nclass TrainingMonitor:\n    \"\"\"Monitor training progress for Deep RL.\"\"\"\n    \n    def__init__(self, window_size=100):\n        self.episode_rewards = []\n        self.episode_lengths = []\n        self.window_size = window_size\n        self.reward_window = deque(maxlen=window_size)\n    \n    def record_episode(self, reward, length):\n        \"\"\"Record an episode's results.\"\"\"\n        self.episode_rewards.append(reward)\n        self.episode_lengths.append(length)\n        self.reward_window.append(reward)\n    \n    def get_average_reward(self):\n        \"\"\"Get average reward over window.\"\"\"\n        return np.mean(self.reward_window) if self.reward_window else 0.0\n    \n    def plot_learning_curve(self):\n        \"\"\"Plot learning curves.\"\"\"\n        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n        \n        # Plot 1: Episode Rewards\n        axes[0].plot(self.episode_rewards, alpha=0.3, label='Raw rewards', color='blue')\n        if len(self.episode_rewards) >= self.window_size:\n            smoothed = [np.mean(self.episode_rewards[max(0, i-self.window_size):i+1]) \n                       for i in range(len(self.episode_rewards))]\n            axes[0].plot(smoothed, label=f'Smoothed (window={self.window_size})', \n                        color='red', linewidth=2)\n        axes[0].set_xlabel('Episode')\n        axes[0].set_ylabel('Reward')\n        axes[0].set_title('Learning Curve: Episode Rewards')\n        axes[0].legend()\n        axes[0].grid(True, alpha=0.3)\n        \n        # Plot 2: Episode Lengths\n        axes[1].plot(self.episode_lengths, alpha=0.3, label='Episode lengths', color='green')\n        if len(self.episode_lengths) >= self.window_size:\n            smoothed_lengths = [np.mean(self.episode_lengths[max(0, i-self.window_size):i+1]) \n                               for i in range(len(self.episode_lengths))]\n            axes[1].plot(smoothed_lengths, label=f'Smoothed (window={self.window_size})', \n                        color='orange', linewidth=2)\n        axes[1].set_xlabel('Episode')\n        axes[1].set_ylabel('Episode Length')\n        axes[1].set_title('Learning Curve: Episode Lengths')\n        axes[1].legend()\n        axes[1].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n\n# Simulate training data\nmonitor = TrainingMonitor(window_size=50)\n\n# Simulate training progress (improving over time)\nnp.random.seed(42)\nfor episode in range(200):\n    # Simulate improving performance\n    base_reward = 20 + episode * 0.5 + np.random.normal(0, 5)\n    reward = max(0, base_reward)\n    length = int(50 + episode * 0.3 + np.random.normal(0, 10))\n    length = max(1, length)\n    monitor.record_episode(reward, length)\n\nprint(f\"\\nTraining Statistics:\")\nprint(f\"  Total episodes: {len(monitor.episode_rewards)}\")\nprint(f\"  Average reward (final 50 episodes): {monitor.get_average_reward():.2f}\")\nprint(f\"  Best episode reward: {max(monitor.episode_rewards):.2f}\")\nprint(f\"  Average episode length: {np.mean(monitor.episode_lengths):.2f}\")\n\nmonitor.plot_learning_curve()\n\nprint(\"\\n\u2705 Learning curves monitored!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, window_size=100):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/05_optimization_experience_replay_reward_shaping.ipynb",
      "status": "failed",
      "execution_time": 0.776141881942749,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Experience Replay\")\nprint(\"=\" * 60)\n\nclass ReplayBuffer:\n    \"\"\"Experience replay buffer for storing and sampling transitions.\"\"\"\n    \n    def__init__(self, capacity=10000):\n        self.buffer = deque(maxlen=capacity)\n        self.capacity = capacity\n    \n    def push(self, state, action, reward, next_state, done):\n        \"\"\"Store a transition.\"\"\"\n        self.buffer.append((state, action, reward, next_state, done))\n    \n    def sample(self, batch_size):\n        \"\"\"Sample a batch of transitions.\"\"\"\n        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n        states, actions, rewards, next_states, dones = zip(*batch)\n        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n    \n    def__len__(self):\n        return len(self.buffer)\n\n# Example usage\nbuffer = ReplayBuffer(capacity=1000)\n\n# Simulate storing experiences\nfor i in range(100):\n    state = np.random.randn(4)\n    action = random.randint(0, 1)\n    reward = random.random()\n    next_state = np.random.randn(4)\n    done = False\n    buffer.push(state, action, reward, next_state, done)\n\nprint(f\"\\nReplay Buffer:\")\nprint(f\"  Capacity: {buffer.capacity}\")\nprint(f\"  Current size: {len(buffer)}\")\n\n# Sample a batch\nbatch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = buffer.sample(32)\nprint(f\"  Sampled batch size: {len(batch_states)}\")\n\nprint(\"\\nExperience Replay Benefits:\")\nprint(\"  - Breaks correlation between consecutive samples\")\nprint(\"  - Reuses past experiences (sample efficiency)\")\nprint(\"  - Stabilizes training\")\nprint(\"  - Enables off-policy learning\")\n\nprint(\"\\n\u2705 Experience replay implemented!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, capacity=10000):\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Experience Replay\")\nprint(\"=\" * 60)\n\nclass ReplayBuffer:\n    \"\"\"Experience replay buffer for storing and sampling transitions.\"\"\"\n    \n    def__init__(self, capacity=10000):\n        self.buffer = deque(maxlen=capacity)\n        self.capacity = capacity\n    \n    def push(self, state, action, reward, next_state, done):\n        \"\"\"Store a transition.\"\"\"\n        self.buffer.append((state, action, reward, next_state, done))\n    \n    def sample(self, batch_size):\n        \"\"\"Sample a batch of transitions.\"\"\"\n        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n        states, actions, rewards, next_states, dones = zip(*batch)\n        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n    \n    def__len__(self):\n        return len(self.buffer)\n\n# Example usage\nbuffer = ReplayBuffer(capacity=1000)\n\n# Simulate storing experiences\nfor i in range(100):\n    state = np.random.randn(4)\n    action = random.randint(0, 1)\n    reward = random.random()\n    next_state = np.random.randn(4)\n    done = False\n    buffer.push(state, action, reward, next_state, done)\n\nprint(f\"\\nReplay Buffer:\")\nprint(f\"  Capacity: {buffer.capacity}\")\nprint(f\"  Current size: {len(buffer)}\")\n\n# Sample a batch\nbatch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = buffer.sample(32)\nprint(f\"  Sampled batch size: {len(batch_states)}\")\n\nprint(\"\\nExperience Replay Benefits:\")\nprint(\"  - Breaks correlation between consecutive samples\")\nprint(\"  - Reuses past experiences (sample efficiency)\")\nprint(\"  - Stabilizes training\")\nprint(\"  - Enables off-policy learning\")\n\nprint(\"\\n\u2705 Experience replay implemented!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, capacity=10000):\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/applications_applying_deep_rl_in_games_robotics_and_optimization_tasks_in_simula.ipynb",
      "status": "passed",
      "execution_time": 1.6623878479003906,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/handling_challenges_working_on_exploration_vs_exploitation_problems_stability_an.ipynb",
      "status": "passed",
      "execution_time": 1.539309024810791,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/implementing_deep_rl_starting_with_simple_algorithms_like_dqn_and_progressing_to.ipynb",
      "status": "passed",
      "execution_time": 1.5149919986724854,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/optimization_experimenting_with_techniques_like_experience_replay_reward_shaping.ipynb",
      "status": "passed",
      "execution_time": 1.515528917312622,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/training_and_evaluation_monitoring_learning_curves_rewards_and_stability_to_eval.ipynb",
      "status": "passed",
      "execution_time": 1.5585331916809082,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/exercises/01_deep_reinforcement_learning_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.8233439922332764,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit3-deep-rl/solutions/01_deep_reinforcement_learning_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7435834407806396,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "other"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/01_exploration_strategies.ipynb",
      "status": "passed",
      "execution_time": 0.8031318187713623,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/02_balancing_exploration.ipynb",
      "status": "failed",
      "execution_time": 1.7670819759368896,
      "error": "An error occurred while executing the following cell:\n------------------\nclass ThompsonSampling:\n    \"\"\"\n    Thompson Sampling for multi-armed bandit.\n    \n    Real-world: A/B testing, recommendation systems\n    \"\"\"\n    def__init__(self, n_arms):\n        self.n_arms = n_arms\n        self.successes = np.zeros(n_arms)\n        self.failures = np.zeros(n_arms)\n    \n    def select_arm(self):\n        \"\"\"Select arm using Thompson Sampling\"\"\"\n        samples = []\n        for arm in range(self.n_arms):\n            # Sample from Beta distribution\n            sample = beta.rvs(self.successes[arm] + 1, self.failures[arm] + 1)\n            samples.append(sample)\n        return np.argmax(samples)\n    \n    def update(self, arm, reward):\n        \"\"\"Update arm statistics\"\"\"\n        if reward > 0:\n            self.successes[arm] += 1\n        else:\n            self.failures[arm] += 1\n\nprint('\u2705 Thompson Sampling implemented')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_arms):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass ThompsonSampling:\n    \"\"\"\n    Thompson Sampling for multi-armed bandit.\n    \n    Real-world: A/B testing, recommendation systems\n    \"\"\"\n    def__init__(self, n_arms):\n        self.n_arms = n_arms\n        self.successes = np.zeros(n_arms)\n        self.failures = np.zeros(n_arms)\n    \n    def select_arm(self):\n        \"\"\"Select arm using Thompson Sampling\"\"\"\n        samples = []\n        for arm in range(self.n_arms):\n            # Sample from Beta distribution\n            sample = beta.rvs(self.successes[arm] + 1, self.failures[arm] + 1)\n            samples.append(sample)\n        return np.argmax(samples)\n    \n    def update(self, arm, reward):\n        \"\"\"Update arm statistics\"\"\"\n        if reward > 0:\n            self.successes[arm] += 1\n        else:\n            self.failures[arm] += 1\n\nprint('\u2705 Thompson Sampling implemented')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_arms):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/03_adaptive_exploration_ucb.ipynb",
      "status": "failed",
      "execution_time": 0.74310302734375,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass UCB:\n    def__init__(self, n_arms):\n        self.n_arms = n_arms\n        self.counts = np.zeros(n_arms)\n        self.values = np.zeros(n_arms)\n    \n    def select_arm(self, t):\n        # TODO: Implement UCB arm selection\n        # UCB = mean + confidence_bound\n        pass\n    \n    def update(self, arm, reward):\n        # TODO: Update arm statistics\n        pass\n\nprint('UCB algorithm defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_arms):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass UCB:\n    def__init__(self, n_arms):\n        self.n_arms = n_arms\n        self.counts = np.zeros(n_arms)\n        self.values = np.zeros(n_arms)\n    \n    def select_arm(self, t):\n        # TODO: Implement UCB arm selection\n        # UCB = mean + confidence_bound\n        pass\n    \n    def update(self, arm, reward):\n        # TODO: Update arm statistics\n        pass\n\nprint('UCB algorithm defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_arms):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/04_comparing_exploration_methods.ipynb",
      "status": "passed",
      "execution_time": 0.9002389907836914,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/05_tuning_exploration_parameters.ipynb",
      "status": "passed",
      "execution_time": 0.9961428642272949,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/comparing_performance_of_different_exploration_methods.ipynb",
      "status": "passed",
      "execution_time": 1.5449726581573486,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/tuning_exploration_parameters.ipynb",
      "status": "passed",
      "execution_time": 1.548017978668213,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/exercises/02_exploration_exercise.ipynb",
      "status": "failed",
      "execution_time": 1.5663459300994873,
      "error": "An error occurred while executing the following cell:\n------------------\n# TODO: Implement MultiArmedBandit class\nclass MultiArmedBandit:\n    def__init__(self, n_arms, true_rewards):\n        # YOUR CODE HERE\n        pass\n    \n    def pull(self, arm):\n        # YOUR CODE HERE\n        pass\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_arms, true_rewards):\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# TODO: Implement MultiArmedBandit class\nclass MultiArmedBandit:\n    def__init__(self, n_arms, true_rewards):\n        # YOUR CODE HERE\n        pass\n    \n    def pull(self, arm):\n        # YOUR CODE HERE\n        pass\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_arms, true_rewards):\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/solutions/02_exploration_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5300459861755371,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install numpy matplotlib -q\nimport numpy as np\nimport matplotlib.pyplot as plt_np.random.seed(42)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plt_np.random.seed(42)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install numpy matplotlib -q\nimport numpy as np\nimport matplotlib.pyplot as plt_np.random.seed(42)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plt_np.random.seed(42)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "other"
    },
    {
      "path": "Course 09/unit5-applications/examples/01_rl_applications.ipynb",
      "status": "passed",
      "execution_time": 0.734652042388916,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/02_game_playing_agent.ipynb",
      "status": "failed",
      "execution_time": 1.3960611820220947,
      "error": "An error occurred while executing the following cell:\n------------------\nclass TicTacToe:\n    \"\"\"Simple Tic-Tac-Toe game environment\"\"\"\n    def__init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.board = np.zeros((3, 3), dtype=int)\n        self.current_player = 1\n        return self.board.copy()\n    \n    def step(self, action):\n        row, col = action // 3, action % 3\n        if self.board[row, col] != 0:\n            return self.board.copy(), -10, True, {}  # Invalid move\n        \n        self.board[row, col] = self.current_player\n        \n        # Check win\n        if self.check_win():\n            return self.board.copy(), 10, True, {}\n        \n        # Check draw\n        if np.all(self.board != 0):\n            return self.board.copy(), 0, True, {}\n        \n        self.current_player = -self.current_player\n        return self.board.copy(), 0, False, {}\n    \n    def check_win(self):\n        \"\"\"Check if current player won\"\"\"\n        player = self.current_player\n        # Check rows, columns, diagonals\n        for i in range(3):\n            if np.all(self.board[i] == player) or np.all(self.board[:, i] == player):\n                return True\n        if np.all(np.diag(self.board) == player) or np.all(np.diag(np.fliplr(self.board)) == player):\n            return True\n        return False\n\nprint('\u2705 Game environment created')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass TicTacToe:\n    \"\"\"Simple Tic-Tac-Toe game environment\"\"\"\n    def__init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.board = np.zeros((3, 3), dtype=int)\n        self.current_player = 1\n        return self.board.copy()\n    \n    def step(self, action):\n        row, col = action // 3, action % 3\n        if self.board[row, col] != 0:\n            return self.board.copy(), -10, True, {}  # Invalid move\n        \n        self.board[row, col] = self.current_player\n        \n        # Check win\n        if self.check_win():\n            return self.board.copy(), 10, True, {}\n        \n        # Check draw\n        if np.all(self.board != 0):\n            return self.board.copy(), 0, True, {}\n        \n        self.current_player = -self.current_player\n        return self.board.copy(), 0, False, {}\n    \n    def check_win(self):\n        \"\"\"Check if current player won\"\"\"\n        player = self.current_player\n        # Check rows, columns, diagonals\n        for i in range(3):\n            if np.all(self.board[i] == player) or np.all(self.board[:, i] == player):\n                return True\n        if np.all(np.diag(self.board) == player) or np.all(np.diag(np.fliplr(self.board)) == player):\n            return True\n        return False\n\nprint('\u2705 Game environment created')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/03_resource_optimization.ipynb",
      "status": "failed",
      "execution_time": 1.5825390815734863,
      "error": "An error occurred while executing the following cell:\n------------------\nclass ResourceAllocationEnv:\n    \"\"\"\n    Simplified data center resource allocation environment.\n    \n    Real-world: Optimizing server allocation for workloads\n    \"\"\"\n    def__init__(self, n_servers=5, n_workloads=10):\n        self.n_servers = n_servers\n        self.n_workloads = n_workloads\n        self.reset()\n    \n    def reset(self):\n        \"\"\"Reset environment\"\"\"\n        self.server_loads = np.zeros(self.n_servers)\n        self.workloads = np.random.randint(1, 10, self.n_workloads)\n        self.current_workload = 0\n        return self.get_state()\n    \n    def get_state(self):\n        \"\"\"Get current state\"\"\"\n        return np.concatenate([self.server_loads, [self.workloads[self.current_workload]]])\n    \n    def step(self, action):\n        \"\"\"\n        Allocate workload to server.\n        \n        Reward: Negative of load imbalance + efficiency bonus\n        \"\"\"\n        if self.current_workload >= len(self.workloads):\n            return self.get_state(), 0, True, {}\n        \n        # Allocate workload\n        self.server_loads[action] += self.workloads[self.current_workload]\n        self.current_workload += 1\n        \n        # Calculate reward (negative load imbalance)\n        load_std = np.std(self.server_loads)\n        reward = -load_std - 0.1 * np.max(self.server_loads)  # Penalize overload\n        \n        done = self.current_workload >= len(self.workloads)\n        return self.get_state(), reward, done, {}\n\nprint('\u2705 Resource allocation environment created')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_servers=5, n_workloads=10):\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass ResourceAllocationEnv:\n    \"\"\"\n    Simplified data center resource allocation environment.\n    \n    Real-world: Optimizing server allocation for workloads\n    \"\"\"\n    def__init__(self, n_servers=5, n_workloads=10):\n        self.n_servers = n_servers\n        self.n_workloads = n_workloads\n        self.reset()\n    \n    def reset(self):\n        \"\"\"Reset environment\"\"\"\n        self.server_loads = np.zeros(self.n_servers)\n        self.workloads = np.random.randint(1, 10, self.n_workloads)\n        self.current_workload = 0\n        return self.get_state()\n    \n    def get_state(self):\n        \"\"\"Get current state\"\"\"\n        return np.concatenate([self.server_loads, [self.workloads[self.current_workload]]])\n    \n    def step(self, action):\n        \"\"\"\n        Allocate workload to server.\n        \n        Reward: Negative of load imbalance + efficiency bonus\n        \"\"\"\n        if self.current_workload >= len(self.workloads):\n            return self.get_state(), 0, True, {}\n        \n        # Allocate workload\n        self.server_loads[action] += self.workloads[self.current_workload]\n        self.current_workload += 1\n        \n        # Calculate reward (negative load imbalance)\n        load_std = np.std(self.server_loads)\n        reward = -load_std - 0.1 * np.max(self.server_loads)  # Penalize overload\n        \n        done = self.current_workload >= len(self.workloads)\n        return self.get_state(), reward, done, {}\n\nprint('\u2705 Resource allocation environment created')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_servers=5, n_workloads=10):\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/04_multi_agent_rl.ipynb",
      "status": "passed",
      "execution_time": 0.7065451145172119,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/05_hierarchical_rl_options.ipynb",
      "status": "passed",
      "execution_time": 0.6893258094787598,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/06_model_based_rl_world_models.ipynb",
      "status": "passed",
      "execution_time": 0.8010330200195312,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/07_model_based_vs_model_free_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.6970160007476807,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/08_goal_conditioned_rl.ipynb",
      "status": "passed",
      "execution_time": 0.6465170383453369,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/building_model_based_rl_systems_with_learned_world_models.ipynb",
      "status": "passed",
      "execution_time": 1.5630128383636475,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/comparing_model_based_vs_model_free_approaches.ipynb",
      "status": "passed",
      "execution_time": 1.4660589694976807,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/experimenting_with_hierarchical_rl_using_options_framework.ipynb",
      "status": "passed",
      "execution_time": 1.4321238994598389,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/implementing_goal_conditioned_rl_for_complex_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.4312288761138916,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/implementing_multi_agent_rl_environments_and_training_cooperativecompetitive_age.ipynb",
      "status": "failed",
      "execution_time": 0.8334150314331055,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/exercises/01_rl_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7784309387207031,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit5-applications/solutions/01_rl_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7430088520050049,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass RecommendationEnv:\n    def__init__(self, n_products=10, n_users=100):\n        self.n_products = n_products_self.user_preferences = np.random.rand(n_users, n_products)\n        self.current_user = 0\n    \n    def reset(self):\n        self.current_user = np.random.randint(len(self.user_preferences))\n        return self.current_user\n    \n    def step(self, action):\n        # Reward based on user preference_reward = self.user_preferences[self.current_user, action]\n        return self.current_user, reward, False, {}\n\nprint('\u2705 Recommendation environment')\nprint('\\nTeaching Notes: RL for personalization, exploration vs exploitation')\nprint('Grading: Task 1 (30pts), Task 2 (35pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_products=10, n_users=100):\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass RecommendationEnv:\n    def__init__(self, n_products=10, n_users=100):\n        self.n_products = n_products_self.user_preferences = np.random.rand(n_users, n_products)\n        self.current_user = 0\n    \n    def reset(self):\n        self.current_user = np.random.randint(len(self.user_preferences))\n        return self.current_user\n    \n    def step(self, action):\n        # Reward based on user preference_reward = self.user_preferences[self.current_user, action]\n        return self.current_user, reward, False, {}\n\nprint('\u2705 Recommendation environment')\nprint('\\nTeaching Notes: RL for personalization, exploration vs exploitation')\nprint('Grading: Task 1 (30pts), Task 2 (35pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, n_products=10, n_users=100):\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "other"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/01_generative_vs_discriminative.ipynb",
      "status": "failed",
      "execution_time": 0.738090991973877,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Generative vs Discriminative Models\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\n\nThis example demonstrates:\n1. Difference between generative and discriminative models2. Simple examples of each\n3. When to use each type\n\"\"\"\n\nimport numpy as np\nfrom sklearn.naive_bayes \nimport GaussianNB # Generative\nfrom sklearn.linear_model \nimport LogisticRegression # Discriminative print(\"=\" * 60)\nprint(\"Example 1: Generative vs Discriminative Models\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\")\nprint(\"=\" * 60)\n\n# Sample data: Height and Weight to predict Gender\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629: \u0627\u0644\u0637\u0648\u0644 \u0648\u0627\u0644\u0648\u0632\u0646 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0627\u0644\u062c\u0646\u0633p\nrint(\"\\n1. Understanding the Difference\")\nprint(\"\u0641\u0647\u0645 \u0627\u0644\u0641\u0631\u0642\")\nprint(\"-\" * 60)\ndifference_explanation = \"\"\"\nGenerative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629):\n- Learn P(X, Y) - joint probability of features and labels\n- Can generate new data samples\n- Examples: Naive Bayes, GANs, VAEs\n\nDiscriminative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629):\n- Learn P(Y|X) - conditional probability of labels given features\n- Focus on decision boundary\n- Examples: Logistic Regression, SVM, Neural Networks\n\"\"\"\n\nprint(difference_explanation)\n\n# Example: Simple classification proble\nmp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Practical Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u064a\")\nprint(\"=\" * 60)\n\n# Generate sample data\n# \u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629np.random.seed(42)\nn_samples = 100\n\n# Male: taller and heavier on average\n# \u0627\u0644\u0630\u0643\u0648\u0631: \u0623\u0637\u0648\u0644 \u0648\u0623\u062b\u0642\u0644 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637m\nale_height = np.random.normal(175, 7, n_samples // 2)\nmale_weight = np.random.normal(80, 10, n_samples // 2)\nmale_data = np.column_stack([male_height, male_weight])\n\n# Female: shorter and lighter on average\n# \u0627\u0644\u0625\u0646\u0627\u062b: \u0623\u0642\u0635\u0631 \u0648\u0623\u062e\u0641 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637f\nemale_height = np.random.normal(165, 6, n_samples // 2)\nfemale_weight = np.random.normal(65, 8, n_samples // 2)\nfemale_data = np.column_stack([female_height, female_weight])\n\n# Combine data\nX = np.vstack([male_data, female_data])\ny = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\nprint(f\"\\nDataset created: {len(X)} samples\")\nprint(f\"Features: Height (cm), Weight (kg)\")\nprint(f\"Labels: 0 = Male, 1 = Female\")\n\n# Generative Model: Naive Baye\nsp\nrint(\"\\n\" + \"-\" * 60)\nprint(\"Generative Model: Naive Bayes\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a: Naive Bayes\")\nprint(\"-\" * 60)\ngenerative_model = GaussianNB()\ngenerative_model.fit(X, y)\nprint(\"\u2713 Naive Bayes trained (learns P(X, Y))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 Naive Bayes (\u064a\u062a\u0639\u0644\u0645 P(X, Y))\")\n\n# Discriminative Model: Logistic Regression\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Discriminative Model: Logistic Regression\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a: \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\")\nprint(\"-\" * 60)\ndiscriminative_model = LogisticRegression()\ndiscriminative_model.fit(X, y)\nprint(\"\u2713 Logistic Regression trained (learns P(Y|X))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a (\u064a\u062a\u0639\u0644\u0645 P(Y|X))\")\n\n# Make prediction\nsp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Predictions\")\nprint(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\")\nprint(\"=\" * 60)\ntest_samples = np.array([\n [170, 75], # Average\n [180, 85], # Likely male\n [160, 60] # Likely female\n])\ngen_predictions = generative_model.predict(test_samples)\ndisc_predictions = discriminative_model.predict(test_samples)\nprint(\"\\nTest samples:\")\nfor i, sample in enumerate(test_samples):\n gen_pred = \"Male\" if gen_predictions[i] == 0 else \"Female\"\n disc_pred = \"Male\" if disc_predictions[i] == 0 else \"Female\"\n print(f\"\\nSample {i+1}: Height={sample[0]}\ncm, Weight={sample[1]}\nkg\")\nprint(f\" Generative (Naive Bayes): {gen_pred}\")\n print(f\" Discriminative (Logistic): {disc_pred}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Generative vs Discriminative Models\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\n\nThis example demonstrates:\n1. Difference between generative and discriminative models2. Simple examples of each\n3. When to use each type\n\"\"\"\n\nimport numpy as np\nfrom sklearn.naive_bayes \nimport GaussianNB # Generative\nfrom sklearn.linear_model \nimport LogisticRegression # Discriminative print(\"=\" * 60)\nprint(\"Example 1: Generative vs Discriminative Models\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\")\nprint(\"=\" * 60)\n\n# Sample data: Height and Weight to predict Gender\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629: \u0627\u0644\u0637\u0648\u0644 \u0648\u0627\u0644\u0648\u0632\u0646 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0627\u0644\u062c\u0646\u0633p\nrint(\"\\n1. Understanding the Difference\")\nprint(\"\u0641\u0647\u0645 \u0627\u0644\u0641\u0631\u0642\")\nprint(\"-\" * 60)\ndifference_explanation = \"\"\"\nGenerative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629):\n- Learn P(X, Y) - joint probability of features and labels\n- Can generate new data samples\n- Examples: Naive Bayes, GANs, VAEs\n\nDiscriminative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629):\n- Learn P(Y|X) - conditional probability of labels given features\n- Focus on decision boundary\n- Examples: Logistic Regression, SVM, Neural Networks\n\"\"\"\n\nprint(difference_explanation)\n\n# Example: Simple classification proble\nmp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Practical Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u064a\")\nprint(\"=\" * 60)\n\n# Generate sample data\n# \u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629np.random.seed(42)\nn_samples = 100\n\n# Male: taller and heavier on average\n# \u0627\u0644\u0630\u0643\u0648\u0631: \u0623\u0637\u0648\u0644 \u0648\u0623\u062b\u0642\u0644 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637m\nale_height = np.random.normal(175, 7, n_samples // 2)\nmale_weight = np.random.normal(80, 10, n_samples // 2)\nmale_data = np.column_stack([male_height, male_weight])\n\n# Female: shorter and lighter on average\n# \u0627\u0644\u0625\u0646\u0627\u062b: \u0623\u0642\u0635\u0631 \u0648\u0623\u062e\u0641 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637f\nemale_height = np.random.normal(165, 6, n_samples // 2)\nfemale_weight = np.random.normal(65, 8, n_samples // 2)\nfemale_data = np.column_stack([female_height, female_weight])\n\n# Combine data\nX = np.vstack([male_data, female_data])\ny = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\nprint(f\"\\nDataset created: {len(X)} samples\")\nprint(f\"Features: Height (cm), Weight (kg)\")\nprint(f\"Labels: 0 = Male, 1 = Female\")\n\n# Generative Model: Naive Baye\nsp\nrint(\"\\n\" + \"-\" * 60)\nprint(\"Generative Model: Naive Bayes\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a: Naive Bayes\")\nprint(\"-\" * 60)\ngenerative_model = GaussianNB()\ngenerative_model.fit(X, y)\nprint(\"\u2713 Naive Bayes trained (learns P(X, Y))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 Naive Bayes (\u064a\u062a\u0639\u0644\u0645 P(X, Y))\")\n\n# Discriminative Model: Logistic Regression\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Discriminative Model: Logistic Regression\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a: \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\")\nprint(\"-\" * 60)\ndiscriminative_model = LogisticRegression()\ndiscriminative_model.fit(X, y)\nprint(\"\u2713 Logistic Regression trained (learns P(Y|X))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a (\u064a\u062a\u0639\u0644\u0645 P(Y|X))\")\n\n# Make prediction\nsp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Predictions\")\nprint(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\")\nprint(\"=\" * 60)\ntest_samples = np.array([\n [170, 75], # Average\n [180, 85], # Likely male\n [160, 60] # Likely female\n])\ngen_predictions = generative_model.predict(test_samples)\ndisc_predictions = discriminative_model.predict(test_samples)\nprint(\"\\nTest samples:\")\nfor i, sample in enumerate(test_samples):\n gen_pred = \"Male\" if gen_predictions[i] == 0 else \"Female\"\n disc_pred = \"Male\" if disc_predictions[i] == 0 else \"Female\"\n print(f\"\\nSample {i+1}: Height={sample[0]}\ncm, Weight={sample[1]}\nkg\")\nprint(f\" Generative (Naive Bayes): {gen_pred}\")\n print(f\" Discriminative (Logistic): {disc_pred}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/02_generative_model_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.6805307865142822,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/03_probabilistic_generative_models.ipynb",
      "status": "passed",
      "execution_time": 0.8635320663452148,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/04_building_training_simple_gan.ipynb",
      "status": "passed",
      "execution_time": 3.28783917427063,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/05_implementing_vae_image_generation.ipynb",
      "status": "passed",
      "execution_time": 3.284726142883301,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/06_comparing_gan_vae_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.9020922183990479,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/06_comparing_generative_models_gans_vae.ipynb",
      "status": "passed",
      "execution_time": 0.8300862312316895,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/07_training_techniques_gradient_penalties.ipynb",
      "status": "passed",
      "execution_time": 3.2048630714416504,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/08_evaluating_generative_models_fid_bleu.ipynb",
      "status": "passed",
      "execution_time": 1.3740551471710205,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/09_generating_samples_trained_models.ipynb",
      "status": "passed",
      "execution_time": 0.7744030952453613,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/10_exploring_latent_spaces_interpolation.ipynb",
      "status": "passed",
      "execution_time": 0.9044718742370605,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/building_and_training_a_simple_gan_using_tensorflowpytorch.ipynb",
      "status": "passed",
      "execution_time": 1.4726712703704834,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/experimenting_with_training_techniques_like_gradient_penalties_and_spectral_norm.ipynb",
      "status": "passed",
      "execution_time": 1.4907960891723633,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/exploring_latent_spaces_and_interpolation_in_vaes.ipynb",
      "status": "passed",
      "execution_time": 1.3511478900909424,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/exercises/01_generative_models_fundamentals_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.5393221378326416,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/solutions/01_generative_models_fundamentals_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6799817085266113,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 10/unit2-gans/examples/01_gan_architecture.ipynb",
      "status": "failed",
      "execution_time": 0.5992319583892822,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 2 - Example 1: GAN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\n\nThis example demonstrates:\n1. GAN architecture components2. Generator and Discriminator3. Adversarial training concept4. Loss functions\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60)\nprint(\"Example 1: GAN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\")\nprint(\"=\" * 60)\n\n# 1. GAN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a GA\nNp\nrint(\"\\n1. GAN Architecture\")\nprint(\"\u0647\u064a\u0643\u0644 GAN\")\nprint(\"-\" * 60)\ngan_explanation = \"\"\"\nGAN consists of two networks:\n\nGenerator (\u0627\u0644\u0645\u0648\u0644\u062f):\n- Takes random noise as input\n- Generates fake data\n- Tries to fool the discriminator\n- Goal: Generate realistic data\n\nDiscriminator (\u0627\u0644\u0645\u0645\u064a\u0632):\n- Takes real or fake data as input\n- Classifies as real or fake\n- Tries to distinguish real from fake\n- Goal: Correctly identify fake data\n\nTraining Process:\n- Generator and Discriminator compete\n- Generator improves to create better fakes\n- Discriminator improves to detect fakes\n- Equilibrium: Generator creates perfect fakes\n\"\"\"\n\nprint(gan_explanation)\n\n# 2. Simple Generator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0648\u0644\u062fp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Generator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0648\u0644\u062f\")\nprint(\"=\" * 60)\ndef simple_generator(noise, weights):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple generator that transforms noise to data.\n \u0645\u0648\u0644\u062f \u0628\u0633\u064a\u0637 \u064a\u062d\u0648\u0644 \u0627\u0644\u0636\u0648\u0636\u0627\u0621 \u0625\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n \"\"\"\n # Simulate: noise -> hidden -> output hidden = noise * weights[0]\n output = hidden * weights[1]\n return output\n\n# Example: Generate fake data\nnoise = np.random.randn(10) # Random noisew\neights = [2.0, 1.5] # Generator weightsf\nake_data = simple_generator(noise, weights)\nprint(f\"\\nInput noise shape: {noise.shape}\")\nprint(f\"Generated fake data shape: {fake_data.shape}\")\nprint(f\"Sample fake data: {fake_data[:5]}\")\n\n# 3. Simple Discriminator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0645\u064a\u0632p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Discriminator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0645\u064a\u0632\")\nprint(\"=\" * 60)\ndef simple_discriminator(data, threshold=0.5):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple discriminator that classifies real vs fake.\n \u0645\u0645\u064a\u0632 \u0628\u0633\u064a\u0637 \u064a\u0635\u0646\u0641 \u0627\u0644\u062d\u0642\u064a\u0642\u064a \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0645\u0632\u064a\u0641.\n \"\"\"\n # Simple rule: if data > threshold, likely real probability = 1\n(1 + np.exp(-np.mean(data)))\n prediction = \"real\" if probability > threshold else \"fake\"\n return prediction, probability\n\n# Test discriminato\nrr\neal_data = np.random.randn(10) + 2 # Real data (shifted)\nfake_data = np.random.randn(10) - 2 # Fake data (shifted)\nreal_pred, real_prob = simple_discriminator(real_data)\nfake_pred, fake_prob = simple_discriminator(fake_data)\nprint(f\"\\nReal data: {real_pred} (probability: {real_prob:.3 f})\")\nprint(f\"Fake data: {fake_pred} (probability: {fake_prob:.3 f})\")\n\n# 4. Adversarial Training Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064ap\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Adversarial Training\")\nprint(\"\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064a\")\nprint(\"=\" * 60)\ntraining_concept = \"\"\"\nAdversarial Training Process:\n\nStep 1: Train Discriminator\n- Show real data \u2192 Discriminator learns real patterns\n- Show fake data \u2192 Discriminator learns to detect fakes\n\nStep 2: Train Generator\n- Generate fake data\n- Try to fool discriminator\n- Update generator to create better fakes\n\nStep 3: Repeat\n- Discriminator gets better at detection\n- Generator gets better at generation\n- Both improve together\n\nThis creates a competitive learning environment!\n\"\"\"\n\nprint(training_concept)\n\n# 5. Loss Functions\n# \u062f\u0648\u0627\u0644 \u0627\u0644\u062e\u0633\u0627\u0631\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"5. GAN Loss Functions\")\nprint(\"\u062f\u0648\u0627\u0644 \u062e\u0633\u0627\u0631\u0629 GAN\")\nprint(\"=\" * 60)\nloss_explanation = \"\"\"\nGenerator Loss:\n- Wants to maximize discriminator's error on fake data\n- Loss = -log(D(fake_data))\nDiscriminator Loss:\n- Wants to correctly classify real and fake\n- Loss = -log(D(real_data)) - log(1 - D(fake_data))\nMinimax Game:\n- Generator minimizes its loss\n- Discriminator minimizes its loss\n- Nash equilibrium when both are optimal\n\"\"\"\n\nprint(loss_explanation)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 2 - Example 1: GAN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\n\nThis example demonstrates:\n1. GAN architecture components2. Generator and Discriminator3. Adversarial training concept4. Loss functions\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60)\nprint(\"Example 1: GAN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\")\nprint(\"=\" * 60)\n\n# 1. GAN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a GA\nNp\nrint(\"\\n1. GAN Architecture\")\nprint(\"\u0647\u064a\u0643\u0644 GAN\")\nprint(\"-\" * 60)\ngan_explanation = \"\"\"\nGAN consists of two networks:\n\nGenerator (\u0627\u0644\u0645\u0648\u0644\u062f):\n- Takes random noise as input\n- Generates fake data\n- Tries to fool the discriminator\n- Goal: Generate realistic data\n\nDiscriminator (\u0627\u0644\u0645\u0645\u064a\u0632):\n- Takes real or fake data as input\n- Classifies as real or fake\n- Tries to distinguish real from fake\n- Goal: Correctly identify fake data\n\nTraining Process:\n- Generator and Discriminator compete\n- Generator improves to create better fakes\n- Discriminator improves to detect fakes\n- Equilibrium: Generator creates perfect fakes\n\"\"\"\n\nprint(gan_explanation)\n\n# 2. Simple Generator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0648\u0644\u062fp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Generator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0648\u0644\u062f\")\nprint(\"=\" * 60)\ndef simple_generator(noise, weights):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple generator that transforms noise to data.\n \u0645\u0648\u0644\u062f \u0628\u0633\u064a\u0637 \u064a\u062d\u0648\u0644 \u0627\u0644\u0636\u0648\u0636\u0627\u0621 \u0625\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n \"\"\"\n # Simulate: noise -> hidden -> output hidden = noise * weights[0]\n output = hidden * weights[1]\n return output\n\n# Example: Generate fake data\nnoise = np.random.randn(10) # Random noisew\neights = [2.0, 1.5] # Generator weightsf\nake_data = simple_generator(noise, weights)\nprint(f\"\\nInput noise shape: {noise.shape}\")\nprint(f\"Generated fake data shape: {fake_data.shape}\")\nprint(f\"Sample fake data: {fake_data[:5]}\")\n\n# 3. Simple Discriminator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0645\u064a\u0632p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Discriminator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0645\u064a\u0632\")\nprint(\"=\" * 60)\ndef simple_discriminator(data, threshold=0.5):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple discriminator that classifies real vs fake.\n \u0645\u0645\u064a\u0632 \u0628\u0633\u064a\u0637 \u064a\u0635\u0646\u0641 \u0627\u0644\u062d\u0642\u064a\u0642\u064a \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0645\u0632\u064a\u0641.\n \"\"\"\n # Simple rule: if data > threshold, likely real probability = 1\n(1 + np.exp(-np.mean(data)))\n prediction = \"real\" if probability > threshold else \"fake\"\n return prediction, probability\n\n# Test discriminato\nrr\neal_data = np.random.randn(10) + 2 # Real data (shifted)\nfake_data = np.random.randn(10) - 2 # Fake data (shifted)\nreal_pred, real_prob = simple_discriminator(real_data)\nfake_pred, fake_prob = simple_discriminator(fake_data)\nprint(f\"\\nReal data: {real_pred} (probability: {real_prob:.3 f})\")\nprint(f\"Fake data: {fake_pred} (probability: {fake_prob:.3 f})\")\n\n# 4. Adversarial Training Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064ap\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Adversarial Training\")\nprint(\"\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064a\")\nprint(\"=\" * 60)\ntraining_concept = \"\"\"\nAdversarial Training Process:\n\nStep 1: Train Discriminator\n- Show real data \u2192 Discriminator learns real patterns\n- Show fake data \u2192 Discriminator learns to detect fakes\n\nStep 2: Train Generator\n- Generate fake data\n- Try to fool discriminator\n- Update generator to create better fakes\n\nStep 3: Repeat\n- Discriminator gets better at detection\n- Generator gets better at generation\n- Both improve together\n\nThis creates a competitive learning environment!\n\"\"\"\n\nprint(training_concept)\n\n# 5. Loss Functions\n# \u062f\u0648\u0627\u0644 \u0627\u0644\u062e\u0633\u0627\u0631\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"5. GAN Loss Functions\")\nprint(\"\u062f\u0648\u0627\u0644 \u062e\u0633\u0627\u0631\u0629 GAN\")\nprint(\"=\" * 60)\nloss_explanation = \"\"\"\nGenerator Loss:\n- Wants to maximize discriminator's error on fake data\n- Loss = -log(D(fake_data))\nDiscriminator Loss:\n- Wants to correctly classify real and fake\n- Loss = -log(D(real_data)) - log(1 - D(fake_data))\nMinimax Game:\n- Generator minimizes its loss\n- Discriminator minimizes its loss\n- Nash equilibrium when both are optimal\n\"\"\"\n\nprint(loss_explanation)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/02_conditional_gans.ipynb",
      "status": "passed",
      "execution_time": 0.7880399227142334,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/03_stylegan_basics.ipynb",
      "status": "passed",
      "execution_time": 0.6664259433746338,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/04_text_generation_gpt_models.ipynb",
      "status": "passed",
      "execution_time": 5.358266830444336,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/04_training_techniques_gradient_penalties.ipynb",
      "status": "passed",
      "execution_time": 0.7438116073608398,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/05_fine_tuning_language_models.ipynb",
      "status": "failed",
      "execution_time": 0.5774650573730469,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Configure training\")\nprint(\" 4. Train on task data\")\nprint(\" 5. Evaluate performance\")\n\nprint(\"\\nFine-tuning Strategies:\")\nprint(\" - Full fine-tuning\")\nprint(\" - LoRA (Low-Rank Adaptation)\")\nprint(\" - Prompt tuning\")\nprint(\" - Adapter layers\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Task-specific performance\")\nprint(\" - Less data needed\")\nprint(\" - Faster training\")\nprint(\" - Better results\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Configure training\")\nprint(\" 4. Train on task data\")\nprint(\" 5. Evaluate performance\")\n\nprint(\"\\nFine-tuning Strategies:\")\nprint(\" - Full fine-tuning\")\nprint(\" - LoRA (Low-Rank Adaptation)\")\nprint(\" - Prompt tuning\")\nprint(\" - Adapter layers\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Task-specific performance\")\nprint(\" - Less data needed\")\nprint(\" - Faster training\")\nprint(\" - Better results\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/05_finetuning_language_models.ipynb",
      "status": "failed",
      "execution_time": 0.7483599185943604,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Update model parameters\")\nprint(\" 4. Evaluate on task\")\nprint(\" 5. Deploy fine-tuned model\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Better task performance\")\nprint(\" - Less data needed\")\nprint(\" - Domain adaptation\")\nprint(\" - Faster training\")\n\nprint(\"\\nTasks:\")\nprint(\" - Text classification\")\nprint(\" - Question answering\")\nprint(\" - Named entity recognition\")\nprint(\" - Summarization\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Update model parameters\")\nprint(\" 4. Evaluate on task\")\nprint(\" 5. Deploy fine-tuned model\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Better task performance\")\nprint(\" - Less data needed\")\nprint(\" - Domain adaptation\")\nprint(\" - Faster training\")\n\nprint(\"\\nTasks:\")\nprint(\" - Text classification\")\nprint(\" - Question answering\")\nprint(\" - Named entity recognition\")\nprint(\" - Summarization\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/06_prompt_engineering_openai_huggingface.ipynb",
      "status": "passed",
      "execution_time": 0.5392849445343018,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/07_building_text_to_text_generation.ipynb",
      "status": "passed",
      "execution_time": 5.22792911529541,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/07_text_to_text_generation_transformers.ipynb",
      "status": "passed",
      "execution_time": 0.82222580909729,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/08_generating_creative_text_stories_poems.ipynb",
      "status": "passed",
      "execution_time": 5.26826286315918,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/09_evaluating_text_quality_bleu_perplexity.ipynb",
      "status": "passed",
      "execution_time": 1.6804471015930176,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/building_a_text_to_text_generation_system_using_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.4651939868927002,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/evaluating_text_generation_quality_using_metrics_like_bleu_and_perplexity.ipynb",
      "status": "passed",
      "execution_time": 1.5248198509216309,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/fine_tuning_language_models_for_specific_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.5717709064483643,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/generating_creative_text_stories_poems_using_language_models.ipynb",
      "status": "passed",
      "execution_time": 1.5151221752166748,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/implementing_conversational_ai_or_chatbot_using_generative_models.ipynb",
      "status": "passed",
      "execution_time": 1.4382779598236084,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/implementing_text_generation_using_gpt_models.ipynb",
      "status": "passed",
      "execution_time": 1.5463910102844238,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/practicing_prompt_engineering_with_openai_api_or_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.5075562000274658,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/exercises/01_gan_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.656235933303833,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit2-gans/solutions/01_gan_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6272838115692139,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision -q\nimport torch.nn as nn\n\nclass Generator(nn.Module):\n    def__init__(self, latent_dim=100):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 256),\n            nn.ReLU(), nn.Linear(256, 512),\n            nn.ReLU(), nn.Linear(512, 1024),\n            nn.ReLU(), nn.Linear(1024, 784),\n            nn.Tanh()\n        )\n    \n    def forward(self, z):\n        return self.model(z).view(-1, 1, 28, 28)\n\nclass Discriminator(nn.Module):\n    def__init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(784, 512),\n            nn.LeakyReLU(0.2), nn.Linear(512, 256),\n            nn.LeakyReLU(0.2), nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.model(x.view(-1, 784))\n\nprint('\u2705 GAN architecture defined')\nprint('\\nTeaching Notes: Adversarial training, balance generator/discriminator')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, latent_dim=100):\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision -q\nimport torch.nn as nn\n\nclass Generator(nn.Module):\n    def__init__(self, latent_dim=100):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 256),\n            nn.ReLU(), nn.Linear(256, 512),\n            nn.ReLU(), nn.Linear(512, 1024),\n            nn.ReLU(), nn.Linear(1024, 784),\n            nn.Tanh()\n        )\n    \n    def forward(self, z):\n        return self.model(z).view(-1, 1, 28, 28)\n\nclass Discriminator(nn.Module):\n    def__init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(784, 512),\n            nn.LeakyReLU(0.2), nn.Linear(512, 256),\n            nn.LeakyReLU(0.2), nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.model(x.view(-1, 784))\n\nprint('\u2705 GAN architecture defined')\nprint('\\nTeaching Notes: Adversarial training, balance generator/discriminator')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, latent_dim=100):\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "other"
    },
    {
      "path": "Course 10/unit3-vaes/examples/01_vae_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.7354872226715088,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/02_vae_applications.ipynb",
      "status": "passed",
      "execution_time": 2.569624185562134,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/03_vae_advanced_topics.ipynb",
      "status": "failed",
      "execution_time": 0.6606159210205078,
      "error": "An error occurred while executing the following cell:\n------------------\nimport torch\nimport torch.nn as nn\n\n# Conditional VAE structure\nclass ConditionalVAE(nn.Module):\n    def__init__(self, input_dim, latent_dim, condition_dim):\n        super().__init__()\n        # TODO: Define encoder and decoder with condition\n        pass\n    \n    def encode(self, x, condition):\n        # TODO: Encode with condition\n        pass\n    \n    def decode(self, z, condition):\n        # TODO: Decode with condition\n        pass\n\nprint('Conditional VAE defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, input_dim, latent_dim, condition_dim):\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport torch\nimport torch.nn as nn\n\n# Conditional VAE structure\nclass ConditionalVAE(nn.Module):\n    def__init__(self, input_dim, latent_dim, condition_dim):\n        super().__init__()\n        # TODO: Define encoder and decoder with condition\n        pass\n    \n    def encode(self, x, condition):\n        # TODO: Encode with condition\n        pass\n    \n    def decode(self, z, condition):\n        # TODO: Decode with condition\n        pass\n\nprint('Conditional VAE defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, input_dim, latent_dim, condition_dim):\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/applying_models_like_openai_codex_or_github_copilot_for_code_generation.ipynb",
      "status": "passed",
      "execution_time": 1.4423749446868896,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/audio_and_voice_synthesis_using_ai_tools_like_wavenet_or_jukebox.ipynb",
      "status": "passed",
      "execution_time": 1.3243482112884521,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/automating_code_generation_and_software_development_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.4726521968841553,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/creating_ai_generated_music_and_human_voice_synthesis.ipynb",
      "status": "passed",
      "execution_time": 1.51186203956604,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/developing_comprehensive_projects_integrating_generative_ai_in_real_world_applic.ipynb",
      "status": "passed",
      "execution_time": 1.324875831604004,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/experimenting_with_deepfake_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.4442291259765625,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/generating_ai_created_images_using_stylegan_dall_e_or_stable_diffusion.ipynb",
      "status": "passed",
      "execution_time": 1.4383668899536133,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/exercises/01_vae_exercise.ipynb",
      "status": "failed",
      "execution_time": 2.601353168487549,
      "error": "An error occurred while executing the following cell:\n------------------\n# TODO: Implement VAE class\nclass VAE(nn.Module):\n    def__init__(self, latent_dim=20):\n        super().__init__()\n        # YOUR CODE HERE\n        pass\n    \n    def encode(self, x):\n        # YOUR CODE HERE\n        pass\n    \n    def decode(self, z):\n        # YOUR CODE HERE\n        pass\n    \n    def forward(self, x):\n        # YOUR CODE HERE\n        pass\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, latent_dim=20):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# TODO: Implement VAE class\nclass VAE(nn.Module):\n    def__init__(self, latent_dim=20):\n        super().__init__()\n        # YOUR CODE HERE\n        pass\n    \n    def encode(self, x):\n        # YOUR CODE HERE\n        pass\n    \n    def decode(self, z):\n        # YOUR CODE HERE\n        pass\n    \n    def forward(self, x):\n        # YOUR CODE HERE\n        pass\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, latent_dim=20):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit3-vaes/solutions/01_vae_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7779052257537842,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision matplotlib -q\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\nelse 'cpu')\nprint(f'Using device: {device}')\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision matplotlib -q\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\nelse 'cpu')\nprint(f'Using device: {device}')\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "other"
    },
    {
      "path": "Course 10/unit4-applications/examples/01_generative_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 0.525986909866333,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/02_image_generation_advanced.ipynb",
      "status": "passed",
      "execution_time": 7.27707314491272,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/03_music_generation.ipynb",
      "status": "failed",
      "execution_time": 1.875380039215088,
      "error": "An error occurred while executing the following cell:\n------------------\nclass MusicGenerator(nn.Module):\n    \"\"\"LSTM-based music generator\"\"\"\n    def__init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        output = self.fc(lstm_out)\n        return output\n\nprint('\u2705 Music generator architecture defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass MusicGenerator(nn.Module):\n    \"\"\"LSTM-based music generator\"\"\"\n    def__init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        output = self.fc(lstm_out)\n        return output\n\nprint('\u2705 Music generator architecture defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/04_generating_ai_images_stylegan_dalle.ipynb",
      "status": "passed",
      "execution_time": 0.8053178787231445,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/05_audio_voice_synthesis_wavenet_jukebox.ipynb",
      "status": "passed",
      "execution_time": 0.6442129611968994,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/06_code_generation_openai_codex_copilot.ipynb",
      "status": "passed",
      "execution_time": 0.61863112449646,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/applying_ai_regulatory_guidelines_like_gdpr_to_ensure_compliance_in_model_develo.ipynb",
      "status": "passed",
      "execution_time": 1.8105971813201904,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/building_ethical_ai_models_with_principles_like_fairness_and_transparency.ipynb",
      "status": "passed",
      "execution_time": 1.4636139869689941,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/exercises/01_generation_exercise.ipynb",
      "status": "passed",
      "execution_time": 6.068403005599976,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit4-applications/solutions/01_generation_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7435641288757324,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n# Load pre-trained model_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprint('\u2705 Text generation model loaded')\nprint('\\nTeaching Notes: Fine-tune GPT-2 on creative writing dataset')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n# Load pre-trained model_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprint('\u2705 Text generation model loaded')\nprint('\\nTeaching Notes: Fine-tune GPT-2 on creative writing dataset')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "other"
    },
    {
      "path": "Course 10/unit5-ethics/examples/01_generative_ai_ethics.ipynb",
      "status": "passed",
      "execution_time": 0.732154130935669,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/02_deepfake_detection.ipynb",
      "status": "failed",
      "execution_time": 1.9666790962219238,
      "error": "An error occurred while executing the following cell:\n------------------\nclass DeepfakeDetector(nn.Module):\n    \"\"\"CNN-based deepfake detector\"\"\"\n    def__init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(), nn.Linear(128 * 32 * 32, 256),\n            nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(256, 2)  # Real or Fake\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\nprint('\u2705 Deepfake detector architecture defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass DeepfakeDetector(nn.Module):\n    \"\"\"CNN-based deepfake detector\"\"\"\n    def__init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(), nn.MaxPool2d(2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(), nn.Linear(128 * 32 * 32, 256),\n            nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(256, 2)  # Real or Fake\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\nprint('\u2705 Deepfake detector architecture defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/03_future_trends_research.ipynb",
      "status": "passed",
      "execution_time": 0.8417637348175049,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/04_detecting_mitigating_bias_generative.ipynb",
      "status": "passed",
      "execution_time": 0.8523190021514893,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/05_experimenting_advanced_generative_models.ipynb",
      "status": "passed",
      "execution_time": 0.7433180809020996,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/exercises/01_generative_ai_ethics_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.6585240364074707,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit5-ethics/solutions/01_generative_ai_ethics_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7312788963317871,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "other"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/01_model_serving_api.ipynb",
      "status": "passed",
      "execution_time": 1.6231341361999512,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/02_model_packaging.ipynb",
      "status": "passed",
      "execution_time": 4.438208103179932,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/03_local_deployment_testing.ipynb",
      "status": "failed",
      "execution_time": 0.746337890625,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom flask import Flask, request, jsonify\nimport joblib\n\n# Load model\n# model = joblib.load('model.pkl')\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n # TODO: Implement prediction endpoint\n # Handle request, make prediction, return response\n pass\n\nif__name__ == '__main__':\n app.run(debug=True, host='0.0.0.0', port=5000)\n\nprint('Local deployment server defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == '__main__':\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom flask import Flask, request, jsonify\nimport joblib\n\n# Load model\n# model = joblib.load('model.pkl')\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n # TODO: Implement prediction endpoint\n # Handle request, make prediction, return response\n pass\n\nif__name__ == '__main__':\n app.run(debug=True, host='0.0.0.0', port=5000)\n\nprint('Local deployment server defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == '__main__':\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/04_model_preparation_saving.ipynb",
      "status": "passed",
      "execution_time": 0.6844000816345215,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/05_model_validation_testing.ipynb",
      "status": "passed",
      "execution_time": 0.7782728672027588,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/06_monitoring_updating_models.ipynb",
      "status": "passed",
      "execution_time": 0.6728081703186035,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/building_api_interface_for_ai_models_implementing_a_simple_api_using_flask_or_fa.ipynb",
      "status": "passed",
      "execution_time": 1.63714599609375,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/containerizing_ai_model_using_docker_packaging_ai_model_into_a_container_and_dep.ipynb",
      "status": "passed",
      "execution_time": 1.4169018268585205,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/containerizing_ai_model_using_docker_to_package_a_trained_model_for_scalable_dep.ipynb",
      "status": "passed",
      "execution_time": 1.6446080207824707,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/creating_rest_api_for_ai_model_inference_using_flask_or_fastapi_to_serve_predict.ipynb",
      "status": "passed",
      "execution_time": 1.5409979820251465,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/deploying_model_on_cloud_hosting_a_model_on_aws_google_cloud_or_azure.ipynb",
      "status": "passed",
      "execution_time": 1.6124777793884277,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/implementing_security_measures_applying_authentication_encryption_and_access_con.ipynb",
      "status": "passed",
      "execution_time": 1.5400099754333496,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/managing_ai_model_deployment_using_kubernetes_running_and_scaling_a_deployed_mod.ipynb",
      "status": "passed",
      "execution_time": 1.505983829498291,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/model_validation_and_testing_running_unit_tests_and_performance_evaluations_befo.ipynb",
      "status": "passed",
      "execution_time": 1.6458637714385986,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/monitoring_and_logging_deployed_models_on_cloud_setting_up_logging_tracking_api_.ipynb",
      "status": "passed",
      "execution_time": 1.731733798980713,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/monitoring_and_updating_deployed_models_implementing_logs_feedback_loops_and_ret.ipynb",
      "status": "passed",
      "execution_time": 1.5625300407409668,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/preparing_ai_model_for_deployment_training_and_saving_a_model_using_tensorflow_o.ipynb",
      "status": "passed",
      "execution_time": 1.405522346496582,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/exercises/01_packaging_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.628398895263672,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit1-deployment-basics/solutions/01_packaging_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6603419780731201,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pickle5 onnx scikit-learn joblib -q\nimport pickle\nimport joblib\nimport onnx\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Create and train model_model = RandomForestClassifier(n_estimators=100)\nX = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\ny = np.random.randint(0, 2, 100)\nmodel.fit(X, y)\n\n# Package in different formats_pickle.dump(model, open('model.pkl', 'wb'))\njoblib.dump(model, 'model.joblib')\nprint('\u2705 Model packaged in multiple formats')\nprint('\\nTeaching Notes: Different formats for different use cases')\nprint('Grading: Task 1 (40pts), Task 2 (30pts), Task 3 (30pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pickle5 onnx scikit-learn joblib -q\nimport pickle\nimport joblib\nimport onnx\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Create and train model_model = RandomForestClassifier(n_estimators=100)\nX = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\ny = np.random.randint(0, 2, 100)\nmodel.fit(X, y)\n\n# Package in different formats_pickle.dump(model, open('model.pkl', 'wb'))\njoblib.dump(model, 'model.joblib')\nprint('\u2705 Model packaged in multiple formats')\nprint('\\nTeaching Notes: Different formats for different use cases')\nprint('Grading: Task 1 (40pts), Task 2 (30pts), Task 3 (30pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "other"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/01_flask_api_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7508480548858643,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/02_fastapi_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7690341472625732,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/03_model_versioning.ipynb",
      "status": "failed",
      "execution_time": 0.6110730171203613,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install mlflow -q\nimport mlflow\nimport mlflow.sklearnprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mlflow.sklearnprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install mlflow -q\nimport mlflow\nimport mlflow.sklearnprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mlflow.sklearnprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/04_saving_loading_models_pickle_onnx.ipynb",
      "status": "passed",
      "execution_time": 0.8225390911102295,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/05_tensorflow_serving_torchserve.ipynb",
      "status": "passed",
      "execution_time": 0.636012077331543,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/06_batch_vs_realtime_inference.ipynb",
      "status": "passed",
      "execution_time": 0.6427741050720215,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/07_kubernetes_scaling.ipynb",
      "status": "passed",
      "execution_time": 0.6812920570373535,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/containerizing_ai_model_using_docker_creating_docker_image_for_trained_ai_model_.ipynb",
      "status": "passed",
      "execution_time": 1.5602068901062012,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/deploying_using_tensorflow_serving_or_torchserve_using_ready_made_frameworks_for.ipynb",
      "status": "passed",
      "execution_time": 1.649371862411499,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/saving_and_loading_ai_model_using_pickle_onnx_or_savedmodel_for_tensorflow.ipynb",
      "status": "passed",
      "execution_time": 1.5072269439697266,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/scaling_model_deployment_using_kubernetes_deploying_container_based_ai_model_on_.ipynb",
      "status": "passed",
      "execution_time": 1.641098976135254,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/testing_batch_vs_real_time_inference_running_batch_processing_scripts_and_deploy.ipynb",
      "status": "passed",
      "execution_time": 1.388411283493042,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/exercises/03_api_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.3353078365325928,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit2-versioning-serving/solutions/03_api_deployment_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5409278869628906,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install fastapi uvicorn pydantic scikit-learn -q\nfrom fastapi \nimport FastAPI, HTTPException\nfrom pydantic \nimport BaseModel, validator\nimport pickle\nimport numpy as np\nfrom typing \nimport List_\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from fastapi\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install fastapi uvicorn pydantic scikit-learn -q\nfrom fastapi \nimport FastAPI, HTTPException\nfrom pydantic \nimport BaseModel, validator\nimport pickle\nimport numpy as np\nfrom typing \nimport List_\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from fastapi\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "other"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/01_cloud_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.5442681312561035,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/02_aws_sagemaker.ipynb",
      "status": "passed",
      "execution_time": 2.091701030731201,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/03_azure_ml_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.6995429992675781,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/04_gcp_vertex_ai.ipynb",
      "status": "passed",
      "execution_time": 0.7603130340576172,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/05_security_measures.ipynb",
      "status": "passed",
      "execution_time": 0.7719588279724121,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/06_monitoring_logging_cloud.ipynb",
      "status": "passed",
      "execution_time": 0.6013128757476807,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/exercises/01_cloud_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.8038091659545898,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/solutions/01_cloud_deployment_solution.ipynb",
      "status": "passed",
      "execution_time": 0.547166109085083,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "other"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/01_docker_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.770021915435791,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/02_kubernetes_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.6625118255615234,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/03_cloud_deployment_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.7857651710510254,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/04_cicd_pipelines.ipynb",
      "status": "passed",
      "execution_time": 0.8415470123291016,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/setting_up_cicd_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.637753963470459,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/exercises/01_docker_and_containerization_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7597382068634033,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/solutions/01_docker_and_containerization_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5305569171905518,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "other"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/01_model_monitoring.ipynb",
      "status": "passed",
      "execution_time": 0.5697638988494873,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/02_retraining_pipeline.ipynb",
      "status": "passed",
      "execution_time": 1.300016164779663,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/03_alerting_incident_management.ipynb",
      "status": "failed",
      "execution_time": 0.6461212635040283,
      "error": "An error occurred while executing the following cell:\n------------------\nclass AlertManager:\n    def__init__(self, thresholds):\n        self.thresholds = thresholds\n    \n    def check_metrics(self, metrics):\n        # TODO: Check metrics against thresholds\n        # Trigger alerts if needed\n        pass\n    \n    def send_alert(self, alert_type, message):\n        # TODO: Send alert (email, Slack, etc.)\n        pass\n\nprint('Alert manager defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, thresholds):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nclass AlertManager:\n    def__init__(self, thresholds):\n        self.thresholds = thresholds\n    \n    def check_metrics(self, metrics):\n        # TODO: Check metrics against thresholds\n        # Trigger alerts if needed\n        pass\n    \n    def send_alert(self, alert_type, message):\n        # TODO: Send alert (email, Slack, etc.)\n        pass\n\nprint('Alert manager defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, thresholds):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/04_drift_detection.ipynb",
      "status": "passed",
      "execution_time": 0.9811017513275146,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/05_experiment_tracking_mlflow_wandb.ipynb",
      "status": "passed",
      "execution_time": 0.5355749130249023,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/06_model_versioning_reproducibility.ipynb",
      "status": "passed",
      "execution_time": 0.7455720901489258,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/07_ab_testing_canary_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.8496279716491699,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_canary_deployment_strategies.ipynb",
      "status": "passed",
      "execution_time": 1.432974100112915,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_drift_detection_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.6472821235656738,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_model_versioning_and_reproducibility_practices.ipynb",
      "status": "passed",
      "execution_time": 1.326672077178955,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/performing_ab_testing_for_model_comparison.ipynb",
      "status": "passed",
      "execution_time": 1.4369761943817139,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/setting_up_model_monitoring_and_performance_tracking_systems.ipynb",
      "status": "passed",
      "execution_time": 1.4342572689056396,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/setting_up_retraining_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.7753257751464844,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/using_experiment_tracking_tools_mlflow_weights_biases.ipynb",
      "status": "passed",
      "execution_time": 1.4326820373535156,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/exercises/01_monitoring_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.889754056930542,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/solutions/01_monitoring_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5997018814086914,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pandas matplotlib numpy -q\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nclass ModelMonitor:\n    def__init__(self):\n        self.predictions = []\n        self.actuals = []\n        self.metrics_history = []\n    \n    def log_prediction(self, prediction, actual=None):\n        self.predictions.append(prediction)\n        if actual is not None:\n            self.actuals.append(actual)\n    \n    def calculate_metrics(self):\n        if len(self.actuals) > 0:\n            accuracy = np.mean([p == a for p, a in zip(self.predictions, self.actuals)])\n            self.metrics_history.append(accuracy)\n            return accuracy\n        return None\n    \n    def plot_metrics(self):\n        if self.metrics_history:\n            plt.plot(self.metrics_history)\n            plt.title('Model Performance Over Time')\n            plt.xlabel('Time')\n            plt.ylabel('Accuracy')\n            plt.show()\n\nmonitor = ModelMonitor()\nprint('\u2705 Monitoring system implemented')\nprint('\\nTeaching Notes: Track predictions, detect drift, create alerts')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pandas matplotlib numpy -q\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nclass ModelMonitor:\n    def__init__(self):\n        self.predictions = []\n        self.actuals = []\n        self.metrics_history = []\n    \n    def log_prediction(self, prediction, actual=None):\n        self.predictions.append(prediction)\n        if actual is not None:\n            self.actuals.append(actual)\n    \n    def calculate_metrics(self):\n        if len(self.actuals) > 0:\n            accuracy = np.mean([p == a for p, a in zip(self.predictions, self.actuals)])\n            self.metrics_history.append(accuracy)\n            return accuracy\n        return None\n    \n    def plot_metrics(self):\n        if self.metrics_history:\n            plt.plot(self.metrics_history)\n            plt.title('Model Performance Over Time')\n            plt.xlabel('Time')\n            plt.ylabel('Accuracy')\n            plt.show()\n\nmonitor = ModelMonitor()\nprint('\u2705 Monitoring system implemented')\nprint('\\nTeaching Notes: Track predictions, detect drift, create alerts')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "other"
    },
    {
      "path": "Course 12/EXAMPLES/01_project_structure_template.ipynb",
      "status": "passed",
      "execution_time": 1.2198410034179688,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/02_data_collection_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 1.0325281620025635,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/03_model_development.ipynb",
      "status": "passed",
      "execution_time": 1.0234060287475586,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/04_model_evaluation.ipynb",
      "status": "passed",
      "execution_time": 0.8772521018981934,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/05_deployment_example.ipynb",
      "status": "passed",
      "execution_time": 1.1768200397491455,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/06_project_documentation_template.ipynb",
      "status": "passed",
      "execution_time": 0.8607769012451172,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_01_project_proposal_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6231689453125,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_02_system_design_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7553961277008057,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_03_implementation_planning_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6160938739776611,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_01_project_proposal.ipynb",
      "status": "passed",
      "execution_time": 0.6094918251037598,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_02_system_design.ipynb",
      "status": "passed",
      "execution_time": 0.7500090599060059,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_03_implementation_planning.ipynb",
      "status": "passed",
      "execution_time": 0.5443589687347412,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/01_project_proposal_literature_review.ipynb",
      "status": "passed",
      "execution_time": 0.9453990459442139,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/04_literature_review_research_papers.ipynb",
      "status": "passed",
      "execution_time": 0.533970832824707,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/compiling_source_code_documents_and_final_submission_package.ipynb",
      "status": "passed",
      "execution_time": 1.5786969661712646,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/creating_project_timeline_and_resource_allocation_plan.ipynb",
      "status": "passed",
      "execution_time": 1.4359099864959717,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/defining_success_metrics_and_evaluation_criteria_for_the_project.ipynb",
      "status": "passed",
      "execution_time": 1.44464111328125,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/preparing_recorded_video_or_live_demonstration_of_project.ipynb",
      "status": "passed",
      "execution_time": 1.5651659965515137,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/selecting_and_defining_a_graduation_project_topic.ipynb",
      "status": "passed",
      "execution_time": 1.400834083557129,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/01_data_collection_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 1.600052833557129,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/04_data_sourcing_strategies.ipynb",
      "status": "passed",
      "execution_time": 0.9622459411621094,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/collecting_and_acquiring_datasets_for_the_graduation_project.ipynb",
      "status": "passed",
      "execution_time": 1.5779531002044678,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/creating_data_exploration_notebooks_with_visualizations.ipynb",
      "status": "passed",
      "execution_time": 2.348017930984497,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/implementing_feature_engineering_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.6976919174194336,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/performing_data_cleaning_and_preprocessing_using_python_libraries_pandas_numpy.ipynb",
      "status": "passed",
      "execution_time": 1.4991481304168701,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/validating_data_quality_and_preparing_trainvalidationtest_splits.ipynb",
      "status": "passed",
      "execution_time": 1.401357889175415,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/01_model_training_hyperparameter_optimization.ipynb",
      "status": "passed",
      "execution_time": 16.025240182876587,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/04_model_selection_architecture_design.ipynb",
      "status": "failed",
      "execution_time": 2.923686981201172,
      "error": "An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nModel Selection and Architecture Design\")\nprint(\"=\" * 60)\n\nprint(\"\\nModel Selection:\")\nprint(\"  - Problem type (classification, regression)\")\nprint(\"  - Data characteristics\")\nprint(\"  - Performance requirements\")\nprint(\"  - Resource constraints\")\n\nprint(\"\\nArchitecture Design:\")\nprint(\"  - Layer types\")\nprint(\"  - Network depth\")\nprint(\"  - Activation functions\")\nprint(\"  - Regularization\")\n\nprint(\"\\nConsiderations:\")\nprint(\"  - Complexity vs performance\")\nprint(\"  - Training time\")\nprint(\"  - Inference speed\")\nprint(\"  - Model size\")\n\nprint(\"\\n\u2705 Model selection concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nModel Selection and Architecture Design\")\nprint(\"=\" * 60)\n\nprint(\"\\nModel Selection:\")\nprint(\"  - Problem type (classification, regression)\")\nprint(\"  - Data characteristics\")\nprint(\"  - Performance requirements\")\nprint(\"  - Resource constraints\")\n\nprint(\"\\nArchitecture Design:\")\nprint(\"  - Layer types\")\nprint(\"  - Network depth\")\nprint(\"  - Activation functions\")\nprint(\"  - Regularization\")\n\nprint(\"\\nConsiderations:\")\nprint(\"  - Complexity vs performance\")\nprint(\"  - Training time\")\nprint(\"  - Inference speed\")\nprint(\"  - Model size\")\n\nprint(\"\\n\u2705 Model selection concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/analyzing_model_outputs_and_identifying_areas_for_improvement.ipynb",
      "status": "passed",
      "execution_time": 1.5484910011291504,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/documenting_training_procedures_and_results.ipynb",
      "status": "passed",
      "execution_time": 1.3946201801300049,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/evaluating_model_performance_using_appropriate_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.6446690559387207,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/iteratively_refining_the_model_based_on_validation_results.ipynb",
      "status": "passed",
      "execution_time": 1.421604871749878,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/performing_hyperparameter_optimization_using_grid_search_or_automated_tools.ipynb",
      "status": "passed",
      "execution_time": 1.634979009628296,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/01_model_evaluation_optimization.ipynb",
      "status": "passed",
      "execution_time": 1.8620390892028809,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/04_experiments_performance_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.5528488159179688,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/05_comparing_baseline_models.ipynb",
      "status": "passed",
      "execution_time": 1.645141839981079,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/06_analyzing_failure_cases.ipynb",
      "status": "passed",
      "execution_time": 1.0885887145996094,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/07_visualizing_results_graphs_matrices.ipynb",
      "status": "passed",
      "execution_time": 1.6974711418151855,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/08_iterative_improvement_retraining.ipynb",
      "status": "passed",
      "execution_time": 1.4969263076782227,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/analyzing_failure_cases_and_identifying_weaknesses_in_the_model.ipynb",
      "status": "passed",
      "execution_time": 1.5931119918823242,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/comparing_results_with_baseline_or_standard_models.ipynb",
      "status": "passed",
      "execution_time": 1.5806598663330078,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/conducting_experiments_and_collecting_performance_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.5029399394989014,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/iteratively_improving_model_parameters_or_retraining_with_improved_data.ipynb",
      "status": "passed",
      "execution_time": 1.3472838401794434,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/visualizing_results_using_graphs_confusion_matrices_or_heat_maps.ipynb",
      "status": "passed",
      "execution_time": 1.4103238582611084,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit5-documentation-presentation/examples/01_project_documentation_presentation.ipynb",
      "status": "failed",
      "execution_time": 0.7928080558776855,
      "error": "An error occurred while executing the following cell:\n------------------\n# Presentation Slide Structure\npresentation_structure = {\n    \"Slide 1\": \"Title Slide (Project title, your name, date)\",\n    \"Slide 2-3\": \"Introduction (Problem statement, motivation, objectives)\",\n    \"Slide 4-5\": \"Literature Review Summary (Key related work, gap analysis)\",\n    \"Slide 6-8\": \"Methodology (Data, model architecture, approach)\",\n    \"Slide 9-12\": \"Results (Performance metrics, visualizations, comparisons)\",\n    \"Slide 13\": \"Demo/Live Demonstration\",\n    \"Slide 14\": \"Discussion (Limitations, challenges, future work)\",\n    \"Slide 15\": \"Conclusion and Contributions\",\n    \"Slide 16\": \"Q&A\nThank You\"\n}\n\nprint(\"=\" * 60)\nprint(\"Presentation Structure (15-20 minutes)\")\nprint(\"=\" * 60)\nfor slide, content in presentation_structure.items():\n    print(f\"{slide}: {content}\")\n\nprint(\"\\n\u2705 Presentation Best Practices:\")\nprint(\"  - Keep slides concise (1 idea per slide)\")\nprint(\"  - Use visualizations over text when possible\")\nprint(\"  - Practice timing (typically 15-20 minutes)\")\nprint(\"  - Prepare for questions\")\nprint(\"  - Include live demo or video demonstration\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Slide 16\": \"Q&A\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 11)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Presentation Slide Structure\npresentation_structure = {\n    \"Slide 1\": \"Title Slide (Project title, your name, date)\",\n    \"Slide 2-3\": \"Introduction (Problem statement, motivation, objectives)\",\n    \"Slide 4-5\": \"Literature Review Summary (Key related work, gap analysis)\",\n    \"Slide 6-8\": \"Methodology (Data, model architecture, approach)\",\n    \"Slide 9-12\": \"Results (Performance metrics, visualizations, comparisons)\",\n    \"Slide 13\": \"Demo/Live Demonstration\",\n    \"Slide 14\": \"Discussion (Limitations, challenges, future work)\",\n    \"Slide 15\": \"Conclusion and Contributions\",\n    \"Slide 16\": \"Q&A\nThank You\"\n}\n\nprint(\"=\" * 60)\nprint(\"Presentation Structure (15-20 minutes)\")\nprint(\"=\" * 60)\nfor slide, content in presentation_structure.items():\n    print(f\"{slide}: {content}\")\n\nprint(\"\\n\u2705 Presentation Best Practices:\")\nprint(\"  - Keep slides concise (1 idea per slide)\")\nprint(\"  - Use visualizations over text when possible\")\nprint(\"  - Practice timing (typically 15-20 minutes)\")\nprint(\"  - Prepare for questions\")\nprint(\"  - Include live demo or video demonstration\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Slide 16\": \"Q&A\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 11)\n\n\n",
      "course": "Course 12",
      "unit": "unit5-documentation-presentation",
      "type": "example"
    },
    {
      "path": "Course 12/unit5-documentation-presentation/examples/04_writing_final_project_report.ipynb",
      "status": "passed",
      "execution_time": 0.6582410335540771,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit5-documentation-presentation",
      "type": "example"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit1-data-processing/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 1.6797211170196533,
      "error": "An error occurred while executing the following cell:\n------------------\n# Sample dataset - Sales datanp.random.seed(42)\ndata = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    data = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Sample dataset - Sales datanp.random.seed(42)\ndata = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    data = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit1-data-processing/solutions/exercise_02_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7469048500061035,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit2-regression/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7549021244049072,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as \nfrom sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit3-classification/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6682431697845459,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                            confusion_matrix)\nfrom sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                            confusion_matrix)\nfrom sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit4-clustering/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.0026748180389404297,
      "error": "The notebook is invalid and is missing an expected key: metadata",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 82, in reads\n    raise ValidationError(msg) from None\njsonschema.exceptions.ValidationError: The notebook is invalid and is missing an expected key: metadata\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit5-model-selection/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.00033402442932128906,
      "error": "The notebook is invalid and is missing an expected key: metadata",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 82, in reads\n    raise ValidationError(msg) from None\njsonschema.exceptions.ValidationError: The notebook is invalid and is missing an expected key: metadata\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit1-ethics-foundations/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6262130737304688,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI EthicsExercise 1 Solution: Ethical Framework Application_This is the solution to Exercise 1.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\n# ============================================================================\n# SOLUTION: TASK 1 - Identify Ethical Issues\n# ============================================================================\ndef identify_ethical_issues():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify ethical issues in employee monitoring scenario\"\"\"_ethical_issues =  [\n ethical_issues = [\n {\n 'issue': 'Privacy Violation', 'issue_ar': '',\n 'severity': 9,\n 'description': 'Monitoring computer usage, emails, and keystrokes violates employee privacy',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Consent',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Employees may not be aware of or consent to this level of monitoring',\n 'description_ar': ''\n },\n {\n 'issue': 'Autonomy and Dignity',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Constant monitoring undermines employee autonomy and human dignity',\n 'description_ar': ''\n },\n {\n 'issue': 'Potential for Discrimination',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Productivity metrics may be biased against certain work styles or disabilities',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Transparency',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Employees may not know how their data is being used or evaluated',\n 'description_ar': ''\n }\n ]\n return ethical_issues\n# ============================================================================\n# SOLUTION: TASK 2 - Apply Ethical Frameworks\n# ============================================================================\ndef apply_utilitarianism():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nUtilitarian analysis\"\"\"_analysis =  {\n analysis = {\n 'benefits': [\n 'Increased productivity for company', 'Better performance management',\n 'Cost savings through efficiency',\n 'Data-driven decision making'\n ],\n 'harms': [\n 'Employee stress and anxiety',\n 'Loss of privacy',\n 'Reduced trust and morale',\n 'Potential for discrimination',\n 'Invasion of personal space'\n ],\n 'overall_utility': -2, # Harms outweigh benefits\n 'conclusion': 'Unethical - The harms to employees (stress, privacy loss, dignity)\noutweigh the benefits to the company. The overall utility is negative.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_deontology():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nDeontological analysis\"\"\"_analysis =  {\n analysis = {\n 'moral_rules': [\n 'Respect for human dignity', 'Right to privacy',\n 'Informed consent',\n 'Treat people as ends, not means',\n 'Fair treatment and non-discrimination'\n ],\n 'violations': [\n 'Violates right to privacy without consent',\n 'Uses employees as means to company ends',\n 'Lacks informed consent',\n 'May violate fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates multiple moral duties including respect for privacy, dignity, and informed consent. The system treats employees as means rather than ends.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_rights_based():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nRights-based analysis\"\"\"_analysis =  {\n analysis = {\n 'rights_at_stake': [\n 'Right to privacy', 'Right to autonomy',\n 'Right to dignity',\n 'Right to informed consent',\n 'Right to fair treatment',\n 'Right to work-life balance'\n ],\n 'violations': [\n 'Severe violation of privacy rights',\n 'Violation of autonomy and dignity',\n 'Lack of informed consent',\n 'Potential violation of fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates fundamental human rights including privacy, autonomy, and dignity. The system cannot be justified from a rights-based perspective.',\n 'conclusion_ar': ''\n }\n return analysis\n# ============================================================================\n# SOLUTION: TASK 3 - Identify Stakeholders\n# ============================================================================\ndef identify_stakeholders():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify all stakeholders\"\"\"_stakeholders =  {\n stakeholders = {\n 'Employees': {\n 'interests': ['Privacy', 'Autonomy', 'Fair treatment', 'Job security'],\n 'interests_ar': ['', '', '', ''],\n 'impact': 9, # Highly affected\n 'influence': 5 # Moderate influence\n },\n 'Company Management': {\n 'interests': ['Productivity', 'Cost efficiency', 'Performance metrics'],\n 'interests_ar': ['', '', ''],\n 'impact': 6, # Moderately affected\n 'influence': 9 # High influence\n },\n 'HR Department': {\n 'interests': ['Performance management', 'Compliance', 'Employee relations'],\n 'interests_ar': ['', '', ''],\n 'impact': 7,\n 'influence': 7\n },\n 'AI Developers': {\n 'interests': ['Technical success', 'Innovation', 'Ethical development'],\n 'interests_ar': ['', '', ''],\n 'impact': 5,\n 'influence': 8\n },\n 'Unions': {\n 'interests': ['Worker rights', 'Privacy protection', 'Fair treatment'],\n 'interests_ar': ['', '', ''],\n 'impact': 8,\n 'influence': 6\n },\n 'Regulators': {\n 'interests': ['Compliance', 'Privacy laws', 'Labor rights'],\n 'interests_ar': ['', '', ''],\n 'impact': 4,\n 'influence': 9\n }\n }\n return stakeholders\n# ============================================================================\n# SOLUTION: TASK 4 - Recommendations\n# ============================================================================\ndef provide_recommendations():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nProvide ethical recommendations\"\"\"_recommendations =  [\n recommendations = [\n {\n 'recommendation': 'Obtain explicit, informed consent from all employees',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Limit monitoring to work-related activities only',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Ensure transparency about what is monitored and how data is used',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Implement privacy-preserving techniques (e.g., aggregate data only)',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Regular audits for bias and discrimination',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Provide opt-out mechanisms for employees',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Establish clear accountability and redress mechanisms',\n 'recommendation_ar': '',\n 'priority': 'High'\n }\n ]\n return recommendations\n# ============================================================================\n# SOLUTION: TASK 5 - Visualizations\n# ============================================================================\ndef create_stakeholder_matrix(stakeholders):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nCreate stakeholder impact\"\"\"_names =  list(stakeholders.keys())\n names = list(stakeholders.keys())_impacts =  [s['impact'] for s in stakeholders.values()]\n impacts = [s['impact'] for s in stakeholders.values()]_influences =  [s['influence'] for s in stakeholders.values()]\n influences = [s['influence'] for s in stakeholders.values()]\n fig, ax = plt.subplots(figsize=(12, 8))_scatter =  ax.scatter(influences, impacts, s=200, alpha=0.6,\n scatter = ax.scatter(influences, impacts, s=200, alpha=0.6, \n c=range(len(names)), cmap='viridis', edgecolors='black', linewidth=2)\n for i, name in enumerate(names):\n ax.annotate(name, (influences[i], impacts[i]), \n xytext=(5, 5), textcoords='offset points', fontsize=9)\n ax.set_xlabel('Influence Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_ylabel('Impact Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Stakeholder Impact-Influence Matrix\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: stakeholder_matrix.png\")\nplt.close()\ndef create_ethical_issues_chart(ethical_issues):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"Create ethical issues severity chart\"\"\"\n_issues =  [e['issue'] for e in ethical_issues]\n issues = [e['issue'] for e in ethical_issues]_severities =  [e['severity'] for e in ethical_issues]\n severities = [e['severity'] for e in ethical_issues]_colors =  ['# e74_c3_c' if s >= 9 else '#f39_colors = ['# e74_c3_c' if s >= 9 else '#f39\nc12' if s >= 7 else '#3498\ndb' \n for s in severities]\n fig, ax = plt.subplots(figsize=(12, 8))_bars =  ax.barh(issues, severities, color=colors, alpha=0.8,\n bars = ax.barh(issues, severities, color=colors, alpha=0.8, \n edgecolor='black', linewidth=1.5)\nax.set_xlabel('Severity Score (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Ethical Issues Severity Analysis\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.grid(axis='x', alpha=0.3, linestyle='--')\nfor i, (bar, severity)\nin enumerate(zip(bars, severities)):\n ax.text(severity + 0.2, i, f'{severity}', \n va='center', fontweight='bold', fontsize=11)\n # Legend_high = mpatches.Patch(color='# e74_c3_c', label='High (9-10)' medium = mpatches.Patch(color='# f39\nc12', label='Medium (7-8)_low =  mpatches.Patch(color='# 3498_low = mpatches.Patch(color='# 3498\ndb', label='Low (<7)\nax.legend(handles=[high, medium, low], loc='lower right', fontsize=10)\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: ethical_issues_severity.png\")\nplt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\nprint(\"Unit 1 - Exercise 1 Solution\")\nprint(\"\")\nprint(\"=\"*80)\n # Task 1__\nprint(\"\\n\ud83d\udccb TASK 1: Ethical Issues\")\nprint(\"-\" * 60)_ethical_issues =  identify_ethical_issues()\n ethical_issues = identify_ethical_issues()\n for issue in ethical_issues:\n print(f\"\\n{issue[\"issue']}'issue_ar']}')\nprint(f\" Severity: {issue[\"severity']}')\nprint(f\" {issue[\"description']}')\n # Task 2__\nprint(\"\\n\\n\ud83d\udccb TASK 2: Framework Analysis\")\nprint(\"-\" * 60)\nprint(\"\\nUtilitarianism:\")_util =  apply_utilitarianism()\n util = apply_utilitarianism()\n print(f\" Overall Utility: {util[\"overall_utility']}')\nprint(f\" Conclusion: {util[\"conclusion']}')\nprint(\"\\nDeontology:\")_deon =  apply_deontology()\n deon = apply_deontology()\n print(f\" Conclusion: {deon[\"conclusion']}')\nprint(\"\\nRights-Based:\")_rights =  apply_rights_based()\n rights = apply_rights_based()\n print(f\" Conclusion: {rights[\"conclusion']}')\n # Task 3__\nprint(\"\\n\\n\ud83d\udccb TASK 3: Stakeholders\")\nprint(\"-\" * 60)_stakeholders =  identify_stakeholders()\n stakeholders = identify_stakeholders()\n for name, info in stakeholders.items():\n print(f\"\\n{name}:\")\nprint(f\" Impact: {info[\"impact']}'influence']}')\nprint(f\" Interests: {\", '.join(info['interests'])}')\n # Task 4__\nprint(\"\\n\\n\ud83d\udccb TASK 4: Recommendations\")\nprint(\"-\" * 60)_recommendations =  provide_recommendations()\n recommendations = provide_recommendations()\n for i, rec in enumerate(recommendations, 1):\n print(f\"\\n{i}. [{rec[\"priority']}] {rec['recommendation']}')\nprint(f\" {rec[\"recommendation_ar']}')\n # Task 5__\nprint(\"\\n\\n\ud83d\udccb TASK 5: Creating Visualizations\")\nprint(\"-\" * 60)\ncreate_stakeholder_matrix(stakeholders)\ncreate_ethical_issues_chart(ethical_issues)\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 Solution completed successfully!\")\nprint(\"\")\nprint(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI EthicsExercise 1 Solution: Ethical Framework Application_This is the solution to Exercise 1.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\n# ============================================================================\n# SOLUTION: TASK 1 - Identify Ethical Issues\n# ============================================================================\ndef identify_ethical_issues():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify ethical issues in employee monitoring scenario\"\"\"_ethical_issues =  [\n ethical_issues = [\n {\n 'issue': 'Privacy Violation', 'issue_ar': '',\n 'severity': 9,\n 'description': 'Monitoring computer usage, emails, and keystrokes violates employee privacy',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Consent',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Employees may not be aware of or consent to this level of monitoring',\n 'description_ar': ''\n },\n {\n 'issue': 'Autonomy and Dignity',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Constant monitoring undermines employee autonomy and human dignity',\n 'description_ar': ''\n },\n {\n 'issue': 'Potential for Discrimination',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Productivity metrics may be biased against certain work styles or disabilities',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Transparency',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Employees may not know how their data is being used or evaluated',\n 'description_ar': ''\n }\n ]\n return ethical_issues\n# ============================================================================\n# SOLUTION: TASK 2 - Apply Ethical Frameworks\n# ============================================================================\ndef apply_utilitarianism():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nUtilitarian analysis\"\"\"_analysis =  {\n analysis = {\n 'benefits': [\n 'Increased productivity for company', 'Better performance management',\n 'Cost savings through efficiency',\n 'Data-driven decision making'\n ],\n 'harms': [\n 'Employee stress and anxiety',\n 'Loss of privacy',\n 'Reduced trust and morale',\n 'Potential for discrimination',\n 'Invasion of personal space'\n ],\n 'overall_utility': -2, # Harms outweigh benefits\n 'conclusion': 'Unethical - The harms to employees (stress, privacy loss, dignity)\noutweigh the benefits to the company. The overall utility is negative.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_deontology():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nDeontological analysis\"\"\"_analysis =  {\n analysis = {\n 'moral_rules': [\n 'Respect for human dignity', 'Right to privacy',\n 'Informed consent',\n 'Treat people as ends, not means',\n 'Fair treatment and non-discrimination'\n ],\n 'violations': [\n 'Violates right to privacy without consent',\n 'Uses employees as means to company ends',\n 'Lacks informed consent',\n 'May violate fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates multiple moral duties including respect for privacy, dignity, and informed consent. The system treats employees as means rather than ends.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_rights_based():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nRights-based analysis\"\"\"_analysis =  {\n analysis = {\n 'rights_at_stake': [\n 'Right to privacy', 'Right to autonomy',\n 'Right to dignity',\n 'Right to informed consent',\n 'Right to fair treatment',\n 'Right to work-life balance'\n ],\n 'violations': [\n 'Severe violation of privacy rights',\n 'Violation of autonomy and dignity',\n 'Lack of informed consent',\n 'Potential violation of fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates fundamental human rights including privacy, autonomy, and dignity. The system cannot be justified from a rights-based perspective.',\n 'conclusion_ar': ''\n }\n return analysis\n# ============================================================================\n# SOLUTION: TASK 3 - Identify Stakeholders\n# ============================================================================\ndef identify_stakeholders():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify all stakeholders\"\"\"_stakeholders =  {\n stakeholders = {\n 'Employees': {\n 'interests': ['Privacy', 'Autonomy', 'Fair treatment', 'Job security'],\n 'interests_ar': ['', '', '', ''],\n 'impact': 9, # Highly affected\n 'influence': 5 # Moderate influence\n },\n 'Company Management': {\n 'interests': ['Productivity', 'Cost efficiency', 'Performance metrics'],\n 'interests_ar': ['', '', ''],\n 'impact': 6, # Moderately affected\n 'influence': 9 # High influence\n },\n 'HR Department': {\n 'interests': ['Performance management', 'Compliance', 'Employee relations'],\n 'interests_ar': ['', '', ''],\n 'impact': 7,\n 'influence': 7\n },\n 'AI Developers': {\n 'interests': ['Technical success', 'Innovation', 'Ethical development'],\n 'interests_ar': ['', '', ''],\n 'impact': 5,\n 'influence': 8\n },\n 'Unions': {\n 'interests': ['Worker rights', 'Privacy protection', 'Fair treatment'],\n 'interests_ar': ['', '', ''],\n 'impact': 8,\n 'influence': 6\n },\n 'Regulators': {\n 'interests': ['Compliance', 'Privacy laws', 'Labor rights'],\n 'interests_ar': ['', '', ''],\n 'impact': 4,\n 'influence': 9\n }\n }\n return stakeholders\n# ============================================================================\n# SOLUTION: TASK 4 - Recommendations\n# ============================================================================\ndef provide_recommendations():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nProvide ethical recommendations\"\"\"_recommendations =  [\n recommendations = [\n {\n 'recommendation': 'Obtain explicit, informed consent from all employees',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Limit monitoring to work-related activities only',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Ensure transparency about what is monitored and how data is used',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Implement privacy-preserving techniques (e.g., aggregate data only)',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Regular audits for bias and discrimination',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Provide opt-out mechanisms for employees',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Establish clear accountability and redress mechanisms',\n 'recommendation_ar': '',\n 'priority': 'High'\n }\n ]\n return recommendations\n# ============================================================================\n# SOLUTION: TASK 5 - Visualizations\n# ============================================================================\ndef create_stakeholder_matrix(stakeholders):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nCreate stakeholder impact\"\"\"_names =  list(stakeholders.keys())\n names = list(stakeholders.keys())_impacts =  [s['impact'] for s in stakeholders.values()]\n impacts = [s['impact'] for s in stakeholders.values()]_influences =  [s['influence'] for s in stakeholders.values()]\n influences = [s['influence'] for s in stakeholders.values()]\n fig, ax = plt.subplots(figsize=(12, 8))_scatter =  ax.scatter(influences, impacts, s=200, alpha=0.6,\n scatter = ax.scatter(influences, impacts, s=200, alpha=0.6, \n c=range(len(names)), cmap='viridis', edgecolors='black', linewidth=2)\n for i, name in enumerate(names):\n ax.annotate(name, (influences[i], impacts[i]), \n xytext=(5, 5), textcoords='offset points', fontsize=9)\n ax.set_xlabel('Influence Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_ylabel('Impact Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Stakeholder Impact-Influence Matrix\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: stakeholder_matrix.png\")\nplt.close()\ndef create_ethical_issues_chart(ethical_issues):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"Create ethical issues severity chart\"\"\"\n_issues =  [e['issue'] for e in ethical_issues]\n issues = [e['issue'] for e in ethical_issues]_severities =  [e['severity'] for e in ethical_issues]\n severities = [e['severity'] for e in ethical_issues]_colors =  ['# e74_c3_c' if s >= 9 else '#f39_colors = ['# e74_c3_c' if s >= 9 else '#f39\nc12' if s >= 7 else '#3498\ndb' \n for s in severities]\n fig, ax = plt.subplots(figsize=(12, 8))_bars =  ax.barh(issues, severities, color=colors, alpha=0.8,\n bars = ax.barh(issues, severities, color=colors, alpha=0.8, \n edgecolor='black', linewidth=1.5)\nax.set_xlabel('Severity Score (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Ethical Issues Severity Analysis\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.grid(axis='x', alpha=0.3, linestyle='--')\nfor i, (bar, severity)\nin enumerate(zip(bars, severities)):\n ax.text(severity + 0.2, i, f'{severity}', \n va='center', fontweight='bold', fontsize=11)\n # Legend_high = mpatches.Patch(color='# e74_c3_c', label='High (9-10)' medium = mpatches.Patch(color='# f39\nc12', label='Medium (7-8)_low =  mpatches.Patch(color='# 3498_low = mpatches.Patch(color='# 3498\ndb', label='Low (<7)\nax.legend(handles=[high, medium, low], loc='lower right', fontsize=10)\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: ethical_issues_severity.png\")\nplt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\nprint(\"Unit 1 - Exercise 1 Solution\")\nprint(\"\")\nprint(\"=\"*80)\n # Task 1__\nprint(\"\\n\ud83d\udccb TASK 1: Ethical Issues\")\nprint(\"-\" * 60)_ethical_issues =  identify_ethical_issues()\n ethical_issues = identify_ethical_issues()\n for issue in ethical_issues:\n print(f\"\\n{issue[\"issue']}'issue_ar']}')\nprint(f\" Severity: {issue[\"severity']}')\nprint(f\" {issue[\"description']}')\n # Task 2__\nprint(\"\\n\\n\ud83d\udccb TASK 2: Framework Analysis\")\nprint(\"-\" * 60)\nprint(\"\\nUtilitarianism:\")_util =  apply_utilitarianism()\n util = apply_utilitarianism()\n print(f\" Overall Utility: {util[\"overall_utility']}')\nprint(f\" Conclusion: {util[\"conclusion']}')\nprint(\"\\nDeontology:\")_deon =  apply_deontology()\n deon = apply_deontology()\n print(f\" Conclusion: {deon[\"conclusion']}')\nprint(\"\\nRights-Based:\")_rights =  apply_rights_based()\n rights = apply_rights_based()\n print(f\" Conclusion: {rights[\"conclusion']}')\n # Task 3__\nprint(\"\\n\\n\ud83d\udccb TASK 3: Stakeholders\")\nprint(\"-\" * 60)_stakeholders =  identify_stakeholders()\n stakeholders = identify_stakeholders()\n for name, info in stakeholders.items():\n print(f\"\\n{name}:\")\nprint(f\" Impact: {info[\"impact']}'influence']}')\nprint(f\" Interests: {\", '.join(info['interests'])}')\n # Task 4__\nprint(\"\\n\\n\ud83d\udccb TASK 4: Recommendations\")\nprint(\"-\" * 60)_recommendations =  provide_recommendations()\n recommendations = provide_recommendations()\n for i, rec in enumerate(recommendations, 1):\n print(f\"\\n{i}. [{rec[\"priority']}] {rec['recommendation']}')\nprint(f\" {rec[\"recommendation_ar']}')\n # Task 5__\nprint(\"\\n\\n\ud83d\udccb TASK 5: Creating Visualizations\")\nprint(\"-\" * 60)\ncreate_stakeholder_matrix(stakeholders)\ncreate_ethical_issues_chart(ethical_issues)\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 Solution completed successfully!\")\nprint(\"\")\nprint(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit2-bias-justice/solutions/exercise_02_solution.ipynb",
      "status": "failed",
      "execution_time": 0.8414530754089355,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI_Exercise 2 Solution: Bias Mitigation TechniquesComplete solution for the bias mitigation exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# SOLUTION 1: Generate Biased Dataset\n# ============================================================================\ndef generate_biased_dataset(n_samples = 2000):\n \n    \n    \n    \"\"\"\n Generate a synthetic dataset with bias.\n \"\"\"\n np.random.seed(42)\n # Sensitive attribute (e.g., gender: 0 = group A, 1 = group B)\n sensitive = np.random.binomial(1, 0.5, n_samples)\n # Features_X1 = np.random.normal(0, 1, n_samples)\n X2 = np.random.normal(0, 1, n_samples)\n # Introduce bias: group B has lower probability of positive outcome_true_prob = 0.3 + 0.4 * X1 + 0.3 * X2_bias_penalty = 0.3 * (1 - sensitive) # Group B (0) gets penalty_prob = true_prob - bias_penalty + np.random.normal(0, 0.1, n_samples)\n prob = np.clip(prob, 0, 1)\n # Target variable_y = (prob > 0.5).astype(int)\n # Create DataFrame_df = pd.DataFrame({\n 'feature1': X1, 'feature2': X2,\n 'sensitive': sensitive,\n 'target': y\n })\n return df\n# ============================================================================\n# SOLUTION 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Implement reweighing technique.\n \"\"\"\n # Calculate weights to balance groups_group_counts = pd.Series(sensitive_train).value_counts()\n total = len(sensitive_train)_weights =  np.ones(len(sensitive_train))\n weights = np.ones(len(sensitive_train))\n for group in group_counts.index:\n group_size = group_counts[group]\n # Weight inversely proportional to group size_weights[sensitive_train = = group] = total\n(len(group_counts) * group_size)\n return weights\n# ============================================================================\n# SOLUTION 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \n    \"\"\"\n Train a baseline model without any bias mitigation.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)_model =  RandomForestClassifier(n_estimators = 100, random_state = 42)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train)\n return model, scaler\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Train a model using reweighing technique.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)\n # Get weights from reweighing_weights = preprocess_reweighing(X_train_scaled, y_train, sensitive_train)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train, sample_weight = weights)\n return model, scaler\n# ============================================================================\n# SOLUTION 4: Evaluate Fairness Metrics\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \n    \"\"\"\n Evaluate fairness metrics.\n \"\"\"\n_metrics =  {\n metrics = {\n 'demographic_parity_diff': demographic_parity_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'equalized_odds_diff': equalized_odds_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'accuracy': accuracy_score(y_true, y_pred)\n }\n return metrics\n# ============================================================================\n# SOLUTION 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \n    \"\"\"\n Compare baseline vs reweighing techniques.\n \"\"\"\n # Prepare data_X = df[['feature1', 'feature2']].valuesy = df['target'].values_sensitive = df['sensitive'].values\n # Split data_X_train, X_test, y_train, y_test, sensitive\ntrain, sensitive_test = train_test_split(\n X, y, sensitive, test_size = 0.3, random_state = 42, stratify=y\n )\n print(\"\\n\" + \"=\"*80)\n print(\"BASELINE MODEL (No Mitigation)\")\n print(\"=\"*80)\n # Train baseline model_baseline\nmodel, baseline_scaler = train_baseline_model(X_train, y_train)_X_test_scaled =  baseline_scaler.transform(X_test)\n X_test_scaled = baseline_scaler.transform(X_test)_y_pred_baseline =  baseline_model.predict(X_test_scaled)\n y_pred_baseline = baseline_model.predict(X_test_scaled)\n # Evaluate baseline_baseline_metrics = evaluate_fairness(y_test, y_pred_baseline, sensitive_test)\n print(f\"Accuracy: {baseline_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {baseline_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {baseline_metrics[\"equalized_odds_diff']:.4 f}')\n print(\"\\n\" + \"=\"*80)\n print(\"REWEIGHING MODEL\")\n print(\"=\"*80)\n # Train reweighed model_reweigh\nmodel, reweigh_scaler = train_reweighed_model(X_train, y_train, sensitive_train)_X_test_reweigh =  reweigh_scaler.transform(X_test)\n X_test_reweigh = reweigh_scaler.transform(X_test)_y_pred_reweigh =  reweigh_model.predict(X_test_reweigh)\n y_pred_reweigh = reweigh_model.predict(X_test_reweigh)\n # Evaluate reweighing_reweigh_metrics = evaluate_fairness(y_test, y_pred_reweigh, sensitive_test)\n print(f\"Accuracy: {reweigh_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {reweigh_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {reweigh_metrics[\"equalized_odds_diff']:.4 f}')\n # Comparison__\nprint(\"\\n\" + \"=\"*80)\n print(\"COMPARISON\")\n print(\"=\"*80)\n print(f\"Demographic Parity Improvement: \"\n f\"{abs(baseline_metrics[\"demographic_parity_diff']) - abs(reweigh_metrics['demographic_parity_diff']):.4 f}')\n print(f\"Equalized Odds Improvement: \"\n f\"{abs(baseline_metrics[\"equalized_odds_diff']) - abs(reweigh_metrics['equalized_odds_diff']):.4 f}')\n print(f\"Accuracy Change: {reweigh_metrics[\"accuracy'] - baseline_metrics['accuracy']:.4 f}')\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2 Solution: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate dataset__\nprint(\"\\nGenerating biased dataset...\")_df =  generate_biased_dataset()\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"\\nSensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n print(f\"\\nTarget distribution:\")\n print(df['target'].value_counts())\n # Compare techniques_compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Solution completed!\")\n print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI_Exercise 2 Solution: Bias Mitigation TechniquesComplete solution for the bias mitigation exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# SOLUTION 1: Generate Biased Dataset\n# ============================================================================\ndef generate_biased_dataset(n_samples = 2000):\n \n    \n    \n    \"\"\"\n Generate a synthetic dataset with bias.\n \"\"\"\n np.random.seed(42)\n # Sensitive attribute (e.g., gender: 0 = group A, 1 = group B)\n sensitive = np.random.binomial(1, 0.5, n_samples)\n # Features_X1 = np.random.normal(0, 1, n_samples)\n X2 = np.random.normal(0, 1, n_samples)\n # Introduce bias: group B has lower probability of positive outcome_true_prob = 0.3 + 0.4 * X1 + 0.3 * X2_bias_penalty = 0.3 * (1 - sensitive) # Group B (0) gets penalty_prob = true_prob - bias_penalty + np.random.normal(0, 0.1, n_samples)\n prob = np.clip(prob, 0, 1)\n # Target variable_y = (prob > 0.5).astype(int)\n # Create DataFrame_df = pd.DataFrame({\n 'feature1': X1, 'feature2': X2,\n 'sensitive': sensitive,\n 'target': y\n })\n return df\n# ============================================================================\n# SOLUTION 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Implement reweighing technique.\n \"\"\"\n # Calculate weights to balance groups_group_counts = pd.Series(sensitive_train).value_counts()\n total = len(sensitive_train)_weights =  np.ones(len(sensitive_train))\n weights = np.ones(len(sensitive_train))\n for group in group_counts.index:\n group_size = group_counts[group]\n # Weight inversely proportional to group size_weights[sensitive_train = = group] = total\n(len(group_counts) * group_size)\n return weights\n# ============================================================================\n# SOLUTION 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \n    \"\"\"\n Train a baseline model without any bias mitigation.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)_model =  RandomForestClassifier(n_estimators = 100, random_state = 42)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train)\n return model, scaler\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Train a model using reweighing technique.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)\n # Get weights from reweighing_weights = preprocess_reweighing(X_train_scaled, y_train, sensitive_train)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train, sample_weight = weights)\n return model, scaler\n# ============================================================================\n# SOLUTION 4: Evaluate Fairness Metrics\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \n    \"\"\"\n Evaluate fairness metrics.\n \"\"\"\n_metrics =  {\n metrics = {\n 'demographic_parity_diff': demographic_parity_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'equalized_odds_diff': equalized_odds_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'accuracy': accuracy_score(y_true, y_pred)\n }\n return metrics\n# ============================================================================\n# SOLUTION 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \n    \"\"\"\n Compare baseline vs reweighing techniques.\n \"\"\"\n # Prepare data_X = df[['feature1', 'feature2']].valuesy = df['target'].values_sensitive = df['sensitive'].values\n # Split data_X_train, X_test, y_train, y_test, sensitive\ntrain, sensitive_test = train_test_split(\n X, y, sensitive, test_size = 0.3, random_state = 42, stratify=y\n )\n print(\"\\n\" + \"=\"*80)\n print(\"BASELINE MODEL (No Mitigation)\")\n print(\"=\"*80)\n # Train baseline model_baseline\nmodel, baseline_scaler = train_baseline_model(X_train, y_train)_X_test_scaled =  baseline_scaler.transform(X_test)\n X_test_scaled = baseline_scaler.transform(X_test)_y_pred_baseline =  baseline_model.predict(X_test_scaled)\n y_pred_baseline = baseline_model.predict(X_test_scaled)\n # Evaluate baseline_baseline_metrics = evaluate_fairness(y_test, y_pred_baseline, sensitive_test)\n print(f\"Accuracy: {baseline_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {baseline_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {baseline_metrics[\"equalized_odds_diff']:.4 f}')\n print(\"\\n\" + \"=\"*80)\n print(\"REWEIGHING MODEL\")\n print(\"=\"*80)\n # Train reweighed model_reweigh\nmodel, reweigh_scaler = train_reweighed_model(X_train, y_train, sensitive_train)_X_test_reweigh =  reweigh_scaler.transform(X_test)\n X_test_reweigh = reweigh_scaler.transform(X_test)_y_pred_reweigh =  reweigh_model.predict(X_test_reweigh)\n y_pred_reweigh = reweigh_model.predict(X_test_reweigh)\n # Evaluate reweighing_reweigh_metrics = evaluate_fairness(y_test, y_pred_reweigh, sensitive_test)\n print(f\"Accuracy: {reweigh_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {reweigh_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {reweigh_metrics[\"equalized_odds_diff']:.4 f}')\n # Comparison__\nprint(\"\\n\" + \"=\"*80)\n print(\"COMPARISON\")\n print(\"=\"*80)\n print(f\"Demographic Parity Improvement: \"\n f\"{abs(baseline_metrics[\"demographic_parity_diff']) - abs(reweigh_metrics['demographic_parity_diff']):.4 f}')\n print(f\"Equalized Odds Improvement: \"\n f\"{abs(baseline_metrics[\"equalized_odds_diff']) - abs(reweigh_metrics['equalized_odds_diff']):.4 f}')\n print(f\"Accuracy Change: {reweigh_metrics[\"accuracy'] - baseline_metrics['accuracy']:.4 f}')\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2 Solution: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate dataset__\nprint(\"\\nGenerating biased dataset...\")_df =  generate_biased_dataset()\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"\\nSensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n print(f\"\\nTarget distribution:\")\n print(df['target'].value_counts())\n # Compare techniques_compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Solution completed!\")\n print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit3-privacy-security/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6651818752288818,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1 Solution: Privacy Techniques\nComplete solution for the privacy techniques exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport hashlib\ndef anonymize_data(df, columns_to_anonymize):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data anonymization\"\"\"_df_anonymized =  df.copy()\n    df_anonymized = df.copy()\n    for col in columns_to_anonymize:\n        if col in df_anonymized.columns:\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]\n    return df_anonymized\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data pseudonymization using hashing\"\"\"_df_pseudonymized =  df.copy()\n    df_pseudonymized = df.copy()\n    for col in columns_to_pseudonymize:\n        if col in df_pseudonymized.columns:\n            df_pseudonymized[col] = df_pseudonymized[col].apply(lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]\n            )\n    return df_pseudonymized\ndef add_differential_privacy_noise(value, epsilon=1.0, sensitivity=1.0):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nAdd Laplace noise for differential privacy\"\"\"_scale =  sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nscale = sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nreturn value + noise\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 3 - Exercise 1 Solution: Privacy Techniques\")\nprint(\"=\"*80)\n    # Test with sample data_np.random.seed(42)\ndf = pd.DataFrame({\n        'name': [f'Person_{i}' for i in range(10)], 'email': [f'user{i}@example.com' for i in range(10)], 'value': np.random.normal(100, 20, 10)\n    })\n    print(\"\\nOriginal Data:\")\nprint(df.head())\n    print(\"\\nAnonymized Data:\")_df_anon =  anonymize_data(df, ['name', 'email'])\ndf_anon = anonymize_data(df, ['name', 'email'])\nprint(df_anon.head())\n    print(\"\\nPseudonymized Data:\")_df_pseudo =  pseudonymize_data(df, ['name', 'email'])\ndf_pseudo = pseudonymize_data(df, ['name', 'email'])\nprint(df_pseudo.head())\n    print(\"\\nDifferential Privacy:\")_true_mean =  df['value'].mean()\n    true_mean = df['value'].mean()_noisy_mean =  add_differential_privacy_noise(true_mean, epsilon=1.0)\nnoisy_mean = add_differential_privacy_noise(true_mean, epsilon=1.0)\nprint(f\"True mean: {true_mean:.2f}\")\nprint(f\"Noisy mean: {noisy_mean:.2f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    Implement data anonymization\"\"\"_df_anonymized =  df.copy()\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1 Solution: Privacy Techniques\nComplete solution for the privacy techniques exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport hashlib\ndef anonymize_data(df, columns_to_anonymize):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data anonymization\"\"\"_df_anonymized =  df.copy()\n    df_anonymized = df.copy()\n    for col in columns_to_anonymize:\n        if col in df_anonymized.columns:\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]\n    return df_anonymized\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data pseudonymization using hashing\"\"\"_df_pseudonymized =  df.copy()\n    df_pseudonymized = df.copy()\n    for col in columns_to_pseudonymize:\n        if col in df_pseudonymized.columns:\n            df_pseudonymized[col] = df_pseudonymized[col].apply(lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]\n            )\n    return df_pseudonymized\ndef add_differential_privacy_noise(value, epsilon=1.0, sensitivity=1.0):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nAdd Laplace noise for differential privacy\"\"\"_scale =  sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nscale = sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nreturn value + noise\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 3 - Exercise 1 Solution: Privacy Techniques\")\nprint(\"=\"*80)\n    # Test with sample data_np.random.seed(42)\ndf = pd.DataFrame({\n        'name': [f'Person_{i}' for i in range(10)], 'email': [f'user{i}@example.com' for i in range(10)], 'value': np.random.normal(100, 20, 10)\n    })\n    print(\"\\nOriginal Data:\")\nprint(df.head())\n    print(\"\\nAnonymized Data:\")_df_anon =  anonymize_data(df, ['name', 'email'])\ndf_anon = anonymize_data(df, ['name', 'email'])\nprint(df_anon.head())\n    print(\"\\nPseudonymized Data:\")_df_pseudo =  pseudonymize_data(df, ['name', 'email'])\ndf_pseudo = pseudonymize_data(df, ['name', 'email'])\nprint(df_pseudo.head())\n    print(\"\\nDifferential Privacy:\")_true_mean =  df['value'].mean()\n    true_mean = df['value'].mean()_noisy_mean =  add_differential_privacy_noise(true_mean, epsilon=1.0)\nnoisy_mean = add_differential_privacy_noise(true_mean, epsilon=1.0)\nprint(f\"True mean: {true_mean:.2f}\")\nprint(f\"Noisy mean: {noisy_mean:.2f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    Implement data anonymization\"\"\"_df_anonymized =  df.copy()\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit4-transparency-accountability/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5426058769226074,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1 Solution: SHAP and LIME Explanations\nComplete solution for the SHAP/LIME exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\nage = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples)\nincome = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples)\ncredit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\napproval = (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\nreturn pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval})\ndef calculate_shap_values(model, X_sample, X_train, feature_names):\n    baseline = model.predict_proba(X_train)[:, 1].mean()_sample_pred =  model.predict_proba(X_sample)[0, 1]\n    sample_pred = model.predict_proba(X_sample)[0, 1]_shap_values =  []\n    shap_values = []\n    for i in range(len(feature_names)):\n        X_perm = X_train.copy()\n        X_perm[:, i] = X_sample[0, i]_perm_pred =  model.predict_proba(X_perm)[:, 1].mean()\n        perm_pred = model.predict_proba(X_perm)[:, 1].mean()\n        shap_values.append(sample_pred - perm_pred)\nreturn np.array(shap_values)\ndef calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    perturbations = np.random.normal(0, 0.1, (1000, X_sample.shape[1]))_X_pert =  X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]\n    X_pert = X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]_distances =  np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))\n    distances = np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))_linear_model =  Ridge(alpha=0.1)\nlinear_model = Ridge(alpha=0.1)\nlinear_model.fit(X_pert, y_pert, sample_weight=distances)\nreturn linear_model.coef_\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 4 - Exercise 1 Solution: SHAP and LIME Explanations\")\nprint(\"=\"*80)_df =  generate_dataset()\n    df = generate_dataset()_X =  df[['age', 'income', 'credit_score']].values_y = df['approved'].values_X = df[['age', 'income', 'credit_score']].values_y = df['approved'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)_scaler =  StandardScaler()\n    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n    X_test_scaled = scaler.transform(X_test)_model =  RandomForestClassifier(n_estimators=100, random_state=42)\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)_sample =  X_test_scaled[0:1]\n    sample = X_test_scaled[0:1]_feature_names =  ['age', 'income', 'credit_score']\n    feature_names = ['age', 'income', 'credit_score']_shap_vals =  calculate_shap_values(model, sample, X_train_scaled, feature_names)\nshap_vals = calculate_shap_values(model, sample, X_train_scaled, feature_names)_lime_vals =  calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nlime_vals = calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nprint(\"\\nSHAP Values:\")\nfor name, val in zip(feature_names, shap_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\nLIME Values:\")\nfor name, val in zip(feature_names, lime_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1 Solution: SHAP and LIME Explanations\nComplete solution for the SHAP/LIME exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\nage = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples)\nincome = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples)\ncredit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\napproval = (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\nreturn pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval})\ndef calculate_shap_values(model, X_sample, X_train, feature_names):\n    baseline = model.predict_proba(X_train)[:, 1].mean()_sample_pred =  model.predict_proba(X_sample)[0, 1]\n    sample_pred = model.predict_proba(X_sample)[0, 1]_shap_values =  []\n    shap_values = []\n    for i in range(len(feature_names)):\n        X_perm = X_train.copy()\n        X_perm[:, i] = X_sample[0, i]_perm_pred =  model.predict_proba(X_perm)[:, 1].mean()\n        perm_pred = model.predict_proba(X_perm)[:, 1].mean()\n        shap_values.append(sample_pred - perm_pred)\nreturn np.array(shap_values)\ndef calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    perturbations = np.random.normal(0, 0.1, (1000, X_sample.shape[1]))_X_pert =  X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]\n    X_pert = X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]_distances =  np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))\n    distances = np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))_linear_model =  Ridge(alpha=0.1)\nlinear_model = Ridge(alpha=0.1)\nlinear_model.fit(X_pert, y_pert, sample_weight=distances)\nreturn linear_model.coef_\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 4 - Exercise 1 Solution: SHAP and LIME Explanations\")\nprint(\"=\"*80)_df =  generate_dataset()\n    df = generate_dataset()_X =  df[['age', 'income', 'credit_score']].values_y = df['approved'].values_X = df[['age', 'income', 'credit_score']].values_y = df['approved'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)_scaler =  StandardScaler()\n    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n    X_test_scaled = scaler.transform(X_test)_model =  RandomForestClassifier(n_estimators=100, random_state=42)\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)_sample =  X_test_scaled[0:1]\n    sample = X_test_scaled[0:1]_feature_names =  ['age', 'income', 'credit_score']\n    feature_names = ['age', 'income', 'credit_score']_shap_vals =  calculate_shap_values(model, sample, X_train_scaled, feature_names)\nshap_vals = calculate_shap_values(model, sample, X_train_scaled, feature_names)_lime_vals =  calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nlime_vals = calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nprint(\"\\nSHAP Values:\")\nfor name, val in zip(feature_names, shap_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\nLIME Values:\")\nfor name, val in zip(feature_names, lime_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit5-governance-regulations/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5310859680175781,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExercise 1 Solution: Regulations\nComplete solution for the regulations exercise.\n\"\"\"\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Exercise 1 Solution: Regulations\")\n    print(\"=\"*80)\n    print(\"\\n\u2705 Solution completed!\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5: AI Governance, Regulations, and Future Challenges\nExercise 1 Solution: Regulations\nComplete solution for the regulations exercise.\n\"\"\"\nif__name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"Unit 5 - Exercise 1 Solution: Regulations\")\n    print(\"=\"*80)\n    print(\"\\n\u2705 Solution completed!\")\n    print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_01/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6506690979003906,
      "error": "An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\nprint(\"=\" * 60) # Test 1: Create data matrix print(\"\\n1. create_data_matrix:\")\ndata = create_data_matrix(5, 3)\nprint(f\" Created matrix shape: {data.shape}\")\nprint(f\" Matrix:\\n{data}\") # Test 2: Dot product print(\"\\n2. compute_dot_product:\")\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\nresult = compute_dot_product(v1, v2)\nprint(f\" v1: {v1}\")\nprint(f\" v2: {v2}\")\nprint(f\" Dot product: {result}\")\nprint(f\" Explanation: (1\u00d74) + (2\u00d75) + (3\u00d76) = {result}\") # Test 3: Matrix multiplication print(\"\\n3. matrix_multiplication:\") A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]])\nresult = matrix_multiplication(A, B)\nprint(f\" A:\\n{A}\")\nprint(f\" B:\\n{B}\")\nprint(f\" A @ B:\\n{result}\")\nprint(f\" Explanation:\")\nprint(f\" - First row: [1\u00d75+2\u00d77, 1\u00d76+2\u00d78] = [{result[0,0]}, {result[0,1]}]\")\nprint(f\" - Second row: [3\u00d75+4\u00d77, 3\u00d76+4\u00d78] = [{result[1,0]}, {result[1,1]}]\") # Test 4: Transpose print(\"\\n4. compute_transpose:\")\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])\nresult = compute_transpose(matrix)\nprint(f\" Original:\\n{matrix}\")\nprint(f\" Shape: {matrix.shape}\")\nprint(f\" Transposed:\\n{result}\")\nprint(f\" Shape: {result.shape}\")\nprint(f\" Explanation: Rows become columns, columns become rows\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 Solution verified!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\nprint(\"=\" * 60) # Test 1: Create data matrix print(\"\\n1. create_data_matrix:\")\ndata = create_data_matrix(5, 3)\nprint(f\" Created matrix shape: {data.shape}\")\nprint(f\" Matrix:\\n{data}\") # Test 2: Dot product print(\"\\n2. compute_dot_product:\")\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\nresult = compute_dot_product(v1, v2)\nprint(f\" v1: {v1}\")\nprint(f\" v2: {v2}\")\nprint(f\" Dot product: {result}\")\nprint(f\" Explanation: (1\u00d74) + (2\u00d75) + (3\u00d76) = {result}\") # Test 3: Matrix multiplication print(\"\\n3. matrix_multiplication:\") A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]])\nresult = matrix_multiplication(A, B)\nprint(f\" A:\\n{A}\")\nprint(f\" B:\\n{B}\")\nprint(f\" A @ B:\\n{result}\")\nprint(f\" Explanation:\")\nprint(f\" - First row: [1\u00d75+2\u00d77, 1\u00d76+2\u00d78] = [{result[0,0]}, {result[0,1]}]\")\nprint(f\" - Second row: [3\u00d75+4\u00d77, 3\u00d76+4\u00d78] = [{result[1,0]}, {result[1,1]}]\") # Test 4: Transpose print(\"\\n4. compute_transpose:\")\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])\nresult = compute_transpose(matrix)\nprint(f\" Original:\\n{matrix}\")\nprint(f\" Shape: {matrix.shape}\")\nprint(f\" Transposed:\\n{result}\")\nprint(f\" Shape: {result.shape}\")\nprint(f\" Explanation: Rows become columns, columns become rows\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 Solution verified!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_01/exercises/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5363638401031494,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_determinant(matrix): return np.linalg.det(matrix)\ndef compute_matrix_inverse(matrix): return np.linalg.inv(matrix)\ndef compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix)\nreturn eigenvals, eigenvecs\ndef verify_inverse(matrix, inverse): identity = np.eye(matrix.shape[0])\nresult = matrix @ inverse return np.allclose(result, identity)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = matrix @ inverse return np.allclose(result, identity)# Test the solution\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_determinant(matrix): return np.linalg.det(matrix)\ndef compute_matrix_inverse(matrix): return np.linalg.inv(matrix)\ndef compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix)\nreturn eigenvals, eigenvecs\ndef verify_inverse(matrix, inverse): identity = np.eye(matrix.shape[0])\nresult = matrix @ inverse return np.allclose(result, identity)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = matrix @ inverse return np.allclose(result, identity)# Test the solution\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_02/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.8957650661468506,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead\ndef compute_derivative(func, x, h=1e-6): return (func(x + h) - func(x))\nh\ndef compute_gradient(func, point): h = 1e-6 grad = np.zeros_like(point)\nfor i in range(len(point)): # Create points for computing partial derivative point_plus = point.copy() point_plus[i] += h point_minus = point.copy() point_minus[i] -= h # Partial derivative: \u2202f/\u2202x\ni \u2248 (f(x+h) - f(x-h))\n(2\nh)\ngrad[i] = (func(point_plus) - func(point_minus))\n(2 * h)\nreturn grad\ndef gradient_descent_step(func, x, learning_rate = 0.1): h = 1e-6 # Compute gradient numerically grad = (func(x + h) - func(x - h))\n(2 * h) # Move in opposite direction return x - learning\nrate * grad# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    i \u2248 (f(x+h) - f(x-h))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '\u2248' (U+2248)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead\ndef compute_derivative(func, x, h=1e-6): return (func(x + h) - func(x))\nh\ndef compute_gradient(func, point): h = 1e-6 grad = np.zeros_like(point)\nfor i in range(len(point)): # Create points for computing partial derivative point_plus = point.copy() point_plus[i] += h point_minus = point.copy() point_minus[i] -= h # Partial derivative: \u2202f/\u2202x\ni \u2248 (f(x+h) - f(x-h))\n(2\nh)\ngrad[i] = (func(point_plus) - func(point_minus))\n(2 * h)\nreturn grad\ndef gradient_descent_step(func, x, learning_rate = 0.1): h = 1e-6 # Compute gradient numerically grad = (func(x + h) - func(x - h))\n(2 * h) # Move in opposite direction return x - learning\nrate * grad# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    i \u2248 (f(x+h) - f(x-h))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '\u2248' (U+2248)\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_02/exercises/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.6371140480041504,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\nreturn x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50): results = {} for lr in learning_rates: final_x, _ = gradient_descent(func, gradient_func, initial_x, lr, iterations)\nresults[lr] = final\nx return results# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\nreturn x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50): results = {} for lr in learning_rates: final_x, _ = gradient_descent(func, gradient_func, initial_x, lr, iterations)\nresults[lr] = final\nx return results# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_03/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6602706909179688,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nclass SimpleGDOptimizer: \n\ndef__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\nclass MomentumOptimizer: \n\ndef__init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.velocity = None def update(self, params, grads): if self.velocity is None: self.velocity = np.zeros_like(params) # Update velocity: v = momentum * v + lr * grads self.velocity = self.momentum * self.velocity + self.lr * grads # Update params: params = params - velocity return params - self.velocity\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100): results = {} for name, optimizer in optimizers.items(): params = initial_params.copy() if isinstance(initial_params, np.ndarray) else initial_params for i in range(iterations): grads = grad_func(params) params = optimizer.update(params, grads) results[name] = params return results\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 2\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nclass SimpleGDOptimizer: \n\ndef__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\nclass MomentumOptimizer: \n\ndef__init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.velocity = None def update(self, params, grads): if self.velocity is None: self.velocity = np.zeros_like(params) # Update velocity: v = momentum * v + lr * grads self.velocity = self.momentum * self.velocity + self.lr * grads # Update params: params = params - velocity return params - self.velocity\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100): results = {} for name, optimizer in optimizers.items(): params = initial_params.copy() if isinstance(initial_params, np.ndarray) else initial_params for i in range(iterations): grads = grad_func(params) params = optimizer.update(params, grads) results[name] = params return results\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 2\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_04/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5345039367675781,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_covariance_matrix(data): # Center the data (subtract mean) centered = data - np.mean(data, axis=0) # Compute covariance: (1/n) * X^T @ X n = data.shape[0] return (centered.T @ centered)\n(n - 1)\ndef pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\ncomponents top_eigenvectors = eigenvectors[:, :n_components] # 6. Project data reduced = centered @ top_eigenvectors # 7. Calculate explained variance ratio explained_variance_ratio = np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues) return reduced, explained_variance_ratio\ndef calculate_variance_explained(eigenvalues, n_components): return np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    (n - 1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_covariance_matrix(data): # Center the data (subtract mean) centered = data - np.mean(data, axis=0) # Compute covariance: (1/n) * X^T @ X n = data.shape[0] return (centered.T @ centered)\n(n - 1)\ndef pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\ncomponents top_eigenvectors = eigenvectors[:, :n_components] # 6. Project data reduced = centered @ top_eigenvectors # 7. Calculate explained variance ratio explained_variance_ratio = np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues) return reduced, explained_variance_ratio\ndef calculate_variance_explained(eigenvalues, n_components): return np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    (n - 1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_05/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5391027927398682,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95): n = len(data)\nmean = np.mean(data)\nstd_err = stats.sem(data) # Standard error of the mean # Get t-critical value alpha = 1 - confidence t_critical = stats.t.ppf(1 - alpha/2, df=n-1) # Compute CI margin = t_critical * std\nerr lower = mean - margin upper = mean + margin return (lower, upper)\ndef t_test_two_samples(sample1, sample2): t_stat, p_value = stats.ttest_ind(sample1, sample2)\nreturn t_stat, p_value\ndef interpret_p_value(p_value, alpha=0.05): if p_value < alpha: return f\"Significant difference (p={p_value:.4f} < {alpha})\" else: return f\"No significant difference (p={p_value:.4f} >= {alpha})\"def compare_models(model1_scores, model2_scores, alpha=0.05): # Compute means and CIs mean1 = np.mean(model1_scores)\nmean2 = np.mean(model2_scores)\nci1 = compute_confidence_interval(model1_scores)\nci2 = compute_confidence_interval(model2_scores) # Perform t-test t\nstat, p_value = t_test_two_samples(model1_scores, model2_scores) # Interpret interpretation = interpret_p_value(p_value, alpha)\nreturn { 'model1_mean': mean1, 'model2_mean': mean2, 'model1_ci': ci1, 'model2_ci': ci2, 't_statistic': t_stat, 'p_value': p_value, 'interpretation': interpretation, 'significant': p\nvalue < alpha }\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    err lower = mean - margin upper = mean + margin return (lower, upper)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95): n = len(data)\nmean = np.mean(data)\nstd_err = stats.sem(data) # Standard error of the mean # Get t-critical value alpha = 1 - confidence t_critical = stats.t.ppf(1 - alpha/2, df=n-1) # Compute CI margin = t_critical * std\nerr lower = mean - margin upper = mean + margin return (lower, upper)\ndef t_test_two_samples(sample1, sample2): t_stat, p_value = stats.ttest_ind(sample1, sample2)\nreturn t_stat, p_value\ndef interpret_p_value(p_value, alpha=0.05): if p_value < alpha: return f\"Significant difference (p={p_value:.4f} < {alpha})\" else: return f\"No significant difference (p={p_value:.4f} >= {alpha})\"def compare_models(model1_scores, model2_scores, alpha=0.05): # Compute means and CIs mean1 = np.mean(model1_scores)\nmean2 = np.mean(model2_scores)\nci1 = compute_confidence_interval(model1_scores)\nci2 = compute_confidence_interval(model2_scores) # Perform t-test t\nstat, p_value = t_test_two_samples(model1_scores, model2_scores) # Interpret interpretation = interpret_p_value(p_value, alpha)\nreturn { 'model1_mean': mean1, 'model2_mean': mean2, 'model1_ci': ci1, 'model2_ci': ci2, 't_statistic': t_stat, 'p_value': p_value, 'interpretation': interpretation, 'significant': p\nvalue < alpha }\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    err lower = mean - margin upper = mean + margin return (lower, upper)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    }
  ],
  "summary": {
    "passed": 527,
    "failed": 290,
    "pass_rate": 64.50428396572828
  }
}