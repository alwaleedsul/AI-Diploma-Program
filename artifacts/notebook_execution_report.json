{
  "timestamp": "2026-01-17T03:49:18.861389",
  "total_notebooks": 817,
  "execution_method": "nbclient",
  "timeout_per_notebook": 300,
  "results": [
    {
      "path": "Course 01/unit1-ai-foundations/examples/01_ai_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.9433331489562988,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/02_ai_history.ipynb",
      "status": "passed",
      "execution_time": 0.9544320106506348,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/03_intelligent_agents_rationality.ipynb",
      "status": "passed",
      "execution_time": 0.6307797431945801,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/04_philosophy_turing_test.ipynb",
      "status": "passed",
      "execution_time": 0.6625900268554688,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/05_adversarial_search_minimax.ipynb",
      "status": "passed",
      "execution_time": 0.7831652164459229,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/06_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.843756914138794,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/07_python_basics_for_ai.ipynb",
      "status": "passed",
      "execution_time": 0.7877280712127686,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/08_generative_ai_intro.ipynb",
      "status": "passed",
      "execution_time": 0.7459938526153564,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/09_case_studies_intelligent_agents.ipynb",
      "status": "passed",
      "execution_time": 0.7531728744506836,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/implementing_search_algorithms_uninformed_heuristic_greedy.ipynb",
      "status": "passed",
      "execution_time": 1.6685881614685059,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/working_with_numpy_for_data_processing_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.6430001258850098,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.9141130447387695,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit1-ai-foundations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6985747814178467,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "other"
    },
    {
      "path": "Course 01/unit1-introduction/examples/10_implementing_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.742063045501709,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/10_search_algorithms_uninformed_heuristic.ipynb",
      "status": "passed",
      "execution_time": 0.8116331100463867,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/11_numpy_data_processing.ipynb",
      "status": "passed",
      "execution_time": 0.8581678867340088,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/11_working_with_numpy_data_processing.ipynb",
      "status": "passed",
      "execution_time": 0.813079833984375,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/01_applied_python_review.ipynb",
      "status": "passed",
      "execution_time": 0.5454928874969482,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/02_encoding_categorical_features.ipynb",
      "status": "passed",
      "execution_time": 1.3991212844848633,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/03_supervised_unsupervised_models.ipynb",
      "status": "passed",
      "execution_time": 1.516517162322998,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_applied_python_review.ipynb",
      "status": "passed",
      "execution_time": 0.6689300537109375,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_data_generation_process.ipynb",
      "status": "passed",
      "execution_time": 0.953575849533081,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_implementing_expert_system.ipynb",
      "status": "passed",
      "execution_time": 0.7512109279632568,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/05_implementing_simple_expert_system.ipynb",
      "status": "passed",
      "execution_time": 0.5275042057037354,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/05_working_with_rdf_sparql.ipynb",
      "status": "passed",
      "execution_time": 0.8270719051361084,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_applying_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.7712550163269043,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_expert_system_python.ipynb",
      "status": "passed",
      "execution_time": 0.6643040180206299,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_working_with_rdf_sparql.ipynb",
      "status": "passed",
      "execution_time": 0.6989519596099854,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/07_applying_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.7306380271911621,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/07_bayes_theorem_applications.ipynb",
      "status": "passed",
      "execution_time": 0.5891931056976318,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/08_encoding_categorical_features.ipynb",
      "status": "passed",
      "execution_time": 1.4459397792816162,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/09_supervised_unsupervised_models.ipynb",
      "status": "passed",
      "execution_time": 1.5281929969787598,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/10_data_generation_process.ipynb",
      "status": "passed",
      "execution_time": 1.0693869590759277,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/01_bfs_algorithm.ipynb",
      "status": "passed",
      "execution_time": 1.1676859855651855,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/02_dfs_algorithm.ipynb",
      "status": "passed",
      "execution_time": 1.1243791580200195,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/03_astar_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.9120450019836426,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/04_expert_systems.ipynb",
      "status": "passed",
      "execution_time": 0.6659789085388184,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/05_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.781574010848999,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/06_machine_learning_intro.ipynb",
      "status": "failed",
      "execution_time": 3.5326719284057617,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom sklearn.preprocessing import LabelEncoder\n# Method 1: Label Encoding (for ordinal data)\nlabel_encoder = LabelEncoder()\ndf['location_encoded'] = label_encoder.fit_transform(df['location'])\n\nprint(\"=== Label Encoding ===\")\nprint(df[['location', 'location_encoded']])\n\n# Method 2: One-Hot Encoding (for nominal data)\nonehot_encoder = OneHotEncoder(sparse=False)\nlocation_onehot = onehot_encoder.fit_transform(df[['location']])\nlocation_df = pd.DataFrame(\n location_onehot, columns=[f'location_{cat}' for cat in label_encoder.classes_]\n)\n\nprint(\"\\n=== One-Hot Encoding ===\")\nprint(location_df)\n\n# Combine with original features\nX_encoded = pd.concat([X, location_df], axis=1)\nprint(\"\\n=== Combined Features ===\")\nprint(X_encoded)\n\n------------------\n\n----- stdout -----\n=== Label Encoding ===\n  location  location_encoded\n0        A                 0\n1        B                 1\n2        A                 0\n3        C                 2\n4        B                 1\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 2: One-Hot Encoding (for nominal data)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m location_onehot \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m location_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     13\u001b[0m  location_onehot, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_]\n\u001b[1;32m     14\u001b[0m )\n\n\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom sklearn.preprocessing import LabelEncoder\n# Method 1: Label Encoding (for ordinal data)\nlabel_encoder = LabelEncoder()\ndf['location_encoded'] = label_encoder.fit_transform(df['location'])\n\nprint(\"=== Label Encoding ===\")\nprint(df[['location', 'location_encoded']])\n\n# Method 2: One-Hot Encoding (for nominal data)\nonehot_encoder = OneHotEncoder(sparse=False)\nlocation_onehot = onehot_encoder.fit_transform(df[['location']])\nlocation_df = pd.DataFrame(\n location_onehot, columns=[f'location_{cat}' for cat in label_encoder.classes_]\n)\n\nprint(\"\\n=== One-Hot Encoding ===\")\nprint(location_df)\n\n# Combine with original features\nX_encoded = pd.concat([X, location_df], axis=1)\nprint(\"\\n=== Combined Features ===\")\nprint(X_encoded)\n\n------------------\n\n----- stdout -----\n=== Label Encoding ===\n  location  location_encoded\n0        A                 0\n1        B                 1\n2        A                 0\n3        C                 2\n4        B                 1\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 2: One-Hot Encoding (for nominal data)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m location_onehot \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m location_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     13\u001b[0m  location_onehot, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_]\n\u001b[1;32m     14\u001b[0m )\n\n\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/07_rdf_sparql_knowledge_graph.ipynb",
      "status": "failed",
      "execution_time": 0.7005476951599121,
      "error": "An error occurred while executing the following cell:\n------------------\n# Serialize the graph in different formats\nprint(\"=\" * 60)\nprint(\"RDF/XML Format:\")\nprint(\"=\" * 60)\nprint(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\u001b[0m\n\u001b[0m                                                                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Serialize the graph in different formats\nprint(\"=\" * 60)\nprint(\"RDF/XML Format:\")\nprint(\"=\" * 60)\nprint(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\u001b[0m\n\u001b[0m                                                                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5432689189910889,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 1: AI Concepts and Applications\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0627\u0644\u062a\u0637\u0628\u064a\u0642\u0627\u062a\n\nComplete the following exercises to practice Unit 2 concepts.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0648\u062d\u062f\u0629 2.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n\n# Exercise 1: Expert System Implementation\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631p\nrint(\"Exercise 1: Expert System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631\")\nprint(\"-\" * 60)\n\n# TODO: Create a simple expert system for product recommendation\n# The system should recommend products based on:\n# - Budget (low, medium, high)\n# - Interest (tech, fashion, sports)\n# - Age group (young, adult, senior)\n# TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637 \u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u0645\u0646\u062a\u062c\u0627\u062a\n\ndef bfs_complete(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Complete the BFS implementation.\n TODO: \u0623\u0643\u0645\u0644 \u062a\u0646\u0641\u064a\u0630 BFS.\n \n Args:\n graph: Dictionary representing the graph\n start: Starting nodegoal: Target node\n \n Returns:\n Shortest path from start to goal\n \"\"\"\n # TODO: Initialize queue with start node\n # TODO: Initialize visited se\nt\n # TODO: Implement BFS algorith\nm\n # TODO: Return path when goal is foun\nd\n pass\n\n# Test your implementation\nprint(\"\\nTesting BFS:\")\nresult = bfs_complete(graph, '1', '6')\nprint(f\"Path from 1 to 6: {result}\")\n\n# Exercise 2: DFS Path Findin\ng\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DF\nSp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: DFS Path Finding\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DFS\")\nprint(\"=\" * 60)\n\ndef dfs_path(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Implement DFS to find any path from start to goal.\n TODO: \u0646\u0641\u0630 DFS \u0644\u0625\u064a\u062c\u0627\u062f \u0623\u064a \u0645\u0633\u0627\u0631 \u0645\u0646 \u0627\u0644\u0628\u062f\u0627\u064a\u0629 \u0625\u0644\u0649 \u0627\u0644\u0647\u062f\u0641.\n \"\"\"\n # TODO: Implement DFS (recursive or iterativ\ne)\n pass\n\n# Test your implementation\nresult = dfs_path(graph, '4', '3')\nprint(f\"Path from 4 to 3: {result}\")\n\n# Exercise 3: Maze Solver\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 3: Maze Solver\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629\")\nprint(\"=\" * 60)\n\n# Simple maze representation (0 = wall, 1 = path)\n# \u062a\u0645\u062b\u064a\u0644 \u0645\u062a\u0627\u0647\u0629 \u0628\u0633\u064a\u0637\u0629 (0 = \u062c\u062f\u0627\u0631\u060c 1 = \u0645\u0633\u0627\u0631)\nmaze = [\n [1, 1, 0, 1],\n [0, 1, 1, 1],\n [1, 0, 1, 0],\n [1, 1, 1, 1]\n]\n\ndef solve_maze(maze, start, end):\n \n    \n    \"\"\"\n TODO: Use BFS or DFS to solve the maze.\n TODO: \u0627\u0633\u062a\u062e\u062f\u0645 BFS \u0623\u0648 DFS \u0644\u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629.\n \n Args:\n maze: 2D list representing the mazestart: (row, col) starting position\n end: (row, col) ending position\n \n Returns:\n List of (row, col) positions forming the path\n \"\"\"\n # TODO: Implement maze solving algorith\nm\n pass\n\n# Test maze solver\nstart_pos = (0, 0)\nend_pos = (3, 3)\npath = solve_maze(maze, start_pos, end_pos)\nprint(f\"Path from {start_pos} to {end_pos}: {path}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 1: AI Concepts and Applications\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0627\u0644\u062a\u0637\u0628\u064a\u0642\u0627\u062a\n\nComplete the following exercises to practice Unit 2 concepts.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0648\u062d\u062f\u0629 2.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n\n# Exercise 1: Expert System Implementation\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631p\nrint(\"Exercise 1: Expert System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631\")\nprint(\"-\" * 60)\n\n# TODO: Create a simple expert system for product recommendation\n# The system should recommend products based on:\n# - Budget (low, medium, high)\n# - Interest (tech, fashion, sports)\n# - Age group (young, adult, senior)\n# TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637 \u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u0645\u0646\u062a\u062c\u0627\u062a\n\ndef bfs_complete(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Complete the BFS implementation.\n TODO: \u0623\u0643\u0645\u0644 \u062a\u0646\u0641\u064a\u0630 BFS.\n \n Args:\n graph: Dictionary representing the graph\n start: Starting nodegoal: Target node\n \n Returns:\n Shortest path from start to goal\n \"\"\"\n # TODO: Initialize queue with start node\n # TODO: Initialize visited se\nt\n # TODO: Implement BFS algorith\nm\n # TODO: Return path when goal is foun\nd\n pass\n\n# Test your implementation\nprint(\"\\nTesting BFS:\")\nresult = bfs_complete(graph, '1', '6')\nprint(f\"Path from 1 to 6: {result}\")\n\n# Exercise 2: DFS Path Findin\ng\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DF\nSp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: DFS Path Finding\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DFS\")\nprint(\"=\" * 60)\n\ndef dfs_path(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Implement DFS to find any path from start to goal.\n TODO: \u0646\u0641\u0630 DFS \u0644\u0625\u064a\u062c\u0627\u062f \u0623\u064a \u0645\u0633\u0627\u0631 \u0645\u0646 \u0627\u0644\u0628\u062f\u0627\u064a\u0629 \u0625\u0644\u0649 \u0627\u0644\u0647\u062f\u0641.\n \"\"\"\n # TODO: Implement DFS (recursive or iterativ\ne)\n pass\n\n# Test your implementation\nresult = dfs_path(graph, '4', '3')\nprint(f\"Path from 4 to 3: {result}\")\n\n# Exercise 3: Maze Solver\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 3: Maze Solver\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629\")\nprint(\"=\" * 60)\n\n# Simple maze representation (0 = wall, 1 = path)\n# \u062a\u0645\u062b\u064a\u0644 \u0645\u062a\u0627\u0647\u0629 \u0628\u0633\u064a\u0637\u0629 (0 = \u062c\u062f\u0627\u0631\u060c 1 = \u0645\u0633\u0627\u0631)\nmaze = [\n [1, 1, 0, 1],\n [0, 1, 1, 1],\n [1, 0, 1, 0],\n [1, 1, 1, 1]\n]\n\ndef solve_maze(maze, start, end):\n \n    \n    \"\"\"\n TODO: Use BFS or DFS to solve the maze.\n TODO: \u0627\u0633\u062a\u062e\u062f\u0645 BFS \u0623\u0648 DFS \u0644\u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629.\n \n Args:\n maze: 2D list representing the mazestart: (row, col) starting position\n end: (row, col) ending position\n \n Returns:\n List of (row, col) positions forming the path\n \"\"\"\n # TODO: Implement maze solving algorith\nm\n pass\n\n# Test maze solver\nstart_pos = (0, 0)\nend_pos = (3, 3)\npath = solve_maze(maze, start_pos, end_pos)\nprint(f\"Path from {start_pos} to {end_pos}: {path}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit2-search-algorithms/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7478630542755127,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "other"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/01_knowledge_graph.ipynb",
      "status": "passed",
      "execution_time": 0.6532669067382812,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/02_rule_based_systems.ipynb",
      "status": "passed",
      "execution_time": 0.534635066986084,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/03_expert_systems.ipynb",
      "status": "passed",
      "execution_time": 0.6142370700836182,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/04_regression_classification.ipynb",
      "status": "passed",
      "execution_time": 1.7817790508270264,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/05_perceptron_xor.ipynb",
      "status": "passed",
      "execution_time": 13.590374946594238,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.7492337226867676,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6839921474456787,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "other"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/04_implementing_regression_classification.ipynb",
      "status": "passed",
      "execution_time": 1.4283788204193115,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/04_xor_problem_neural_network.ipynb",
      "status": "passed",
      "execution_time": 0.7614200115203857,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/05_solving_xor_keras.ipynb",
      "status": "passed",
      "execution_time": 12.369170188903809,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/05_single_neuron_activation_functions.ipynb",
      "status": "passed",
      "execution_time": 0.892888069152832,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/06_multiclass_classification_keras.ipynb",
      "status": "passed",
      "execution_time": 0.7750949859619141,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/07_cnn_image_classification.ipynb",
      "status": "passed",
      "execution_time": 0.5484139919281006,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/08_rnn_lstm_gru_sequential.ipynb",
      "status": "passed",
      "execution_time": 0.7756390571594238,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/09_early_stopping_regularization.ipynb",
      "status": "passed",
      "execution_time": 0.7764089107513428,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/01_simple_perceptron.ipynb",
      "status": "passed",
      "execution_time": 0.9010989665985107,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/02_generative_ai_intro.ipynb",
      "status": "passed",
      "execution_time": 0.6741998195648193,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/03_cnn_rnn_architectures.ipynb",
      "status": "passed",
      "execution_time": 3.282799005508423,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/applying_early_stopping_and_regularization_to_prevent_overfitting.ipynb",
      "status": "passed",
      "execution_time": 1.680405855178833,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/building_a_multi_class_classification_model_with_keras.ipynb",
      "status": "passed",
      "execution_time": 1.3209171295166016,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/experimenting_with_rnn_lstm_gru_for_sequential_data.ipynb",
      "status": "passed",
      "execution_time": 1.629256010055542,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/implementing_a_cnn_for_image_classification_using_tensorflowkeras.ipynb",
      "status": "passed",
      "execution_time": 1.5632262229919434,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/implementing_a_single_neuron_with_different_activation_functions_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.4502179622650146,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7452828884124756,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 1: Neural Networks Basics\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\nComplete the following exercises.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Implement Activation Function\ns\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637p\nrint(\"Exercise 1: Activation Functions\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\nprint(\"-\" * 60)\n\ndef sigmoid(x):\n \n    \n    \"\"\"\n TODO: Implement sigmoid activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n \n Formula: 1 / (1 + e^(-x))\n \"\"\"\n # TODO: Implement sigmoi\nd\n pass\n\ndef relu(x):\n \n    \n    \"\"\"\n TODO: Implement ReLU activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n \n Formula: max(0, x)\n \"\"\"\n # TODO: Implement ReLU\n pass\n\n# Test activation function\nst\nest_values = [-2, -1, 0, 1, 2]\nprint(\"\\nTesting activation functions:\")\nfor x in test_values:\n sig_result = sigmoid(x)\n relu_result = relu(x)\n print(f\"x={x:3d}: sigmoid={sig _result:.3f}, ReLU={relu_result:.3f}\")\n\n# Exercise 2: Simple Perceptron for OR Gate\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: OR Gate Perceptron\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\nprint(\"=\" * 60)\n\n# TODO: Create training data for OR gate\n# TODO: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nX_or = np.array([\n # TODO: Add OR gate inputs\n])\n\ny_or = np.array([\n # TODO: Add OR gate output\ns\n])\n\n# TODO: Train a perceptron to learn OR gate\n# TODO: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:40\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 1: Neural Networks Basics\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\nComplete the following exercises.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Implement Activation Function\ns\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637p\nrint(\"Exercise 1: Activation Functions\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\nprint(\"-\" * 60)\n\ndef sigmoid(x):\n \n    \n    \"\"\"\n TODO: Implement sigmoid activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n \n Formula: 1 / (1 + e^(-x))\n \"\"\"\n # TODO: Implement sigmoi\nd\n pass\n\ndef relu(x):\n \n    \n    \"\"\"\n TODO: Implement ReLU activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n \n Formula: max(0, x)\n \"\"\"\n # TODO: Implement ReLU\n pass\n\n# Test activation function\nst\nest_values = [-2, -1, 0, 1, 2]\nprint(\"\\nTesting activation functions:\")\nfor x in test_values:\n sig_result = sigmoid(x)\n relu_result = relu(x)\n print(f\"x={x:3d}: sigmoid={sig _result:.3f}, ReLU={relu_result:.3f}\")\n\n# Exercise 2: Simple Perceptron for OR Gate\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: OR Gate Perceptron\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\nprint(\"=\" * 60)\n\n# TODO: Create training data for OR gate\n# TODO: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nX_or = np.array([\n # TODO: Add OR gate inputs\n])\n\ny_or = np.array([\n # TODO: Add OR gate output\ns\n])\n\n# TODO: Train a perceptron to learn OR gate\n# TODO: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:40\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7719459533691406,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "other"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/04_gan_transformer_generative.ipynb",
      "status": "passed",
      "execution_time": 0.7766439914703369,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/05_eda_data_preprocessing_medical.ipynb",
      "status": "passed",
      "execution_time": 1.6827549934387207,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/06_feature_scaling_encoding_missing_data.ipynb",
      "status": "passed",
      "execution_time": 1.4603140354156494,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/01_generative_ai_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.896618127822876,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/02_generative_vs_discriminative.ipynb",
      "status": "passed",
      "execution_time": 2.020972728729248,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/03_course_summary.ipynb",
      "status": "passed",
      "execution_time": 0.7909433841705322,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/04_diabetes_classification_ffnn.ipynb",
      "status": "failed",
      "execution_time": 4.673556089401245,
      "error": "An error occurred while executing the following cell:\n------------------\n# Create sample medical dataset (simplified)\nnp.random.seed(42)\nn_samples = 1000\n\n# Features: age, BMI, glucose, blood pressure, etc.\ndata = {\n 'age': np.random.randint(20, 80, n_samples),\n 'bmi': np.random.normal(25, 5, n_samples),\n 'glucose': np.random.normal(120, 30, n_samples),\n 'blood_pressure': np.random.normal(80, 10, n_samples),\n 'insulin': np.random.normal(100, 40, n_samples)\n}\n\ndf = pd.DataFrame(data)\n\n# Create target: diabetes (1) or no diabetes (0)\n# Higher glucose and BMI increase diabetes risk\ndiabetes_prob = 1 / (1 + np.exp(-(df['glucose'] - 120) / 30 - (df['bmi'] - 25) / 5))\ndf['diabetes'] = (np.random.random(n_samples) < diabetes_prob).astype(int)\n\nprint(\"=== Dataset Overview ===\")\nprint(f\"Total samples: {len(df)}\")\nprint(f\"Diabetes cases: {df['diabetes'].sum()} ({df['diabetes'].mean():.1%})\")\nprint(f\"No diabetes: {(1-df['diabetes']).sum()} ({(1-df['diabetes']).mean():.1%})\")\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n# EDA: Check for missing values\nprint(\"\\n=== EDA: Missing Values ===\")\nprint(df.isnull().sum())\n\n# Prepare data\nX = df[['age', 'bmi', 'glucose', 'blood_pressure', 'insulin']].valuesy = df['diabetes'].values\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"\\nTraining set: {X_train_scaled.shape[0]} samples\")\nprint(f\"Test set: {X_test_scaled.shape[0]} samples\")\n\n------------------\n\n----- stdout -----\n=== Dataset Overview ===\nTotal samples: 1000\nDiabetes cases: 533 (53.3%)\nNo diabetes: 467 (46.7%)\n\nFirst few rows:\n   age        bmi     glucose  blood_pressure     insulin  diabetes\n0   58  24.991820   99.492186       74.965789  122.493762         0\n1   71  22.869838  141.286007       78.583902   84.487996         0\n2   48  31.377316  113.659917       66.175401   88.088104         0\n3   34  24.542170  116.477974       95.407858   52.931859         1\n4   62  29.685363  119.185247       80.695481   99.402529         1\n\n=== EDA: Missing Values ===\nage               0\nbmi               0\nglucose           0\nblood_pressure    0\ninsulin           0\ndiabetes          0\ndtype: int64\n----- stderr -----\n/var/folders/7n/l2c2z2x57871xg4f_0drsv1m0000gn/T/ipykernel_80888/389187144.py:32: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  X = df[['age', 'bmi', 'glucose', 'blood_pressure', 'insulin']].valuesy = df['diabetes'].values\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglucose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblood_pressure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsulin\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvaluesy \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Feature scaling\u001b[39;00m\n\u001b[1;32m     38\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Create sample medical dataset (simplified)\nnp.random.seed(42)\nn_samples = 1000\n\n# Features: age, BMI, glucose, blood pressure, etc.\ndata = {\n 'age': np.random.randint(20, 80, n_samples),\n 'bmi': np.random.normal(25, 5, n_samples),\n 'glucose': np.random.normal(120, 30, n_samples),\n 'blood_pressure': np.random.normal(80, 10, n_samples),\n 'insulin': np.random.normal(100, 40, n_samples)\n}\n\ndf = pd.DataFrame(data)\n\n# Create target: diabetes (1) or no diabetes (0)\n# Higher glucose and BMI increase diabetes risk\ndiabetes_prob = 1 / (1 + np.exp(-(df['glucose'] - 120) / 30 - (df['bmi'] - 25) / 5))\ndf['diabetes'] = (np.random.random(n_samples) < diabetes_prob).astype(int)\n\nprint(\"=== Dataset Overview ===\")\nprint(f\"Total samples: {len(df)}\")\nprint(f\"Diabetes cases: {df['diabetes'].sum()} ({df['diabetes'].mean():.1%})\")\nprint(f\"No diabetes: {(1-df['diabetes']).sum()} ({(1-df['diabetes']).mean():.1%})\")\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n# EDA: Check for missing values\nprint(\"\\n=== EDA: Missing Values ===\")\nprint(df.isnull().sum())\n\n# Prepare data\nX = df[['age', 'bmi', 'glucose', 'blood_pressure', 'insulin']].valuesy = df['diabetes'].values\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"\\nTraining set: {X_train_scaled.shape[0]} samples\")\nprint(f\"Test set: {X_test_scaled.shape[0]} samples\")\n\n------------------\n\n----- stdout -----\n=== Dataset Overview ===\nTotal samples: 1000\nDiabetes cases: 533 (53.3%)\nNo diabetes: 467 (46.7%)\n\nFirst few rows:\n   age        bmi     glucose  blood_pressure     insulin  diabetes\n0   58  24.991820   99.492186       74.965789  122.493762         0\n1   71  22.869838  141.286007       78.583902   84.487996         0\n2   48  31.377316  113.659917       66.175401   88.088104         0\n3   34  24.542170  116.477974       95.407858   52.931859         1\n4   62  29.685363  119.185247       80.695481   99.402529         1\n\n=== EDA: Missing Values ===\nage               0\nbmi               0\nglucose           0\nblood_pressure    0\ninsulin           0\ndiabetes          0\ndtype: int64\n----- stderr -----\n/var/folders/7n/l2c2z2x57871xg4f_0drsv1m0000gn/T/ipykernel_80888/389187144.py:32: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  X = df[['age', 'bmi', 'glucose', 'blood_pressure', 'insulin']].valuesy = df['diabetes'].values\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglucose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblood_pressure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsulin\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvaluesy \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Feature scaling\u001b[39;00m\n\u001b[1;32m     38\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n\n",
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/developing_simple_supervised_and_unsupervised_learning_models.ipynb",
      "status": "passed",
      "execution_time": 1.4353821277618408,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/eda_and_data_preprocessing_for_medical_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.5851387977600098,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/encoding_categorical_features_for_ml_models.ipynb",
      "status": "passed",
      "execution_time": 1.6745800971984863,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/exploring_the_data_generation_process_using_python_and_pandas.ipynb",
      "status": "passed",
      "execution_time": 1.5698668956756592,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/implementing_a_simple_expert_system_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.4915039539337158,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/implementing_feature_scaling_encoding_and_handling_missing_data_in_a_medical_dat.ipynb",
      "status": "passed",
      "execution_time": 1.6628799438476562,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/solving_the_xor_problem_using_a_neural_network_in_keras.ipynb",
      "status": "passed",
      "execution_time": 1.7416441440582275,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/exercises/01_generative_ai_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7337369918823242,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/solutions/01_generative_ai_solution.ipynb",
      "status": "failed",
      "execution_time": 1.174367904663086,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Solution 1: Generative AI Concepts\n\u0627\u0644\u0648\u062d\u062f\u0629 5 - \u062d\u0644 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\n\nComplete solutions to Exercise 1.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt_\nprint(\"=\" * 70)\nprint(\"Solution 1: Generative AI Concepts\")\nprint(\"=\" * 70)\n\n# Solution 1: Identify Model Types_\nprint(\"\\nSolution 1: Identify Model Types\")\nprint(\"-\" * 70)\n\nmodels = {\n    \"Logistic Regression\": \"D\",  # Discriminative - learns P(Y|X)\n    \"GAN (Generative Adversarial Network)\": \"G\",  # Generative - creates new data\n    \"Support Vector Machine\": \"D\",  # Discriminative - learns decision boundary\n    \"VAE (Variational Autoencoder)\": \"G\",  # Generative - learns data distribution\n    \"Neural Network Classifier\": \"D\",  # Discriminative - learns P(Y|X)\n    \"Naive Bayes\": \"G\"  # Generative - learns P(X|Y) and P(Y)\n}\n\nfor model, answer in models.items():\n    print(f\"{model}: {answer}\")\n\n# Solution 2: Generate Synthetic Data_\nprint(\"\\nSolution 2: Generate Synthetic Data\")\nprint(\"-\" * 70)\n\ndef generate_square_pattern(n_points=100):\n    \n    \n    \n    \"\"\"\n    Generate synthetic data points forming a square pattern.\n    \"\"\"\n    # Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\n    \n    # Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\n    y_top = np.full(points_per_side, side_length/2)\n    \n    # Right side_x_right = np.full(points_per_side, side_length/2)\n    y_right = np.linspace(side_length/2, -side_length/2, points_per_side)\n    \n    # Bottom side_x_bottom = np.linspace(side_length/2, -side_length/2, points_per_side)\n    y_bottom = np.full(points_per_side, -side_length/2)\n    \n    # Left side_x_left = np.full(points_per_side, -side_length/2)\n    y_left = np.linspace(-side_length/2, side_length/2, points_per_side)\n    \n    # Combine and add noise_x = np.concatenate([x_top, x_right, x_bottom, x_left])\n    y = np.concatenate([y_top, y_right, y_bottom, y_left])\n    \n    # Add noise to make it more realistic\n    x += np.random.normal(0, 0.1, len(x))\n    y += np.random.normal(0, 0.1, len(y))\n    \n    return x, y\n\n# Test and visualize\nx_square, y_square = generate_square_pattern(200)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_square, y_square, alpha=0.6, s=30)\nplt.title('Generated Square Pattern\\n(Solution)', fontsize=12)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.show()\n\nprint(\"\u2705 Square pattern generated successfully!\")\n\n# Solution 3: Compare Approaches_\nprint(\"\\nSolution 3: Compare Generative vs Discriminative\")\nprint(\"-\" * 70)\n\ncomparison = {\n    \"What does it learn?\": {\n        \"Generative\": \"P(X|Y) and P(Y) - Joint probability distribution\", \"Discriminative\": \"P(Y|X) - Conditional probability\"\n    },\n    \"Can it generate new data?\": {\n        \"Generative\": True,\n        \"Discriminative\": False\n    },\n    \"Best use case\": {\n        \"Generative\": \"Image generation, data augmentation, anomaly detection\",\n        \"Discriminative\": \"Classification, prediction, spam detection\"\n    }\n}\n\nfor question, answers in comparison.items():\n    print(f\"\\n{question}\")\n    for model_type, answer in answers.items():\n        print(f\"  {model_type}: {answer}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\u2705 All exercises completed!\")\nprint(\"=\" * 70)\n\n------------------\n\n----- stdout -----\n======================================================================\nSolution 1: Generative AI Concepts\n======================================================================\n\nSolution 1: Identify Model Types\n----------------------------------------------------------------------\nLogistic Regression: D\nGAN (Generative Adversarial Network): G\nSupport Vector Machine: D\nVAE (Variational Autoencoder): G\nNeural Network Classifier: D\nNaive Bayes: G\n\nSolution 2: Generate Synthetic Data\n----------------------------------------------------------------------\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Test and visualize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m x_square, y_square \u001b[38;5;241m=\u001b[39m generate_square_pattern(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_square, y_square, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mgenerate_square_pattern\u001b[0;34m(n_points)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mGenerate synthetic data points forming a square pattern.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m y_top \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(points_per_side, side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Right side_x_right = np.full(points_per_side, side_length/2)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39mside_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, points_per_side)\n\n\u001b[0;31mNameError\u001b[0m: name 'points_per_side' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Solution 1: Generative AI Concepts\n\u0627\u0644\u0648\u062d\u062f\u0629 5 - \u062d\u0644 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\n\nComplete solutions to Exercise 1.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt_\nprint(\"=\" * 70)\nprint(\"Solution 1: Generative AI Concepts\")\nprint(\"=\" * 70)\n\n# Solution 1: Identify Model Types_\nprint(\"\\nSolution 1: Identify Model Types\")\nprint(\"-\" * 70)\n\nmodels = {\n    \"Logistic Regression\": \"D\",  # Discriminative - learns P(Y|X)\n    \"GAN (Generative Adversarial Network)\": \"G\",  # Generative - creates new data\n    \"Support Vector Machine\": \"D\",  # Discriminative - learns decision boundary\n    \"VAE (Variational Autoencoder)\": \"G\",  # Generative - learns data distribution\n    \"Neural Network Classifier\": \"D\",  # Discriminative - learns P(Y|X)\n    \"Naive Bayes\": \"G\"  # Generative - learns P(X|Y) and P(Y)\n}\n\nfor model, answer in models.items():\n    print(f\"{model}: {answer}\")\n\n# Solution 2: Generate Synthetic Data_\nprint(\"\\nSolution 2: Generate Synthetic Data\")\nprint(\"-\" * 70)\n\ndef generate_square_pattern(n_points=100):\n    \n    \n    \n    \"\"\"\n    Generate synthetic data points forming a square pattern.\n    \"\"\"\n    # Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\n    \n    # Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\n    y_top = np.full(points_per_side, side_length/2)\n    \n    # Right side_x_right = np.full(points_per_side, side_length/2)\n    y_right = np.linspace(side_length/2, -side_length/2, points_per_side)\n    \n    # Bottom side_x_bottom = np.linspace(side_length/2, -side_length/2, points_per_side)\n    y_bottom = np.full(points_per_side, -side_length/2)\n    \n    # Left side_x_left = np.full(points_per_side, -side_length/2)\n    y_left = np.linspace(-side_length/2, side_length/2, points_per_side)\n    \n    # Combine and add noise_x = np.concatenate([x_top, x_right, x_bottom, x_left])\n    y = np.concatenate([y_top, y_right, y_bottom, y_left])\n    \n    # Add noise to make it more realistic\n    x += np.random.normal(0, 0.1, len(x))\n    y += np.random.normal(0, 0.1, len(y))\n    \n    return x, y\n\n# Test and visualize\nx_square, y_square = generate_square_pattern(200)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_square, y_square, alpha=0.6, s=30)\nplt.title('Generated Square Pattern\\n(Solution)', fontsize=12)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.show()\n\nprint(\"\u2705 Square pattern generated successfully!\")\n\n# Solution 3: Compare Approaches_\nprint(\"\\nSolution 3: Compare Generative vs Discriminative\")\nprint(\"-\" * 70)\n\ncomparison = {\n    \"What does it learn?\": {\n        \"Generative\": \"P(X|Y) and P(Y) - Joint probability distribution\", \"Discriminative\": \"P(Y|X) - Conditional probability\"\n    },\n    \"Can it generate new data?\": {\n        \"Generative\": True,\n        \"Discriminative\": False\n    },\n    \"Best use case\": {\n        \"Generative\": \"Image generation, data augmentation, anomaly detection\",\n        \"Discriminative\": \"Classification, prediction, spam detection\"\n    }\n}\n\nfor question, answers in comparison.items():\n    print(f\"\\n{question}\")\n    for model_type, answer in answers.items():\n        print(f\"  {model_type}: {answer}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\u2705 All exercises completed!\")\nprint(\"=\" * 70)\n\n------------------\n\n----- stdout -----\n======================================================================\nSolution 1: Generative AI Concepts\n======================================================================\n\nSolution 1: Identify Model Types\n----------------------------------------------------------------------\nLogistic Regression: D\nGAN (Generative Adversarial Network): G\nSupport Vector Machine: D\nVAE (Variational Autoencoder): G\nNeural Network Classifier: D\nNaive Bayes: G\n\nSolution 2: Generate Synthetic Data\n----------------------------------------------------------------------\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Test and visualize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m x_square, y_square \u001b[38;5;241m=\u001b[39m generate_square_pattern(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_square, y_square, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mgenerate_square_pattern\u001b[0;34m(n_points)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mGenerate synthetic data points forming a square pattern.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m y_top \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(points_per_side, side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Right side_x_right = np.full(points_per_side, side_length/2)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39mside_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, points_per_side)\n\n\u001b[0;31mNameError\u001b[0m: name 'points_per_side' is not defined\n\n",
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "other"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_01_search_algorithms_solution.ipynb",
      "status": "passed",
      "execution_time": 0.672321081161499,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_02_knowledge_representation_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6822960376739502,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_03_probability_and_uncertainty_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5732059478759766,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_04_optimization_techniques_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5375988483428955,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_05_machine_learning_models_solution.ipynb",
      "status": "passed",
      "execution_time": 0.54587721824646,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_01_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.6335158348083496,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_02_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.6109511852264404,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_03_probability_and_uncertainty.ipynb",
      "status": "passed",
      "execution_time": 0.8261849880218506,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_04_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.656296968460083,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_05_machine_learning_models.ipynb",
      "status": "passed",
      "execution_time": 0.7478530406951904,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/NOTEBOOKS/00_Python_Libraries_for_AI.ipynb",
      "status": "passed",
      "execution_time": 12.697768926620483,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/01_Introduction_Search_Algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.176738977432251,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/02_Knowledge_Representation.ipynb",
      "status": "passed",
      "execution_time": 0.8618507385253906,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/03_Learning_Under_Uncertainty.ipynb",
      "status": "passed",
      "execution_time": 1.5387909412384033,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/04_Optimization_Techniques.ipynb",
      "status": "passed",
      "execution_time": 2.439162015914917,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/05_AI_Learning_Models.ipynb",
      "status": "passed",
      "execution_time": 2.3010659217834473,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/00_Python_Libraries_for_AI.ipynb",
      "status": "passed",
      "execution_time": 12.609920024871826,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/01_Introduction_Search_Algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.2436089515686035,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/02_real_world_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 0.5562751293182373,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/03_implementing_ai_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.771207332611084,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/04_implementing_adversarial_search.ipynb",
      "status": "passed",
      "execution_time": 0.5462961196899414,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/05_ai_learning_methods_research.ipynb",
      "status": "passed",
      "execution_time": 0.5288257598876953,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/ai_learning_methods_and_research.ipynb",
      "status": "passed",
      "execution_time": 1.4710729122161865,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/evaluating_ai_models.ipynb",
      "status": "passed",
      "execution_time": 1.6089701652526855,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/implementing_adversarial_search.ipynb",
      "status": "passed",
      "execution_time": 1.418752908706665,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/implementing_ai_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.7426538467407227,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/real_world_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.3310308456420898,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/exercises/exercise_01_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.5334210395812988,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/02_Knowledge_Representation.ipynb",
      "status": "passed",
      "execution_time": 1.0430059432983398,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/03_propositional_logic_truth_tables.ipynb",
      "status": "passed",
      "execution_time": 0.8546271324157715,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/04_inference_rules_logical_reasoning.ipynb",
      "status": "passed",
      "execution_time": 0.75826096534729,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/05_first_order_logic_fol.ipynb",
      "status": "passed",
      "execution_time": 0.757943868637085,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/06_logical_operators_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.789297342300415,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/07_logical_arguments_validation.ipynb",
      "status": "passed",
      "execution_time": 0.6342599391937256,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/08_model_checking_temporal_logic.ipynb",
      "status": "passed",
      "execution_time": 0.6399710178375244,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/09_fol_parsing_evaluation.ipynb",
      "status": "passed",
      "execution_time": 0.5323987007141113,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/building_logical_arguments_and_validating_them_programmatically.ipynb",
      "status": "passed",
      "execution_time": 1.421731948852539,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/implementing_logical_operators_and_or_not_implies_biconditional.ipynb",
      "status": "passed",
      "execution_time": 1.4477801322937012,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/implementing_model_checking_algorithms_for_temporal_logic.ipynb",
      "status": "passed",
      "execution_time": 1.4205520153045654,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/writing_code_to_parse_and_evaluate_fol_formulas.ipynb",
      "status": "passed",
      "execution_time": 1.6563560962677002,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/exercises/exercise_02_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.7577419281005859,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/02_bayesian_networks.ipynb",
      "status": "passed",
      "execution_time": 0.5410349369049072,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/03_Learning_Under_Uncertainty.ipynb",
      "status": "passed",
      "execution_time": 1.4806761741638184,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/03_hmm_viterbi.ipynb",
      "status": "passed",
      "execution_time": 0.7129290103912354,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/04_mdp_value_iteration.ipynb",
      "status": "passed",
      "execution_time": 0.760706901550293,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/exercises/exercise_03_probability_and_uncertainty.ipynb",
      "status": "passed",
      "execution_time": 0.5417888164520264,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/03_gradient_descent_variants.ipynb",
      "status": "passed",
      "execution_time": 0.6639091968536377,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/04_Optimization_Techniques.ipynb",
      "status": "passed",
      "execution_time": 2.2476420402526855,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/04_advanced_optimizers_adam_rmsprop.ipynb",
      "status": "passed",
      "execution_time": 0.7693049907684326,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/applying_advanced_optimizers_adam_rmsprop_in_neural_networks.ipynb",
      "status": "passed",
      "execution_time": 1.6701622009277344,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/comparing_different_optimization_algorithms_on_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.618419885635376,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_bayesian_optimization_for_hyperparameter_search.ipynb",
      "status": "passed",
      "execution_time": 1.4475030899047852,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_gradient_descent_algorithms_batch_stochastic_mini_batch.ipynb",
      "status": "passed",
      "execution_time": 1.5537199974060059,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_regularization_techniques_l1_l2_dropout_early_stopping.ipynb",
      "status": "passed",
      "execution_time": 1.4363181591033936,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/performing_hyperparameter_tuning_using_grid_search_and_random_search.ipynb",
      "status": "passed",
      "execution_time": 1.655958890914917,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/using_cross_validation_to_select_optimal_hyperparameters.ipynb",
      "status": "passed",
      "execution_time": 1.3454258441925049,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/exercises/exercise_04_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.6279392242431641,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/03_neural_network_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.5996701717376709,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/04_transfer_learning_pretrained.ipynb",
      "status": "passed",
      "execution_time": 0.6584780216217041,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/05_AI_Learning_Models.ipynb",
      "status": "passed",
      "execution_time": 2.342822790145874,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/05_model_evaluation_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.7614059448242188,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/applying_transfer_learning_with_pre_trained_models_vgg_resnet_bert.ipynb",
      "status": "passed",
      "execution_time": 1.7251720428466797,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/building_simple_apis_for_model_serving_flask_fastapi.ipynb",
      "status": "passed",
      "execution_time": 1.4293429851531982,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/fine_tuning_pre_trained_models_for_domain_specific_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.5210609436035156,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/implementing_different_neural_network_architectures_feedforward_cnn_rnn.ipynb",
      "status": "passed",
      "execution_time": 1.7503418922424316,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/implementing_model_selection_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.577197790145874,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/introduction_to_reinforcement_learning_setting_up_environments_and_agents.ipynb",
      "status": "passed",
      "execution_time": 1.5140159130096436,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/performing_model_evaluation_and_comparison_using_cross_validation.ipynb",
      "status": "passed",
      "execution_time": 1.6590142250061035,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/serializing_and_saving_models_for_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.5043609142303467,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/working_on_end_to_end_projects_integrating_multiple_ai_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.5141170024871826,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/exercises/exercise_05_machine_learning_models.ipynb",
      "status": "passed",
      "execution_time": 0.7512409687042236,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_01_search_algorithms_solution.ipynb",
      "status": "passed",
      "execution_time": 0.744948148727417,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_02_knowledge_representation_solution.ipynb",
      "status": "passed",
      "execution_time": 0.780432939529419,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_03_probability_and_uncertainty_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5888171195983887,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_04_optimization_techniques_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7469220161437988,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_05_machine_learning_models_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6105129718780518,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/examples/01_vectors_matrices_basics.ipynb",
      "status": "passed",
      "execution_time": 0.9807949066162109,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/examples/02_matrix_operations.ipynb",
      "status": "passed",
      "execution_time": 1.026625156402588,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/examples/03_eigenvalues_eigenvectors.ipynb",
      "status": "passed",
      "execution_time": 1.003880262374878,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6913669109344482,
      "error": "An error occurred while executing the following cell:\n------------------\nif __name__ == \"__main__\":\n print(\"Testing Exercise 01: Vector and Matrix Operations\")\n print(\"=\" * 60)\n \n # Test 1: Create data matrix\n print(\"\\n1. Testing create_data\\n_matrix:\")\n data = create_data_matrix(5, 3)\n if data is None:\n print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.random.randn(samples, features)\")\n raise NotImplementedError(\"Please implement create_data_matrix() first!\")\n print(f\" Created matrix shape: {data.shape}\")\n print(f\" Expected: (5, 3)\")\n assert data.shape == (5, 3), \"Shape should be (5, 3)\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Dot product\n print(\"\\n2. Testing compute\\n_dot\\n_product:\")\n v1 = np.array([1, 2, 3])\n v2 = np.array([4, 5, 6])\n result = compute_dot_product(v1, v2)\n if result is None:\n print(\" \u274c ERROR: compute\\n_dot\\n_product() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(v1, v2)\")\n raise NotImplementedError(\"Please implement compute_dot_product() first!\")\n expected = 32 # 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n print(f\" Result: {result}\")\n print(f\" Expected: {expected}\")\n assert result == expected, f\"Expected {expected}, got {result}\"\n print(\" \u2705 Passed!\")\n \n # Test 3: Matrix multiplication\n print(\"\\n3. Testing matrix_multiplication:\")\n A = np.array([[1, 2], [3, 4]])\n B = np.array([[5, 6], [7, 8]])\n result = matrix_multiplication(A, B)\n if result is None:\n print(\" \u274c ERROR: matrix_multiplication() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(A, B)\")\n raise NotImplementedError(\"Please implement matrix_multiplication() first!\")\n expected = np.array([[19, 22], [43, 50]])\n print(f\" Result:\\n{result}\")\n print(f\" Expected:\\n{expected}\")\n assert np.allclose(result, expected), \"Matrix multiplication incorrect\"\n print(\" \u2705 Passed!\")\n \n # Test 4: Transpose\n print(\"\\n4. Testing compute\\n_transpose:\")\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\n result = compute_transpose(matrix)\n if result is None:\n print(\" \u274c ERROR: compute\\n_transpose() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return matrix.T\")\n raise NotImplementedError(\"Please implement compute_transpose() first!\")\n expected = np.array([[1, 4], [2, 5], [3, 6]])\n print(f\" Original shape: {matrix.shape}\")\n print(f\" Transposed shape: {result.shape}\")\n assert np.allclose(result, expected), \"Transpose incorrect\"\n print(\" \u2705 Passed!\")\n \n print(\"\\n\" + \"=\" * 60)\n print(\"\ud83c\udf89 All tests passed! Great job!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 8\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif __name__ == \"__main__\":\n print(\"Testing Exercise 01: Vector and Matrix Operations\")\n print(\"=\" * 60)\n \n # Test 1: Create data matrix\n print(\"\\n1. Testing create_data\\n_matrix:\")\n data = create_data_matrix(5, 3)\n if data is None:\n print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.random.randn(samples, features)\")\n raise NotImplementedError(\"Please implement create_data_matrix() first!\")\n print(f\" Created matrix shape: {data.shape}\")\n print(f\" Expected: (5, 3)\")\n assert data.shape == (5, 3), \"Shape should be (5, 3)\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Dot product\n print(\"\\n2. Testing compute\\n_dot\\n_product:\")\n v1 = np.array([1, 2, 3])\n v2 = np.array([4, 5, 6])\n result = compute_dot_product(v1, v2)\n if result is None:\n print(\" \u274c ERROR: compute\\n_dot\\n_product() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(v1, v2)\")\n raise NotImplementedError(\"Please implement compute_dot_product() first!\")\n expected = 32 # 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n print(f\" Result: {result}\")\n print(f\" Expected: {expected}\")\n assert result == expected, f\"Expected {expected}, got {result}\"\n print(\" \u2705 Passed!\")\n \n # Test 3: Matrix multiplication\n print(\"\\n3. Testing matrix_multiplication:\")\n A = np.array([[1, 2], [3, 4]])\n B = np.array([[5, 6], [7, 8]])\n result = matrix_multiplication(A, B)\n if result is None:\n print(\" \u274c ERROR: matrix_multiplication() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(A, B)\")\n raise NotImplementedError(\"Please implement matrix_multiplication() first!\")\n expected = np.array([[19, 22], [43, 50]])\n print(f\" Result:\\n{result}\")\n print(f\" Expected:\\n{expected}\")\n assert np.allclose(result, expected), \"Matrix multiplication incorrect\"\n print(\" \u2705 Passed!\")\n \n # Test 4: Transpose\n print(\"\\n4. Testing compute\\n_transpose:\")\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\n result = compute_transpose(matrix)\n if result is None:\n print(\" \u274c ERROR: compute\\n_transpose() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return matrix.T\")\n raise NotImplementedError(\"Please implement compute_transpose() first!\")\n expected = np.array([[1, 4], [2, 5], [3, 6]])\n print(f\" Original shape: {matrix.shape}\")\n print(f\" Transposed shape: {result.shape}\")\n assert np.allclose(result, expected), \"Transpose incorrect\"\n print(\" \u2705 Passed!\")\n \n print(\"\\n\" + \"=\" * 60)\n print(\"\ud83c\udf89 All tests passed! Great job!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 8\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_01/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.5790777206420898,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_determinant(matrix):\n \n # TODO: Compute determinant using np.linalg.de\nt()\n pass\n\n\ndef compute_matrix_inverse(matrix):\n \n # TODO: Compute inverse using np.linalg.in\nv()\n # Note: Matrix must be square and have non-zero determinan\ntpass\n\n\ndef compute_eigenvalues__eigenvectors(matrix):\n \n # TODO: Use np.linalg.eig() to compute eigenvalues and eigenvectors\n pass\n\n\ndef verify_inverse(matrix, inverse):\n \n # TODO: Multiply matrix by inverse and check if result is identity\n # Use np.allclose() for floating point comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_determinant(matrix):\n \n # TODO: Compute determinant using np.linalg.de\nt()\n pass\n\n\ndef compute_matrix_inverse(matrix):\n \n # TODO: Compute inverse using np.linalg.in\nv()\n # Note: Matrix must be square and have non-zero determinan\ntpass\n\n\ndef compute_eigenvalues__eigenvectors(matrix):\n \n # TODO: Use np.linalg.eig() to compute eigenvalues and eigenvectors\n pass\n\n\ndef verify_inverse(matrix, inverse):\n \n # TODO: Multiply matrix by inverse and check if result is identity\n # Use np.allclose() for floating point comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_01/notebook_01_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 0.8881909847259521,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.8315141201019287,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5305120944976807,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef create_data_matrix(samples, features):        # # SOLUTION: Create a matrix with the specified shape    # Use np.random.randn() to generate random values    pass\ndef compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\ndef matrix_multiplication(A, B):        # # SOLUTION: Perform matrix multiplication    # Remember: A @ B or np.dot(A, B)    pass\ndef compute_transpose(matrix):        # # SOLUTION: Compute transpose using .T or np.transpose()    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef create_data_matrix(samples, features):        # # SOLUTION: Create a matrix with the specified shape    # Use np.random.randn() to generate random values    pass\ndef compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\ndef matrix_multiplication(A, B):        # # SOLUTION: Perform matrix multiplication    # Remember: A @ B or np.dot(A, B)    pass\ndef compute_transpose(matrix):        # # SOLUTION: Compute transpose using .T or np.transpose()    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.7447669506072998,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_determinant(matrix):        # # SOLUTION: Compute determinant using np.linalg.det()    pass\ndef compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\ndef compute_eigenvalues_eigenvectors(matrix):        # # SOLUTION: Use np.linalg.eig() to compute eigenvalues and eigenvectors    pass\ndef verify_inverse(matrix, inverse):        # # SOLUTION: Multiply matrix by inverse and check if result is identity    # Use np.allclose() for floating point comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_determinant(matrix):        # # SOLUTION: Compute determinant using np.linalg.det()    pass\ndef compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\ndef compute_eigenvalues_eigenvectors(matrix):        # # SOLUTION: Use np.linalg.eig() to compute eigenvalues and eigenvectors    pass\ndef verify_inverse(matrix, inverse):        # # SOLUTION: Multiply matrix by inverse and check if result is identity    # Use np.allclose() for floating point comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/examples/01_derivatives_basics.ipynb",
      "status": "passed",
      "execution_time": 1.0002720355987549,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/examples/02_gradients_multivariable.ipynb",
      "status": "passed",
      "execution_time": 1.0271170139312744,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/examples/03_gradient_descent.ipynb",
      "status": "passed",
      "execution_time": 0.9024121761322021,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7492759227752686,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead def compute_derivative(func, x, h=1e-6):\n \n # TODO: Implement numerical derivative\n # Formula: (f(x+h) - f(x))  h pass\n\n\ndef compute_gradient(func, point):\n \n # TODO: Compute partial derivatives\n # Use compute_derivative for each variable h = 1e-6\n pass\n\n\ndef gradient_descent_step(func, x, learning_rate=0.1):\n \n # TODO: \n # 1. Compute gradient at current point\n # 2. Move in opposite direction: x_new = x - lr * gradient pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Test your solution\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead def compute_derivative(func, x, h=1e-6):\n \n # TODO: Implement numerical derivative\n # Formula: (f(x+h) - f(x))  h pass\n\n\ndef compute_gradient(func, point):\n \n # TODO: Compute partial derivatives\n # Use compute_derivative for each variable h = 1e-6\n pass\n\n\ndef gradient_descent_step(func, x, learning_rate=0.1):\n \n # TODO: \n # 1. Compute gradient at current point\n # 2. Move in opposite direction: x_new = x - lr * gradient pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Test your solution\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_02/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.7776241302490234,
      "error": "An error occurred while executing the following cell:\n------------------\nif __name__ == \"__main__\":\n print(\"Testing Exercise 02: Gradient Descent\") / print(\"=\" * 60)\n \n # Test 1: Gradient descent print(\"\\n1. Testing gradient_descent:\") / def f(x):\n return (x - 3)**2 # Minimum at x = 3 def grad_f(x):\n return 2 * (x - 3) # Gradient of (x-3)\u00b2\n \n initial_x = 5.0\n final_x, history = gradient_descent(f, grad_f, initial_x, learning_rate=0.1, iterations=20) / print(f\" Function: f(x) = (x - 3)\u00b2 (minimum at x = 3)\")\n print(f\" Starting at: {initial _x}\") / print(f\" Final value: {final_x:.4f}\") / print(f\" Expected: close to 3.0\") / print(f\" Converged: {abs(final _x - 3) < 0.1}\")\n assert abs(final_x - 3) < 0.5, \"Should converge close to minimum\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Learning rate analysis print(\"\\n2. Testing analyze\\n_learning_rate:\") / learning_rates = [0.01, 0.1, 0.5, 1.0]\n results = analyze_learning_rate(f, grad_f, initial_x, learning_rates, iterations=30) / print(f\" Learning Rate Analysis:\") / for lr, final_val in results.items():\n converged = abs(final_val - 3) < 0.5\n status = \"\u2705 Converged\" if converged else \"\u274c Diverged\"\n print(f\" LR = {lr:.2\nf}: Final x = {final_val:.4f} {status}\") / print(\"\\n\" + \"=\" * 60) / print(\"\ud83c\udf89 All tests passed!\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\" Starting at: {initial _x}\") / print(f\" Final value: {final_x:.4f}\") / print(f\" Expected: close to 3.0\") / print(f\" Converged: {abs(final _x - 3) < 0.1}\")\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif __name__ == \"__main__\":\n print(\"Testing Exercise 02: Gradient Descent\") / print(\"=\" * 60)\n \n # Test 1: Gradient descent print(\"\\n1. Testing gradient_descent:\") / def f(x):\n return (x - 3)**2 # Minimum at x = 3 def grad_f(x):\n return 2 * (x - 3) # Gradient of (x-3)\u00b2\n \n initial_x = 5.0\n final_x, history = gradient_descent(f, grad_f, initial_x, learning_rate=0.1, iterations=20) / print(f\" Function: f(x) = (x - 3)\u00b2 (minimum at x = 3)\")\n print(f\" Starting at: {initial _x}\") / print(f\" Final value: {final_x:.4f}\") / print(f\" Expected: close to 3.0\") / print(f\" Converged: {abs(final _x - 3) < 0.1}\")\n assert abs(final_x - 3) < 0.5, \"Should converge close to minimum\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Learning rate analysis print(\"\\n2. Testing analyze\\n_learning_rate:\") / learning_rates = [0.01, 0.1, 0.5, 1.0]\n results = analyze_learning_rate(f, grad_f, initial_x, learning_rates, iterations=30) / print(f\" Learning Rate Analysis:\") / for lr, final_val in results.items():\n converged = abs(final_val - 3) < 0.5\n status = \"\u2705 Converged\" if converged else \"\u274c Diverged\"\n print(f\" LR = {lr:.2\nf}: Final x = {final_val:.4f} {status}\") / print(\"\\n\" + \"=\" * 60) / print(\"\ud83c\udf89 All tests passed!\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\" Starting at: {initial _x}\") / print(f\" Final value: {final_x:.4f}\") / print(f\" Expected: close to 3.0\") / print(f\" Converged: {abs(final _x - 3) < 0.1}\")\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_02/notebook_02_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 0.734198808670044,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Why Calculus matters in ML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example: Understanding loss functions and optimization\n# In ML, we want to minimize a loss function\ndef simple_loss_function(x):\n \n    \n    \"\"\"A simple quadratic loss function\"\"\"\n return (x - 3)**2 + 2\n\n# The derivative tells us the direction to minimize\ndef loss_derivative(x):\n \n    \n    \"\"\"Derivative of the loss function\"\"\"\n return 2 * (x - 3)\n\n# Example: Finding the minimum\nx_values = np.linspace(0, 6, 100)\nloss_values = [simple_loss_function(x) for x in x_values]\n\nprint(\"Loss function example:\")\nprint(f\"At x=2, loss = {simple_loss_function(2):.2f}, derivative = {loss_derivative(2):.2f}\")\nprint(f\"At x=4, loss = {simple_loss_function(4):.2f}, derivative = {loss_derivative(4):.2f}\")\nprint(\"\\nThe derivative tells us which direction to move to minimize loss!\")\nprint(\"This is exactly how gradient descent works in ML!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (x - 3)**2 + 2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Why Calculus matters in ML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example: Understanding loss functions and optimization\n# In ML, we want to minimize a loss function\ndef simple_loss_function(x):\n \n    \n    \"\"\"A simple quadratic loss function\"\"\"\n return (x - 3)**2 + 2\n\n# The derivative tells us the direction to minimize\ndef loss_derivative(x):\n \n    \n    \"\"\"Derivative of the loss function\"\"\"\n return 2 * (x - 3)\n\n# Example: Finding the minimum\nx_values = np.linspace(0, 6, 100)\nloss_values = [simple_loss_function(x) for x in x_values]\n\nprint(\"Loss function example:\")\nprint(f\"At x=2, loss = {simple_loss_function(2):.2f}, derivative = {loss_derivative(2):.2f}\")\nprint(f\"At x=4, loss = {simple_loss_function(4):.2f}, derivative = {loss_derivative(4):.2f}\")\nprint(\"\\nThe derivative tells us which direction to move to minimize loss!\")\nprint(\"This is exactly how gradient descent works in ML!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (x - 3)**2 + 2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.588266134262085,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6162848472595215,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy.misc import derivative\ndef compute_derivative(func, x, h=1e-6):        # # SOLUTION: Implement numerical derivative    # Formula: (f(x+h) - f(x)) / h    pass\ndef compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\ndef gradient_descent_step(func, x, learning_rate=0.1):        # # SOLUTION:     # 1. Compute gradient at current point    # 2. Move in opposite direction: x_new = x - lr * gradient    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy.misc import derivative\ndef compute_derivative(func, x, h=1e-6):        # # SOLUTION: Implement numerical derivative    # Formula: (f(x+h) - f(x)) / h    pass\ndef compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\ndef gradient_descent_step(func, x, learning_rate=0.1):        # # SOLUTION:     # 1. Compute gradient at current point    # 2. Move in opposite direction: x_new = x - lr * gradient    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.648421049118042,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50):        results = {}        # # SOLUTION: For each learning rate, run gradient descent    # Store the final value in results dictionary       return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\u001b[0m\n\u001b[0m                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50):        results = {}        # # SOLUTION: For each learning rate, run gradient descent    # Store the final value in results dictionary       return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\u001b[0m\n\u001b[0m                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/examples/01_optimizers_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.8543853759765625,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/examples/02_loss_functions.ipynb",
      "status": "passed",
      "execution_time": 0.7672131061553955,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/examples/03_statistical_measures.ipynb",
      "status": "passed",
      "execution_time": 0.9885540008544922,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7881648540496826,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\nclass SimpleGDOptimizer:\n \n \ndef __init__(self, lr=0.01):\n self.lr = lr\n \n def update(self, params, grads):\n \n # TODO: Implement simple gradient descent update\n pass\n\n\nclass MomentumOptimizer:\n \n \ndef __init__(self, lr=0.01, momentum=0.9):\n self.lr = lr\n self.momentum = momentum\n self.velocity = None\n \n def update(self, params, grads):\n \n # TODO: Initialize velocity if first call\n # TODO: Update velocity: v = momentum * v + lr * grad\ns\n # TODO: Update params: params = params - velocity\n pass\n\n\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):\n \n results = {}\n \n # TODO: For each optimize\nr:\n # 1. Start with initial_params\n # 2. Run for 'iterations' step\ns\n # 3. Store final parameters\n \n return results\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, lr=0.01):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\nclass SimpleGDOptimizer:\n \n \ndef __init__(self, lr=0.01):\n self.lr = lr\n \n def update(self, params, grads):\n \n # TODO: Implement simple gradient descent update\n pass\n\n\nclass MomentumOptimizer:\n \n \ndef __init__(self, lr=0.01, momentum=0.9):\n self.lr = lr\n self.momentum = momentum\n self.velocity = None\n \n def update(self, params, grads):\n \n # TODO: Initialize velocity if first call\n # TODO: Update velocity: v = momentum * v + lr * grad\ns\n # TODO: Update params: params = params - velocity\n pass\n\n\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):\n \n results = {}\n \n # TODO: For each optimize\nr:\n # 1. Start with initial_params\n # 2. Run for 'iterations' step\ns\n # 3. Store final parameters\n \n return results\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, lr=0.01):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_03/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.6178743839263916,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef calculate_mse(predictions, targets):\n \n # TODO: Calculate MS\nE\n # Formula: mean((predictions - targets)^2)\n pass\n\n\ndef calculate_rmse(predictions, targets):\n \n # TODO: Calculate RMSE\n # Formula: sqrt(MS\nE) / pass\n\n\ndef calculate_r2__score(predictions, targets):\n \n # TODO: Calculate R\u00b2\n # Formula: 1 - sum((targets - predictions)^2) / sum((targets - mean(target\ns))^2)\n pass\n\n\ndef evaluate_model(predictions, targets):\n \n # TODO: Calculate all metrics and return as dictionary pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    E) / pass\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef calculate_mse(predictions, targets):\n \n # TODO: Calculate MS\nE\n # Formula: mean((predictions - targets)^2)\n pass\n\n\ndef calculate_rmse(predictions, targets):\n \n # TODO: Calculate RMSE\n # Formula: sqrt(MS\nE) / pass\n\n\ndef calculate_r2__score(predictions, targets):\n \n # TODO: Calculate R\u00b2\n # Formula: 1 - sum((targets - predictions)^2) / sum((targets - mean(target\ns))^2)\n pass\n\n\ndef evaluate_model(predictions, targets):\n \n # TODO: Calculate all metrics and return as dictionary pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    E) / pass\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_03/notebook_03_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 1.4628291130065918,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.6211428642272949,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6884088516235352,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nclass SimpleGDOptimizer:        \n\ndef __init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\nclass MomentumOptimizer:        \n\ndef __init__(self, lr=0.01, momentum=0.9):        self.lr = lr        self.momentum = momentum        self.velocity = None        def update(self, params, grads):                # # SOLUTION: Initialize velocity if first call        # # SOLUTION: Update velocity: v = momentum * v + lr * grads        # # SOLUTION: Update params: params = params - velocity        pass\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):        results = {}        # # SOLUTION: For each optimizer:    #   1. Start with initial_params    #   2. Run for 'iterations' steps    #   3. Store final parameters        return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nclass SimpleGDOptimizer:        \n\ndef __init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\nclass MomentumOptimizer:        \n\ndef __init__(self, lr=0.01, momentum=0.9):        self.lr = lr        self.momentum = momentum        self.velocity = None        def update(self, params, grads):                # # SOLUTION: Initialize velocity if first call        # # SOLUTION: Update velocity: v = momentum * v + lr * grads        # # SOLUTION: Update params: params = params - velocity        pass\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):        results = {}        # # SOLUTION: For each optimizer:    #   1. Start with initial_params    #   2. Run for 'iterations' steps    #   3. Store final parameters        return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.623305082321167,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef calculate_mse(predictions, targets):        # # SOLUTION: Calculate MSE    # Formula: mean((predictions - targets)^2)    pass\ndef calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\ndef calculate_r2_score(predictions, targets):        # # SOLUTION: Calculate R\u00b2    # Formula: 1 - sum((targets - predictions)^2) / sum((targets - mean(targets))^2)    pass\ndef evaluate_model(predictions, targets):        # # SOLUTION: Calculate all metrics and return as dictionary    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef calculate_mse(predictions, targets):        # # SOLUTION: Calculate MSE    # Formula: mean((predictions - targets)^2)    pass\ndef calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\ndef calculate_r2_score(predictions, targets):        # # SOLUTION: Calculate R\u00b2    # Formula: 1 - sum((targets - predictions)^2) / sum((targets - mean(targets))^2)    pass\ndef evaluate_model(predictions, targets):        # # SOLUTION: Calculate all metrics and return as dictionary    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/examples/01_pca_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.8456192016601562,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/examples/02_curse_dimensionality.ipynb",
      "status": "passed",
      "execution_time": 0.7766740322113037,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/examples/03_feature_selection.ipynb",
      "status": "passed",
      "execution_time": 0.8392901420593262,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.52740478515625,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_covariance_matrix(data):\n \n # TODO: Compute covariance matrix\n # Hint: Center data first (subtract mean), then compute covariance\n pass\n\n\ndef pca_from_scratch(data, n_components=2):\n \n # TODO: Implement PC\nA\n # Step\ns:\n # 1. Center the data (subtract mean)\n # 2. Compute covariance matrix\n # 3. Find eigenvalues and eigenvectors\n # 4. Sort by eigenvalues (descending)\n # 5. Select top n_components\n # 6. Project data: reduced = data @ eigenvectors\n # 7. Calculate explained variance rati\no\n pass\n\n\ndef calculate_variance_explained(eigenvalues, n_components):\n \n # TODO: Calculate variance explaine\nd\n # Formula: sum(top_n_eigenvalues) / sum(all_eigenvalues)\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    A\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 11\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_covariance_matrix(data):\n \n # TODO: Compute covariance matrix\n # Hint: Center data first (subtract mean), then compute covariance\n pass\n\n\ndef pca_from_scratch(data, n_components=2):\n \n # TODO: Implement PC\nA\n # Step\ns:\n # 1. Center the data (subtract mean)\n # 2. Compute covariance matrix\n # 3. Find eigenvalues and eigenvectors\n # 4. Sort by eigenvalues (descending)\n # 5. Select top n_components\n # 6. Project data: reduced = data @ eigenvectors\n # 7. Calculate explained variance rati\no\n pass\n\n\ndef calculate_variance_explained(eigenvalues, n_components):\n \n # TODO: Calculate variance explaine\nd\n # Formula: sum(top_n_eigenvalues) / sum(all_eigenvalues)\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    A\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 11\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_04/notebook_04_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 1.8219099044799805,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.7367892265319824,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5381760597229004,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_covariance_matrix(data):        # # SOLUTION: Compute covariance matrix    # Hint: Center data first (subtract mean), then compute covariance    pass\ndef pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\ndef calculate_variance_explained(eigenvalues, n_components):        # # SOLUTION: Calculate variance explained    # Formula: sum(top_n_eigenvalues) / sum(all_eigenvalues)    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_covariance_matrix(data):        # # SOLUTION: Compute covariance matrix    # Hint: Center data first (subtract mean), then compute covariance    pass\ndef pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\ndef calculate_variance_explained(eigenvalues, n_components):        # # SOLUTION: Calculate variance explained    # Formula: sum(top_n_eigenvalues) / sum(all_eigenvalues)    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/examples/01_probability_distributions.ipynb",
      "status": "passed",
      "execution_time": 0.9826068878173828,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/examples/02_statistical_inference.ipynb",
      "status": "passed",
      "execution_time": 0.9442827701568604,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/examples/03_bayesian_inference.ipynb",
      "status": "passed",
      "execution_time": 1.5225317478179932,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6231248378753662,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\n\n\ndef compute_confidence_interval(data, confidence=0.95):\n \n # TODO: Compute confidence interval\n # Step\ns:\n # 1. Calculate sample mean and standard erro\nr\n # 2. Get t-critical value for confidence leve\nl\n # 3. CI = mean \u00b1 t_critical * standard_error\n pass\n\n\ndef t_test_two_samples(sample1, sample2):\n \n # TODO: Perform two-sample t-test\n # Use scipy.stats.ttest_in\nd()\n pass\n\n\ndef interpret_p__value(p_value, alpha=0.05):\n \n # TODO: Interpret p-valu\ne\n # If p < alpha: significant difference\n # If p >= alpha: no significant difference\n pass\n\n\ndef compare_models(model1_scores, model2_scores, alpha=0.05):\n \n # TODO: \n # 1. Compute means and confidence interval\ns\n # 2. Perform t-test\n # 3. Interpret result\ns\n # 4. Return comprehensive comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    s:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\n\n\ndef compute_confidence_interval(data, confidence=0.95):\n \n # TODO: Compute confidence interval\n # Step\ns:\n # 1. Calculate sample mean and standard erro\nr\n # 2. Get t-critical value for confidence leve\nl\n # 3. CI = mean \u00b1 t_critical * standard_error\n pass\n\n\ndef t_test_two_samples(sample1, sample2):\n \n # TODO: Perform two-sample t-test\n # Use scipy.stats.ttest_in\nd()\n pass\n\n\ndef interpret_p__value(p_value, alpha=0.05):\n \n # TODO: Interpret p-valu\ne\n # If p < alpha: significant difference\n # If p >= alpha: no significant difference\n pass\n\n\ndef compare_models(model1_scores, model2_scores, alpha=0.05):\n \n # TODO: \n # 1. Compute means and confidence interval\ns\n # 2. Perform t-test\n # 3. Interpret result\ns\n # 4. Return comprehensive comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    s:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_05/notebook_05_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 2.580693244934082,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Analyzing Results and Understanding Implications\n# This demonstrates what happens AFTER applying statistical inference\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"AFTER: Understanding the Impact of Statistical Inference\")\nprint(\"=\" * 60)\n\n# Simulate model evaluation results\nnp.random.seed(42)\nmodel_predictions = np.random.normal(0.88, 0.05, 100)\ntrue_values = np.random.normal(0.87, 0.03, 100)\n\n# Calculate metrics\nmean_pred = np.mean(model_predictions)\nstd_pred = np.std(model_predictions)\nci_95 = stats.t.interval(0.95, len(model_predictions)-1, loc=mean_pred, scale=stats.sem(model_predictions))\nprint(f\"\\n1. Model Prediction Analysis:\")\nprint(f\" Mean prediction: {mean_pred:.4f}\")\nprint(f\" Standard deviation: {std_pred:.4f}\")\nprint(f\" 95% Confidence Interval: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\n\n# Statistical test: Is model significantly different from baseline?\nbaseline = 0.85\nt_stat, p_value = stats.ttest_1samp(model_predictions, baseline)\n\nprint(f\"\\n2. Statistical Significance Test:\")\nprint(f\" Testing if model (mean={mean_pred:.4f}) is better than baseline ({baseline})\")\nprint(f\" t-statistic: {t_stat:.4f}\")\nprint(f\" p-value: {p_value:.4f}\")\nif p_value < 0.05:\n print(f\" \u2705 Model is significantly better than baseline! (p < 0.05)\")\nelse:\n print(f\" \u274c No significant improvement over baseline (p >= 0.05)\")\n\n# Visualize results\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n# Distribution of predictions with CI\naxes[0].hist(model_predictions, bins=20, alpha=0.7, color='blue', edgecolor='black')\naxes[0].axvline(mean_pred, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_pred:.3f}')\naxes[0].axvline(ci_95[0], color='green', linestyle=':', linewidth=2, label=f'95% CI: [{ci_95[0]:.3f}, {ci_95[1]:.3f}]')\naxes[0].axvline(ci_95[1], color='green', linestyle=':', linewidth=2)\naxes[0].axvline(baseline, color='orange', linestyle='-', linewidth=2, label=f'Baseline: {baseline}')\naxes[0].set_title('Prediction Distribution with Confidence Interval', fontsize=12, fontweight='bold')\naxes[0].set_xlabel('Prediction Value')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# Comparison with baseline\naxes[1].bar(['Baseline', 'Model'], [baseline, mean_pred], \n yerr=[[0, 0], [mean_pred - ci_95[0], ci_95[1] - mean_pred]],\n color=['orange', 'blue'], alpha=0.7, capsize=10, capthick=2, edgecolor='black')\naxes[1].set_title('Model vs Baseline Comparison', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Score')\naxes[1].set_ylim(0.8, 0.95)\naxes[1].grid(True, alpha=0.3, axis='y')\naxes[1].text(1, mean_pred + 0.01, f'p={p_value:.4f}', ha='center', fontsize=10,\n bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n3. Key Insights:\")\nprint(\" \u2705 Quantified uncertainty in predictions\")\nprint(\" \u2705 Statistically compared model to baseline\")\nprint(\" \u2705 Made data-driven decision about model performance\")\nprint(\" \u2705 Understand confidence in model predictions\")\n\nprint(\"\\n4. Implications for Machine Learning:\")\nprint(\" \ud83d\udcca Uncertainty Quantification: Know how confident we are in predictions\")\nprint(\" \ud83c\udfaf Model Selection: Use statistical tests to choose best model\")\nprint(\" \ud83d\udd2c A/B Testing: Compare models in production using statistical inference\")\nprint(\" \ud83d\udcc8 Decision Making: Make informed decisions based on statistical evidence\")\nprint(\" \ud83e\udde0 Bayesian ML: Foundation for probabilistic machine learning methods\")\n\nprint(\"\\n5. When to Use Statistical Inference:\")\nprint(\" \u2705 Comparing different models\")\nprint(\" \u2705 Evaluating model improvements\")\nprint(\" \u2705 Quantifying prediction uncertainty\")\nprint(\" \u2705 Making production deployment decisions\")\nprint(\" \u2705 Understanding model reliability\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Remember: Statistical inference helps make data-driven decisions!\")\nprint(\" Always quantify uncertainty and test significance before deploying models.\")\nprint(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nAFTER: Understanding the Impact of Statistical Inference\n============================================================\n\n1. Model Prediction Analysis:\n Mean prediction: 0.8748\n Standard deviation: 0.0452\n 95% Confidence Interval: [0.8658, 0.8838]\n\n2. Statistical Significance Test:\n Testing if model (mean=0.8748) is better than baseline (0.85)\n t-statistic: 5.4632\n p-value: 0.0000\n \u2705 Model is significantly better than baseline! (p < 0.05)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\nCell \u001b[0;32mIn[6], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Comparison with baseline\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mbar([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m], [baseline, mean_pred], \n\u001b[1;32m     55\u001b[0m  yerr\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [mean_pred \u001b[38;5;241m-\u001b[39m ci_95[\u001b[38;5;241m0\u001b[39m], ci_95[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m mean_pred]],\n\u001b[1;32m     56\u001b[0m  color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m], alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, capsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, capthick\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel vs Baseline Comparison\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[1;32m   1522\u001b[0m             ax,\n\u001b[1;32m   1523\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(cbook\u001b[38;5;241m.\u001b[39msanitize_sequence, args),\n\u001b[1;32m   1524\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: cbook\u001b[38;5;241m.\u001b[39msanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/axes/_axes.py:2643\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m   2635\u001b[0m     r \u001b[38;5;241m=\u001b[39m mpatches\u001b[38;5;241m.\u001b[39mRectangle(\n\u001b[1;32m   2636\u001b[0m         xy\u001b[38;5;241m=\u001b[39m(l, b), width\u001b[38;5;241m=\u001b[39mw, height\u001b[38;5;241m=\u001b[39mh,\n\u001b[1;32m   2637\u001b[0m         facecolor\u001b[38;5;241m=\u001b[39mc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         hatch\u001b[38;5;241m=\u001b[39mhtch,\n\u001b[1;32m   2642\u001b[0m         )\n\u001b[0;32m-> 2643\u001b[0m     r\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[1;32m   2644\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/artist.py:1233\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \n\u001b[1;32m   1231\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_props(\n\u001b[1;32m   1234\u001b[0m         kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{cls.__name__}\u001b[39;00m\u001b[38;5;124m.set() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prop_name!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/artist.py:1206\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1204\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1205\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m-> 1206\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1207\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk),\n\u001b[1;32m   1208\u001b[0m                     name\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m   1209\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\n\u001b[0;31mAttributeError\u001b[0m: Rectangle.set() got an unexpected keyword argument 'capthick'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Analyzing Results and Understanding Implications\n# This demonstrates what happens AFTER applying statistical inference\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"AFTER: Understanding the Impact of Statistical Inference\")\nprint(\"=\" * 60)\n\n# Simulate model evaluation results\nnp.random.seed(42)\nmodel_predictions = np.random.normal(0.88, 0.05, 100)\ntrue_values = np.random.normal(0.87, 0.03, 100)\n\n# Calculate metrics\nmean_pred = np.mean(model_predictions)\nstd_pred = np.std(model_predictions)\nci_95 = stats.t.interval(0.95, len(model_predictions)-1, loc=mean_pred, scale=stats.sem(model_predictions))\nprint(f\"\\n1. Model Prediction Analysis:\")\nprint(f\" Mean prediction: {mean_pred:.4f}\")\nprint(f\" Standard deviation: {std_pred:.4f}\")\nprint(f\" 95% Confidence Interval: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\n\n# Statistical test: Is model significantly different from baseline?\nbaseline = 0.85\nt_stat, p_value = stats.ttest_1samp(model_predictions, baseline)\n\nprint(f\"\\n2. Statistical Significance Test:\")\nprint(f\" Testing if model (mean={mean_pred:.4f}) is better than baseline ({baseline})\")\nprint(f\" t-statistic: {t_stat:.4f}\")\nprint(f\" p-value: {p_value:.4f}\")\nif p_value < 0.05:\n print(f\" \u2705 Model is significantly better than baseline! (p < 0.05)\")\nelse:\n print(f\" \u274c No significant improvement over baseline (p >= 0.05)\")\n\n# Visualize results\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n# Distribution of predictions with CI\naxes[0].hist(model_predictions, bins=20, alpha=0.7, color='blue', edgecolor='black')\naxes[0].axvline(mean_pred, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_pred:.3f}')\naxes[0].axvline(ci_95[0], color='green', linestyle=':', linewidth=2, label=f'95% CI: [{ci_95[0]:.3f}, {ci_95[1]:.3f}]')\naxes[0].axvline(ci_95[1], color='green', linestyle=':', linewidth=2)\naxes[0].axvline(baseline, color='orange', linestyle='-', linewidth=2, label=f'Baseline: {baseline}')\naxes[0].set_title('Prediction Distribution with Confidence Interval', fontsize=12, fontweight='bold')\naxes[0].set_xlabel('Prediction Value')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# Comparison with baseline\naxes[1].bar(['Baseline', 'Model'], [baseline, mean_pred], \n yerr=[[0, 0], [mean_pred - ci_95[0], ci_95[1] - mean_pred]],\n color=['orange', 'blue'], alpha=0.7, capsize=10, capthick=2, edgecolor='black')\naxes[1].set_title('Model vs Baseline Comparison', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Score')\naxes[1].set_ylim(0.8, 0.95)\naxes[1].grid(True, alpha=0.3, axis='y')\naxes[1].text(1, mean_pred + 0.01, f'p={p_value:.4f}', ha='center', fontsize=10,\n bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n3. Key Insights:\")\nprint(\" \u2705 Quantified uncertainty in predictions\")\nprint(\" \u2705 Statistically compared model to baseline\")\nprint(\" \u2705 Made data-driven decision about model performance\")\nprint(\" \u2705 Understand confidence in model predictions\")\n\nprint(\"\\n4. Implications for Machine Learning:\")\nprint(\" \ud83d\udcca Uncertainty Quantification: Know how confident we are in predictions\")\nprint(\" \ud83c\udfaf Model Selection: Use statistical tests to choose best model\")\nprint(\" \ud83d\udd2c A/B Testing: Compare models in production using statistical inference\")\nprint(\" \ud83d\udcc8 Decision Making: Make informed decisions based on statistical evidence\")\nprint(\" \ud83e\udde0 Bayesian ML: Foundation for probabilistic machine learning methods\")\n\nprint(\"\\n5. When to Use Statistical Inference:\")\nprint(\" \u2705 Comparing different models\")\nprint(\" \u2705 Evaluating model improvements\")\nprint(\" \u2705 Quantifying prediction uncertainty\")\nprint(\" \u2705 Making production deployment decisions\")\nprint(\" \u2705 Understanding model reliability\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Remember: Statistical inference helps make data-driven decisions!\")\nprint(\" Always quantify uncertainty and test significance before deploying models.\")\nprint(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nAFTER: Understanding the Impact of Statistical Inference\n============================================================\n\n1. Model Prediction Analysis:\n Mean prediction: 0.8748\n Standard deviation: 0.0452\n 95% Confidence Interval: [0.8658, 0.8838]\n\n2. Statistical Significance Test:\n Testing if model (mean=0.8748) is better than baseline (0.85)\n t-statistic: 5.4632\n p-value: 0.0000\n \u2705 Model is significantly better than baseline! (p < 0.05)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\nCell \u001b[0;32mIn[6], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Comparison with baseline\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mbar([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m], [baseline, mean_pred], \n\u001b[1;32m     55\u001b[0m  yerr\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [mean_pred \u001b[38;5;241m-\u001b[39m ci_95[\u001b[38;5;241m0\u001b[39m], ci_95[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m mean_pred]],\n\u001b[1;32m     56\u001b[0m  color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m], alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, capsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, capthick\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel vs Baseline Comparison\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[1;32m   1522\u001b[0m             ax,\n\u001b[1;32m   1523\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(cbook\u001b[38;5;241m.\u001b[39msanitize_sequence, args),\n\u001b[1;32m   1524\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: cbook\u001b[38;5;241m.\u001b[39msanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/axes/_axes.py:2643\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m   2635\u001b[0m     r \u001b[38;5;241m=\u001b[39m mpatches\u001b[38;5;241m.\u001b[39mRectangle(\n\u001b[1;32m   2636\u001b[0m         xy\u001b[38;5;241m=\u001b[39m(l, b), width\u001b[38;5;241m=\u001b[39mw, height\u001b[38;5;241m=\u001b[39mh,\n\u001b[1;32m   2637\u001b[0m         facecolor\u001b[38;5;241m=\u001b[39mc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         hatch\u001b[38;5;241m=\u001b[39mhtch,\n\u001b[1;32m   2642\u001b[0m         )\n\u001b[0;32m-> 2643\u001b[0m     r\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[1;32m   2644\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/artist.py:1233\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \n\u001b[1;32m   1231\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_props(\n\u001b[1;32m   1234\u001b[0m         kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{cls.__name__}\u001b[39;00m\u001b[38;5;124m.set() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prop_name!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/matplotlib/artist.py:1206\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1204\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1205\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m-> 1206\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1207\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk),\n\u001b[1;32m   1208\u001b[0m                     name\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m   1209\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\n\u001b[0;31mAttributeError\u001b[0m: Rectangle.set() got an unexpected keyword argument 'capthick'\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.6741011142730713,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6129419803619385,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95):        # # SOLUTION: Compute confidence interval    # Steps:    # 1. Calculate sample mean and standard error    # 2. Get t-critical value for confidence level    # 3. CI = mean \u00b1 t_critical * standard_error    pass\ndef t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\ndef interpret_p_value(p_value, alpha=0.05):        # # SOLUTION: Interpret p-value    # If p < alpha: significant difference    # If p >= alpha: no significant difference    pass\ndef compare_models(model1_scores, model2_scores, alpha=0.05):        # # SOLUTION:     # 1. Compute means and confidence intervals    # 2. Perform t-test    # 3. Interpret results    # 4. Return comprehensive comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95):        # # SOLUTION: Compute confidence interval    # Steps:    # 1. Calculate sample mean and standard error    # 2. Get t-critical value for confidence level    # 3. CI = mean \u00b1 t_critical * standard_error    pass\ndef t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\ndef interpret_p_value(p_value, alpha=0.05):        # # SOLUTION: Interpret p-value    # If p < alpha: significant difference    # If p >= alpha: no significant difference    pass\ndef compare_models(model1_scores, model2_scores, alpha=0.05):        # # SOLUTION:     # 1. Compute means and confidence intervals    # 2. Perform t-test    # 3. Interpret results    # 4. Return comprehensive comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/01_vectors_matrices_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8756129741668701,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/02_matrix_operations.ipynb",
      "status": "passed",
      "execution_time": 0.9411461353302002,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/03_eigenvalues_eigenvectors.ipynb",
      "status": "passed",
      "execution_time": 1.1190509796142578,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/04_substitution_elimination_linear_equations.ipynb",
      "status": "passed",
      "execution_time": 1.136293888092041,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/05_determinants_inverse_matrices.ipynb",
      "status": "passed",
      "execution_time": 0.7908480167388916,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/06_transformation_matrices_orthogonal_basis.ipynb",
      "status": "failed",
      "execution_time": 1.0367300510406494,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Applying Transformation Matrices\")\nprint(\"=\" * 60)\n\n# Transformation matrices represent linear transformations\n# Examples: rotation, scaling, reflection, shearing\n\ndef apply_transformation(points, transformation_matrix):\n \n    \n    \"\"\"Apply transformation matrix to points\"\"\"\n return (transformation_matrix @ points.T).T\n\n# Example: 2D points\npoints = np.array([[1, 0],\n [0, 1],\n [1, 1],\n [2, 1]])\n\nprint(\"\\nOriginal points:\")\nprint(points)\n\n# Rotation matrix (90 degrees counterclockwise)\nrotation_90 = np.array([[0, -1],\n [1, 0]])\n\nrotated_points = apply_transformation(points, rotation_90)\nprint(\"\\nRotated 90\u00b0 counterclockwise:\")\nprint(rotated_points)\n\n# Scaling matrix\nscaling = np.array([[2, 0],\n [0, 3]])\n\nscaled_points = apply_transformation(points, scaling)\nprint(\"\\nScaled (x*2, y*3):\")\nprint(scaled_points)\n\n# Shear transformation\nshear = np.array([[1, 0.5],\n [0, 1]])\n\nsheared_points = apply_transformation(points, shear)\nprint(\"\\nSheared:\")\nprint(sheared_points)\n\n# Visualize transformations\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n# Original\naxes[0, 0].scatter(points[:, 0], points[:, 1], c='blue', s=100, alpha=0.7)\naxes[0, 0].plot([0, 0], [0, 2], 'b--', alpha=0.3)\naxes[0, 0].plot([0, 2], [0, 0], 'b--', alpha=0.3)\naxes[0, 0].set_title('Original Points')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(-2, 3)\naxes[0, 0].set_ylim(-2, 3)\naxes[0, 0].axis('equal')\n\n# Rotated\naxes[0, 1].scatter(rotated_points[:, 0], rotated_points[:, 1], c='red', s=100, alpha=0.7)\naxes[0, 1].plot([0, 0], [-2, 2], 'r--', alpha=0.3)\naxes[0, 1].plot([-2, 2], [0, 0], 'r--', alpha=0.3)\naxes[0, 1].set_title('Rotated 90\u00b0')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(-2, 3)\naxes[0, 1].set_ylim(-2, 3)\naxes[0, 1].axis('equal')\n\n# Scaled\naxes[1, 0].scatter(scaled_points[:, 0], scaled_points[:, 1], c='green', s=100, alpha=0.7)\naxes[1, 0].plot([0, 0], [0, 3], 'g--', alpha=0.3)\naxes[1, 0].plot([0, 4], [0, 0], 'g--', alpha=0.3)\naxes[1, 0].set_title('Scaled (x*2, y*3)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(-1, 5)\naxes[1, 0].set_ylim(-1, 4)\naxes[1, 0].axis('equal')\n\n# Sheared\naxes[1, 1].scatter(sheared_points[:, 0], sheared_points[:, 1], c='orange', s=100, alpha=0.7)\naxes[1, 1].plot([0, 0], [0, 2], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].plot([0, 3], [0, 0], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].set_title('Sheared')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].set_xlim(-1, 4)\naxes[1, 1].set_ylim(-1, 2)\naxes[1, 1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Transformation matrices applied and visualized!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (transformation_matrix @ points.T).T\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Applying Transformation Matrices\")\nprint(\"=\" * 60)\n\n# Transformation matrices represent linear transformations\n# Examples: rotation, scaling, reflection, shearing\n\ndef apply_transformation(points, transformation_matrix):\n \n    \n    \"\"\"Apply transformation matrix to points\"\"\"\n return (transformation_matrix @ points.T).T\n\n# Example: 2D points\npoints = np.array([[1, 0],\n [0, 1],\n [1, 1],\n [2, 1]])\n\nprint(\"\\nOriginal points:\")\nprint(points)\n\n# Rotation matrix (90 degrees counterclockwise)\nrotation_90 = np.array([[0, -1],\n [1, 0]])\n\nrotated_points = apply_transformation(points, rotation_90)\nprint(\"\\nRotated 90\u00b0 counterclockwise:\")\nprint(rotated_points)\n\n# Scaling matrix\nscaling = np.array([[2, 0],\n [0, 3]])\n\nscaled_points = apply_transformation(points, scaling)\nprint(\"\\nScaled (x*2, y*3):\")\nprint(scaled_points)\n\n# Shear transformation\nshear = np.array([[1, 0.5],\n [0, 1]])\n\nsheared_points = apply_transformation(points, shear)\nprint(\"\\nSheared:\")\nprint(sheared_points)\n\n# Visualize transformations\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n# Original\naxes[0, 0].scatter(points[:, 0], points[:, 1], c='blue', s=100, alpha=0.7)\naxes[0, 0].plot([0, 0], [0, 2], 'b--', alpha=0.3)\naxes[0, 0].plot([0, 2], [0, 0], 'b--', alpha=0.3)\naxes[0, 0].set_title('Original Points')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(-2, 3)\naxes[0, 0].set_ylim(-2, 3)\naxes[0, 0].axis('equal')\n\n# Rotated\naxes[0, 1].scatter(rotated_points[:, 0], rotated_points[:, 1], c='red', s=100, alpha=0.7)\naxes[0, 1].plot([0, 0], [-2, 2], 'r--', alpha=0.3)\naxes[0, 1].plot([-2, 2], [0, 0], 'r--', alpha=0.3)\naxes[0, 1].set_title('Rotated 90\u00b0')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(-2, 3)\naxes[0, 1].set_ylim(-2, 3)\naxes[0, 1].axis('equal')\n\n# Scaled\naxes[1, 0].scatter(scaled_points[:, 0], scaled_points[:, 1], c='green', s=100, alpha=0.7)\naxes[1, 0].plot([0, 0], [0, 3], 'g--', alpha=0.3)\naxes[1, 0].plot([0, 4], [0, 0], 'g--', alpha=0.3)\naxes[1, 0].set_title('Scaled (x*2, y*3)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(-1, 5)\naxes[1, 0].set_ylim(-1, 4)\naxes[1, 0].axis('equal')\n\n# Sheared\naxes[1, 1].scatter(sheared_points[:, 0], sheared_points[:, 1], c='orange', s=100, alpha=0.7)\naxes[1, 1].plot([0, 0], [0, 2], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].plot([0, 3], [0, 0], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].set_title('Sheared')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].set_xlim(-1, 4)\naxes[1, 1].set_ylim(-1, 2)\naxes[1, 1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Transformation matrices applied and visualized!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (transformation_matrix @ points.T).T\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/07_eigenvalue_analysis_large_matrices.ipynb",
      "status": "passed",
      "execution_time": 1.9526748657226562,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/08_ml_parameter_experiments.ipynb",
      "status": "passed",
      "execution_time": 1.656723976135254,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/computing_determinants_and_inverse_matrices_computationally.ipynb",
      "status": "passed",
      "execution_time": 1.4210610389709473,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/experimenting_with_changes_in_ml_model_parameters_and_observing_changes_in_model.ipynb",
      "status": "passed",
      "execution_time": 1.6628379821777344,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/implementing_substitutionelimination_techniques_for_solving_linear_equations.ipynb",
      "status": "passed",
      "execution_time": 1.552022933959961,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/performing_vector_and_matrix_operations_using_pythonnumpy.ipynb",
      "status": "passed",
      "execution_time": 1.6511292457580566,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/solving_eigenvalue_problems_programmatically_and_applying_eigenvalue_analysis_on.ipynb",
      "status": "passed",
      "execution_time": 1.6288869380950928,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/writing_code_to_apply_transformation_matrices_and_compute_orthogonal_basis_sets.ipynb",
      "status": "passed",
      "execution_time": 1.4354701042175293,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/01_derivatives_basics.ipynb",
      "status": "passed",
      "execution_time": 0.9883849620819092,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/02_gradients_multivariable.ipynb",
      "status": "passed",
      "execution_time": 0.9312970638275146,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/03_gradient_descent.ipynb",
      "status": "passed",
      "execution_time": 0.8322827816009521,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/04_backpropagation_neural_networks.ipynb",
      "status": "passed",
      "execution_time": 1.268561840057373,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/05_function_approximation_ml.ipynb",
      "status": "failed",
      "execution_time": 1.4416828155517578,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Taylor Series Approximation\")\nprint(\"=\" * 60)\n\n# Taylor series: f(x) \u2248 f(a) + f'(a)(x-a) + f''(a)(x-a)\u00b2/2! + ...\n\ndef exp_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of exp(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # f^(n)(a) = exp(a) for all n\n result += (np.exp(a) * (x_minus_a)**n) / np.math.factorial(n)\n return result\n\ndef sin_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of sin(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # Derivatives of sin cycle: sin, cos, -sin, -cos\n derivatives = [np.sin(a), np.cos(a), -np.sin(a), -np.cos(a)]\n result += (derivatives[n % 4] * (x_minus_a)**n) / np.math.factorial(n)\n return result\n\n# Visualize approximations\nx = np.linspace(-2, 2, 100)\n\nplt.figure(figsize=(14, 5))\n# Exponential approximation\nplt.subplot(1, 2, 1)\nplt.plot(x, np.exp(x), 'b-', label='exp(x)', linewidth=2)\nfor n in [1, 2, 3, 5, 10]:\n y_approx = [exp_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of exp(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1, 8)\n\n# Sine approximation\nplt.subplot(1, 2, 2)\nplt.plot(x, np.sin(x), 'r-', label='sin(x)', linewidth=2)\nfor n in [1, 3, 5, 7, 9]:\n y_approx = [sin_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of sin(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1.5, 1.5)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Taylor series approximations visualized!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Taylor Series Approximation\")\nprint(\"=\" * 60)\n\n# Taylor series: f(x) \u2248 f(a) + f'(a)(x-a) + f''(a)(x-a)\u00b2/2! + ...\n\ndef exp_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of exp(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # f^(n)(a) = exp(a) for all n\n result += (np.exp(a) * (x_minus_a)**n) / np.math.factorial(n)\n return result\n\ndef sin_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of sin(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # Derivatives of sin cycle: sin, cos, -sin, -cos\n derivatives = [np.sin(a), np.cos(a), -np.sin(a), -np.cos(a)]\n result += (derivatives[n % 4] * (x_minus_a)**n) / np.math.factorial(n)\n return result\n\n# Visualize approximations\nx = np.linspace(-2, 2, 100)\n\nplt.figure(figsize=(14, 5))\n# Exponential approximation\nplt.subplot(1, 2, 1)\nplt.plot(x, np.exp(x), 'b-', label='exp(x)', linewidth=2)\nfor n in [1, 2, 3, 5, 10]:\n y_approx = [exp_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of exp(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1, 8)\n\n# Sine approximation\nplt.subplot(1, 2, 2)\nplt.plot(x, np.sin(x), 'r-', label='sin(x)', linewidth=2)\nfor n in [1, 3, 5, 7, 9]:\n y_approx = [sin_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of sin(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1.5, 1.5)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Taylor series approximations visualized!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/applying_function_approximation_on_real_world_ml_models.ipynb",
      "status": "passed",
      "execution_time": 1.6237602233886719,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/implementing_gradient_computations_for_multivariate_functions.ipynb",
      "status": "passed",
      "execution_time": 1.5531048774719238,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/programming_backpropagation_in_neural_networks_using_differentiation_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.546151876449585,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/solving_differentiation_problems_using_symbolic_computation_tools.ipynb",
      "status": "passed",
      "execution_time": 1.665308952331543,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/01_optimizers_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.8208050727844238,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/02_loss_functions.ipynb",
      "status": "passed",
      "execution_time": 0.9666430950164795,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/03_statistical_measures.ipynb",
      "status": "passed",
      "execution_time": 0.8423459529876709,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/04_regression_real_datasets.ipynb",
      "status": "failed",
      "execution_time": 0.6390769481658936,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing \nimport StandardScaler, PolynomialFeatures\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.datasets \nimport load_boston, fetch_california_housing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Regression Techniques to Real Datasets\")\nprint(\"=\" * 60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing \nimport StandardScaler, PolynomialFeatures\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.datasets \nimport load_boston, fetch_california_housing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Regression Techniques to Real Datasets\")\nprint(\"=\" * 60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/05_image_similarity_measures.ipynb",
      "status": "passed",
      "execution_time": 1.9704217910766602,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/applying_regression_techniques_to_fit_models_on_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.6438038349151611,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/implementing_gradient_descent_for_optimization_problems.ipynb",
      "status": "passed",
      "execution_time": 1.5727241039276123,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/implementing_projection_and_dimensionality_reduction_techniques_in_ml.ipynb",
      "status": "passed",
      "execution_time": 1.9130539894104004,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/representing_images_as_vectors_and_computing_angles_and_distances_between_them.ipynb",
      "status": "passed",
      "execution_time": 1.424144983291626,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/writing_code_to_compute_basic_statistical_properties_of_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.3178551197052002,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/01_pca_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.7978589534759521,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/02_curse_dimensionality.ipynb",
      "status": "passed",
      "execution_time": 0.9967570304870605,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/03_feature_selection.ipynb",
      "status": "passed",
      "execution_time": 1.0333070755004883,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/04_svd_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.5253748893737793,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/05_tsne_visualization.ipynb",
      "status": "passed",
      "execution_time": 2.594973087310791,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/06_dimensionality_reduction_real_world_datasets.ipynb",
      "status": "passed",
      "execution_time": 3.304119110107422,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/implementing_pca_using_python_for_dimensionality_reduction_of_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.8509039878845215,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/writing_code_to_apply_these_dimensionality_reduction_techniques_on_real_world_da.ipynb",
      "status": "passed",
      "execution_time": 1.8786120414733887,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/01_probability_distributions.ipynb",
      "status": "passed",
      "execution_time": 0.7533431053161621,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/02_statistical_inference.ipynb",
      "status": "passed",
      "execution_time": 0.9604370594024658,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/03_bayesian_inference.ipynb",
      "status": "passed",
      "execution_time": 1.4023571014404297,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/04_central_limit_theorem_simulations.ipynb",
      "status": "passed",
      "execution_time": 2.067873001098633,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/05_sampling_point_estimation.ipynb",
      "status": "passed",
      "execution_time": 1.9634122848510742,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/06_maximum_likelihood_estimation.ipynb",
      "status": "failed",
      "execution_time": 1.2383179664611816,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: MLE for Gaussian Distribution\")\nprint(\"=\" * 60)\n\n# Generate data from Gaussian distribution\nnp.random.seed(42)\ntrue_mu = 5.0\ntrue_sigma = 2.0\ndata = np.random.normal(true_mu, true_sigma, 100)\n\nprint(f\"\\nTrue parameters:\")\nprint(f\" \u03bc (mean): {true_mu}\")\nprint(f\" \u03c3 (std): {true_sigma}\")\nprint(f\" Sample size: {len(data)}\")\n\n# MLE for Gaussian: sample mean and sample std\nmle_mu = np.mean(data)\nmle_sigma = np.std(data, ddof=0) # MLE uses N, not N-1\n\nprint(f\"\\nMLE estimates:\")\nprint(f\" \u03bc_MLE (sample mean): {mle_mu:.4f}\")\nprint(f\" \u03c3_MLE (sample std): {mle_sigma:.4f}\")\n\n# Negative log-likelihood function (we minimize this)\ndef neg_log_likelihood_gaussian(params, data):\n \n    \n    \n    \"\"\"Negative log-likelihood for Gaussian distribution\"\"\"\n mu, sigma = paramsif sigma <= 0:\n return np.inf\n n = len(data)\n log_likelihood = -n * np.log(sigma * np.sqrt(2 * np.pi)) - np.sum((data - mu)**2) / (2 * sigma**2)\n return -log_likelihood # Return negative for minimization\n\n# Optimize using scipy\nresult = minimize(lambda p: neg_log_likelihood_gaussian(p, data), \n x0=[mle_mu, mle_sigma], \n method='BFGS')\nmle_mu_opt = result.x[0]\nmle_sigma_opt = result.x[1]\n\nprint(f\"\\nMLE from optimization:\")\nprint(f\" \u03bc_MLE: {mle_mu_opt:.4f}\")\nprint(f\" \u03c3_MLE: {mle_sigma_opt:.4f}\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(data, bins=20, density=True, alpha=0.7, color='blue', label='Data')\nx = np.linspace(data.min(), data.max(), 100)\nplt.plot(x, stats.norm.pdf(x, true_mu, true_sigma), 'r-', linewidth=2, label=f'True (\u03bc={true_mu}, \u03c3={true_sigma})')\nplt.plot(x, stats.norm.pdf(x, mle_mu, mle_sigma), 'g--', linewidth=2, label=f'MLE (\u03bc={mle_mu:.2f}, \u03c3={mle_sigma:.2f})')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Gaussian Distribution MLE')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nmu_range = np.linspace(3, 7, 100)\nlog_likelihoods = [-neg_log_likelihood_gaussian([mu, mle_sigma], data) for mu in mu_range]\nplt.plot(mu_range, log_likelihoods, 'b-', linewidth=2)\nplt.axvline(true_mu, color='r', linestyle='--', label=f'True \u03bc={true_mu}')\nplt.axvline(mle_mu, color='g', linestyle='--', label=f'MLE \u03bc={mle_mu:.2f}')\nplt.xlabel('\u03bc (mean)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 MLE for Gaussian distribution implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:30\u001b[0;36m\u001b[0m\n\u001b[0;31m    mu, sigma = paramsif sigma <= 0:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: MLE for Gaussian Distribution\")\nprint(\"=\" * 60)\n\n# Generate data from Gaussian distribution\nnp.random.seed(42)\ntrue_mu = 5.0\ntrue_sigma = 2.0\ndata = np.random.normal(true_mu, true_sigma, 100)\n\nprint(f\"\\nTrue parameters:\")\nprint(f\" \u03bc (mean): {true_mu}\")\nprint(f\" \u03c3 (std): {true_sigma}\")\nprint(f\" Sample size: {len(data)}\")\n\n# MLE for Gaussian: sample mean and sample std\nmle_mu = np.mean(data)\nmle_sigma = np.std(data, ddof=0) # MLE uses N, not N-1\n\nprint(f\"\\nMLE estimates:\")\nprint(f\" \u03bc_MLE (sample mean): {mle_mu:.4f}\")\nprint(f\" \u03c3_MLE (sample std): {mle_sigma:.4f}\")\n\n# Negative log-likelihood function (we minimize this)\ndef neg_log_likelihood_gaussian(params, data):\n \n    \n    \n    \"\"\"Negative log-likelihood for Gaussian distribution\"\"\"\n mu, sigma = paramsif sigma <= 0:\n return np.inf\n n = len(data)\n log_likelihood = -n * np.log(sigma * np.sqrt(2 * np.pi)) - np.sum((data - mu)**2) / (2 * sigma**2)\n return -log_likelihood # Return negative for minimization\n\n# Optimize using scipy\nresult = minimize(lambda p: neg_log_likelihood_gaussian(p, data), \n x0=[mle_mu, mle_sigma], \n method='BFGS')\nmle_mu_opt = result.x[0]\nmle_sigma_opt = result.x[1]\n\nprint(f\"\\nMLE from optimization:\")\nprint(f\" \u03bc_MLE: {mle_mu_opt:.4f}\")\nprint(f\" \u03c3_MLE: {mle_sigma_opt:.4f}\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(data, bins=20, density=True, alpha=0.7, color='blue', label='Data')\nx = np.linspace(data.min(), data.max(), 100)\nplt.plot(x, stats.norm.pdf(x, true_mu, true_sigma), 'r-', linewidth=2, label=f'True (\u03bc={true_mu}, \u03c3={true_sigma})')\nplt.plot(x, stats.norm.pdf(x, mle_mu, mle_sigma), 'g--', linewidth=2, label=f'MLE (\u03bc={mle_mu:.2f}, \u03c3={mle_sigma:.2f})')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Gaussian Distribution MLE')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nmu_range = np.linspace(3, 7, 100)\nlog_likelihoods = [-neg_log_likelihood_gaussian([mu, mle_sigma], data) for mu in mu_range]\nplt.plot(mu_range, log_likelihoods, 'b-', linewidth=2)\nplt.axvline(true_mu, color='r', linestyle='--', label=f'True \u03bc={true_mu}')\nplt.axvline(mle_mu, color='g', linestyle='--', label=f'MLE \u03bc={mle_mu:.2f}')\nplt.xlabel('\u03bc (mean)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 MLE for Gaussian distribution implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:30\u001b[0;36m\u001b[0m\n\u001b[0;31m    mu, sigma = paramsif sigma <= 0:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/07_hypothesis_testing_procedures.ipynb",
      "status": "passed",
      "execution_time": 1.537687063217163,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/08_pvalues_confidence_intervals.ipynb",
      "status": "passed",
      "execution_time": 1.5576729774475098,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/09_probability_ml_connections.ipynb",
      "status": "passed",
      "execution_time": 1.9346110820770264,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/applying_central_limit_theorem_with_simulations.ipynb",
      "status": "passed",
      "execution_time": 1.6684398651123047,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/computing_p_values_and_confidence_intervals.ipynb",
      "status": "passed",
      "execution_time": 1.501589059829712,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/connecting_probability_theory_to_ml_model_implementations.ipynb",
      "status": "passed",
      "execution_time": 1.4358367919921875,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/implementing_hypothesis_testing_procedures.ipynb",
      "status": "passed",
      "execution_time": 1.5393660068511963,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/implementing_maximum_likelihood_estimation_mle_for_different_distributions.ipynb",
      "status": "passed",
      "execution_time": 1.3314599990844727,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/performing_sampling_and_point_estimation.ipynb",
      "status": "passed",
      "execution_time": 1.5675849914550781,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/01_data_loading_exploration.ipynb",
      "status": "failed",
      "execution_time": 1.6025679111480713,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us work with data and create visualizations\n\nimport pandas as pd # For data manipulation and analysis (DataFrames, reading CSV) / import numpy as np # For numerical operations (arrays, math functions) / import matplotlib.pyplot as plt # For creating plots and visualizations\nimport seaborn as sns # For statistical visualizations (beautiful plots) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - pandas: Load, manipulate, and analyze data (our main tool!)\")\nprint(\" - numpy: Fast numerical computations (arrays, math)\")\nprint(\" - matplotlib: Create basic plots and charts\") / print(\" - seaborn: Create beautiful statistical visualizations\")\n\n------------------\n\n----- stdout -----\n - numpy: Fast numerical computations (arrays, math)\n - matplotlib: Create basic plots and charts\n - seaborn: Create beautiful statistical visualizations\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m \u001b[38;5;66;03m# For statistical visualizations (beautiful plots) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - pandas: Load, manipulate, and analyze data (our main tool!)\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - numpy: Fast numerical computations (arrays, math)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - matplotlib: Create basic plots and charts\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - seaborn: Create beautiful statistical visualizations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us work with data and create visualizations\n\nimport pandas as pd # For data manipulation and analysis (DataFrames, reading CSV) / import numpy as np # For numerical operations (arrays, math functions) / import matplotlib.pyplot as plt # For creating plots and visualizations\nimport seaborn as sns # For statistical visualizations (beautiful plots) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - pandas: Load, manipulate, and analyze data (our main tool!)\")\nprint(\" - numpy: Fast numerical computations (arrays, math)\")\nprint(\" - matplotlib: Create basic plots and charts\") / print(\" - seaborn: Create beautiful statistical visualizations\")\n\n------------------\n\n----- stdout -----\n - numpy: Fast numerical computations (arrays, math)\n - matplotlib: Create basic plots and charts\n - seaborn: Create beautiful statistical visualizations\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m \u001b[38;5;66;03m# For statistical visualizations (beautiful plots) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - pandas: Load, manipulate, and analyze data (our main tool!)\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - numpy: Fast numerical computations (arrays, math)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - matplotlib: Create basic plots and charts\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - seaborn: Create beautiful statistical visualizations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/02_data_cleaning.ipynb",
      "status": "passed",
      "execution_time": 2.3744850158691406,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/03_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 0.7321741580963135,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us preprocess data for machine learning import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nfrom sklearn.preprocessing import (, LabelEncoder\n StandardScaler, # For standardization (mean=0, std=1) MinMaxScaler, # For normalization (range 0-1) LabelEncoder, # For ordinal encoding OneHotEncoder # For nominal encoding\n)\nfrom sklearn.model_selection import train_test_split # For splitting data print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each preprocessing tool does:\") / print(\" - StandardScaler: Scale features to mean=0, std=1 (z-score)\")\nprint(\" - MinMaxScaler: Scale features to range [0, 1]\") / print(\" - LabelEncoder: Convert categories to numbers (ordinal)\")\nprint(\" - OneHotEncoder: Convert categories to binary columns (nominal)\")\nprint(\" - train_test_split: Split data into train/test sets\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing import (, LabelEncoder\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us preprocess data for machine learning import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nfrom sklearn.preprocessing import (, LabelEncoder\n StandardScaler, # For standardization (mean=0, std=1) MinMaxScaler, # For normalization (range 0-1) LabelEncoder, # For ordinal encoding OneHotEncoder # For nominal encoding\n)\nfrom sklearn.model_selection import train_test_split # For splitting data print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each preprocessing tool does:\") / print(\" - StandardScaler: Scale features to mean=0, std=1 (z-score)\")\nprint(\" - MinMaxScaler: Scale features to range [0, 1]\") / print(\" - LabelEncoder: Convert categories to numbers (ordinal)\")\nprint(\" - OneHotEncoder: Convert categories to binary columns (nominal)\")\nprint(\" - train_test_split: Split data into train/test sets\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing import (, LabelEncoder\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/04_linear_regression.ipynb",
      "status": "failed",
      "execution_time": 1.7360291481018066,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build and evaluate linear regression models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.linear_model import LinearRegression # The regression model!\nfrom sklearn.metrics import (\n mean_squared_error, # MSE - measures average squared error\n mean_absolute_error, # MAE - measures average absolute error\n r2_score # R\u00b2 - measures how well model fits (0-1, higher is better)\n)\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each tool does:\") / print(\" - LinearRegression: Builds the regression model\") / print(\" - train_test_split: Splits data for training and testing\") / print(\" - MSE/MAE/R\u00b2: Metrics to evaluate model performance\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each tool does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression \u001b[38;5;66;03m# The regression model!\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m  mean_squared_error, \u001b[38;5;66;03m# MSE - measures average squared error\u001b[39;00m\n\u001b[1;32m     12\u001b[0m  mean_absolute_error, \u001b[38;5;66;03m# MAE - measures average absolute error\u001b[39;00m\n\u001b[1;32m     13\u001b[0m  r2_score \u001b[38;5;66;03m# R\u00b2 - measures how well model fits (0-1, higher is better)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each tool does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - LinearRegression: Builds the regression model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - train_test_split: Splits data for training and testing\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - MSE/MAE/R\u00b2: Metrics to evaluate model performance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build and evaluate linear regression models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.linear_model import LinearRegression # The regression model!\nfrom sklearn.metrics import (\n mean_squared_error, # MSE - measures average squared error\n mean_absolute_error, # MAE - measures average absolute error\n r2_score # R\u00b2 - measures how well model fits (0-1, higher is better)\n)\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each tool does:\") / print(\" - LinearRegression: Builds the regression model\") / print(\" - train_test_split: Splits data for training and testing\") / print(\" - MSE/MAE/R\u00b2: Metrics to evaluate model performance\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each tool does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression \u001b[38;5;66;03m# The regression model!\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m  mean_squared_error, \u001b[38;5;66;03m# MSE - measures average squared error\u001b[39;00m\n\u001b[1;32m     12\u001b[0m  mean_absolute_error, \u001b[38;5;66;03m# MAE - measures average absolute error\u001b[39;00m\n\u001b[1;32m     13\u001b[0m  r2_score \u001b[38;5;66;03m# R\u00b2 - measures how well model fits (0-1, higher is better)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each tool does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - LinearRegression: Builds the regression model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - train_test_split: Splits data for training and testing\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - MSE/MAE/R\u00b2: Metrics to evaluate model performance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/05_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6560781002044678,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build polynomial regression models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nfrom sklearn.preprocessing import PolynomialFeatures # Creates polynomial features (x\u00b2, x\u00b3, etc.) / from sklearn.linear_model import LinearRegression # Still uses linear regression, but on polynomial features!\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.metrics import mean_squared_error, r2_score # For evaluation\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each tool does:\") / print(\" - PolynomialFeatures: Transforms x into [x, x\u00b2, x\u00b3, ...]\") / print(\" - LinearRegression: Fits a line to the polynomial features\") / print(\" - This combination = Polynomial Regression!\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each tool does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split \u001b[38;5;66;03m# For splitting data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score \u001b[38;5;66;03m# For evaluation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each tool does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - PolynomialFeatures: Transforms x into [x, x\u00b2, x\u00b3, ...]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - LinearRegression: Fits a line to the polynomial features\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - This combination = Polynomial Regression!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build polynomial regression models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nfrom sklearn.preprocessing import PolynomialFeatures # Creates polynomial features (x\u00b2, x\u00b3, etc.) / from sklearn.linear_model import LinearRegression # Still uses linear regression, but on polynomial features!\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.metrics import mean_squared_error, r2_score # For evaluation\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each tool does:\") / print(\" - PolynomialFeatures: Transforms x into [x, x\u00b2, x\u00b3, ...]\") / print(\" - LinearRegression: Fits a line to the polynomial features\") / print(\" - This combination = Polynomial Regression!\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each tool does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split \u001b[38;5;66;03m# For splitting data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score \u001b[38;5;66;03m# For evaluation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each tool does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - PolynomialFeatures: Transforms x into [x, x\u00b2, x\u00b3, ...]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - LinearRegression: Fits a line to the polynomial features\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - This combination = Polynomial Regression!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/06_ridge_lasso_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6324069499969482,
      "error": "An error occurred while executing the following cell:\n------------------\n# Generate sample data with multiple features_np.random.seed(42) / n_samples = 100\n\n# Create features with some correlation_X = np.random.randn(n_samples, 5)\n# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for regularization) / scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\nX_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\nX_test_scaled = scaler.transform(X_test) / print(f\"Training set: {X_train_scaled.shape}\") / print(f\"Test set: {X_test_scaled.shape}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Generate sample data with multiple features_np.random.seed(42) / n_samples = 100\n\n# Create features with some correlation_X = np.random.randn(n_samples, 5)\n# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for regularization) / scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\nX_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\nX_test_scaled = scaler.transform(X_test) / print(f\"Training set: {X_train_scaled.shape}\") / print(f\"Test set: {X_test_scaled.shape}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/07_svr_decision_tree_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5263862609863281,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.svm \nimport SVR\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.metrics \nimport mean_squared_error, r2_score\nfrom sklearn.preprocessing \nimport StandardScaler_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.svm \nimport SVR\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.metrics \nimport mean_squared_error, r2_score\nfrom sklearn.preprocessing \nimport StandardScaler_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/comparing_regression_algorithms_on_real_datasets.ipynb",
      "status": "failed",
      "execution_time": 0.7405848503112793,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/implementing_decision_tree_and_random_forest_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5781731605529785,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/visualizing_regression_results_and_residuals.ipynb",
      "status": "failed",
      "execution_time": 0.5323889255523682,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5650157928466797,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plti_mport seaborn as sn\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plti_mport seaborn as sn\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plti_mport seaborn as sn\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plti_mport seaborn as sn\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.6488220691680908,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_03_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6754872798919678,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 3: Polynomial Regression Practice\n\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\n\nInstructions:\n1. Load the provided dataset_2. Create polynomial regression models with different degrees_3. Detect overfitting by comparing train vs test performance_4. Find the optimal polynomial degree_5. Visualize the results_6. Understand the bias-variance tradeoff\n\nUse the provided dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample non-linear data_np.random.seed(123)\nX = np.linspace(0, 10, 200).reshape(-1, 1)\n# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\n\ndf = pd.DataFrame({'x': X.flatten(), 'y': y})\n\nprint(\"Dataset Info:\")\nprint(f\"Shape: {df.shape}\")\nprint(df.head())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train polynomial regression with degree 1 (linear)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Polynomial Regression (degree=1)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=1\n# Train LinearRegression\n# Evaluate on both train and test\n# Your code here...\n\n# Task 3: Train polynomial regression with degree 2_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Polynomial Regression (degree=2)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=2\n# Train and evaluate\n# Your code here...\n\n# Task 4: Train polynomial regression with degree 5_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Polynomial Regression (degree=5)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=5\n# Train and evaluate\n# Notice overfitting (high train accuracy, lower test accuracy)\n# Your code here...\n\n# Task 5: Find optimal degree using validation_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Find optimal polynomial degree\")\nprint(\"=\"*60)\n# Test degrees from 1 to 10\n# Plot degree vs MSE (both train and test)\n# Find degree with best test performance\n# Your code here...\n\n# Task 6: Visualize results_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize polynomial fits\")\nprint(\"=\"*60)\n# Plot original data\n# Plot polynomial fits for different degrees\n# Show how higher degrees can overfit\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Info:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 3: Polynomial Regression Practice\n\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\n\nInstructions:\n1. Load the provided dataset_2. Create polynomial regression models with different degrees_3. Detect overfitting by comparing train vs test performance_4. Find the optimal polynomial degree_5. Visualize the results_6. Understand the bias-variance tradeoff\n\nUse the provided dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample non-linear data_np.random.seed(123)\nX = np.linspace(0, 10, 200).reshape(-1, 1)\n# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\n\ndf = pd.DataFrame({'x': X.flatten(), 'y': y})\n\nprint(\"Dataset Info:\")\nprint(f\"Shape: {df.shape}\")\nprint(df.head())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train polynomial regression with degree 1 (linear)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Polynomial Regression (degree=1)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=1\n# Train LinearRegression\n# Evaluate on both train and test\n# Your code here...\n\n# Task 3: Train polynomial regression with degree 2_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Polynomial Regression (degree=2)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=2\n# Train and evaluate\n# Your code here...\n\n# Task 4: Train polynomial regression with degree 5_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Polynomial Regression (degree=5)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=5\n# Train and evaluate\n# Notice overfitting (high train accuracy, lower test accuracy)\n# Your code here...\n\n# Task 5: Find optimal degree using validation_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Find optimal polynomial degree\")\nprint(\"=\"*60)\n# Test degrees from 1 to 10\n# Plot degree vs MSE (both train and test)\n# Find degree with best test performance\n# Your code here...\n\n# Task 6: Visualize results_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize polynomial fits\")\nprint(\"=\"*60)\n# Plot original data\n# Plot polynomial fits for different degrees\n# Show how higher degrees can overfit\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Info:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_04_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 1.441946268081665,
      "error": "An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations / Terrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    'transaction_amount': np.random.uniform(10, 10000, n_samples),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations / Terrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    'transaction_amount': np.random.uniform(10, 10000, n_samples),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 1.590977668762207,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 1: Data Processing Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062aInstructions:1. Load the sample dataset provided below2. Explore the data (shape, info, statistics)3. Handle missing values appropriately4. Remove any duplicates5. Create visualizations (at least 2 different plots)\nDataset: Sales data for a retail stor_e\"\"\"\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dataset: Sales data for a retail stor_e\"\"\"\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 3)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 1: Data Processing Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062aInstructions:1. Load the sample dataset provided below2. Explore the data (shape, info, statistics)3. Handle missing values appropriately4. Remove any duplicates5. Create visualizations (at least 2 different plots)\nDataset: Sales data for a retail stor_e\"\"\"\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dataset: Sales data for a retail stor_e\"\"\"\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 3)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5577919483184814,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_03_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 0.8590340614318848,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 3: Polynomial Regression Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062fInstructions:1. Load the provided dataset2. Create polynomial regression models with different degrees3. Detect overfitting by comparing train vs test performance4. Find the optimal polynomial degree5. Visualize the results6. Understand the bias-variance tradeoffUse the provided dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score# Generate sample non-linear datanp.random.seed(123)X = np.linspace(0, 10, 200).reshape(-1, 1)# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noisey = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)df = pd.DataFrame({'x': X.flatten(), 'y': y})print(\"Dataset Info:\")print(f\"Shape: {df.shape}\")print(df.head())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train polynomial regression with degree 1 (linear)print(\"\\n\" + \"=\"*60)print(\"Task 2: Polynomial Regression (degree=1)\")print(\"=\"*60)# Use PolynomialFeatures with degree=1# Train LinearRegression# Evaluate on both train and test# Your code here...\n# Task 3: Train polynomial regression with degree 2\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Polynomial Regression (degree=5)\")print(\"=\"*60)# Use PolynomialFeatures with degree=5# Train and evaluate# Notice overfitting (high train accuracy, lower test accuracy)# Your code here...# Task 5: Find optimal degree using validation\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Find optimal polynomial degree\")print(\"=\"*60)# Test degrees from 1 to 10# Plot degree vs MSE (both train and test)# Find degree with best test performance# Your code here...# Task 6: Visualize results\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize polynomial fits\")print(\"=\"*60)# Plot original data# Plot polynomial fits for different degrees# Show how higher degrees can overfit# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 3: Polynomial Regression Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062fInstructions:1. Load the provided dataset2. Create polynomial regression models with different degrees3. Detect overfitting by comparing train vs test performance4. Find the optimal polynomial degree5. Visualize the results6. Understand the bias-variance tradeoffUse the provided dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score# Generate sample non-linear datanp.random.seed(123)X = np.linspace(0, 10, 200).reshape(-1, 1)# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noisey = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)df = pd.DataFrame({'x': X.flatten(), 'y': y})print(\"Dataset Info:\")print(f\"Shape: {df.shape}\")print(df.head())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train polynomial regression with degree 1 (linear)print(\"\\n\" + \"=\"*60)print(\"Task 2: Polynomial Regression (degree=1)\")print(\"=\"*60)# Use PolynomialFeatures with degree=1# Train LinearRegression# Evaluate on both train and test# Your code here...\n# Task 3: Train polynomial regression with degree 2\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Polynomial Regression (degree=5)\")print(\"=\"*60)# Use PolynomialFeatures with degree=5# Train and evaluate# Notice overfitting (high train accuracy, lower test accuracy)# Your code here...# Task 5: Find optimal degree using validation\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Find optimal polynomial degree\")print(\"=\"*60)# Test degrees from 1 to 10# Plot degree vs MSE (both train and test)# Find degree with best test performance# Your code here...# Task 6: Visualize results\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize polynomial fits\")print(\"=\"*60)# Plot original data# Plot polynomial fits for different degrees# Show how higher degrees can overfit# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_04_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 1.4658360481262207,
      "error": "An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations / Terrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    'transaction_amount': np.random.uniform(10, 10000, n_samples),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations / Terrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    'transaction_amount': np.random.uniform(10, 10000, n_samples),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit2-regression/examples/01_ridge_lasso_regression.ipynb",
      "status": "failed",
      "execution_time": 1.7766978740692139,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build regularized regression models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.linear_model import (\n LinearRegression, # Baseline model (no regularization)\n Ridge, # L2 regularization (shrinks coefficients)\n Lasso # L1 regularization (shrinks + feature selection)\n)\nfrom sklearn.preprocessing import StandardScaler # Important! Regularization needs scaled features\nfrom sklearn.metrics import mean_squared_error, r2_score # For evaluation\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each model does:\") / print(\" - LinearRegression: No regularization (baseline)\")\nprint(\" - Ridge: L2 regularization (keeps all features, shrinks coefficients)\")\nprint(\" - Lasso: L1 regularization (removes some features, shrinks others)\")\nprint(\" - StandardScaler: CRITICAL! Regularization requires scaled features!\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each model does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler \u001b[38;5;66;03m# Important! Regularization needs scaled features\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score \u001b[38;5;66;03m# For evaluation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each model does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - LinearRegression: No regularization (baseline)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Ridge: L2 regularization (keeps all features, shrinks coefficients)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Lasso: L1 regularization (removes some features, shrinks others)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build regularized regression models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.linear_model import (\n LinearRegression, # Baseline model (no regularization)\n Ridge, # L2 regularization (shrinks coefficients)\n Lasso # L1 regularization (shrinks + feature selection)\n)\nfrom sklearn.preprocessing import StandardScaler # Important! Regularization needs scaled features\nfrom sklearn.metrics import mean_squared_error, r2_score # For evaluation\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each model does:\") / print(\" - LinearRegression: No regularization (baseline)\")\nprint(\" - Ridge: L2 regularization (keeps all features, shrinks coefficients)\")\nprint(\" - Lasso: L1 regularization (removes some features, shrinks others)\")\nprint(\" - StandardScaler: CRITICAL! Regularization requires scaled features!\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each model does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler \u001b[38;5;66;03m# Important! Regularization needs scaled features\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score \u001b[38;5;66;03m# For evaluation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each model does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - LinearRegression: No regularization (baseline)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Ridge: L2 regularization (keeps all features, shrinks coefficients)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Lasso: L1 regularization (removes some features, shrinks others)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/02_cross_validation.ipynb",
      "status": "passed",
      "execution_time": 2.6588780879974365,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/03_bias_variance_learning_curves.ipynb",
      "status": "failed",
      "execution_time": 0.5563819408416748,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve, validation_curve\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.preprocessing \nimport PolynomialFeatures\nfrom sklearn.pipeline \nimport Pipeline\nfrom sklearn.metrics \nimport mean_squared_error_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve, validation_curve\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.preprocessing \nimport PolynomialFeatures\nfrom sklearn.pipeline \nimport Pipeline\nfrom sklearn.metrics \nimport mean_squared_error_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/04_regression_evaluation_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.657423734664917,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport mean_squared_error, mean_absolute_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRegression Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nMSE (Mean Squared Error):\")\nprint(\"  - Average squared differences\")\nprint(\"  - Penalizes large errors\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nRMSE (Root Mean Squared Error):\")\nprint(\"  - Square root of MSE\")\nprint(\"  - Same units as target\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nMAE (Mean Absolute Error):\")\nprint(\"  - Average absolute differences\")\nprint(\"  - Less sensitive to outliers\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nR\u00b2 (Coefficient of Determination):\")\nprint(\"  - Proportion of variance explained\")\nprint(\"  - Range: -\u221e to 1\")\nprint(\"  - Higher is better (closer to 1)\")\n\nprint(\"\\n\u2705 Regression metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport mean_squared_error, mean_absolute_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRegression Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nMSE (Mean Squared Error):\")\nprint(\"  - Average squared differences\")\nprint(\"  - Penalizes large errors\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nRMSE (Root Mean Squared Error):\")\nprint(\"  - Square root of MSE\")\nprint(\"  - Same units as target\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nMAE (Mean Absolute Error):\")\nprint(\"  - Average absolute differences\")\nprint(\"  - Less sensitive to outliers\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nR\u00b2 (Coefficient of Determination):\")\nprint(\"  - Proportion of variance explained\")\nprint(\"  - Range: -\u221e to 1\")\nprint(\"  - Higher is better (closer to 1)\")\n\nprint(\"\\n\u2705 Regression metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/05_leave_one_out_stratified_cv.ipynb",
      "status": "failed",
      "execution_time": 0.6337740421295166,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport LeaveOneOut, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model \nimport LinearRegression_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nLeave-One-Out and Stratified Cross-Validation\")\nprint(\"=\" * 60)\n\nprint(\"\\nLeave-One-Out CV:\")\nprint(\"  - Each sample as test set\")\nprint(\"  - Maximum data usage\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nStratified Cross-Validation:\")\nprint(\"  - Preserves class distribution\")\nprint(\"  - Important for imbalanced data\")\nprint(\"  - Better for classification\")\n\nprint(\"\\n\u2705 Advanced CV concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport LeaveOneOut, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model \nimport LinearRegression_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nLeave-One-Out and Stratified Cross-Validation\")\nprint(\"=\" * 60)\n\nprint(\"\\nLeave-One-Out CV:\")\nprint(\"  - Each sample as test set\")\nprint(\"  - Maximum data usage\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nStratified Cross-Validation:\")\nprint(\"  - Preserves class distribution\")\nprint(\"  - Important for imbalanced data\")\nprint(\"  - Better for classification\")\n\nprint(\"\\n\u2705 Advanced CV concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/06_overfitting_underfitting_handling.ipynb",
      "status": "failed",
      "execution_time": 0.5298938751220703,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve\nfrom sklearn.linear_model \nimport LinearRegression, Ridge\nfrom sklearn.tree \nimport DecisionTreeRegressor_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nIdentifying and Handling Overfitting/Underfitting\")\nprint(\"=\" * 60)\n\nprint(\"\\nOverfitting Signs:\")\nprint(\"  - High training accuracy, low validation accuracy\")\nprint(\"  - Large gap between train/test performance\")\nprint(\"  - Model too complex\")\n\nprint(\"\\nUnderfitting Signs:\")\nprint(\"  - Low training accuracy\")\nprint(\"  - Low validation accuracy\")\nprint(\"  - Model too simple\")\n\nprint(\"\\nSolutions:\")\nprint(\"  - Regularization (L1, L2)\")\nprint(\"  - Cross-validation\")\nprint(\"  - Feature selection\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 Overfitting/underfitting concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve\nfrom sklearn.linear_model \nimport LinearRegression, Ridge\nfrom sklearn.tree \nimport DecisionTreeRegressor_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nIdentifying and Handling Overfitting/Underfitting\")\nprint(\"=\" * 60)\n\nprint(\"\\nOverfitting Signs:\")\nprint(\"  - High training accuracy, low validation accuracy\")\nprint(\"  - Large gap between train/test performance\")\nprint(\"  - Model too complex\")\n\nprint(\"\\nUnderfitting Signs:\")\nprint(\"  - Low training accuracy\")\nprint(\"  - Low validation accuracy\")\nprint(\"  - Model too simple\")\n\nprint(\"\\nSolutions:\")\nprint(\"  - Regularization (L1, L2)\")\nprint(\"  - Cross-validation\")\nprint(\"  - Feature selection\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 Overfitting/underfitting concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/07_optimal_model_complexity.ipynb",
      "status": "failed",
      "execution_time": 0.7423248291015625,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport validation_curve, GridSearchCV\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.linear_model \nimport Ridge_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSelecting Optimal Model Complexity\")\nprint(\"=\" * 60)\n\nprint(\"\\nValidation Sets:\")\nprint(\"  - Separate from training/test\")\nprint(\"  - Used for hyperparameter tuning\")\nprint(\"  - Prevents overfitting\")\n\nprint(\"\\nComplexity Tuning:\")\nprint(\"  - Tree depth\")\nprint(\"  - Regularization strength\")\nprint(\"  - Number of features\")\nprint(\"  - Model architecture\")\n\nprint(\"\\nMethods:\")\nprint(\"  - Validation curves\")\nprint(\"  - Grid search\")\nprint(\"  - Random search\")\nprint(\"  - Cross-validation\")\n\nprint(\"\\n\u2705 Model complexity selection concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport validation_curve, GridSearchCV\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.linear_model \nimport Ridge_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSelecting Optimal Model Complexity\")\nprint(\"=\" * 60)\n\nprint(\"\\nValidation Sets:\")\nprint(\"  - Separate from training/test\")\nprint(\"  - Used for hyperparameter tuning\")\nprint(\"  - Prevents overfitting\")\n\nprint(\"\\nComplexity Tuning:\")\nprint(\"  - Tree depth\")\nprint(\"  - Regularization strength\")\nprint(\"  - Number of features\")\nprint(\"  - Model architecture\")\n\nprint(\"\\nMethods:\")\nprint(\"  - Validation curves\")\nprint(\"  - Grid search\")\nprint(\"  - Random search\")\nprint(\"  - Cross-validation\")\n\nprint(\"\\n\u2705 Model complexity selection concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/08_comparing_model_performance.ipynb",
      "status": "failed",
      "execution_time": 0.6647028923034668,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Model Performance Across Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nComparison Metrics:\")\nprint(\"  - Cross-validation scores\")\nprint(\"  - Training time\")\nprint(\"  - Prediction time\")\nprint(\"  - Model complexity\")\n\nprint(\"\\nVisualization:\")\nprint(\"  - Bar charts\")\nprint(\"  - Box plots\")\nprint(\"  - Performance tables\")\nprint(\"  - Statistical tests\")\n\nprint(\"\\n\u2705 Model comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Model Performance Across Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nComparison Metrics:\")\nprint(\"  - Cross-validation scores\")\nprint(\"  - Training time\")\nprint(\"  - Prediction time\")\nprint(\"  - Model complexity\")\n\nprint(\"\\nVisualization:\")\nprint(\"  - Bar charts\")\nprint(\"  - Box plots\")\nprint(\"  - Performance tables\")\nprint(\"  - Statistical tests\")\n\nprint(\"\\n\u2705 Model comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/08_decision_tree_random_forest_regression.ipynb",
      "status": "passed",
      "execution_time": 1.8625316619873047,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/09_comparing_regression_algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.6024351119995117,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Regression Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nAlgorithms to Compare:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Ridge Regression\")\nprint(\"  - Lasso Regression\")\nprint(\"  - Decision Tree\")\nprint(\"  - Random Forest\")\n\nprint(\"\\nEvaluation Metrics:\")\nprint(\"  - MSE (Mean Squared Error)\")\nprint(\"  - RMSE (Root Mean Squared Error)\")\nprint(\"  - MAE (Mean Absolute Error)\")\nprint(\"  - R\u00b2 (Coefficient of Determination)\")\n\nprint(\"\\n\u2705 Regression comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Regression Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nAlgorithms to Compare:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Ridge Regression\")\nprint(\"  - Lasso Regression\")\nprint(\"  - Decision Tree\")\nprint(\"  - Random Forest\")\n\nprint(\"\\nEvaluation Metrics:\")\nprint(\"  - MSE (Mean Squared Error)\")\nprint(\"  - RMSE (Root Mean Squared Error)\")\nprint(\"  - MAE (Mean Absolute Error)\")\nprint(\"  - R\u00b2 (Coefficient of Determination)\")\n\nprint(\"\\n\u2705 Regression comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/10_visualizing_regression_results_residuals.ipynb",
      "status": "failed",
      "execution_time": 0.6817600727081299,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.metrics \nimport mean_squared_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nVisualizing Regression Results and Residuals\")\nprint(\"=\" * 60)\n\nprint(\"\\nVisualizations:\")\nprint(\"  - Predicted vs Actual scatter plot\")\nprint(\"  - Residual plots\")\nprint(\"  - Residual distribution\")\nprint(\"  - Q-Q plots for normality\")\n\nprint(\"\\nResidual Analysis:\")\nprint(\"  - Check for patterns\")\nprint(\"  - Identify outliers\")\nprint(\"  - Verify assumptions\")\nprint(\"  - Diagnose model issues\")\n\nprint(\"\\n\u2705 Visualization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.metrics \nimport mean_squared_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nVisualizing Regression Results and Residuals\")\nprint(\"=\" * 60)\n\nprint(\"\\nVisualizations:\")\nprint(\"  - Predicted vs Actual scatter plot\")\nprint(\"  - Residual plots\")\nprint(\"  - Residual distribution\")\nprint(\"  - Q-Q plots for normality\")\n\nprint(\"\\nResidual Analysis:\")\nprint(\"  - Check for patterns\")\nprint(\"  - Identify outliers\")\nprint(\"  - Verify assumptions\")\nprint(\"  - Diagnose model issues\")\n\nprint(\"\\n\u2705 Visualization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/comparing_model_performance_across_different_algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.5322840213775635,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/computing_regression_evaluation_metrics_mse_rmse_mae_r\u00b2.ipynb",
      "status": "failed",
      "execution_time": 0.5607931613922119,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/identifying_and_handling_overfittingunderfitting.ipynb",
      "status": "failed",
      "execution_time": 0.7419929504394531,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/performing_leave_one_out_and_stratified_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.7987368106842041,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/selecting_optimal_model_complexity_using_validation_sets.ipynb",
      "status": "failed",
      "execution_time": 0.6590147018432617,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7998738288879395,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lassof\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lassof\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit2-regression/exercises/exercise_02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.7416188716888428,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 2: Cross-Validation Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\n\nInstructions:\n1. Load the provided dataset_2. Implement K-Fold cross-validation manually_3. Use sklearn's KFold for cross-validation_4. Compare single train-test split vs K-Fold CV_5. Calculate mean and std of CV scores_6. Understand why CV gives more reliable estimates\n\nDataset: Regression dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample regression data_np.random.seed(123)\nX = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\ndf['target'] = y_\nprint(\"Dataset loaded!\") / print(f\"Shape: {df.shape}\")\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Single train-test split (baseline) / print(\"\\n\" + \"=\"*60) / print(\"Task 1: Single train-test split\") / print(\"=\"*60)\n# Split data 80/20\n# Train Linear Regression\n# Evaluate on test set\n# Print MSE and R\u00b2\n# Your code here...\n\n# Task 2: Manual K-Fold cross-validation (K=5) / print(\"\\n\" + \"=\"*60) / print(\"Task 2: Manual K-Fold CV (K=5)\")\nprint(\"=\"*60)\n# Split data into 5 folds manually\n# For each fold:\n#   - Train on 4 folds, test on 1 fold\n#   - Calculate MSE and R\u00b2\n# Store all scores\n# Print mean and std of scores\n# Your code here...\n\n# Task 3: Use sklearn's KFold_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 3: sklearn KFold\") / print(\"=\"*60)\n# Use KFold(n_splits=5, shuffle=True, random_state=123)\n# Implement CV loop using KFold\n# Calculate mean and std of scores\n# Your code here...\n\n# Task 4: Use cross_val_score_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 4: cross_val_score\") / print(\"=\"*60)\n# Use sklearn's cross_val_score function\n# Much simpler than manual implementation!\n# Print mean and std\n# Your code here...\n\n# Task 5: Compare single split vs CV_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 5: Compare single split vs CV\") / print(\"=\"*60)\n# Show that CV gives more reliable estimate\n# Single split: One score (might be lucky/unlucky)\n# CV: Multiple scores, mean gives better estimate\n# Your code here...\n\n# Task 6: Visualize CV score distribution_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 6: Visualize CV scores\") / print(\"=\"*60)\n# Plot histogram of CV scores\n# Show mean and std\n# Your code here... print(\"\\n\" + \"=\"*60) / print(\"Exercise 2 Complete!\") / print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\") / print(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 2: Cross-Validation Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\n\nInstructions:\n1. Load the provided dataset_2. Implement K-Fold cross-validation manually_3. Use sklearn's KFold for cross-validation_4. Compare single train-test split vs K-Fold CV_5. Calculate mean and std of CV scores_6. Understand why CV gives more reliable estimates\n\nDataset: Regression dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample regression data_np.random.seed(123)\nX = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\ndf['target'] = y_\nprint(\"Dataset loaded!\") / print(f\"Shape: {df.shape}\")\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Single train-test split (baseline) / print(\"\\n\" + \"=\"*60) / print(\"Task 1: Single train-test split\") / print(\"=\"*60)\n# Split data 80/20\n# Train Linear Regression\n# Evaluate on test set\n# Print MSE and R\u00b2\n# Your code here...\n\n# Task 2: Manual K-Fold cross-validation (K=5) / print(\"\\n\" + \"=\"*60) / print(\"Task 2: Manual K-Fold CV (K=5)\")\nprint(\"=\"*60)\n# Split data into 5 folds manually\n# For each fold:\n#   - Train on 4 folds, test on 1 fold\n#   - Calculate MSE and R\u00b2\n# Store all scores\n# Print mean and std of scores\n# Your code here...\n\n# Task 3: Use sklearn's KFold_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 3: sklearn KFold\") / print(\"=\"*60)\n# Use KFold(n_splits=5, shuffle=True, random_state=123)\n# Implement CV loop using KFold\n# Calculate mean and std of scores\n# Your code here...\n\n# Task 4: Use cross_val_score_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 4: cross_val_score\") / print(\"=\"*60)\n# Use sklearn's cross_val_score function\n# Much simpler than manual implementation!\n# Print mean and std\n# Your code here...\n\n# Task 5: Compare single split vs CV_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 5: Compare single split vs CV\") / print(\"=\"*60)\n# Show that CV gives more reliable estimate\n# Single split: One score (might be lucky/unlucky)\n# CV: Multiple scores, mean gives better estimate\n# Your code here...\n\n# Task 6: Visualize CV score distribution_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 6: Visualize CV scores\") / print(\"=\"*60)\n# Plot histogram of CV scores\n# Show mean and std\n# Your code here... print(\"\\n\" + \"=\"*60) / print(\"Exercise 2 Complete!\") / print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\") / print(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300) / df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit2-regression/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6128830909729004,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "Course 04/unit2-regression/solutions/solution_02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.5869300365447998,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 2 - Exercise 2: Cross-Validation Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639Instructions:1. Load the provided dataset2. Implement K-Fold cross-validation manually3. Use sklearn's KFold for cross-validation4. Compare single train-test split vs K-Fold CV5. Calculate mean and std of CV scores6. Understand why CV gives more reliable estimatesDataset: Regression dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Generate sample regression datanp.random.seed(123)X = np.random.randn(300, 5)y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: sklearn KFold\")print(\"=\"*60)# Use KFold(n_splits=5, shuffle=True, random_state=123)# Implement CV loop using KFold# Calculate mean and std of scores# Your code here...# Task 4: Use cross_val_score\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: cross_val_score\")print(\"=\"*60)# Use sklearn's cross_val_score function# Much simpler than manual implementation!# Print mean and std# Your code here...# Task 5: Compare single split vs CV\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare single split vs CV\")print(\"=\"*60)# Show that CV gives more reliable estimate# Single split: One score (might be lucky/unlucky)# CV: Multiple scores, mean gives better estimate# Your code here...# Task 6: Visualize CV score distribution\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize CV scores\")print(\"=\"*60)# Plot histogram of CV scores# Show mean and std# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 2 - Exercise 2: Cross-Validation Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639Instructions:1. Load the provided dataset2. Implement K-Fold cross-validation manually3. Use sklearn's KFold for cross-validation4. Compare single train-test split vs K-Fold CV5. Calculate mean and std of CV scores6. Understand why CV gives more reliable estimatesDataset: Regression dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Generate sample regression datanp.random.seed(123)X = np.random.randn(300, 5)y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: sklearn KFold\")print(\"=\"*60)# Use KFold(n_splits=5, shuffle=True, random_state=123)# Implement CV loop using KFold# Calculate mean and std of scores# Your code here...# Task 4: Use cross_val_score\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: cross_val_score\")print(\"=\"*60)# Use sklearn's cross_val_score function# Much simpler than manual implementation!# Print mean and std# Your code here...# Task 5: Compare single split vs CV\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare single split vs CV\")print(\"=\"*60)# Show that CV gives more reliable estimate# Single split: One score (might be lucky/unlucky)# CV: Multiple scores, mean gives better estimate# Your code here...# Task 6: Visualize CV score distribution\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize CV scores\")print(\"=\"*60)# Plot histogram of CV scores# Show mean and std# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/examples/01_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 1.697500228881836,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build and evaluate classification models\n# ALL imports are here at the beginning - this is best practice!\n\n# Data manipulation and numerical operations\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\n\n# Visualization libraries\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\n\n# Standard library utilities\nfrom io import StringIO # For capturing print output (used in classification report) / import sys # For system operations (used in classification report)\n\n# Scikit-learn: Data loading\nfrom sklearn.datasets import make_circles # Generate non-linear data for dead end example\n\n# Scikit-learn: Data preprocessing\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.preprocessing import StandardScaler # For scaling features\n\n# Scikit-learn: Models\nfrom sklearn.linear_model import LogisticRegression # The classification model!\n\n# Scikit-learn: Metrics\nfrom sklearn.metrics import (\n accuracy_score, # Accuracy: % of correct predictions\n precision_score, # Precision: Of predicted positives, how many are actually positive?\n recall_score, # Recall: Of actual positives, how many did we catch?\n f1_score, # F1: Harmonic mean of precision and recall\n confusion_matrix, # Shows true/false positives/negatives\n classification_report, # Comprehensive classification metrics\n roc_curve, # ROC curve (True Positive Rate vs False Positive Rate) / roc_auc_score # AUC: Area under ROC curve (0-1, higher is better)\n)\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each classification metric does:\") / print(\" - Accuracy: Overall correctness\") / print(\" - Precision: How reliable are positive predictions?\") / print(\" - Recall: How many positives did we catch?\") / print(\" - F1: Balance between precision and recall\") / print(\" - ROC/AUC: How well model separates classes\")\n\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each classification metric does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Scikit-learn: Metrics\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m  accuracy_score, \u001b[38;5;66;03m# Accuracy: % of correct predictions\u001b[39;00m\n\u001b[1;32m     29\u001b[0m  precision_score, \u001b[38;5;66;03m# Precision: Of predicted positives, how many are actually positive?\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m  roc_curve, \u001b[38;5;66;03m# ROC curve (True Positive Rate vs False Positive Rate) / roc_auc_score # AUC: Area under ROC curve (0-1, higher is better)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each classification metric does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Accuracy: Overall correctness\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Precision: How reliable are positive predictions?\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Recall: How many positives did we catch?\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - F1: Balance between precision and recall\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - ROC/AUC: How well model separates classes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build and evaluate classification models\n# ALL imports are here at the beginning - this is best practice!\n\n# Data manipulation and numerical operations\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\n\n# Visualization libraries\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\n\n# Standard library utilities\nfrom io import StringIO # For capturing print output (used in classification report) / import sys # For system operations (used in classification report)\n\n# Scikit-learn: Data loading\nfrom sklearn.datasets import make_circles # Generate non-linear data for dead end example\n\n# Scikit-learn: Data preprocessing\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.preprocessing import StandardScaler # For scaling features\n\n# Scikit-learn: Models\nfrom sklearn.linear_model import LogisticRegression # The classification model!\n\n# Scikit-learn: Metrics\nfrom sklearn.metrics import (\n accuracy_score, # Accuracy: % of correct predictions\n precision_score, # Precision: Of predicted positives, how many are actually positive?\n recall_score, # Recall: Of actual positives, how many did we catch?\n f1_score, # F1: Harmonic mean of precision and recall\n confusion_matrix, # Shows true/false positives/negatives\n classification_report, # Comprehensive classification metrics\n roc_curve, # ROC curve (True Positive Rate vs False Positive Rate) / roc_auc_score # AUC: Area under ROC curve (0-1, higher is better)\n)\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each classification metric does:\") / print(\" - Accuracy: Overall correctness\") / print(\" - Precision: How reliable are positive predictions?\") / print(\" - Recall: How many positives did we catch?\") / print(\" - F1: Balance between precision and recall\") / print(\" - ROC/AUC: How well model separates classes\")\n\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda What each classification metric does:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Scikit-learn: Metrics\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m  accuracy_score, \u001b[38;5;66;03m# Accuracy: % of correct predictions\u001b[39;00m\n\u001b[1;32m     29\u001b[0m  precision_score, \u001b[38;5;66;03m# Precision: Of predicted positives, how many are actually positive?\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m  roc_curve, \u001b[38;5;66;03m# ROC curve (True Positive Rate vs False Positive Rate) / roc_auc_score # AUC: Area under ROC curve (0-1, higher is better)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda What each classification metric does:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Accuracy: Overall correctness\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Precision: How reliable are positive predictions?\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Recall: How many positives did we catch?\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - F1: Balance between precision and recall\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - ROC/AUC: How well model separates classes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/02_decision_trees.ipynb",
      "status": "failed",
      "execution_time": 0.7425239086151123,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build tree-based classification models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.tree import DecisionTreeClassifier # Single decision tree\nfrom sklearn.ensemble import RandomForestClassifier # Ensemble of trees (Random Forest) / from sklearn.preprocessing import StandardScaler # For scaling (trees don't need it, but shown for consistency) / from sklearn.metrics import (\n accuracy_score, # Classification accuracy\n classification_report, # Comprehensive metrics\n confusion_matrix, # Confusion matrix\n roc_auc_score, # AUC scoreroc_curve # ROC curve\n)\n# Removed label_binarize - not needed for binary classification\n# Removed make_classification - using real Wine dataset instead\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each model does:\") / print(\" - DecisionTreeClassifier: Single tree (interpretable, can overfit)\")\nprint(\" - RandomForestClassifier: Many trees combined (less overfitting, better performance)\")\nprint(\" - Note: Trees don't require feature scaling (unlike logistic regression)!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    accuracy_score, # Classification accuracy\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build tree-based classification models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.tree import DecisionTreeClassifier # Single decision tree\nfrom sklearn.ensemble import RandomForestClassifier # Ensemble of trees (Random Forest) / from sklearn.preprocessing import StandardScaler # For scaling (trees don't need it, but shown for consistency) / from sklearn.metrics import (\n accuracy_score, # Classification accuracy\n classification_report, # Comprehensive metrics\n confusion_matrix, # Confusion matrix\n roc_auc_score, # AUC scoreroc_curve # ROC curve\n)\n# Removed label_binarize - not needed for binary classification\n# Removed make_classification - using real Wine dataset instead\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each model does:\") / print(\" - DecisionTreeClassifier: Single tree (interpretable, can overfit)\")\nprint(\" - RandomForestClassifier: Many trees combined (less overfitting, better performance)\")\nprint(\" - Note: Trees don't require feature scaling (unlike logistic regression)!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    accuracy_score, # Classification accuracy\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/03_svm.ipynb",
      "status": "failed",
      "execution_time": 0.5327539443969727,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build SVM classification models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.svm import SVC # Support Vector Classifier (SVM) / from sklearn.preprocessing import StandardScaler # CRITICAL for SVM! Must scale features\nfrom sklearn.decomposition import PCA # For dimensionality reduction (2D visualization) / from sklearn.metrics import (\n accuracy_score, # Classification accuracy\n classification_report, # Comprehensive metrics\n confusion_matrix, # Confusion matrix\n roc_auc_score, # AUC scoreroc_curve # ROC curve\n) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key SVM Concepts:\") / print(\" - SVC: Support Vector Classifier (SVM for classification)\")\nprint(\" - Kernels: Transform data to handle non-linear patterns\") / print(\" - Support Vectors: Critical data points that define the boundary\") / print(\" - C parameter: Controls regularization (higher = less regularization)\")\nprint(\" - Gamma parameter: Controls kernel influence (higher = more complex boundaries)\")\nprint(\"\\n \u26a0\ufe0f IMPORTANT: SVM requires feature scaling! Always use StandardScaler!\") / print(\" \ud83d\udcca Note: We'll use PCA to reduce 30D data to 2D for visualization only!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    accuracy_score, # Classification accuracy\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build SVM classification models\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.svm import SVC # Support Vector Classifier (SVM) / from sklearn.preprocessing import StandardScaler # CRITICAL for SVM! Must scale features\nfrom sklearn.decomposition import PCA # For dimensionality reduction (2D visualization) / from sklearn.metrics import (\n accuracy_score, # Classification accuracy\n classification_report, # Comprehensive metrics\n confusion_matrix, # Confusion matrix\n roc_auc_score, # AUC scoreroc_curve # ROC curve\n) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key SVM Concepts:\") / print(\" - SVC: Support Vector Classifier (SVM for classification)\")\nprint(\" - Kernels: Transform data to handle non-linear patterns\") / print(\" - Support Vectors: Critical data points that define the boundary\") / print(\" - C parameter: Controls regularization (higher = less regularization)\")\nprint(\" - Gamma parameter: Controls kernel influence (higher = more complex boundaries)\")\nprint(\"\\n \u26a0\ufe0f IMPORTANT: SVM requires feature scaling! Always use StandardScaler!\") / print(\" \ud83d\udcca Note: We'll use PCA to reduce 30D data to 2D for visualization only!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    accuracy_score, # Classification accuracy\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/04_knn.ipynb",
      "status": "failed",
      "execution_time": 0.5359432697296143,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build KNN classification models import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.neighbors import KNeighborsClassifier # KNN classifier\nfrom sklearn.preprocessing import StandardScaler # CRITICAL for KNN! Must scale features\nfrom sklearn.metrics import (\n accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve\n) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key KNN Concepts:\") / print(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\nprint(\" - K parameter: Number of neighbors to consider (critical hyperparameter)\")\nprint(\" - Distance metrics: Euclidean (default), Manhattan, etc.\")\nprint(\" - Lazy learning: No training phase, just prediction\") / print(\"\\n \u26a0\ufe0f IMPORTANT: KNN requires feature scaling! Always use StandardScaler!\") / print(\" \ud83d\udca1 Why? Distance calculations are affected by feature scales!\") / print(\"\\n \ud83c\udfaf GDI Theme: Financial Investigations & Administrative Crimes Detection\") / print(\" \ud83d\udca1 We'll use credit card fraud data to detect fraudulent transactions!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    ) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key KNN Concepts:\") / print(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build KNN classification models import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.neighbors import KNeighborsClassifier # KNN classifier\nfrom sklearn.preprocessing import StandardScaler # CRITICAL for KNN! Must scale features\nfrom sklearn.metrics import (\n accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve\n) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key KNN Concepts:\") / print(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\nprint(\" - K parameter: Number of neighbors to consider (critical hyperparameter)\")\nprint(\" - Distance metrics: Euclidean (default), Manhattan, etc.\")\nprint(\" - Lazy learning: No training phase, just prediction\") / print(\"\\n \u26a0\ufe0f IMPORTANT: KNN requires feature scaling! Always use StandardScaler!\") / print(\" \ud83d\udca1 Why? Distance calculations are affected by feature scales!\") / print(\"\\n \ud83c\udfaf GDI Theme: Financial Investigations & Administrative Crimes Detection\") / print(\" \ud83d\udca1 We'll use credit card fraud data to detect fraudulent transactions!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    ) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key KNN Concepts:\") / print(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/05_random_forest_naive_bayes.ipynb",
      "status": "failed",
      "execution_time": 1.7389981746673584,
      "error": "An error occurred while executing the following cell:\n------------------\n# Generate classification dataset\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n                          n_redundant=5, n_classes=2, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42) / rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test) / rf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\nrf_pred_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"=\" * 60) / print(\"Random Forest Classifier:\") / print(\"=\" * 60) / print(f\"Accuracy: {rf.score(X_test, y_test):.4f}\")\nprint(\"\\nConfusion Matrix:\") / print(confusion_matrix(y_test, rf_pred))\nprint(\"\\nClassification Report:\") / print(classification_report(y_test, rf_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42) / rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test) / rf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m rf_pred_proba \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Classifier:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf\u001b[38;5;241m.\u001b[39mscore(X_test,\u001b[38;5;250m \u001b[39my_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test, rf_pred))\n\n\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Generate classification dataset\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n                          n_redundant=5, n_classes=2, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42) / rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test) / rf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\nrf_pred_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"=\" * 60) / print(\"Random Forest Classifier:\") / print(\"=\" * 60) / print(f\"Accuracy: {rf.score(X_test, y_test):.4f}\")\nprint(\"\\nConfusion Matrix:\") / print(confusion_matrix(y_test, rf_pred))\nprint(\"\\nClassification Report:\") / print(classification_report(y_test, rf_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42) / rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test) / rf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m rf_pred_proba \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Classifier:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf\u001b[38;5;241m.\u001b[39mscore(X_test,\u001b[38;5;250m \u001b[39my_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test, rf_pred))\n\n\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/06_ensemble_methods_bagging_boosting.ipynb",
      "status": "failed",
      "execution_time": 0.7435839176177979,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.datasets \nimport make_classification\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.tree \nimport DecisionTreeClassifier\nfrom sklearn.ensemble \nimport BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics \nimport accuracy_score, classification_report_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.datasets \nimport make_classification\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.tree \nimport DecisionTreeClassifier\nfrom sklearn.ensemble \nimport BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics \nimport accuracy_score, classification_report_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/07_svm_kernels_comparison.ipynb",
      "status": "passed",
      "execution_time": 1.6644468307495117,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/08_classification_evaluation_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.6354823112487793,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/evaluating_classification_models_using_confusion_matrices_roc_curves_and_analyzi.ipynb",
      "status": "failed",
      "execution_time": 0.6159820556640625,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/using_svm_with_different_kernels_linear_polynomial_rbf_to_handle_complex_classif.ipynb",
      "status": "failed",
      "execution_time": 0.5880911350250244,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7341246604919434,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, classification_report,\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, classification_report,\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_02_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 1.8220808506011963,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 2: Logistic Regression Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\nInstructions:\n1. Load the provided dataset_2. Train a Logistic Regression classifier_3. Calculate and display all classification metrics (accuracy, precision, recall, F1)\n4. Create and visualize a confusion matrix_5. Create and visualize an ROC curve_6. Experiment with different thresholds_7. Handle class imbalance using class weights\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_curve, roc_auc_score, classification_report\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=1000, n_features=10,\n    n_informative=6,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20, use stratify)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Scale the features (important for logistic regression!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Scale features\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 3: Train a Logistic Regression model (default parameters)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train Logistic Regression model\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 4: Make predictions and calculate metrics_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Calculate classification metrics\")\nprint(\"=\"*60)\n# Calculate: accuracy, precision, recall, F1-score\n# Your code here...\n\n# Task 5: Create and visualize confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create confusion matrix and visualize it with seaborn heatmap\n# Your code here...\n\n# Task 6: Get prediction probabilities and create ROC curve_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: ROC Curve\")\nprint(\"=\"*60)\n# Get probabilities using .predict_proba()\n# Calculate ROC curve (fpr, tpr, thresholds)\n# Calculate AUC score\n# Plot ROC curve with AUC value\n# Your code here...\n\n# Task 7: Train model with class weights to handle imbalance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Handle class imbalance with class weights\")\nprint(\"=\"*60)\n# Train new model with class_weight='balanced'\n# Compare metrics with previous model\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     27\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     28\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 35\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 2: Logistic Regression Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\nInstructions:\n1. Load the provided dataset_2. Train a Logistic Regression classifier_3. Calculate and display all classification metrics (accuracy, precision, recall, F1)\n4. Create and visualize a confusion matrix_5. Create and visualize an ROC curve_6. Experiment with different thresholds_7. Handle class imbalance using class weights\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_curve, roc_auc_score, classification_report\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=1000, n_features=10,\n    n_informative=6,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20, use stratify)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Scale the features (important for logistic regression!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Scale features\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 3: Train a Logistic Regression model (default parameters)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train Logistic Regression model\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 4: Make predictions and calculate metrics_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Calculate classification metrics\")\nprint(\"=\"*60)\n# Calculate: accuracy, precision, recall, F1-score\n# Your code here...\n\n# Task 5: Create and visualize confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create confusion matrix and visualize it with seaborn heatmap\n# Your code here...\n\n# Task 6: Get prediction probabilities and create ROC curve_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: ROC Curve\")\nprint(\"=\"*60)\n# Get probabilities using .predict_proba()\n# Calculate ROC curve (fpr, tpr, thresholds)\n# Calculate AUC score\n# Plot ROC curve with AUC value\n# Your code here...\n\n# Task 7: Train model with class weights to handle imbalance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Handle class imbalance with class weights\")\nprint(\"=\"*60)\n# Train new model with class_weight='balanced'\n# Compare metrics with previous model\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     27\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     28\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 35\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_03_svm.ipynb",
      "status": "failed",
      "execution_time": 1.726837158203125,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 3: Support Vector Machine (SVM) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)\n\nInstructions:\n1. Load the provided dataset_2. Train SVM models with different kernels (Linear, RBF, Polynomial)\n3. Compare their performance_4. Tune hyperparameters (C and gamma for RBF)\n5. Visualize decision boundaries (if 2D) or compare metrics_6. Find the best kernel and hyperparameters\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score\n)\n\n# Generate sample classification data_np.random.seed(123)\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=500, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data and scale features (CRITICAL for SVM!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split and scale data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Linear SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Linear SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='linear', C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Train RBF SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train RBF SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='rbf', C=1.0, gamma='scale'\n# Evaluate and print metrics\n# Your code here...\n\n# Task 4: Train Polynomial SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train Polynomial SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='poly', degree=3, C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 5: Compare all three kernels_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare kernels\")\nprint(\"=\"*60)\n# Create a comparison table or visualization\n# Show which kernel performs best\n# Your code here...\n\n# Task 6: Tune C parameter for RBF kernel_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Tune C parameter for RBF\")\nprint(\"=\"*60)\n# Try different C values: [0.1, 1.0, 10.0, 100.0]\n# Find the best C value\n# Your code here...\n\n# Task 7: (Optional) Tune gamma parameter for RBF_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: (Optional) Tune gamma parameter\")\nprint(\"=\"*60)\n# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]\n# Find the best gamma value\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     28\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 3: Support Vector Machine (SVM) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)\n\nInstructions:\n1. Load the provided dataset_2. Train SVM models with different kernels (Linear, RBF, Polynomial)\n3. Compare their performance_4. Tune hyperparameters (C and gamma for RBF)\n5. Visualize decision boundaries (if 2D) or compare metrics_6. Find the best kernel and hyperparameters\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score\n)\n\n# Generate sample classification data_np.random.seed(123)\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=500, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data and scale features (CRITICAL for SVM!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split and scale data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Linear SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Linear SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='linear', C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Train RBF SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train RBF SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='rbf', C=1.0, gamma='scale'\n# Evaluate and print metrics\n# Your code here...\n\n# Task 4: Train Polynomial SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train Polynomial SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='poly', degree=3, C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 5: Compare all three kernels_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare kernels\")\nprint(\"=\"*60)\n# Create a comparison table or visualization\n# Show which kernel performs best\n# Your code here...\n\n# Task 6: Tune C parameter for RBF kernel_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Tune C parameter for RBF\")\nprint(\"=\"*60)\n# Try different C values: [0.1, 1.0, 10.0, 100.0]\n# Find the best C value\n# Your code here...\n\n# Task 7: (Optional) Tune gamma parameter for RBF_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: (Optional) Tune gamma parameter\")\nprint(\"=\"*60)\n# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]\n# Find the best gamma value\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     28\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_04_knn.ipynb",
      "status": "failed",
      "execution_time": 1.823289155960083,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)\n\nInstructions:\n1. Load the provided dataset_2. Scale the features (CRITICAL for KNN!)\n3. Train KNN models with different K values_4. Find the optimal K value using validation_5. Evaluate the final model with optimal K_6. Compare KNN with and without feature scaling (demonstrate importance)\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=800, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Demonstrate why scaling is critical_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Compare KNN with and without scaling\")\nprint(\"=\"*60)\n# Train KNN WITHOUT scaling (use original data)\n# Train KNN WITH scaling (use StandardScaler)\n# Compare accuracies - show the difference!\n# Your code here...\n\n# Task 3: Find optimal K value_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Find optimal K value\")\nprint(\"=\"*60)\n# Test K values from 1 to 30 (odd numbers only)\n# Plot K vs Accuracy (both train and test)\n# Find the K with best test accuracy\n# Your code here...\n\n# Task 4: Train final KNN model with optimal K_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train final model with optimal K\")\nprint(\"=\"*60)\n# Train KNN with the best K value found\n# Evaluate with all metrics (accuracy, precision, recall, F1)\n# Your code here...\n\n# Task 5: Create confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create and visualize confusion matrix\n# Your code here...\n\n# Task 6: (Optional) Compare KNN with other classifiers_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: (Optional) Compare with other classifiers\")\nprint(\"=\"*60)\n# Compare KNN with Logistic Regression or Decision Tree\n# Show which performs better on this dataset\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 4 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     26\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     27\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)\n\nInstructions:\n1. Load the provided dataset_2. Scale the features (CRITICAL for KNN!)\n3. Train KNN models with different K values_4. Find the optimal K value using validation_5. Evaluate the final model with optimal K_6. Compare KNN with and without feature scaling (demonstrate importance)\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=800, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Demonstrate why scaling is critical_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Compare KNN with and without scaling\")\nprint(\"=\"*60)\n# Train KNN WITHOUT scaling (use original data)\n# Train KNN WITH scaling (use StandardScaler)\n# Compare accuracies - show the difference!\n# Your code here...\n\n# Task 3: Find optimal K value_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Find optimal K value\")\nprint(\"=\"*60)\n# Test K values from 1 to 30 (odd numbers only)\n# Plot K vs Accuracy (both train and test)\n# Find the K with best test accuracy\n# Your code here...\n\n# Task 4: Train final KNN model with optimal K_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train final model with optimal K\")\nprint(\"=\"*60)\n# Train KNN with the best K value found\n# Evaluate with all metrics (accuracy, precision, recall, F1)\n# Your code here...\n\n# Task 5: Create confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create and visualize confusion matrix\n# Your code here...\n\n# Task 6: (Optional) Compare KNN with other classifiers_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: (Optional) Compare with other classifiers\")\nprint(\"=\"*60)\n# Compare KNN with Logistic Regression or Decision Tree\n# Show which performs better on this dataset\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 4 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     26\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     27\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5273988246917725,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom from sklearn.tree import train_test_split\nfrom from sklearn.ensemble import DecisionTreeClassifier\nfrom from sklearn.metrics import RandomForestClassifier_from(accuracy_score, classification_report,from sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom from sklearn.tree import train_test_split\nfrom from sklearn.ensemble import DecisionTreeClassifier\nfrom from sklearn.metrics import RandomForestClassifier_from(accuracy_score, classification_report,from sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_02_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5674178600311279,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 2: Logistic Regression Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064aInstructions:1. Load the provided dataset2. Train a Logistic Regression classifier3. Calculate and display all classification metrics (accuracy, precision, recall, F1)4. Create and visualize a confusion matrix5. Create and visualize an ROC curve6. Experiment with different thresholds7. Handle class imbalance using class weightsDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=1000,    n_features=10,    n_informative=6,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Calculate classification metrics\")print(\"=\"*60)# Calculate: accuracy, precision, recall, F1-score# Your code here...# Task 5: Create and visualize confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create confusion matrix and visualize it with seaborn heatmap# Your code here...# Task 6: Get prediction probabilities and create ROC curve\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: ROC Curve\")print(\"=\"*60)# Get probabilities using .predict_proba()# Calculate ROC curve (fpr, tpr, thresholds)# Calculate AUC score# Plot ROC curve with AUC value# Your code here...# Task 7: Train model with class weights to handle imbalance\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Handle class imbalance with class weights\")print(\"=\"*60)# Train new model with class_weight='balanced'# Compare metrics with previous model# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 2: Logistic Regression Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064aInstructions:1. Load the provided dataset2. Train a Logistic Regression classifier3. Calculate and display all classification metrics (accuracy, precision, recall, F1)4. Create and visualize a confusion matrix5. Create and visualize an ROC curve6. Experiment with different thresholds7. Handle class imbalance using class weightsDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=1000,    n_features=10,    n_informative=6,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Calculate classification metrics\")print(\"=\"*60)# Calculate: accuracy, precision, recall, F1-score# Your code here...# Task 5: Create and visualize confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create confusion matrix and visualize it with seaborn heatmap# Your code here...# Task 6: Get prediction probabilities and create ROC curve\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: ROC Curve\")print(\"=\"*60)# Get probabilities using .predict_proba()# Calculate ROC curve (fpr, tpr, thresholds)# Calculate AUC score# Plot ROC curve with AUC value# Your code here...# Task 7: Train model with class weights to handle imbalance\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Handle class imbalance with class weights\")print(\"=\"*60)# Train new model with class_weight='balanced'# Compare metrics with previous model# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_03_svm.ipynb",
      "status": "failed",
      "execution_time": 0.7364871501922607,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 3: Support Vector Machine (SVM) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)Instructions:1. Load the provided dataset2. Train SVM models with different kernels (Linear, RBF, Polynomial)3. Compare their performance4. Tune hyperparameters (C and gamma for RBF)5. Visualize decision boundaries (if 2D) / or compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score)\n# Generate sample classification datanp.random.seed(123)from sklearn.datasets import make_classificationX, y = make_classification(    n_samples=500,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Train Linear SVM\")print(\"=\"*60)# Train SVM with kernel='linear', C=1.0# Evaluate and print metrics# Your code here...# Task 3: Train RBF SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train RBF SVM\")print(\"=\"*60)# Train SVM with kernel='rbf', C=1.0, gamma='scale'# Evaluate and print metrics# Your code here...# Task 4: Train Polynomial SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train Polynomial SVM\")print(\"=\"*60)# Train SVM with kernel='poly', degree=3, C=1.0# Evaluate and print metrics# Your code here...# Task 5: Compare all three kernels\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare kernels\")print(\"=\"*60)# Create a comparison table or visualization# Show which kernel performs best# Your code here...# Task 6: Tune C parameter for RBF kernel\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Tune C parameter for RBF\")print(\"=\"*60)# Try different C values: [0.1, 1.0, 10.0, 100.0]# Find the best C value# Your code here...# Task 7: (Optional) Tune gamma parameter for RBF\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: (Optional) Tune gamma parameter\")print(\"=\"*60)# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]# Find the best gamma value# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 3: Support Vector Machine (SVM) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)Instructions:1. Load the provided dataset2. Train SVM models with different kernels (Linear, RBF, Polynomial)3. Compare their performance4. Tune hyperparameters (C and gamma for RBF)5. Visualize decision boundaries (if 2D) / or compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score)\n# Generate sample classification datanp.random.seed(123)from sklearn.datasets import make_classificationX, y = make_classification(    n_samples=500,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Train Linear SVM\")print(\"=\"*60)# Train SVM with kernel='linear', C=1.0# Evaluate and print metrics# Your code here...# Task 3: Train RBF SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train RBF SVM\")print(\"=\"*60)# Train SVM with kernel='rbf', C=1.0, gamma='scale'# Evaluate and print metrics# Your code here...# Task 4: Train Polynomial SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train Polynomial SVM\")print(\"=\"*60)# Train SVM with kernel='poly', degree=3, C=1.0# Evaluate and print metrics# Your code here...# Task 5: Compare all three kernels\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare kernels\")print(\"=\"*60)# Create a comparison table or visualization# Show which kernel performs best# Your code here...# Task 6: Tune C parameter for RBF kernel\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Tune C parameter for RBF\")print(\"=\"*60)# Try different C values: [0.1, 1.0, 10.0, 100.0]# Find the best C value# Your code here...# Task 7: (Optional) Tune gamma parameter for RBF\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: (Optional) Tune gamma parameter\")print(\"=\"*60)# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]# Find the best gamma value# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_04_knn.ipynb",
      "status": "failed",
      "execution_time": 0.5753428936004639,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)Instructions:1. Load the provided dataset2. Scale the features (CRITICAL for KNN!)3. Train KNN models with different K values4. Find the optimal K value using validation5. Evaluate the final model with optimal K6. Compare KNN with and without feature scaling (demonstrate importance)Dataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=800,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Demonstrate why scaling is critical\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Compare KNN with and without scaling\")print(\"=\"*60)# Train KNN WITHOUT scaling (use original data)# Train KNN WITH scaling (use StandardScaler)# Compare accuracies - show the difference!# Your code here...# Task 3: Find optimal K value\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Find optimal K value\")print(\"=\"*60)# Test K values from 1 to 30 (odd numbers only)# Plot K vs Accuracy (both train and test)# Find the K with best test accuracy# Your code here...# Task 4: Train final KNN model with optimal K\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train final model with optimal K\")print(\"=\"*60)# Train KNN with the best K value found# Evaluate with all metrics (accuracy, precision, recall, F1)# Your code here...# Task 5: Create confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create and visualize confusion matrix# Your code here...# Task 6: (Optional) Compare KNN with other classifiers\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: (Optional) Compare with other classifiers\")print(\"=\"*60)# Compare KNN with Logistic Regression or Decision Tree# Show which performs better on this dataset# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 4 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)Instructions:1. Load the provided dataset2. Scale the features (CRITICAL for KNN!)3. Train KNN models with different K values4. Find the optimal K value using validation5. Evaluate the final model with optimal K6. Compare KNN with and without feature scaling (demonstrate importance)Dataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=800,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Demonstrate why scaling is critical\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Compare KNN with and without scaling\")print(\"=\"*60)# Train KNN WITHOUT scaling (use original data)# Train KNN WITH scaling (use StandardScaler)# Compare accuracies - show the difference!# Your code here...# Task 3: Find optimal K value\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Find optimal K value\")print(\"=\"*60)# Test K values from 1 to 30 (odd numbers only)# Plot K vs Accuracy (both train and test)# Find the K with best test accuracy# Your code here...# Task 4: Train final KNN model with optimal K\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train final model with optimal K\")print(\"=\"*60)# Train KNN with the best K value found# Evaluate with all metrics (accuracy, precision, recall, F1)# Your code here...# Task 5: Create confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create and visualize confusion matrix# Your code here...# Task 6: (Optional) Compare KNN with other classifiers\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: (Optional) Compare with other classifiers\")print(\"=\"*60)# Compare KNN with Logistic Regression or Decision Tree# Show which performs better on this dataset# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 4 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit4-clustering/examples/01_kmeans_clustering.ipynb",
      "status": "failed",
      "execution_time": 1.9369170665740967,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us perform K-Means clustering\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.cluster import KMeans # K-Means clustering algorithm\nfrom sklearn.preprocessing import StandardScaler # For scaling features (important for clustering!) / from sklearn.metrics import silhouette_score # For evaluating cluster quality\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key Clustering Concepts:\") / print(\" - KMeans: Groups data into K clusters based on similarity\") / print(\" - Centroids: Center points of each cluster\") / print(\" - Inertia: Sum of squared distances to centroids (lower is better)\")\nprint(\" - Silhouette Score: Measures how well-separated clusters are (higher is better)\")\nprint(\" - Elbow Method: Visual method to find optimal K\") / print(\"\\n \u26a0\ufe0f IMPORTANT: Clustering requires feature scaling! Always use StandardScaler!\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda Key Clustering Concepts:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans \u001b[38;5;66;03m# K-Means clustering algorithm\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler \u001b[38;5;66;03m# For scaling features (important for clustering!) / from sklearn.metrics import silhouette_score # For evaluating cluster quality\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda Key Clustering Concepts:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - KMeans: Groups data into K clusters based on similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Centroids: Center points of each cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Inertia: Sum of squared distances to centroids (lower is better)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Silhouette Score: Measures how well-separated clusters are (higher is better)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Elbow Method: Visual method to find optimal K\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u26a0\ufe0f IMPORTANT: Clustering requires feature scaling! Always use StandardScaler!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us perform K-Means clustering\n\nimport pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.cluster import KMeans # K-Means clustering algorithm\nfrom sklearn.preprocessing import StandardScaler # For scaling features (important for clustering!) / from sklearn.metrics import silhouette_score # For evaluating cluster quality\n\nprint(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda Key Clustering Concepts:\") / print(\" - KMeans: Groups data into K clusters based on similarity\") / print(\" - Centroids: Center points of each cluster\") / print(\" - Inertia: Sum of squared distances to centroids (lower is better)\")\nprint(\" - Silhouette Score: Measures how well-separated clusters are (higher is better)\")\nprint(\" - Elbow Method: Visual method to find optimal K\") / print(\"\\n \u26a0\ufe0f IMPORTANT: Clustering requires feature scaling! Always use StandardScaler!\")\n------------------\n\n----- stdout -----\n\u2705 Libraries imported successfully!\n\n\ud83d\udcda Key Clustering Concepts:\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans \u001b[38;5;66;03m# K-Means clustering algorithm\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler \u001b[38;5;66;03m# For scaling features (important for clustering!) / from sklearn.metrics import silhouette_score # For evaluating cluster quality\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 Libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcda Key Clustering Concepts:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - KMeans: Groups data into K clusters based on similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Centroids: Center points of each cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Inertia: Sum of squared distances to centroids (lower is better)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Silhouette Score: Measures how well-separated clusters are (higher is better)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Elbow Method: Visual method to find optimal K\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u26a0\ufe0f IMPORTANT: Clustering requires feature scaling! Always use StandardScaler!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/02_hierarchical_clustering.ipynb",
      "status": "passed",
      "execution_time": 3.390188694000244,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/03_pca.ipynb",
      "status": "passed",
      "execution_time": 3.1490890979766846,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/04_lda_tsne_umap.ipynb",
      "status": "failed",
      "execution_time": 0.5277290344238281,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets \nimport make_classification, load_iris\nfrom sklearn.discriminant_analysis \nimport LinearDiscriminantAnalysis\nfrom sklearn.decomposition \nimport PCA\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom sklearn.metrics \nimport accuracy_score\n\n# Try importing t-SNE and UMAP\ntry:\n    from sklearn.manifold \nimport TSNE_HAS_TSNE = True\nexcept ImportError:\n    HAS_TSNE = False_\nprint(\"\u26a0\ufe0f  t-SNE not available (install scikit-learn)\")\n\ntry:\n    import umap_HAS_UMAP = True\nexcept ImportError:\n    HAS_UMAP = False_\nprint(\"\u26a0\ufe0f  UMAP not available (install with: pip install umap-learn)\")\n\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets \nimport make_classification, load_iris\nfrom sklearn.discriminant_analysis \nimport LinearDiscriminantAnalysis\nfrom sklearn.decomposition \nimport PCA\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom sklearn.metrics \nimport accuracy_score\n\n# Try importing t-SNE and UMAP\ntry:\n    from sklearn.manifold \nimport TSNE_HAS_TSNE = True\nexcept ImportError:\n    HAS_TSNE = False_\nprint(\"\u26a0\ufe0f  t-SNE not available (install scikit-learn)\")\n\ntry:\n    import umap_HAS_UMAP = True\nexcept ImportError:\n    HAS_UMAP = False_\nprint(\"\u26a0\ufe0f  UMAP not available (install with: pip install umap-learn)\")\n\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/05_elbow_method_silhouette_score.ipynb",
      "status": "failed",
      "execution_time": 0.6607329845428467,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.metrics \nimport silhouette_score\nfrom sklearn.datasets \nimport make_blobs_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nElbow Method and Silhouette Score\")\nprint(\"=\" * 60)\n\nprint(\"\\nElbow Method:\")\nprint(\"  - Plot within-cluster sum of squares (WCSS)\")\nprint(\"  - Look for 'elbow' in the curve\")\nprint(\"  - Indicates optimal k\")\n\nprint(\"\\nSilhouette Score:\")\nprint(\"  - Measures cluster quality\")\nprint(\"  - Range: -1 to 1\")\nprint(\"  - Higher is better\")\nprint(\"  - Compare across different k values\")\n\nprint(\"\\n\u2705 Cluster optimization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.metrics \nimport silhouette_score\nfrom sklearn.datasets \nimport make_blobs_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nElbow Method and Silhouette Score\")\nprint(\"=\" * 60)\n\nprint(\"\\nElbow Method:\")\nprint(\"  - Plot within-cluster sum of squares (WCSS)\")\nprint(\"  - Look for 'elbow' in the curve\")\nprint(\"  - Indicates optimal k\")\n\nprint(\"\\nSilhouette Score:\")\nprint(\"  - Measures cluster quality\")\nprint(\"  - Range: -1 to 1\")\nprint(\"  - Higher is better\")\nprint(\"  - Compare across different k values\")\n\nprint(\"\\n\u2705 Cluster optimization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/06_evaluating_clustering_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.7435078620910645,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nfrom sklearn.metrics \nimport davies_bouldin_score, calinski_harabasz_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nEvaluating Clustering Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nClustering Metrics:\")\nprint(\"  - Silhouette Score: Cohesion and separation\")\nprint(\"  - Adjusted Rand Index: Agreement with ground truth\")\nprint(\"  - Normalized Mutual Information: Information shared\")\nprint(\"  - Davies-Bouldin Index: Average similarity ratio\")\nprint(\"  - Calinski-Harabasz Index: Ratio of between/within cluster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Silhouette: General quality assessment\")\nprint(\"  - ARI/NMI: When ground truth available\")\nprint(\"  - DB Index: Lower is better\")\nprint(\"  - CH Index: Higher is better\")\n\nprint(\"\\n\u2705 Clustering evaluation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nfrom sklearn.metrics \nimport davies_bouldin_score, calinski_harabasz_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nEvaluating Clustering Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nClustering Metrics:\")\nprint(\"  - Silhouette Score: Cohesion and separation\")\nprint(\"  - Adjusted Rand Index: Agreement with ground truth\")\nprint(\"  - Normalized Mutual Information: Information shared\")\nprint(\"  - Davies-Bouldin Index: Average similarity ratio\")\nprint(\"  - Calinski-Harabasz Index: Ratio of between/within cluster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Silhouette: General quality assessment\")\nprint(\"  - ARI/NMI: When ground truth available\")\nprint(\"  - DB Index: Lower is better\")\nprint(\"  - CH Index: Higher is better\")\n\nprint(\"\\n\u2705 Clustering evaluation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/evaluating_clustering_models_using_appropriate_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.6053338050842285,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\nsil = []_ks =  range(2, 9) / ks = range(2, 9) / for k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X) / labels = km.fit_predict(X) / inertias.append(km.inertia_) / sil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k') / ax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score') / ax[1].set_xlabel('k') / plt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42) / labels = km.fit_predict(X) / plt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15) / plt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\nsil = []_ks =  range(2, 9) / ks = range(2, 9) / for k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X) / labels = km.fit_predict(X) / inertias.append(km.inertia_) / sil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k') / ax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score') / ax[1].set_xlabel('k') / plt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42) / labels = km.fit_predict(X) / plt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15) / plt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/using_elbow_method_and_silhouette_score_to_determine_optimal_number_of_clusters.ipynb",
      "status": "failed",
      "execution_time": 0.630932092666626,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\nsil = []_ks =  range(2, 9) / ks = range(2, 9) / for k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X) / labels = km.fit_predict(X) / inertias.append(km.inertia_) / sil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k') / ax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score') / ax[1].set_xlabel('k') / plt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42) / labels = km.fit_predict(X) / plt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15) / plt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\nsil = []_ks =  range(2, 9) / ks = range(2, 9) / for k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X) / labels = km.fit_predict(X) / inertias.append(km.inertia_) / sil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k') / ax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score') / ax[1].set_xlabel('k') / plt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42) / labels = km.fit_predict(X) / plt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15) / plt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6124980449676514,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.cluster import rom KMeans, AgglomerativeClusteringf\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster import rom KMeans, AgglomerativeClusteringf\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.cluster import rom KMeans, AgglomerativeClusteringf\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster import rom KMeans, AgglomerativeClusteringf\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit4-clustering/exercises/exercise_02_pca.ipynb",
      "status": "failed",
      "execution_time": 0.7409563064575195,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\n\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)\n\nInstructions:\n1. Load the provided dataset_2. Apply PCA to reduce dimensionality_3. Analyze explained variance_4. Choose optimal number of components_5. Visualize data in reduced dimensions_6. Compare original vs PCA-transformed data\n\nDataset: Multi-dimensional dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n\n# Load Iris dataset (4 features, 3 classes) / iris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\nX = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names) / df['target'] = y_\nprint(\"Dataset loaded!\") / print(f\"Shape: {df.shape}\") / print(f\"Features: {feature_names}\") / print(f\"\\nClass distribution:\") / print(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Scale the data (CRITICAL for PCA!) / print(\"\\n\" + \"=\"*60) / print(\"Task 1: Scale data\") / print(\"=\"*60)\n# Use StandardScaler\n# Your code here...\n\n# Task 2: Apply PCA with all components_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 2: Apply PCA (all components)\")\nprint(\"=\"*60)\n# Create PCA object\n# Fit and transform the data\n# Your code here...\n\n# Task 3: Analyze explained variance_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 3: Explained variance analysis\") / print(\"=\"*60)\n# Get explained_variance_ratio_ for each component\n# Calculate cumulative explained variance\n# Print: Each component's variance, cumulative variance\n# Your code here...\n\n# Task 4: Visualize explained variance_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 4: Visualize explained variance\") / print(\"=\"*60)\n# Plot: Component number vs Explained variance\n# Plot: Component number vs Cumulative explained variance\n# Your code here...\n\n# Task 5: Reduce to 2D for visualization_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 5: Reduce to 2D\") / print(\"=\"*60)\n# Apply PCA with n_components=2\n# Transform data to 2D\n# Visualize in 2D (color by original class labels)\n# Your code here...\n\n# Task 6: Find optimal number of components_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 6: Find optimal number of components\") / print(\"=\"*60)\n# Find number of components that explain 95% of variance\n# Find number of components that explain 99% of variance\n# Your code here...\n\n# Task 7: Compare original vs PCA-transformed_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 7: Compare original vs PCA\") / print(\"=\"*60)\n# Show: Original has 4 features, PCA can reduce to 2-3\n# Show: PCA preserves most information with fewer features\n# Your code here... print(\"\\n\" + \"=\"*60) / print(\"Exercise 2 Complete!\") / print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\") / print(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names) / df['target'] = y_\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\n\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)\n\nInstructions:\n1. Load the provided dataset_2. Apply PCA to reduce dimensionality_3. Analyze explained variance_4. Choose optimal number of components_5. Visualize data in reduced dimensions_6. Compare original vs PCA-transformed data\n\nDataset: Multi-dimensional dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n\n# Load Iris dataset (4 features, 3 classes) / iris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\nX = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names) / df['target'] = y_\nprint(\"Dataset loaded!\") / print(f\"Shape: {df.shape}\") / print(f\"Features: {feature_names}\") / print(f\"\\nClass distribution:\") / print(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Scale the data (CRITICAL for PCA!) / print(\"\\n\" + \"=\"*60) / print(\"Task 1: Scale data\") / print(\"=\"*60)\n# Use StandardScaler\n# Your code here...\n\n# Task 2: Apply PCA with all components_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 2: Apply PCA (all components)\")\nprint(\"=\"*60)\n# Create PCA object\n# Fit and transform the data\n# Your code here...\n\n# Task 3: Analyze explained variance_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 3: Explained variance analysis\") / print(\"=\"*60)\n# Get explained_variance_ratio_ for each component\n# Calculate cumulative explained variance\n# Print: Each component's variance, cumulative variance\n# Your code here...\n\n# Task 4: Visualize explained variance_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 4: Visualize explained variance\") / print(\"=\"*60)\n# Plot: Component number vs Explained variance\n# Plot: Component number vs Cumulative explained variance\n# Your code here...\n\n# Task 5: Reduce to 2D for visualization_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 5: Reduce to 2D\") / print(\"=\"*60)\n# Apply PCA with n_components=2\n# Transform data to 2D\n# Visualize in 2D (color by original class labels)\n# Your code here...\n\n# Task 6: Find optimal number of components_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 6: Find optimal number of components\") / print(\"=\"*60)\n# Find number of components that explain 95% of variance\n# Find number of components that explain 99% of variance\n# Your code here...\n\n# Task 7: Compare original vs PCA-transformed_\nprint(\"\\n\" + \"=\"*60) / print(\"Task 7: Compare original vs PCA\") / print(\"=\"*60)\n# Show: Original has 4 features, PCA can reduce to 2-3\n# Show: PCA preserves most information with fewer features\n# Your code here... print(\"\\n\" + \"=\"*60) / print(\"Exercise 2 Complete!\") / print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\") / print(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names) / df['target'] = y_\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit4-clustering/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7499299049377441,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.cluster import plt\nfrom KMeans, from sklearn.preprocessing import AgglomerativeClustering\nfrom from sklearn.metrics import StandardScaler\nfrom silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.cluster import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.cluster import plt\nfrom KMeans, from sklearn.preprocessing import AgglomerativeClustering\nfrom from sklearn.metrics import StandardScaler\nfrom silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.cluster import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "Course 04/unit4-clustering/solutions/solution_02_pca.ipynb",
      "status": "failed",
      "execution_time": 0.6158959865570068,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)Instructions:1. Load the provided dataset2. Apply PCA to reduce dimensionality3. Analyze explained variance4. Choose optimal number of components5. Visualize data in reduced dimensions6. Compare original vs PCA-transformed dataDataset: Multi-dimensional dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n# Load Iris dataset (4 features, 3 classes)iris = load_iris()X = iris.datay = iris.targetfeature_names = iris.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Apply PCA (all components)\")print(\"=\"*60)# Create PCA object# Fit and transform the data# Your code here...# Task 3: Analyze explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Explained variance analysis\")print(\"=\"*60)# Get explained_variance_ratio_ for each component# Calculate cumulative explained variance# Print: Each component's variance, cumulative variance# Your code here...# Task 4: Visualize explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Visualize explained variance\")print(\"=\"*60)# Plot: Component number vs Explained variance# Plot: Component number vs Cumulative explained variance# Your code here...# Task 5: Reduce to 2D for visualization\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Reduce to 2D\")print(\"=\"*60)# Apply PCA with n_components=2# Transform data to 2D# Visualize in 2D (color by original class labels)# Your code here...# Task 6: Find optimal number of components\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Find optimal number of components\")print(\"=\"*60)# Find number of components that explain 95% of variance# Find number of components that explain 99% of variance# Your code here...# Task 7: Compare original vs PCA-transformed\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Compare original vs PCA\")print(\"=\"*60)# Show: Original has 4 features, PCA can reduce to 2-3# Show: PCA preserves most information with fewer features# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)Instructions:1. Load the provided dataset2. Apply PCA to reduce dimensionality3. Analyze explained variance4. Choose optimal number of components5. Visualize data in reduced dimensions6. Compare original vs PCA-transformed dataDataset: Multi-dimensional dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n# Load Iris dataset (4 features, 3 classes)iris = load_iris()X = iris.datay = iris.targetfeature_names = iris.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Apply PCA (all components)\")print(\"=\"*60)# Create PCA object# Fit and transform the data# Your code here...# Task 3: Analyze explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Explained variance analysis\")print(\"=\"*60)# Get explained_variance_ratio_ for each component# Calculate cumulative explained variance# Print: Each component's variance, cumulative variance# Your code here...# Task 4: Visualize explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Visualize explained variance\")print(\"=\"*60)# Plot: Component number vs Explained variance# Plot: Component number vs Cumulative explained variance# Your code here...# Task 5: Reduce to 2D for visualization\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Reduce to 2D\")print(\"=\"*60)# Apply PCA with n_components=2# Transform data to 2D# Visualize in 2D (color by original class labels)# Your code here...# Task 6: Find optimal number of components\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Find optimal number of components\")print(\"=\"*60)# Find number of components that explain 95% of variance# Find number of components that explain 99% of variance# Your code here...# Task 7: Compare original vs PCA-transformed\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Compare original vs PCA\")print(\"=\"*60)# Show: Original has 4 features, PCA can reduce to 2-3# Show: PCA preserves most information with fewer features# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/01_grid_search.ipynb",
      "status": "passed",
      "execution_time": 84.78473997116089,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/02_boosting.ipynb",
      "status": "passed",
      "execution_time": 2.332920789718628,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/03_cross_validation_hyperparameter_tuning.ipynb",
      "status": "failed",
      "execution_time": 0.7365360260009766,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport cross_val_score, KFold\nfrom sklearn.model_selection \nimport validation_curve\nfrom sklearn.ensemble \nimport RandomForestClassifier_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nCross-Validation and Hyperparameter Tuning\")\nprint(\"=\" * 60)\n\nprint(\"\\nCross-Validation:\")\nprint(\"  - k-fold CV: Split into k folds\")\nprint(\"  - Stratified CV: Preserve class distribution\")\nprint(\"  - Leave-one-out: Each sample as test\")\n\nprint(\"\\nHyperparameter Tuning:\")\nprint(\"  - Grid Search: Exhaustive search\")\nprint(\"  - Random Search: Random sampling\")\nprint(\"  - Validation curves: Visualize parameter impact\")\nprint(\"  - Nested CV: Avoid overfitting\")\n\nprint(\"\\n\u2705 CV and hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport cross_val_score, KFold\nfrom sklearn.model_selection \nimport validation_curve\nfrom sklearn.ensemble \nimport RandomForestClassifier_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nCross-Validation and Hyperparameter Tuning\")\nprint(\"=\" * 60)\n\nprint(\"\\nCross-Validation:\")\nprint(\"  - k-fold CV: Split into k folds\")\nprint(\"  - Stratified CV: Preserve class distribution\")\nprint(\"  - Leave-one-out: Each sample as test\")\n\nprint(\"\\nHyperparameter Tuning:\")\nprint(\"  - Grid Search: Exhaustive search\")\nprint(\"  - Random Search: Random sampling\")\nprint(\"  - Validation curves: Visualize parameter impact\")\nprint(\"  - Nested CV: Avoid overfitting\")\n\nprint(\"\\n\u2705 CV and hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/04_grid_search_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.6590087413787842,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint, uniform_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nGrid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search over parameter grid\")\nprint(\"  - Guarantees finding best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling of parameters\")\nprint(\"  - More efficient for large spaces\")\nprint(\"  - Often finds good solutions faster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Grid Search: Small parameter spaces\")\nprint(\"  - Random Search: Large parameter spaces\")\nprint(\"  - Both use cross-validation\")\n\nprint(\"\\n\u2705 Search strategies concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint, uniform_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nGrid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search over parameter grid\")\nprint(\"  - Guarantees finding best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling of parameters\")\nprint(\"  - More efficient for large spaces\")\nprint(\"  - Often finds good solutions faster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Grid Search: Small parameter spaces\")\nprint(\"  - Random Search: Large parameter spaces\")\nprint(\"  - Both use cross-validation\")\n\nprint(\"\\n\u2705 Search strategies concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/05_comparing_boosting_traditional_methods.ipynb",
      "status": "passed",
      "execution_time": 1.7556769847869873,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/applying_confusion_matrices_plotting_roc_curves_for_classification_models.ipynb",
      "status": "failed",
      "execution_time": 0.6795980930328369,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/comparing_performance_with_traditional_methods.ipynb",
      "status": "failed",
      "execution_time": 0.753511905670166,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/evaluating_models_on_real_datasets_using_performance_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.7386970520019531,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/implementing_cross_validation_and_hyperparameter_tuning_using_python.ipynb",
      "status": "failed",
      "execution_time": 0.5309479236602783,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/implementing_final_project_applying_learned_techniques_on_real_dataset_evaluatin.ipynb",
      "status": "failed",
      "execution_time": 0.6285340785980225,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/tuning_models_for_optimal_performance_and_documenting_improvements.ipynb",
      "status": "failed",
      "execution_time": 0.6779181957244873,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/using_grid_search_and_random_search_in_scikit_learn_to_optimize_parameters.ipynb",
      "status": "failed",
      "execution_time": 0.7424631118774414,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5394110679626465,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_reportf\nfrom sklearn.datasets import rom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import rom make_classification\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_reportf\nfrom sklearn.datasets import rom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import rom make_classification\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit5-model-selection/exercises/exercise_02_boosting.ipynb",
      "status": "failed",
      "execution_time": 1.8467459678649902,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Exercise 2: Boosting Algorithms Practice\n\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632\n\nInstructions:\n1. Load the provided dataset_2. Train XGBoost model (if available)\n3. Train LightGBM model (if available)\n4. Compare with Random Forest (bagging)\n5. Compare boosting algorithms with each other_6. Interpret feature importance_7. Understand boosting vs bagging\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve\n)\nfrom sklearn.datasets import load_breast_cancer\n\n# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\nX = cancer_data.data_y = cancer_data.target_df = pd.DataFrame(X, columns=cancer_data.feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Random Forest (bagging - for comparison)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Random Forest (bagging)\")\nprint(\"=\"*60)\n# Train RandomForestClassifier\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Try to import and train XGBoost_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train XGBoost (if available)\")\nprint(\"=\"*60)\n# Try: import xgboost as xgb\n# If available: Train XGBClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 4: Try to import and train LightGBM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train LightGBM (if available)\")\nprint(\"=\"*60)\n# Try: import lightgbm as lgb\n# If available: Train LGBMClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 5: Compare all models_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare models\")\nprint(\"=\"*60)\n# Create comparison table\n# Show: Random Forest vs XGBoost vs LightGBM\n# Show which performs best\n# Your code here...\n\n# Task 6: Feature importance comparison_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Feature importance\")\nprint(\"=\"*60)\n# Get feature importance from all models\n# Visualize and compare\n# Show which features are most important\n# Your code here...\n\n# Task 7: Understand boosting vs bagging_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Boosting vs Bagging\")\nprint(\"=\"*60)\n# Explain the difference:\n# - Bagging (RF): Models trained in parallel, then averaged\n# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_breast_cancer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mtarget_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mcancer_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'X' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Exercise 2: Boosting Algorithms Practice\n\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632\n\nInstructions:\n1. Load the provided dataset_2. Train XGBoost model (if available)\n3. Train LightGBM model (if available)\n4. Compare with Random Forest (bagging)\n5. Compare boosting algorithms with each other_6. Interpret feature importance_7. Understand boosting vs bagging\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve\n)\nfrom sklearn.datasets import load_breast_cancer\n\n# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\nX = cancer_data.data_y = cancer_data.target_df = pd.DataFrame(X, columns=cancer_data.feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Random Forest (bagging - for comparison)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Random Forest (bagging)\")\nprint(\"=\"*60)\n# Train RandomForestClassifier\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Try to import and train XGBoost_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train XGBoost (if available)\")\nprint(\"=\"*60)\n# Try: import xgboost as xgb\n# If available: Train XGBClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 4: Try to import and train LightGBM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train LightGBM (if available)\")\nprint(\"=\"*60)\n# Try: import lightgbm as lgb\n# If available: Train LGBMClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 5: Compare all models_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare models\")\nprint(\"=\"*60)\n# Create comparison table\n# Show: Random Forest vs XGBoost vs LightGBM\n# Show which performs best\n# Your code here...\n\n# Task 6: Feature importance comparison_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Feature importance\")\nprint(\"=\"*60)\n# Get feature importance from all models\n# Visualize and compare\n# Show which features are most important\n# Your code here...\n\n# Task 7: Understand boosting vs bagging_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Boosting vs Bagging\")\nprint(\"=\"*60)\n# Explain the difference:\n# - Bagging (RF): Models trained in parallel, then averaged\n# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_breast_cancer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mtarget_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mcancer_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'X' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit5-model-selection/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5253109931945801,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom train_test_split, from sklearn.ensemble import GridSearchCV\nfrom from sklearn.metrics import RandomForestClassifier\nfrom accuracy_score, from sklearn.datasets import classification_report\nfrom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom train_test_split, from sklearn.ensemble import GridSearchCV\nfrom from sklearn.metrics import RandomForestClassifier\nfrom accuracy_score, from sklearn.datasets import classification_report\nfrom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "Course 04/unit5-model-selection/solutions/solution_02_boosting.ipynb",
      "status": "failed",
      "execution_time": 0.736396074295044,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 5 - Exercise 2: Boosting Algorithms Practice\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632Instructions:1. Load the provided dataset2. Train XGBoost model (if available)3. Train LightGBM model (if available)4. Compare with Random Forest (bagging)5. Compare boosting algorithms with each other6. Interpret feature importance7. Understand boosting vs baggingDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\n# Load real-world Breast Cancer datasetcancer_data = load_breast_cancer()X = cancer_data.datay = cancer_data.targetdf = pd.DataFrame(X, columns=cancer_data.feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train Random Forest (bagging - for comparison)print(\"\\n\" + \"=\"*60)print(\"Task 2: Train Random Forest (bagging)\")print(\"=\"*60)# Train RandomForestClassifier# Evaluate and print metrics# Your code here...# Task 3: Try to import and train XGBoost\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train XGBoost (if available)\")print(\"=\"*60)# Try: import xgboost as xgb# If available: Train XGBClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 4: Try to import and train LightGBM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train LightGBM (if available)\")print(\"=\"*60)# Try: import lightgbm as lgb# If available: Train LGBMClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 5: Compare all models\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare models\")print(\"=\"*60)# Create comparison table# Show: Random Forest vs XGBoost vs LightGBM# Show which performs best# Your code here...# Task 6: Feature importance comparison\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Feature importance\")print(\"=\"*60)# Get feature importance from all models# Visualize and compare# Show which features are most important# Your code here...# Task 7: Understand boosting vs bagging\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Boosting vs Bagging\")print(\"=\"*60)# Explain the difference:# - Bagging (RF): Models trained in parallel, then averaged# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\u001b[0m\n\u001b[0m                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 5 - Exercise 2: Boosting Algorithms Practice\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632Instructions:1. Load the provided dataset2. Train XGBoost model (if available)3. Train LightGBM model (if available)4. Compare with Random Forest (bagging)5. Compare boosting algorithms with each other6. Interpret feature importance7. Understand boosting vs baggingDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\n# Load real-world Breast Cancer datasetcancer_data = load_breast_cancer()X = cancer_data.datay = cancer_data.targetdf = pd.DataFrame(X, columns=cancer_data.feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train Random Forest (bagging - for comparison)print(\"\\n\" + \"=\"*60)print(\"Task 2: Train Random Forest (bagging)\")print(\"=\"*60)# Train RandomForestClassifier# Evaluate and print metrics# Your code here...# Task 3: Try to import and train XGBoost\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train XGBoost (if available)\")print(\"=\"*60)# Try: import xgboost as xgb# If available: Train XGBClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 4: Try to import and train LightGBM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train LightGBM (if available)\")print(\"=\"*60)# Try: import lightgbm as lgb# If available: Train LGBMClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 5: Compare all models\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare models\")print(\"=\"*60)# Create comparison table# Show: Random Forest vs XGBoost vs LightGBM# Show which performs best# Your code here...# Task 6: Feature importance comparison\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Feature importance\")print(\"=\"*60)# Get feature importance from all models# Visualize and compare# Show which features are most important# Your code here...# Task 7: Understand boosting vs bagging\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Boosting vs Bagging\")print(\"=\"*60)# Explain the difference:# - Bagging (RF): Models trained in parallel, then averaged# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\u001b[0m\n\u001b[0m                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "Course 05/unit1-introduction/examples/01_data_science_intro.ipynb",
      "status": "passed",
      "execution_time": 2.4846060276031494,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/02_pandas_numpy_basics.ipynb",
      "status": "passed",
      "execution_time": 2.1377999782562256,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/03_cudf_introduction.ipynb",
      "status": "passed",
      "execution_time": 1.8084051609039307,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/04_python_basics_loops_conditions.ipynb",
      "status": "passed",
      "execution_time": 0.7441098690032959,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/05_jupyter_notebooks_best_practices.ipynb",
      "status": "passed",
      "execution_time": 0.7473030090332031,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/06_data_structures_lists_dictionaries.ipynb",
      "status": "passed",
      "execution_time": 0.6342377662658691,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/07_data_science_applications.ipynb",
      "status": "passed",
      "execution_time": 1.2155799865722656,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/data_science_applications_working_on_small_real_world_projects_using_data_scienc.ipynb",
      "status": "failed",
      "execution_time": 0.6679432392120361,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/python_programming_executing_python_code_to_solve_basic_tasks_like_arithmetic_op.ipynb",
      "status": "failed",
      "execution_time": 0.7380352020263672,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/using_jupyter_notebooks_writing_and_executing_code_in_jupyter_notebooks_combinin.ipynb",
      "status": "failed",
      "execution_time": 0.7407879829406738,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/working_with_data_structures_performing_tasks_like_indexing_slicing_and_transfor.ipynb",
      "status": "failed",
      "execution_time": 0.7565457820892334,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 1.592365026473999,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "exercise"
    },
    {
      "path": "Course 05/unit1-introduction/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 1.5840237140655518,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "other"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/04_data_loading.ipynb",
      "status": "passed",
      "execution_time": 1.0595250129699707,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/05_feature_transformation_scaling_encoding.ipynb",
      "status": "failed",
      "execution_time": 0.8638617992401123,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFeature Transformation: Scaling and Encoding\")\nprint(\"=\" * 60)\n\nprint(\"\\nScaling:\")\nprint(\"  - StandardScaler: Mean 0, std 1\")\nprint(\"  - MinMaxScaler: Range [0, 1]\")\nprint(\"  - RobustScaler: Median and IQR\")\nprint(\"  - Normalization\")\n\nprint(\"\\nEncoding:\")\nprint(\"  - Label Encoding: Ordinal categories\")\nprint(\"  - One-Hot Encoding: Nominal categories\")\nprint(\"  - Target Encoding: Mean target\")\nprint(\"  - Frequency Encoding\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Scaling: Numerical features\")\nprint(\"  - Encoding: Categorical features\")\nprint(\"  - Before ML models\")\nprint(\"  - For distance-based algorithms\")\n\nprint(\"\\n\u2705 Feature transformation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFeature Transformation: Scaling and Encoding\")\nprint(\"=\" * 60)\n\nprint(\"\\nScaling:\")\nprint(\"  - StandardScaler: Mean 0, std 1\")\nprint(\"  - MinMaxScaler: Range [0, 1]\")\nprint(\"  - RobustScaler: Median and IQR\")\nprint(\"  - Normalization\")\n\nprint(\"\\nEncoding:\")\nprint(\"  - Label Encoding: Ordinal categories\")\nprint(\"  - One-Hot Encoding: Nominal categories\")\nprint(\"  - Target Encoding: Mean target\")\nprint(\"  - Frequency Encoding\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Scaling: Numerical features\")\nprint(\"  - Encoding: Categorical features\")\nprint(\"  - Before ML models\")\nprint(\"  - For distance-based algorithms\")\n\nprint(\"\\n\u2705 Feature transformation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/05_missing_values_duplicates.ipynb",
      "status": "passed",
      "execution_time": 2.082751989364624,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/06_eda_visualizations.ipynb",
      "status": "passed",
      "execution_time": 1.5881741046905518,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/06_outliers_transformation.ipynb",
      "status": "passed",
      "execution_time": 2.480522871017456,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/07_cudf_import_export_gpu.ipynb",
      "status": "failed",
      "execution_time": 0.7848150730133057,
      "error": "An error occurred while executing the following cell:\n------------------\n# Try importing cuDF (requires CUDA and RAPIDS installation) / try:\n    import cudf\n    import pandas as pd\n    import numpy as np_HAS_CUDF = True_\nprint(\"\u2705 cuDF imported successfully!\") / print(f\"cuDF version: {cudf.__version__}\") / except ImportError:\n    HAS_CUDF = False\n    import pandas as pd\n    import numpy as np_\nprint(\"\u26a0\ufe0f  cuDF not available. Install RAPIDS for GPU acceleration:\") / print(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\") / print(\"   Continuing with Pandas examples...\") / print(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import cudf\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Try importing cuDF (requires CUDA and RAPIDS installation) / try:\n    import cudf\n    import pandas as pd\n    import numpy as np_HAS_CUDF = True_\nprint(\"\u2705 cuDF imported successfully!\") / print(f\"cuDF version: {cudf.__version__}\") / except ImportError:\n    HAS_CUDF = False\n    import pandas as pd\n    import numpy as np_\nprint(\"\u26a0\ufe0f  cuDF not available. Install RAPIDS for GPU acceleration:\") / print(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\") / print(\"   Continuing with Pandas examples...\") / print(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import cudf\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/feature_transformation_transforming_data_eg_scaling_encoding_to_prepare_it_for_a.ipynb",
      "status": "failed",
      "execution_time": 0.6585228443145752,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/performing_eda_visualizing_data_distributions_and_relationships_to_discover_insi.ipynb",
      "status": "failed",
      "execution_time": 0.6278550624847412,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked}) / df.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked}) / df.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/04_chart_types_matplotlib_seaborn.ipynb",
      "status": "passed",
      "execution_time": 1.3553690910339355,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/05_interactive_visualizations_plotly.ipynb",
      "status": "passed",
      "execution_time": 1.0264840126037598,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/06_customizing_annotating_visualizations.ipynb",
      "status": "passed",
      "execution_time": 1.3703689575195312,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/07_matplotlib_basics.ipynb",
      "status": "passed",
      "execution_time": 2.3023769855499268,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/07_visualization_best_practices.ipynb",
      "status": "passed",
      "execution_time": 1.613156795501709,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/08_seaborn_plots.ipynb",
      "status": "passed",
      "execution_time": 4.463119029998779,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/09_plotly_interactive.ipynb",
      "status": "passed",
      "execution_time": 1.403264045715332,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/applying_visualization_best_practices_for_data_storytelling.ipynb",
      "status": "failed",
      "execution_time": 1.6119561195373535,
      "error": "An error occurred while executing the following cell:\n------------------\n# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\nsns.regplot(data=df, x='x', y='y', scatter_kws={'alpha': 0.35}) / plt.title('y vs x with regression fit') / plt.show()\n\n# Distribution plots\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nsns.histplot(df['x'], kde=True, ax=ax[0]) / ax[0].set_title('Distribution of x') / sns.boxplot(data=df, x='category', y='y', ax=ax[1]) / ax[1].set_title('y by category') / plt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mregplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.35\u001b[39m}) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my vs x with regression fit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distribution plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\n\u001b[0;31mNameError\u001b[0m: name 'df' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\nsns.regplot(data=df, x='x', y='y', scatter_kws={'alpha': 0.35}) / plt.title('y vs x with regression fit') / plt.show()\n\n# Distribution plots\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nsns.histplot(df['x'], kde=True, ax=ax[0]) / ax[0].set_title('Distribution of x') / sns.boxplot(data=df, x='category', y='y', ax=ax[1]) / ax[1].set_title('y by category') / plt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mregplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.35\u001b[39m}) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my vs x with regression fit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distribution plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\n\u001b[0;31mNameError\u001b[0m: name 'df' is not defined\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/building_interactive_visualizations_and_dashboards_with_plotly.ipynb",
      "status": "failed",
      "execution_time": 1.6798670291900635,
      "error": "An error occurred while executing the following cell:\n------------------\n# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\nsns.regplot(data=df, x='x', y='y', scatter_kws={'alpha': 0.35}) / plt.title('y vs x with regression fit') / plt.show()\n\n# Distribution plots\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nsns.histplot(df['x'], kde=True, ax=ax[0]) / ax[0].set_title('Distribution of x') / sns.boxplot(data=df, x='category', y='y', ax=ax[1]) / ax[1].set_title('y by category') / plt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mregplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.35\u001b[39m}) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my vs x with regression fit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distribution plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\n\u001b[0;31mNameError\u001b[0m: name 'df' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\nsns.regplot(data=df, x='x', y='y', scatter_kws={'alpha': 0.35}) / plt.title('y vs x with regression fit') / plt.show()\n\n# Distribution plots\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nsns.histplot(df['x'], kde=True, ax=ax[0]) / ax[0].set_title('Distribution of x') / sns.boxplot(data=df, x='category', y='y', ax=ax[1]) / ax[1].set_title('y by category') / plt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mregplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.35\u001b[39m}) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my vs x with regression fit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distribution plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\n\u001b[0;31mNameError\u001b[0m: name 'df' is not defined\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/creating_various_chart_types_using_matplotlib_and_seaborn.ipynb",
      "status": "failed",
      "execution_time": 1.6033809185028076,
      "error": "An error occurred while executing the following cell:\n------------------\n# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\nsns.regplot(data=df, x='x', y='y', scatter_kws={'alpha': 0.35}) / plt.title('y vs x with regression fit') / plt.show()\n\n# Distribution plots\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nsns.histplot(df['x'], kde=True, ax=ax[0]) / ax[0].set_title('Distribution of x') / sns.boxplot(data=df, x='category', y='y', ax=ax[1]) / ax[1].set_title('y by category') / plt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mregplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.35\u001b[39m}) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my vs x with regression fit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distribution plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\n\u001b[0;31mNameError\u001b[0m: name 'df' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\nsns.regplot(data=df, x='x', y='y', scatter_kws={'alpha': 0.35}) / plt.title('y vs x with regression fit') / plt.show()\n\n# Distribution plots\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nsns.histplot(df['x'], kde=True, ax=ax[0]) / ax[0].set_title('Distribution of x') / sns.boxplot(data=df, x='category', y='y', ax=ax[1]) / ax[1].set_title('y by category') / plt.tight_layout()\nplt.show()\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Seaborn scatter + regression line_sns.set_theme(style='whitegrid') / plt.figure(figsize=(7, 4))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mregplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.35\u001b[39m}) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my vs x with regression fit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distribution plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\n\u001b[0;31mNameError\u001b[0m: name 'df' is not defined\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/05_pandas_data_manipulation.ipynb",
      "status": "passed",
      "execution_time": 0.7707340717315674,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/06_data_preparation_ml_tasks.ipynb",
      "status": "failed",
      "execution_time": 0.5468018054962158,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nData Preparation for ML Tasks\")\nprint(\"=\" * 60)\n\nprint(\"\\nMissing Values:\")\nprint(\"  - Detection: isnull(), info()\")\nprint(\"  - Removal: dropna()\")\nprint(\"  - Imputation: fillna(), SimpleImputer\")\nprint(\"  - Forward/backward fill\")\n\nprint(\"\\nCategorical Encoding:\")\nprint(\"  - Label Encoding\")\nprint(\"  - One-Hot Encoding\")\nprint(\"  - Ordinal Encoding\")\nprint(\"  - Target Encoding\")\n\nprint(\"\\nData Splitting:\")\nprint(\"  - Train/Test split\")\nprint(\"  - Train/Validation/Test\")\nprint(\"  - Stratified splitting\")\nprint(\"  - Time-based splitting\")\n\nprint(\"\\n\u2705 Data preparation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nData Preparation for ML Tasks\")\nprint(\"=\" * 60)\n\nprint(\"\\nMissing Values:\")\nprint(\"  - Detection: isnull(), info()\")\nprint(\"  - Removal: dropna()\")\nprint(\"  - Imputation: fillna(), SimpleImputer\")\nprint(\"  - Forward/backward fill\")\n\nprint(\"\\nCategorical Encoding:\")\nprint(\"  - Label Encoding\")\nprint(\"  - One-Hot Encoding\")\nprint(\"  - Ordinal Encoding\")\nprint(\"  - Target Encoding\")\n\nprint(\"\\nData Splitting:\")\nprint(\"  - Train/Test split\")\nprint(\"  - Train/Validation/Test\")\nprint(\"  - Stratified splitting\")\nprint(\"  - Time-based splitting\")\n\nprint(\"\\n\u2705 Data preparation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/07_implementing_ml_models_scikit_learn.ipynb",
      "status": "failed",
      "execution_time": 0.6211020946502686,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge/Lasso Regression\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nWorkflow:\")\nprint(\"  1. Prepare data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge/Lasso Regression\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nWorkflow:\")\nprint(\"  1. Prepare data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/07_implementing_ml_models_sklearn.ipynb",
      "status": "failed",
      "execution_time": 0.7417972087860107,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge, Lasso\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nScikit-learn Workflow:\")\nprint(\"  1. Import model\")\nprint(\"  2. Create instance\")\nprint(\"  3. Fit on training data\")\nprint(\"  4. Predict on test data\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\n\u2705 Scikit-learn ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge, Lasso\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nScikit-learn Workflow:\")\nprint(\"  1. Import model\")\nprint(\"  2. Create instance\")\nprint(\"  3. Fit on training data\")\nprint(\"  4. Predict on test data\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\n\u2705 Scikit-learn ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/08_supervised_learning_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.7429580688476562,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.metrics \nimport accuracy_score, confusion_matrix, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSupervised Learning: Logistic Regression\")\nprint(\"=\" * 60)\n\nprint(\"\\nSupervised Learning:\")\nprint(\"  - Uses labeled training data\")\nprint(\"  - Learns mapping from inputs to outputs\")\nprint(\"  - Can predict on new data\")\nprint(\"  - Classification and regression\")\n\nprint(\"\\nLogistic Regression:\")\nprint(\"  - Binary classification\")\nprint(\"  - Multi-class classification\")\nprint(\"  - Probabilistic output\")\nprint(\"  - Linear decision boundary\")\n\nprint(\"\\nTraining Process:\")\nprint(\"  1. Prepare labeled data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\nprint(\"  5. Make predictions\")\n\nprint(\"\\n\u2705 Supervised learning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.metrics \nimport accuracy_score, confusion_matrix, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSupervised Learning: Logistic Regression\")\nprint(\"=\" * 60)\n\nprint(\"\\nSupervised Learning:\")\nprint(\"  - Uses labeled training data\")\nprint(\"  - Learns mapping from inputs to outputs\")\nprint(\"  - Can predict on new data\")\nprint(\"  - Classification and regression\")\n\nprint(\"\\nLogistic Regression:\")\nprint(\"  - Binary classification\")\nprint(\"  - Multi-class classification\")\nprint(\"  - Probabilistic output\")\nprint(\"  - Linear decision boundary\")\n\nprint(\"\\nTraining Process:\")\nprint(\"  1. Prepare labeled data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\nprint(\"  5. Make predictions\")\n\nprint(\"\\n\u2705 Supervised learning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/09_unsupervised_learning_kmeans.ipynb",
      "status": "passed",
      "execution_time": 1.701634168624878,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/10_hyperparameter_tuning_grid_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.739678144454956,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nHyperparameter Tuning: Grid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search\")\nprint(\"  - Tests all combinations\")\nprint(\"  - Guarantees best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling\")\nprint(\"  - More efficient\")\nprint(\"  - Good for large spaces\")\nprint(\"  - Often finds good solutions\")\n\nprint(\"\\nHyperparameters:\")\nprint(\"  - Learning rate\")\nprint(\"  - Number of trees\")\nprint(\"  - Max depth\")\nprint(\"  - Regularization strength\")\n\nprint(\"\\n\u2705 Hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nHyperparameter Tuning: Grid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search\")\nprint(\"  - Tests all combinations\")\nprint(\"  - Guarantees best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling\")\nprint(\"  - More efficient\")\nprint(\"  - Good for large spaces\")\nprint(\"  - Often finds good solutions\")\n\nprint(\"\\nHyperparameters:\")\nprint(\"  - Learning rate\")\nprint(\"  - Number of trees\")\nprint(\"  - Max depth\")\nprint(\"  - Regularization strength\")\n\nprint(\"\\n\u2705 Hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/10_linear_regression.ipynb",
      "status": "passed",
      "execution_time": 2.0516717433929443,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/11_classification.ipynb",
      "status": "passed",
      "execution_time": 2.543497323989868,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/11_real_world_problem_solving.ipynb",
      "status": "failed",
      "execution_time": 0.7852649688720703,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nReal-World Problem Solving\")\nprint(\"=\" * 60)\n\nprint(\"\\nCombining Approaches:\")\nprint(\"  - Unsupervised: Discover patterns\")\nprint(\"  - Supervised: Predict outcomes\")\nprint(\"  - Feature engineering\")\nprint(\"  - Dimensionality reduction\")\n\nprint(\"\\nProblem-Solving Steps:\")\nprint(\"  1. Understand problem\")\nprint(\"  2. Explore data (unsupervised)\")\nprint(\"  3. Engineer features\")\nprint(\"  4. Build predictive model (supervised)\")\nprint(\"  5. Evaluate and iterate\")\n\nprint(\"\\nExample Workflow:\")\nprint(\"  - Clustering for segmentation\")\nprint(\"  - Classification for prediction\")\nprint(\"  - Dimensionality reduction\")\nprint(\"  - Feature selection\")\n\nprint(\"\\n\u2705 Real-world problem solving concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nReal-World Problem Solving\")\nprint(\"=\" * 60)\n\nprint(\"\\nCombining Approaches:\")\nprint(\"  - Unsupervised: Discover patterns\")\nprint(\"  - Supervised: Predict outcomes\")\nprint(\"  - Feature engineering\")\nprint(\"  - Dimensionality reduction\")\n\nprint(\"\\nProblem-Solving Steps:\")\nprint(\"  1. Understand problem\")\nprint(\"  2. Explore data (unsupervised)\")\nprint(\"  3. Engineer features\")\nprint(\"  4. Build predictive model (supervised)\")\nprint(\"  5. Evaluate and iterate\")\n\nprint(\"\\nExample Workflow:\")\nprint(\"  - Clustering for segmentation\")\nprint(\"  - Classification for prediction\")\nprint(\"  - Dimensionality reduction\")\nprint(\"  - Feature selection\")\n\nprint(\"\\n\u2705 Real-world problem solving concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/12_model_evaluation.ipynb",
      "status": "passed",
      "execution_time": 8.393090009689331,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/13_cpu_vs_gpu_ml.ipynb",
      "status": "passed",
      "execution_time": 2.1976101398468018,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/applying_supervised_learning_algorithms_on_labeled_data_eg_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.6463022232055664,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/applying_unsupervised_learning_techniques_eg_k_means_clustering_on_unlabeled_dat.ipynb",
      "status": "failed",
      "execution_time": 0.6562418937683105,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\nsil = []_ks =  range(2, 9) / ks = range(2, 9) / for k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X) / labels = km.fit_predict(X) / inertias.append(km.inertia_) / sil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k') / ax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score') / ax[1].set_xlabel('k') / plt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42) / labels = km.fit_predict(X) / plt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15) / plt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\nsil = []_ks =  range(2, 9) / ks = range(2, 9) / for k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X) / labels = km.fit_predict(X) / inertias.append(km.inertia_) / sil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k') / ax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score') / ax[1].set_xlabel('k') / plt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42) / labels = km.fit_predict(X) / plt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15) / plt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42) / inertias = []_sil =  []\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/cleaning_and_preparing_data_for_ml_tasks_handling_missing_values_encoding_catego.ipynb",
      "status": "failed",
      "execution_time": 0.5292751789093018,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked}) / df.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked}) / df.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/hyperparameter_tuning_using_techniques_like_grid_search_and_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.7386298179626465,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/implementing_ml_models_using_scikit_learn_library_regression_classification.ipynb",
      "status": "failed",
      "execution_time": 0.7431061267852783,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/real_world_problem_solving_using_a_mix_of_supervised_and_unsupervised_learning_a.ipynb",
      "status": "failed",
      "execution_time": 0.6616599559783936,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/working_with_data_using_python_libraries_like_pandas.ipynb",
      "status": "failed",
      "execution_time": 0.6538238525390625,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked}) / df.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked}) / df.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd_rng = np.random.default_rng(7) / n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None) / income = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2]) / city = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int) / clicked = (income > 4200).astype(int)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/14_dask_distributed.ipynb",
      "status": "passed",
      "execution_time": 1.804792881011963,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/15_rapids_workflows.ipynb",
      "status": "passed",
      "execution_time": 1.942007064819336,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/16_production_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.6831669807434082,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/17_performance_optimization.ipynb",
      "status": "passed",
      "execution_time": 1.2691693305969238,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/18_large_datasets.ipynb",
      "status": "passed",
      "execution_time": 2.789238929748535,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/19_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.5995657444000244,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/accelerated_data_with_gpu_using_rapids_using_rapids_libraries_like_cudf_data_fra.ipynb",
      "status": "failed",
      "execution_time": 0.6715571880340576,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123) / n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n) / x2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n) / color = rng.choice(['red','green','blue'], size=n) / y = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int) / df = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) / pre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train) / y_pred = clf.predict(X_test) / print('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = df.drop(columns=['y'])_y =  df['y']\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/01_ethical_frameworks.ipynb",
      "status": "passed",
      "execution_time": 1.3303251266479492,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/02_ethical_decision_making.ipynb",
      "status": "passed",
      "execution_time": 1.2080419063568115,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/03_case_study_analysis.ipynb",
      "status": "failed",
      "execution_time": 0.576171875,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us analyze and visualize the case stud\ny\n\nimport matplotlib.pyplot as plt # For creating visualizations: Charts, graphs, bar charts\nimport matplotlib.patches as mpatches # For drawing shapes: Legends, patche\nsi\nmport numpy as np # For numerical operations: Arrays, calculations\nimport pandas as pd # For data manipulation: DataFrames, data analysis\nimport os # For file operations: Saving images\n\n# Configure matplotlib settings: Set default figure size and font size for better visualizations\nplt.rcParams['font.size'] = 10 # Font size: Make text readable (10\npt is good for most displays) / plt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - matplotlib: Create visualizations (charts, graphs)\")\nprint(\" - numpy: Numerical operations (arrays, calculations)\")\nprint(\" - pandas: Data manipulation (DataFrames, analysis)\")\nprint(\" - os: File operations (saving images)\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    pt is good for most displays) / plt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - matplotlib: Create visualizations (charts, graphs)\")\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us analyze and visualize the case stud\ny\n\nimport matplotlib.pyplot as plt # For creating visualizations: Charts, graphs, bar charts\nimport matplotlib.patches as mpatches # For drawing shapes: Legends, patche\nsi\nmport numpy as np # For numerical operations: Arrays, calculations\nimport pandas as pd # For data manipulation: DataFrames, data analysis\nimport os # For file operations: Saving images\n\n# Configure matplotlib settings: Set default figure size and font size for better visualizations\nplt.rcParams['font.size'] = 10 # Font size: Make text readable (10\npt is good for most displays) / plt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - matplotlib: Create visualizations (charts, graphs)\")\nprint(\" - numpy: Numerical operations (arrays, calculations)\")\nprint(\" - pandas: Data manipulation (DataFrames, analysis)\")\nprint(\" - os: File operations (saving images)\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    pt is good for most displays) / plt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts) / print(\"\u2705 Libraries imported successfully!\") / print(\"\\n\ud83d\udcda What each library does:\") / print(\" - matplotlib: Create visualizations (charts, graphs)\")\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/algorithmic_fairness_testing_applying_fairness_metrics_and_interpreting_ai_decis.ipynb",
      "status": "passed",
      "execution_time": 1.4801421165466309,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/case_studies_analysis_investigating_real_ethical_failures_in_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.2974510192871094,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/detecting_bias_in_ai_models_identifying_biases_in_datasets_and_algorithms_and_ap.ipynb",
      "status": "passed",
      "execution_time": 1.6088917255401611,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/privacy_simulation_assessing_privacy_risks_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 2.025801181793213,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.5910956859588623,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6681118011474609,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "other"
    },
    {
      "path": "Course 06/unit2-bias-fairness/examples/06_detecting_bias_ai_models.ipynb",
      "status": "passed",
      "execution_time": 1.3859939575195312,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-fairness",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-fairness/examples/07_fairness_testing_metrics.ipynb",
      "status": "passed",
      "execution_time": 0.9480597972869873,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-fairness",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/01_bias_detection.ipynb",
      "status": "passed",
      "execution_time": 2.2760751247406006,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/02_bias_mitigation.ipynb",
      "status": "passed",
      "execution_time": 1.6914830207824707,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/03_fair_representation.ipynb",
      "status": "passed",
      "execution_time": 1.5950682163238525,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/04_bias_case_studies.ipynb",
      "status": "passed",
      "execution_time": 1.8852670192718506,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/05_fair_ai_development.ipynb",
      "status": "passed",
      "execution_time": 2.50175404548645,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/ai_fairness_auditing_evaluating_and_improving_ethical_compliance_in_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.540328025817871,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/case_studies_analysis_investigating_bias_incidents_in_ai_in_real_world.ipynb",
      "status": "passed",
      "execution_time": 1.7474169731140137,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/detecting_bias_in_ai_models_identifying_biases_in_datasets_and_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.630481243133545,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/developing_ai_ethics_policies_formulating_guidelines_for_responsible_ai_use.ipynb",
      "status": "passed",
      "execution_time": 1.5884957313537598,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/fairness_testing_using_fairness_metrics_to_evaluate_ai_decisions.ipynb",
      "status": "passed",
      "execution_time": 1.823822259902954,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/implementing_bias_mitigation_techniques_applying_correction_techniques_and_evalu.ipynb",
      "status": "passed",
      "execution_time": 1.7474379539489746,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.529026985168457,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI\nExercise 2: Bias Mitigation TechniquesThis exercise requires you to implement and compare different bias mitigation techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# TASK 1: Generate Biased Datase\nt\n# ============================================================================\ndef generate_biased_dataset(n_samples=2000):\n \n    \n    \"\"\"\n TODO: Generate a synthetic dataset with bias.\n Requirements:\n - Create a dataset with features and a sensitive attribute (e.g., gender: 0 or 1)\n - Introduce bias such that one group has lower probability of positive outcome\n - Return a DataFrame with columns: feature1, feature2, sensitive, target\n \"\"\"\n np.random.seed(42)\n # TODO: Your code here\n # Hint: Use np.random functions to generate features\n # Hint: Make the target depend on features but add bias based on sensitive attribut\nepass\n# ============================================================================\n# TASK 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Implement reweighing technique.\n Requirements:\n - Calculate weights to balance representation across groups\n - Return array of weights for each training sample\n \"\"\"\n # TODO: Your code here\n # Hint: Calculate weights inversely proportional to group size\n pass\n# ============================================================================\n# TASK 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \"\"\"\n TODO: Train a baseline model without any bias mitigation.\n \"\"\"\n # TODO: Your code here\n # Hint: Use RandomForestClassifier\n pass\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Train a model using reweighing technique.\n \"\"\"\n # TODO: Your code here\n # Hint: Use the preprocess_reweighing function and pass weights to fi\nt()\n pass\n# ============================================================================\n# TASK 4: Evaluate Fairness Metric\ns\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \"\"\"\n TODO: Evaluate fairness metrics.\n Requirements:\n - Calculate demographic parity difference\n - Calculate equalized odds difference\n - Calculate accuracy\n - Return a dictionary with these metrics\n \"\"\"\n # TODO: Your code here\n # Hint: Use fairlearn.metrics function\nspass\n# ============================================================================\n# TASK 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \"\"\"\n TODO: Compare baseline vs reweighing techniques.\n Requirements:\n - Split data into train/test\n - Train baseline and reweighed models\n - Evaluate fairness metrics for both\n - Print comparison results\n \"\"\"\n # TODO: Your code here\n pass\n# ============================================================================\n# MAIN EXECUTIO\nN\n# ============================================================================\nif __name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate datase\nt\n print(\"\\nTask 1: Generating biased dataset...\")\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"Sensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n # Compare techniques\n print(\"\\nTask 5: Comparing mitigation techniques...\")\n compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Exercise completed! Check your results against the solution.\")\n print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI\nExercise 2: Bias Mitigation TechniquesThis exercise requires you to implement and compare different bias mitigation techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# TASK 1: Generate Biased Datase\nt\n# ============================================================================\ndef generate_biased_dataset(n_samples=2000):\n \n    \n    \"\"\"\n TODO: Generate a synthetic dataset with bias.\n Requirements:\n - Create a dataset with features and a sensitive attribute (e.g., gender: 0 or 1)\n - Introduce bias such that one group has lower probability of positive outcome\n - Return a DataFrame with columns: feature1, feature2, sensitive, target\n \"\"\"\n np.random.seed(42)\n # TODO: Your code here\n # Hint: Use np.random functions to generate features\n # Hint: Make the target depend on features but add bias based on sensitive attribut\nepass\n# ============================================================================\n# TASK 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Implement reweighing technique.\n Requirements:\n - Calculate weights to balance representation across groups\n - Return array of weights for each training sample\n \"\"\"\n # TODO: Your code here\n # Hint: Calculate weights inversely proportional to group size\n pass\n# ============================================================================\n# TASK 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \"\"\"\n TODO: Train a baseline model without any bias mitigation.\n \"\"\"\n # TODO: Your code here\n # Hint: Use RandomForestClassifier\n pass\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Train a model using reweighing technique.\n \"\"\"\n # TODO: Your code here\n # Hint: Use the preprocess_reweighing function and pass weights to fi\nt()\n pass\n# ============================================================================\n# TASK 4: Evaluate Fairness Metric\ns\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \"\"\"\n TODO: Evaluate fairness metrics.\n Requirements:\n - Calculate demographic parity difference\n - Calculate equalized odds difference\n - Calculate accuracy\n - Return a dictionary with these metrics\n \"\"\"\n # TODO: Your code here\n # Hint: Use fairlearn.metrics function\nspass\n# ============================================================================\n# TASK 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \"\"\"\n TODO: Compare baseline vs reweighing techniques.\n Requirements:\n - Split data into train/test\n - Train baseline and reweighed models\n - Evaluate fairness metrics for both\n - Print comparison results\n \"\"\"\n # TODO: Your code here\n pass\n# ============================================================================\n# MAIN EXECUTIO\nN\n# ============================================================================\nif __name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate datase\nt\n print(\"\\nTask 1: Generating biased dataset...\")\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"Sensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n # Compare techniques\n print(\"\\nTask 5: Comparing mitigation techniques...\")\n compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Exercise completed! Check your results against the solution.\")\n print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit2-bias-justice/solutions/solution_02.ipynb",
      "status": "passed",
      "execution_time": 0.5947389602661133,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "other"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/01_data_protection.ipynb",
      "status": "passed",
      "execution_time": 2.218381881713867,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/02_privacy_technologies.ipynb",
      "status": "passed",
      "execution_time": 2.098665952682495,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/03_differential_privacy.ipynb",
      "status": "passed",
      "execution_time": 2.060041904449463,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/04_gdpr_compliance.ipynb",
      "status": "passed",
      "execution_time": 2.185421943664551,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/05_secure_development.ipynb",
      "status": "passed",
      "execution_time": 2.011711835861206,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/06_data_encryption_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.5492668151855469,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/07_anonymization_pseudonymization.ipynb",
      "status": "passed",
      "execution_time": 0.8433539867401123,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/anonymization_techniques_applying_anonymization_and_pseudonymization_methods.ipynb",
      "status": "passed",
      "execution_time": 1.7996480464935303,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/case_study_analysis_investigating_real_world_privacy_breaches_and_security_failu.ipynb",
      "status": "passed",
      "execution_time": 1.5671851634979248,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/compliance_testing_ensuring_ai_systems_comply_with_gdpr_and_other_regulations.ipynb",
      "status": "passed",
      "execution_time": 1.5958518981933594,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/data_encryption_implementing_encryption_techniques_for_data_protection.ipynb",
      "status": "passed",
      "execution_time": 1.8935580253601074,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/privacy_risk_assessment_evaluating_privacy_risks_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.7037739753723145,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/security_auditing_conducting_security_audits_on_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.7927289009094238,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.9909987449645996,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit3-privacy-security/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.5363237857818604,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "other"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/01_shap_explanations.ipynb",
      "status": "passed",
      "execution_time": 2.8499701023101807,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/02_lime_explanations.ipynb",
      "status": "passed",
      "execution_time": 2.335463285446167,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/03_counterfactual_analysis.ipynb",
      "status": "passed",
      "execution_time": 2.1511340141296387,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/04_accountability_frameworks.ipynb",
      "status": "passed",
      "execution_time": 2.2501089572906494,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/05_hitl_approaches.ipynb",
      "status": "passed",
      "execution_time": 2.0435640811920166,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/06_transparency_tools.ipynb",
      "status": "passed",
      "execution_time": 1.6050972938537598,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/07_explainable_ai_techniques.ipynb",
      "status": "failed",
      "execution_time": 0.9380450248718262,
      "error": "An error occurred while executing the following cell:\n------------------\nimport shap\nimport lime\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nExplainable AI Techniques\")\nprint(\"=\" * 60)\n\nprint(\"\\nSHAP (SHapley Additive exPlanations):\")\nprint(\" - Game theory-based\")\nprint(\" - Feature importance\")\nprint(\" - Global and local explanations\")\nprint(\" - Consistent explanations\")\n\nprint(\"\\nLIME (Local Interpretable Model-agnostic Explanations):\")\nprint(\" - Local explanations\")\nprint(\" - Model-agnostic\")\nprint(\" - Perturbation-based\")\nprint(\" - Interpretable models\")\n\nprint(\"\\nApplications:\")\nprint(\" - Model debugging\")\nprint(\" - Feature importance\")\nprint(\" - Regulatory compliance\")\nprint(\" - User trust\")\n\nprint(\"\\n\u2705 Explainable AI concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport shap\nimport lime\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nExplainable AI Techniques\")\nprint(\"=\" * 60)\n\nprint(\"\\nSHAP (SHapley Additive exPlanations):\")\nprint(\" - Game theory-based\")\nprint(\" - Feature importance\")\nprint(\" - Global and local explanations\")\nprint(\" - Consistent explanations\")\n\nprint(\"\\nLIME (Local Interpretable Model-agnostic Explanations):\")\nprint(\" - Local explanations\")\nprint(\" - Model-agnostic\")\nprint(\" - Perturbation-based\")\nprint(\" - Interpretable models\")\n\nprint(\"\\nApplications:\")\nprint(\" - Model debugging\")\nprint(\" - Feature importance\")\nprint(\" - Regulatory compliance\")\nprint(\" - User trust\")\n\nprint(\"\\n\u2705 Explainable AI concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/case_studies_analysis_analyzing_success_and_failure_in_transparency_and_accounta.ipynb",
      "status": "passed",
      "execution_time": 1.444343090057373,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/implementing_xai_techniques_applying_techniques_like_lime_and_shap_to_interpret_.ipynb",
      "status": "passed",
      "execution_time": 1.6136949062347412,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 1.3600430488586426,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.8039863109588623,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "other"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/01_global_regulations.ipynb",
      "status": "passed",
      "execution_time": 2.1841981410980225,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/02_industry_regulations.ipynb",
      "status": "passed",
      "execution_time": 2.0019991397857666,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/03_governance_frameworks.ipynb",
      "status": "passed",
      "execution_time": 2.1038389205932617,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/04_legal_challenges.ipynb",
      "status": "passed",
      "execution_time": 1.7497620582580566,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/06_ai_governance_frameworks.ipynb",
      "status": "passed",
      "execution_time": 0.5892758369445801,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/accountability_practices_in_ai_developing_and_simulating_monitoring_systems_for_.ipynb",
      "status": "passed",
      "execution_time": 1.4412009716033936,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/case_studies_evaluation_evaluating_regulatory_challenges_and_ai_in_real_world.ipynb",
      "status": "passed",
      "execution_time": 1.3966691493988037,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/predictive_analysis_for_future_challenges_identifying_and_predicting_upcoming_ch.ipynb",
      "status": "passed",
      "execution_time": 1.5091819763183594,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/transparency_and_interpretability_tools_implementing_and_testing_interpretabilit.ipynb",
      "status": "passed",
      "execution_time": 1.613943099975586,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.5388720035552979,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit5-governance-regulations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.5329420566558838,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "other"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/01_text_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 0.8591117858886719,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/02_nltk_spacy_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.9062521457672119,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/03_real_world_nlp_applications.ipynb",
      "status": "passed",
      "execution_time": 0.8765659332275391,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/04_text_conversion_script.ipynb",
      "status": "passed",
      "execution_time": 0.7372641563415527,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/05_exploring_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.664689302444458,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/exercises/01_text_preprocessing_exercise.ipynb",
      "status": "failed",
      "execution_time": 0.8428800106048584,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\\n\n%pip install nltk pandas -q\\n\n\\ni\nmport nltk\\ni\nmport pandas as pd\\ni\nmport re\\nf\nrom nltk.corpus import stopwords\\nf\nrom nltk.tokenize import word_tokenize\\nf\nrom nltk.stem import PorterStemmer, WordNetLemmatizer\\n\n\\nn\nltk.download('punkt', quiet=True)\\nn\nltk.download('stopwords', quiet=True)\\nn\nltk.download('wordnet', quiet=True)\\np\nrint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\ni\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\\n\n%pip install nltk pandas -q\\n\n\\ni\nmport nltk\\ni\nmport pandas as pd\\ni\nmport re\\nf\nrom nltk.corpus import stopwords\\nf\nrom nltk.tokenize import word_tokenize\\nf\nrom nltk.stem import PorterStemmer, WordNetLemmatizer\\n\n\\nn\nltk.download('punkt', quiet=True)\\nn\nltk.download('stopwords', quiet=True)\\nn\nltk.download('wordnet', quiet=True)\\np\nrint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\ni\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n\n",
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/solutions/01_text_preprocessing_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7339801788330078,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install nltk pandas -q\nimport nltk\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom collections import Counter_nltk.download('punkt', quiet=True) / nltk.download('stopwords', quiet=True) / nltk.download('wordnet', quiet=True) / nltk.download('omw-1.4', quiet=True) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections import Counter_nltk.download('punkt', quiet=True) / nltk.download('stopwords', quiet=True) / nltk.download('wordnet', quiet=True) / nltk.download('omw-1.4', quiet=True) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install nltk pandas -q\nimport nltk\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom collections import Counter_nltk.download('punkt', quiet=True) / nltk.download('stopwords', quiet=True) / nltk.download('wordnet', quiet=True) / nltk.download('omw-1.4', quiet=True) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections import Counter_nltk.download('punkt', quiet=True) / nltk.download('stopwords', quiet=True) / nltk.download('wordnet', quiet=True) / nltk.download('omw-1.4', quiet=True) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/01_advanced_tokenization.ipynb",
      "status": "passed",
      "execution_time": 0.9350740909576416,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/02_text_vectorization_bow_tfidf.ipynb",
      "status": "passed",
      "execution_time": 0.87782883644104,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/03_word_embeddings_word2vec.ipynb",
      "status": "passed",
      "execution_time": 1.6207599639892578,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/04_word_embeddings_glove_fasttext.ipynb",
      "status": "failed",
      "execution_time": 0.8005340099334717,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom gensim.models \nimport KeyedVectors\nimport gensim.downloader as api\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained Word Embeddings: GloVe and FastText\")\nprint(\"=\" * 60)\n\nprint(\"\\nGloVe (Global Vectors):\")\nprint(\" - Global co-occurrence statistics\")\nprint(\" - Pre-trained on large corpora\")\nprint(\" - Available in multiple dimensions\")\n\nprint(\"\\nFastText:\")\nprint(\" - Subword information\")\nprint(\" - Handles out-of-vocabulary words\")\nprint(\" - Character n-grams\")\n\nprint(\"\\nApplications:\")\nprint(\" - Word similarity\")\nprint(\" - Text classification\")\nprint(\" - Semantic analysis\")\nprint(\" - Transfer learning\")\n\nprint(\"\\n\u2705 Pre-trained embeddings concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gensim.models\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom gensim.models \nimport KeyedVectors\nimport gensim.downloader as api\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained Word Embeddings: GloVe and FastText\")\nprint(\"=\" * 60)\n\nprint(\"\\nGloVe (Global Vectors):\")\nprint(\" - Global co-occurrence statistics\")\nprint(\" - Pre-trained on large corpora\")\nprint(\" - Available in multiple dimensions\")\n\nprint(\"\\nFastText:\")\nprint(\" - Subword information\")\nprint(\" - Handles out-of-vocabulary words\")\nprint(\" - Character n-grams\")\n\nprint(\"\\nApplications:\")\nprint(\" - Word similarity\")\nprint(\" - Text classification\")\nprint(\" - Semantic analysis\")\nprint(\" - Transfer learning\")\n\nprint(\"\\n\u2705 Pre-trained embeddings concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gensim.models\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/applying_dimensionality_reduction_on_high_dimensional_vectors_and_visualizing_re.ipynb",
      "status": "passed",
      "execution_time": 1.834512710571289,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/implementing_basic_text_processing_techniques_using_nltk_and_spacy.ipynb",
      "status": "passed",
      "execution_time": 1.6250360012054443,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/implementing_bert_embeddings_using_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.6844286918640137,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/performing_tokenization_stemming_and_lemmatization_on_sample_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.3263680934906006,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/writing_a_simple_text_conversion_script_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.4013569355010986,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/exercises/01_tokenization_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.865539789199829,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/solutions/01_tokenization_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5378799438476562,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install nltk -q\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re_nltk.download('punkt', quiet=True) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    import re_nltk.download('punkt', quiet=True) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install nltk -q\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re_nltk.download('punkt', quiet=True) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    import re_nltk.download('punkt', quiet=True) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "other"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/01_text_classification.ipynb",
      "status": "passed",
      "execution_time": 1.329071044921875,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/02_named_entity_recognition.ipynb",
      "status": "passed",
      "execution_time": 2.2906899452209473,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/03_topic_modeling_lda_nmf.ipynb",
      "status": "passed",
      "execution_time": 0.6743297576904297,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/04_model_evaluation_metrics_nlp.ipynb",
      "status": "passed",
      "execution_time": 1.4089100360870361,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/exercises/01_sentiment_classification_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.0055689811706543,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/solutions/01_sentiment_classification_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7348239421844482,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pandas scikit-learn nltk -q\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk_nltk.download('stopwords', quiet=True) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nltk_nltk.download('stopwords', quiet=True) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pandas scikit-learn nltk -q\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk_nltk.download('stopwords', quiet=True) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nltk_nltk.download('stopwords', quiet=True) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "other"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/01_rnn_lstm_nlp.ipynb",
      "status": "passed",
      "execution_time": 0.7830941677093506,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/02_lstm_text_generation.ipynb",
      "status": "passed",
      "execution_time": 0.9515032768249512,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/03_bert_advanced_usage.ipynb",
      "status": "passed",
      "execution_time": 5.450326681137085,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/04_seq2seq_attention_translation.ipynb",
      "status": "passed",
      "execution_time": 3.260944128036499,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/05_gpt_openai_text_generation.ipynb",
      "status": "passed",
      "execution_time": 0.6115007400512695,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/06_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 0.646414041519165,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/07_building_simple_chatbot.ipynb",
      "status": "passed",
      "execution_time": 0.6371300220489502,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/building_a_simple_chatbot.ipynb",
      "status": "passed",
      "execution_time": 1.7130448818206787,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/building_an_lstm_based_text_classifier_using_tensorflowkeras.ipynb",
      "status": "passed",
      "execution_time": 1.5184228420257568,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/fine_tuning_bert_model_for_text_classification_using_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.6986491680145264,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/implementing_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 1.5462470054626465,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/exercises/01_ner_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.4967799186706543,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/solutions/01_ner_solution.ipynb",
      "status": "failed",
      "execution_time": 1.4362380504608154,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install spacy -q\n# Note: Requires: python -m spacy download en_core_web_sm\nimport spacy_\nprint('\ud83d\udcdd NER Solution Concept:')\nprint('\\n1. Load spaCy model: nlp = spacy.load(\"en_core_web_sm\")')\nprint('2. Process text: doc = nlp(text)')\nprint('3. Extract entities: doc.ents')\nprint('4. Classify: entity.label_')\nprint('\\n\u2705 NER solution understood!')\nprint('\\nReal-world: Extract key information from news articles')\n------------------\n\n----- stdout -----\nNote: you may need to restart the kernel to use updated packages.\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall spacy -q\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: Requires: python -m spacy download en_core_web_sm\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy_\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\ud83d\udcdd NER Solution Concept:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. Load spaCy model: nlp = spacy.load(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy_'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install spacy -q\n# Note: Requires: python -m spacy download en_core_web_sm\nimport spacy_\nprint('\ud83d\udcdd NER Solution Concept:')\nprint('\\n1. Load spaCy model: nlp = spacy.load(\"en_core_web_sm\")')\nprint('2. Process text: doc = nlp(text)')\nprint('3. Extract entities: doc.ents')\nprint('4. Classify: entity.label_')\nprint('\\n\u2705 NER solution understood!')\nprint('\\nReal-world: Extract key information from news articles')\n------------------\n\n----- stdout -----\nNote: you may need to restart the kernel to use updated packages.\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall spacy -q\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: Requires: python -m spacy download en_core_web_sm\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy_\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\ud83d\udcdd NER Solution Concept:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. Load spaCy model: nlp = spacy.load(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy_'\n\n",
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "other"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/01_bias_detection.ipynb",
      "status": "passed",
      "execution_time": 0.8823549747467041,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/02_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 0.8875267505645752,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/03_chatbot_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.8151299953460693,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/exercises/01_nlp_applications_ethics_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.1478941440582275,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit5-applications-ethics/solutions/01_nlp_applications_ethics_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7357571125030518,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\n%pip install nltk transformers torch pandas numpy matplotlib seaborn -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections \nimport Counter_\nprint('\u2705 Setup complete!')\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\n%pip install nltk transformers torch pandas numpy matplotlib seaborn -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections \nimport Counter_\nprint('\u2705 Setup complete!')\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "other"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/01_simple_neural_network.ipynb",
      "status": "failed",
      "execution_time": 0.6357002258300781,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x) / in enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect) / ax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2) / ax.set_xlim(0, 8) / ax.set_ylim(0, 7) / ax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold') / ax.axis('off') / plt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\") / except ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 1 - Example 1: Simple Neural Network with Keras\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\n\nThis example demonstrates:\n1. Building a simple neural network2. Training on a dataset3. Making predictions4. Evaluating the model\n\"\"\"\n\nprint(\"=\" * 60) / print(\"Example 1: Simple Neural Network with Keras\") / print(\"\u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\") / print(\"=\" * 60)\n\n# Note: This example shows the structure. Actual implementation requires TensorFlow.\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u0627\u0644\u0647\u064a\u0643\u0644. \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a \u064a\u062a\u0637\u0644\u0628 TensorFlow. print(\"\\nNeural Network Structure:\") / print(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629:\") / print(\"-\" * 60) / network_structure = \"\"\"\nModel: Sequential\n\u251c\u2500\u2500 Input Layer: 784 neurons (for 28\nx28 images)\n\u251c\u2500\u2500 Hidden Layer 1: 128 neurons, ReLU activation\n\u251c\u2500\u2500 Hidden Layer 2: 64 neurons, ReLU activation\n\u2514\u2500\u2500 Output Layer: 10 neurons, Softmax activation (for 10 classes)\n\"\"\"\n\nprint(network_structure) / print(\"\\nCode Structure (using Keras):\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0643\u0648\u062f (\u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras):\")\nprint(\"-\" * 60) / code_example = \"\"\"\nfrom tensorflow \nimport kerasf\nrom tensorflow.keras import layers\n\n# Create mode\nlm\nodel = keras.Sequential([\n layers.Dense(128, activation='relu', input_shape=(784,)),\n layers.Dense(64, activation='relu'),\n layers.Dense(10, activation='softmax')\n])\n\n# Compile mode\nlm\nodel.compile(\n optimizer='adam', loss='sparse_categorical_crossentropy',\n metrics=['accuracy']\n)\n\n# Train mode\nlm\nodel.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n# Evaluate\nloss, accuracy = model.evaluate(X_test, y_test) / print(f'Test accuracy: {accuracy}')\n\"\"\"\n\nprint(code_example) / print(\"\\nKey Concepts:\") / print(\"\u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629:\") / print(\"-\" * 60) / concepts = {\n \"Dense Layer\": \"Fully connected layer where each neuron connects to all neurons in next layer\", \"ReLU\": \"Rectified Linear Unit - activation function that outputs max(0, x)\",\n \"Softmax\": \"Activation function for multi-class classification\",\n \"Adam Optimizer\": \"Adaptive learning rate optimization algorithm\",\n \"Epochs\": \"Number of times the model sees the entire training dataset\"\n}\n\nfor concept, explanation in concepts.items():\n print(f\"\\n{concept}:\") / print(f\" {explanation}\") / print(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60) / print(\"\\nNote: Install TensorFlow to run actual code:\") / print(\"pip install tensorflow\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x) / in enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect) / ax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2) / ax.set_xlim(0, 8) / ax.set_ylim(0, 7) / ax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold') / ax.axis('off') / plt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\") / except ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 1 - Example 1: Simple Neural Network with Keras\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\n\nThis example demonstrates:\n1. Building a simple neural network2. Training on a dataset3. Making predictions4. Evaluating the model\n\"\"\"\n\nprint(\"=\" * 60) / print(\"Example 1: Simple Neural Network with Keras\") / print(\"\u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\") / print(\"=\" * 60)\n\n# Note: This example shows the structure. Actual implementation requires TensorFlow.\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u0627\u0644\u0647\u064a\u0643\u0644. \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a \u064a\u062a\u0637\u0644\u0628 TensorFlow. print(\"\\nNeural Network Structure:\") / print(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629:\") / print(\"-\" * 60) / network_structure = \"\"\"\nModel: Sequential\n\u251c\u2500\u2500 Input Layer: 784 neurons (for 28\nx28 images)\n\u251c\u2500\u2500 Hidden Layer 1: 128 neurons, ReLU activation\n\u251c\u2500\u2500 Hidden Layer 2: 64 neurons, ReLU activation\n\u2514\u2500\u2500 Output Layer: 10 neurons, Softmax activation (for 10 classes)\n\"\"\"\n\nprint(network_structure) / print(\"\\nCode Structure (using Keras):\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0643\u0648\u062f (\u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras):\")\nprint(\"-\" * 60) / code_example = \"\"\"\nfrom tensorflow \nimport kerasf\nrom tensorflow.keras import layers\n\n# Create mode\nlm\nodel = keras.Sequential([\n layers.Dense(128, activation='relu', input_shape=(784,)),\n layers.Dense(64, activation='relu'),\n layers.Dense(10, activation='softmax')\n])\n\n# Compile mode\nlm\nodel.compile(\n optimizer='adam', loss='sparse_categorical_crossentropy',\n metrics=['accuracy']\n)\n\n# Train mode\nlm\nodel.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n# Evaluate\nloss, accuracy = model.evaluate(X_test, y_test) / print(f'Test accuracy: {accuracy}')\n\"\"\"\n\nprint(code_example) / print(\"\\nKey Concepts:\") / print(\"\u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629:\") / print(\"-\" * 60) / concepts = {\n \"Dense Layer\": \"Fully connected layer where each neuron connects to all neurons in next layer\", \"ReLU\": \"Rectified Linear Unit - activation function that outputs max(0, x)\",\n \"Softmax\": \"Activation function for multi-class classification\",\n \"Adam Optimizer\": \"Adaptive learning rate optimization algorithm\",\n \"Epochs\": \"Number of times the model sees the entire training dataset\"\n}\n\nfor concept, explanation in concepts.items():\n print(f\"\\n{concept}:\") / print(f\" {explanation}\") / print(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60) / print(\"\\nNote: Install TensorFlow to run actual code:\") / print(\"pip install tensorflow\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n\n",
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/02_backpropagation_detailed.ipynb",
      "status": "passed",
      "execution_time": 0.9056830406188965,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/03_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.7940108776092529,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/04_perceptron_mlp_tensorflow_pytorch_setup.ipynb",
      "status": "passed",
      "execution_time": 5.643756628036499,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/05_image_processing_feature_extraction.ipynb",
      "status": "passed",
      "execution_time": 0.8202919960021973,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/activation_functions_and_optimization_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.6685497760772705,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/deep_learning_fundamentals_compared_to_traditional_ml.ipynb",
      "status": "passed",
      "execution_time": 1.627993106842041,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/ethical_concerns_in_ai_bias_fairness_interpretability.ipynb",
      "status": "passed",
      "execution_time": 1.3369979858398438,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/forward_and_backward_propagation.ipynb",
      "status": "passed",
      "execution_time": 1.4333922863006592,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/gans_and_autoencoders_vaes.ipynb",
      "status": "passed",
      "execution_time": 1.4207241535186768,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/implementing_a_vae_variational_autoencoder_for_anomaly_detection.ipynb",
      "status": "passed",
      "execution_time": 1.4693329334259033,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/reinforcement_learning_fundamentals_deep_q_networks_policy_gradients.ipynb",
      "status": "passed",
      "execution_time": 1.5860710144042969,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/exercises/01_neural_network_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.4506020545959473,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/solutions/01_neural_network_solution.ipynb",
      "status": "passed",
      "execution_time": 2.0237419605255127,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "other"
    },
    {
      "path": "Course 08/unit2-cnns/examples/01_cnn_architecture.ipynb",
      "status": "failed",
      "execution_time": 0.7387371063232422,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x) / in enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect) / ax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2) / ax.set_xlim(0, 8) / ax.set_ylim(0, 7) / ax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold') / ax.axis('off') / plt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\") / except ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 2 - Example 1: CNN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\n\nThis example demonstrates:\n1. CNN architecture components2. Convolution and pooling operations\n3. Building a simple CNN\n\"\"\"\n\nprint(\"=\" * 60) / print(\"Example 1: CNN Architecture\") / print(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\") / print(\"=\" * 60)\n\n# 1. CNN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a CN\nNp\nrint(\"\\n1. CNN Architecture Components\") / print(\"\u0645\u0643\u0648\u0646\u0627\u062a \u0647\u064a\u0643\u0644 CNN\") / print(\"-\" * 60) / cnn_components = \"\"\"\nCNN Architecture:\n1. Convolutional Layers - Detect features (edges, shapes)\n2. Pooling Layers - Reduce dimensionality (Max, Average)\n3. Fully Connected Layers - Classification4. Activation Functions - ReLU, Softmax\n\n\u0647\u064a\u0643\u0644 CNN:\n1. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 - \u0627\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0645\u064a\u0632\u0627\u062a (\u0627\u0644\u062d\u0648\u0627\u0641\u060c \u0627\u0644\u0623\u0634\u0643\u0627\u0644)\n2. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 - \u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f (\u0627\u0644\u062d\u062f \u0627\u0644\u0623\u0642\u0635\u0649\u060c \u0627\u0644\u0645\u062a\u0648\u0633\u0637)\n3. \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0628\u0627\u0644\u0643\u0627\u0645\u0644 - \u0627\u0644\u062a\u0635\u0646\u064a\u06414. \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 - ReLU\u060c Softmax\n\"\"\"\n\nprint(cnn_components)\n\n# 2. Convolution Operation\n# \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641p\nrint(\"\\n\" + \"=\" * 60) / print(\"2. Convolution Operation\") / print(\"\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641\") / print(\"=\" * 60) / def simple_convolution_example():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Demonstrate convolution concept.\n \u062a\u0648\u0636\u064a\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641.\n \"\"\"\n # Simple 3\nx3 imag\neimage = [\n [1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]\n ]\n \n # 2\nx2 filter (kernel) / filter_kernel = [\n [1, 0],\n [0, -1]\n ]\n \n print(\"\\nImage (3\\nx3):\")\n for row in image:\n print(f\" {row}\") / print(\"\\nFilter (2\\nx2):\")\n for row in filter_kernel:\n print(f\" {row}\")\n \n # Apply convolution (simplified) / result = []\n for i in range(len(image) - 1):\n row_result = []\n for j in range(len(image[0]) - 1):\n # Element-wise multiplication and sum\n conv_value = (image[i][j] * filter_kernel[0][0] +\n image[i][j+1] * filter_kernel[0][1] +\n image[i+1][j] * filter_kernel[1][0] +\n image[i+1][j+1] * filter_kernel[1][1]) / row_result.append(conv_value) / result.append(row_result) / print(\"\\nConvolution Result (2\\nx2):\")\n for row in result:\n print(f\" {row}\") / simple_convolution_example()\n\n# 3. CNN Architecture Example\n# \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CN\nNp\nrint(\"\\n\" + \"=\" * 60) / print(\"3. CNN Architecture Example\") / print(\"\u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CNN\") / print(\"=\" * 60) / cnn_architecture = \"\"\"\nSimple CNN for Image Classification:\n\nInput (28\nx28\nx1) # Grayscale image\n \u2193\nConv2\nD (32 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nConv2\nD (64 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nFlatten\n \u2193\nDense (128) + ReLU\n \u2193\nDense (10) + Softmax # 10 classes\n \u2193\nOutput (10 classes)\n\"\"\"\n\nprint(cnn_architecture)\n\n# 4. Transfer Learning Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644p\nrint(\"\\n\" + \"=\" * 60) / print(\"4. Transfer Learning\") / print(\"\u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644\") / print(\"=\" * 60) / transfer_learning = \"\"\"\nTransfer Learning Process:\n1. Use pre-trained model (e.g., ResNet, VGG)\n2. Remove final classification layer3. Add new layers for your task\n4. Fine-tune on your dataset5. Much faster than training from scratch!\n\n\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644:\n1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0645\u0648\u0630\u062c \u0645\u062f\u0631\u0628 \u0645\u0633\u0628\u0642\u0627\u064b (\u0645\u062b\u0644 ResNet\u060c VGG)\n2. \u0625\u0632\u0627\u0644\u0629 \u0637\u0628\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0646\u0647\u0627\u0626\u064a\u06293. \u0625\u0636\u0627\u0641\u0629 \u0637\u0628\u0642\u0627\u062a \u062c\u062f\u064a\u062f\u0629 \u0644\u0645\u0647\u0645\u062a\u06434. \u0627\u0644\u0636\u0628\u0637 \u0627\u0644\u062f\u0642\u064a\u0642 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u062a\u06435. \u0623\u0633\u0631\u0639 \u0628\u0643\u062b\u064a\u0631 \u0645\u0646 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631!\n\"\"\"\n\nprint(transfer_learning) / print(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60) / print(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x) / in enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect) / ax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2) / ax.set_xlim(0, 8) / ax.set_ylim(0, 7) / ax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold') / ax.axis('off') / plt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\") / except ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 2 - Example 1: CNN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\n\nThis example demonstrates:\n1. CNN architecture components2. Convolution and pooling operations\n3. Building a simple CNN\n\"\"\"\n\nprint(\"=\" * 60) / print(\"Example 1: CNN Architecture\") / print(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\") / print(\"=\" * 60)\n\n# 1. CNN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a CN\nNp\nrint(\"\\n1. CNN Architecture Components\") / print(\"\u0645\u0643\u0648\u0646\u0627\u062a \u0647\u064a\u0643\u0644 CNN\") / print(\"-\" * 60) / cnn_components = \"\"\"\nCNN Architecture:\n1. Convolutional Layers - Detect features (edges, shapes)\n2. Pooling Layers - Reduce dimensionality (Max, Average)\n3. Fully Connected Layers - Classification4. Activation Functions - ReLU, Softmax\n\n\u0647\u064a\u0643\u0644 CNN:\n1. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 - \u0627\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0645\u064a\u0632\u0627\u062a (\u0627\u0644\u062d\u0648\u0627\u0641\u060c \u0627\u0644\u0623\u0634\u0643\u0627\u0644)\n2. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 - \u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f (\u0627\u0644\u062d\u062f \u0627\u0644\u0623\u0642\u0635\u0649\u060c \u0627\u0644\u0645\u062a\u0648\u0633\u0637)\n3. \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0628\u0627\u0644\u0643\u0627\u0645\u0644 - \u0627\u0644\u062a\u0635\u0646\u064a\u06414. \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 - ReLU\u060c Softmax\n\"\"\"\n\nprint(cnn_components)\n\n# 2. Convolution Operation\n# \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641p\nrint(\"\\n\" + \"=\" * 60) / print(\"2. Convolution Operation\") / print(\"\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641\") / print(\"=\" * 60) / def simple_convolution_example():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Demonstrate convolution concept.\n \u062a\u0648\u0636\u064a\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641.\n \"\"\"\n # Simple 3\nx3 imag\neimage = [\n [1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]\n ]\n \n # 2\nx2 filter (kernel) / filter_kernel = [\n [1, 0],\n [0, -1]\n ]\n \n print(\"\\nImage (3\\nx3):\")\n for row in image:\n print(f\" {row}\") / print(\"\\nFilter (2\\nx2):\")\n for row in filter_kernel:\n print(f\" {row}\")\n \n # Apply convolution (simplified) / result = []\n for i in range(len(image) - 1):\n row_result = []\n for j in range(len(image[0]) - 1):\n # Element-wise multiplication and sum\n conv_value = (image[i][j] * filter_kernel[0][0] +\n image[i][j+1] * filter_kernel[0][1] +\n image[i+1][j] * filter_kernel[1][0] +\n image[i+1][j+1] * filter_kernel[1][1]) / row_result.append(conv_value) / result.append(row_result) / print(\"\\nConvolution Result (2\\nx2):\")\n for row in result:\n print(f\" {row}\") / simple_convolution_example()\n\n# 3. CNN Architecture Example\n# \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CN\nNp\nrint(\"\\n\" + \"=\" * 60) / print(\"3. CNN Architecture Example\") / print(\"\u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CNN\") / print(\"=\" * 60) / cnn_architecture = \"\"\"\nSimple CNN for Image Classification:\n\nInput (28\nx28\nx1) # Grayscale image\n \u2193\nConv2\nD (32 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nConv2\nD (64 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nFlatten\n \u2193\nDense (128) + ReLU\n \u2193\nDense (10) + Softmax # 10 classes\n \u2193\nOutput (10 classes)\n\"\"\"\n\nprint(cnn_architecture)\n\n# 4. Transfer Learning Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644p\nrint(\"\\n\" + \"=\" * 60) / print(\"4. Transfer Learning\") / print(\"\u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644\") / print(\"=\" * 60) / transfer_learning = \"\"\"\nTransfer Learning Process:\n1. Use pre-trained model (e.g., ResNet, VGG)\n2. Remove final classification layer3. Add new layers for your task\n4. Fine-tune on your dataset5. Much faster than training from scratch!\n\n\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644:\n1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0645\u0648\u0630\u062c \u0645\u062f\u0631\u0628 \u0645\u0633\u0628\u0642\u0627\u064b (\u0645\u062b\u0644 ResNet\u060c VGG)\n2. \u0625\u0632\u0627\u0644\u0629 \u0637\u0628\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0646\u0647\u0627\u0626\u064a\u06293. \u0625\u0636\u0627\u0641\u0629 \u0637\u0628\u0642\u0627\u062a \u062c\u062f\u064a\u062f\u0629 \u0644\u0645\u0647\u0645\u062a\u06434. \u0627\u0644\u0636\u0628\u0637 \u0627\u0644\u062f\u0642\u064a\u0642 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u062a\u06435. \u0623\u0633\u0631\u0639 \u0628\u0643\u062b\u064a\u0631 \u0645\u0646 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631!\n\"\"\"\n\nprint(transfer_learning) / print(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60) / print(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n\n",
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/02_cnn_advanced_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.7748780250549316,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/03_transfer_learning_cnns.ipynb",
      "status": "passed",
      "execution_time": 0.900162935256958,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/04_pretrained_cnn_architectures.ipynb",
      "status": "passed",
      "execution_time": 3.1972639560699463,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/05_training_cnn_image_datasets.ipynb",
      "status": "passed",
      "execution_time": 3.345449924468994,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/06_transfer_learning_object_detection.ipynb",
      "status": "passed",
      "execution_time": 3.3740291595458984,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/cnn_architecture_convolutional_layers_pooling_layers_fully_connected_layers.ipynb",
      "status": "passed",
      "execution_time": 1.73777174949646,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/image_processing_fundamentals_and_feature_extraction.ipynb",
      "status": "passed",
      "execution_time": 1.544914960861206,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/implementing_a_cnn_from_scratch_using_tensorflowpytorch.ipynb",
      "status": "passed",
      "execution_time": 1.7220499515533447,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/introduction_to_pre_trained_cnn_architectures_resnet_vgg_inception.ipynb",
      "status": "passed",
      "execution_time": 1.6728301048278809,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/training_a_cnn_on_image_datasets_eg_cifar_10_imagenet.ipynb",
      "status": "passed",
      "execution_time": 1.5339279174804688,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/exercises/01_cnn_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.160975933074951,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit2-cnns/solutions/01_cnn_solution.ipynb",
      "status": "passed",
      "execution_time": 2.148164987564087,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "other"
    },
    {
      "path": "Course 08/unit3-rnns/examples/01_rnn_basics.ipynb",
      "status": "passed",
      "execution_time": 0.7440700531005859,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/02_lstm_advanced.ipynb",
      "status": "passed",
      "execution_time": 0.6693732738494873,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/03_sequence_to_sequence.ipynb",
      "status": "passed",
      "execution_time": 0.9050118923187256,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/04_text_generation_rnn_lstm_gru.ipynb",
      "status": "passed",
      "execution_time": 3.32966685295105,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/05_transformer_models_bert_gpt_nlp.ipynb",
      "status": "passed",
      "execution_time": 6.2275049686431885,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/06_sentiment_analysis_translation_speech.ipynb",
      "status": "passed",
      "execution_time": 5.543642044067383,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/advanced_architectures_lstm_gru_transformers_attention_mechanism.ipynb",
      "status": "passed",
      "execution_time": 1.6892788410186768,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/applications_in_nlp.ipynb",
      "status": "passed",
      "execution_time": 1.5374729633331299,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/implementing_rnn_lstm_and_gru_for_text_generation.ipynb",
      "status": "passed",
      "execution_time": 1.6274168491363525,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/performing_sentiment_analysis_machine_translation_and_speech_recognition.ipynb",
      "status": "passed",
      "execution_time": 1.575103998184204,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/rnn_structure_and_challenges_vanishing_gradients_problem.ipynb",
      "status": "passed",
      "execution_time": 1.593407154083252,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/understanding_sequential_data_and_time_series_prediction.ipynb",
      "status": "passed",
      "execution_time": 1.4960949420928955,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/using_transformer_models_like_bert_and_gpt_for_nlp_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.5400052070617676,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/exercises/01_rnn_exercise.ipynb",
      "status": "failed",
      "execution_time": 2.6257238388061523,
      "error": "An error occurred while executing the following cell:\n------------------\n# TODO: Generate synthetic time series data\n# Hint: Use sine wave + trend + noise\ndef generate_stock_data(n_samples=1000):\n # YOUR CODE HERE\n pass\n\n# Test\ndata = generate_stock_data()\nplt.plot(data[:100])\nplt.title('Stock Price Data')\nplt.show()\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_stock_data()\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Price Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# TODO: Generate synthetic time series data\n# Hint: Use sine wave + trend + noise\ndef generate_stock_data(n_samples=1000):\n # YOUR CODE HERE\n pass\n\n# Test\ndata = generate_stock_data()\nplt.plot(data[:100])\nplt.title('Stock Price Data')\nplt.show()\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_stock_data()\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Price Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit3-rnns/solutions/01_rnn_solution.ipynb",
      "status": "failed",
      "execution_time": 2.2499661445617676,
      "error": "An error occurred while executing the following cell:\n------------------\ndef generate_stock_data(n_samples=1000):\n    \n    \n    \n    \"\"\"Generate synthetic stock price data\"\"\"\n_t =  np.linspace(0, 100, n_samples)\n    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t / 50)\n    trend = 0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t / 50)_noise =  np.random.normal(0, 2, n_samples)\n    noise = np.random.normal(0, 2, n_samples)\n    return trend + seasonality + noise + 100_data = generate_stock_data()\nplt.figure(figsize=(12, 4))\nplt.plot(data[:200])\nplt.title('Synthetic Stock Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.grid(True)\nplt.show()\nprint(f'\u2705 Generated {len(data)} samples')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t / 50)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\ndef generate_stock_data(n_samples=1000):\n    \n    \n    \n    \"\"\"Generate synthetic stock price data\"\"\"\n_t =  np.linspace(0, 100, n_samples)\n    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t / 50)\n    trend = 0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t / 50)_noise =  np.random.normal(0, 2, n_samples)\n    noise = np.random.normal(0, 2, n_samples)\n    return trend + seasonality + noise + 100_data = generate_stock_data()\nplt.figure(figsize=(12, 4))\nplt.plot(data[:200])\nplt.title('Synthetic Stock Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.grid(True)\nplt.show()\nprint(f'\u2705 Generated {len(data)} samples')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t / 50)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "other"
    },
    {
      "path": "Course 08/unit4-transformers/examples/01_transformer_attention.ipynb",
      "status": "passed",
      "execution_time": 0.6647791862487793,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/examples/02_bert_finetuning.ipynb",
      "status": "passed",
      "execution_time": 0.6478970050811768,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/examples/03_gpt_text_generation.ipynb",
      "status": "failed",
      "execution_time": 0.703822135925293,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch datasets -q\n\nimport torch\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers \nimport Trainer, TrainingArguments\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch datasets -q\n\nimport torch\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers \nimport Trainer, TrainingArguments\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/exercises/01_transformer_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.7976901531219482,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit4-transformers/solutions/01_transformer_solution.ipynb",
      "status": "failed",
      "execution_time": 0.8261740207672119,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Use pre-trained translation model_model_name = 'Helsinki-NLP/opus-mt-en-de'\ntokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name) / model = MarianMTModel.from_pretrained(model_name) / print('\u2705 Translation model loaded') / print('\\nTeaching Notes: Use pre-trained transformer models for translation') / print('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name) / model = MarianMTModel.from_pretrained(model_name) / print('\u2705 Translation model loaded') / print('\\nTeaching Notes: Use pre-trained transformer models for translation') / print('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Use pre-trained translation model_model_name = 'Helsinki-NLP/opus-mt-en-de'\ntokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name) / model = MarianMTModel.from_pretrained(model_name) / print('\u2705 Translation model loaded') / print('\\nTeaching Notes: Use pre-trained transformer models for translation') / print('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name) / model = MarianMTModel.from_pretrained(model_name) / print('\u2705 Translation model loaded') / print('\\nTeaching Notes: Use pre-trained transformer models for translation') / print('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "other"
    },
    {
      "path": "Course 08/unit5-deployment/examples/01_model_optimization.ipynb",
      "status": "passed",
      "execution_time": 0.7859899997711182,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/02_tensorflow_serving.ipynb",
      "status": "failed",
      "execution_time": 4.707512855529785,
      "error": "An error occurred while executing the following cell:\n------------------\n# Create a simple model for demonstration\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n tf.keras.layers.Dense(32, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Save in SavedModel format\nmodel_path = './saved_model'\nmodel.save(model_path, save_format='tf')\nprint(f'\u2705 Model saved to {model_path}')\n------------------\n\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save in SavedModel format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\u2705 Model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:69\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend removing this argument as it can be inferred \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the file path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\n\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Create a simple model for demonstration\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n tf.keras.layers.Dense(32, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Save in SavedModel format\nmodel_path = './saved_model'\nmodel.save(model_path, save_format='tf')\nprint(f'\u2705 Model saved to {model_path}')\n------------------\n\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save in SavedModel format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\u2705 Model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:69\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend removing this argument as it can be inferred \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the file path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\n\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf\n\n",
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/03_onnx_conversion.ipynb",
      "status": "failed",
      "execution_time": 0.6362512111663818,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch onnx onnxruntime -q\nimport torch\nimport torch.nn as nn\nimport onnx\nimport onnxruntime as ortprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import onnxruntime as ortprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch onnx onnxruntime -q\nimport torch\nimport torch.nn as nn\nimport onnx\nimport onnxruntime as ortprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import onnxruntime as ortprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/04_model_pruning.ipynb",
      "status": "passed",
      "execution_time": 0.8962218761444092,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/05_model_distillation.ipynb",
      "status": "passed",
      "execution_time": 0.8888249397277832,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/06_flask_fastapi_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.9885890483856201,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/07_model_optimization_quantization.ipynb",
      "status": "passed",
      "execution_time": 3.3471920490264893,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/cloud_deployment_of_deep_learning_models.ipynb",
      "status": "passed",
      "execution_time": 1.5587430000305176,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/model_compression_for_edge_devices.ipynb",
      "status": "passed",
      "execution_time": 1.5412871837615967,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/optimizing_deep_learning_models_using_regularization.ipynb",
      "status": "passed",
      "execution_time": 1.5756893157958984,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/regularization_and_hyperparameter_tuning.ipynb",
      "status": "passed",
      "execution_time": 1.5399460792541504,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/regularization_techniques_dropout_batch_normalization.ipynb",
      "status": "passed",
      "execution_time": 1.377579927444458,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/exercises/01_deep_learning_model_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.758185863494873,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit5-deployment/solutions/01_deep_learning_model_deployment_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7457830905914307,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "other"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/01_mdp_example.ipynb",
      "status": "passed",
      "execution_time": 0.7891590595245361,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/02_mdp_solving.ipynb",
      "status": "passed",
      "execution_time": 0.8349471092224121,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/03_value_iteration.ipynb",
      "status": "passed",
      "execution_time": 0.754040002822876,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/04_openai_gym_setup.ipynb",
      "status": "failed",
      "execution_time": 0.8723070621490479,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Interacting with Gym Environments\")\nprint(\"=\" * 60)\n\n# Create environment\nenv = gym.make('CartPole-v1')\n\n# Reset environment\nobservation, info = env.reset()\nprint(f\"\\nInitial observation: {observation}\")\n\n# Take a few random actions\ntotal_reward = 0\nfor step in range(5):\n # Sample random action\n action = env.action_space.sample()\n \n # Take step\n observation, reward, terminated, truncated, info = env.step(action)\n \n done = terminated or truncated\n total_reward += reward\n \n print(f\"\\nStep {step + 1}:\")\n print(f\" Action: {action}\")\n print(f\" Reward: {reward}\")\n print(f\" Done: {done}\")\n print(f\" Observation: {observation[:2]}...\") # Show first 2 values\n \n if done:\n print(\" Episode ended!\")\n observation, info = env.reset()\n break\n\nprint(f\"\\nTotal reward: {total_reward}\")\nenv.close()\n\nprint(\"\\n\u2705 Environment interaction complete!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" Episode ended!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Interacting with Gym Environments\")\nprint(\"=\" * 60)\n\n# Create environment\nenv = gym.make('CartPole-v1')\n\n# Reset environment\nobservation, info = env.reset()\nprint(f\"\\nInitial observation: {observation}\")\n\n# Take a few random actions\ntotal_reward = 0\nfor step in range(5):\n # Sample random action\n action = env.action_space.sample()\n \n # Take step\n observation, reward, terminated, truncated, info = env.step(action)\n \n done = terminated or truncated\n total_reward += reward\n \n print(f\"\\nStep {step + 1}:\")\n print(f\" Action: {action}\")\n print(f\" Reward: {reward}\")\n print(f\" Done: {done}\")\n print(f\" Observation: {observation[:2]}...\") # Show first 2 values\n \n if done:\n print(\" Episode ended!\")\n observation, info = env.reset()\n break\n\nprint(f\"\\nTotal reward: {total_reward}\")\nenv.close()\n\nprint(\"\\n\u2705 Environment interaction complete!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" Episode ended!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/05_exploration_strategies_epsilon_greedy.ipynb",
      "status": "passed",
      "execution_time": 0.9596381187438965,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/06_solving_rl_problems_states_actions_rewards.ipynb",
      "status": "failed",
      "execution_time": 0.8639380931854248,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Designing Reward Functions\")\nprint(\"=\" * 60)\n\nprint(\"\\nReward Function Design Principles:\")\nprint(\" 1. Provide clear feedback (positive for good, negative for bad)\")\nprint(\" 2. Shape rewards to guide learning (sparse vs dense)\")\nprint(\" 3. Balance immediate vs long-term rewards\")\nprint(\" 4. Avoid reward hacking (unintended behaviors)\")\n\n# Test CartPole rewards\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint(\"\\nCartPole-v1 Reward Function:\")\nprint(\" +1 for each step the pole remains balanced\")\nprint(\" Episode ends when pole falls or cart goes out of bounds\")\nprint(\" Maximum reward: 500 (episode length limit)\")\n\ntotal_reward = 0\nfor step in range(10):\n action = env.action_space.sample()\n obs, reward, terminated, truncated, info = env.step(action)\n done = terminated or truncated\n total_reward += reward\n print(f\" Step {step+1}: Reward = {reward}, Total = {total_reward}\")\n if done:\n break\n\nenv.close()\n\nprint(\"\\n\u2705 Reward functions understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 27\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Designing Reward Functions\")\nprint(\"=\" * 60)\n\nprint(\"\\nReward Function Design Principles:\")\nprint(\" 1. Provide clear feedback (positive for good, negative for bad)\")\nprint(\" 2. Shape rewards to guide learning (sparse vs dense)\")\nprint(\" 3. Balance immediate vs long-term rewards\")\nprint(\" 4. Avoid reward hacking (unintended behaviors)\")\n\n# Test CartPole rewards\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint(\"\\nCartPole-v1 Reward Function:\")\nprint(\" +1 for each step the pole remains balanced\")\nprint(\" Episode ends when pole falls or cart goes out of bounds\")\nprint(\" Maximum reward: 500 (episode length limit)\")\n\ntotal_reward = 0\nfor step in range(10):\n action = env.action_space.sample()\n obs, reward, terminated, truncated, info = env.step(action)\n done = terminated or truncated\n total_reward += reward\n print(f\" Step {step+1}: Reward = {reward}, Total = {total_reward}\")\n if done:\n break\n\nenv.close()\n\nprint(\"\\n\u2705 Reward functions understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 27\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/07_mini_projects_cartpole_frozenlake_qlearning_dqn.ipynb",
      "status": "failed",
      "execution_time": 1.0237109661102295,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Q-Learning Algorithm Implementation\")\nprint(\"=\" * 60)\n\ndef epsilon_greedy_action(q_table, state, epsilon, n_actions):\n \n    \n    \"\"\"Choose action using epsilon-greedy strategy.\"\"\"\n if random.random() < epsilon:\n return random.randint(0, n_actions - 1)\n else:\n return np.argmax(q_table[state])\n\ndef q_learning_update(q_table, state, action, reward, next_state, alpha, gamma):\n \n    \n    \"\"\"\n Q-learning update rule:\n Q(s,a) = Q(s,a) + \u03b1[r + \u03b3 * max(Q(s',a')) - Q(s,a)]\n \"\"\"\n current_q = q_table[state, action]\n max_next_q = np.max(q_table[next_state])\n new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n q_table[state, action] = new_q\n return q_table\n\nprint(\"\\nQ-Learning Algorithm:\")\nprint(\" 1. Initialize Q-table (states \u00d7 actions)\")\nprint(\" 2. For each episode:\")\nprint(\" a. Initialize state\")\nprint(\" b. While not done:\")\nprint(\" - Choose action using epsilon-greedy\")\nprint(\" - Take action, observe reward and next state\")\nprint(\" - Update Q-table: Q(s,a) = Q(s,a) + \u03b1[r + \u03b3*max(Q(s',a')) - Q(s,a)]\")\nprint(\" - Set state = next_state\")\nprint(\" 3. Return Q-table\")\n\nprint(\"\\nKey Parameters:\")\nprint(\" - \u03b1 (alpha): Learning rate (0.0 to 1.0)\")\nprint(\" - \u03b3 (gamma): Discount factor (0.0 to 1.0)\")\nprint(\" - \u03b5 (epsilon): Exploration rate\")\nprint(\" - Q-table: State-action value function\")\n\nprint(\"\\n\u2705 Q-Learning algorithm understood!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    if random.random() < epsilon:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Q-Learning Algorithm Implementation\")\nprint(\"=\" * 60)\n\ndef epsilon_greedy_action(q_table, state, epsilon, n_actions):\n \n    \n    \"\"\"Choose action using epsilon-greedy strategy.\"\"\"\n if random.random() < epsilon:\n return random.randint(0, n_actions - 1)\n else:\n return np.argmax(q_table[state])\n\ndef q_learning_update(q_table, state, action, reward, next_state, alpha, gamma):\n \n    \n    \"\"\"\n Q-learning update rule:\n Q(s,a) = Q(s,a) + \u03b1[r + \u03b3 * max(Q(s',a')) - Q(s,a)]\n \"\"\"\n current_q = q_table[state, action]\n max_next_q = np.max(q_table[next_state])\n new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n q_table[state, action] = new_q\n return q_table\n\nprint(\"\\nQ-Learning Algorithm:\")\nprint(\" 1. Initialize Q-table (states \u00d7 actions)\")\nprint(\" 2. For each episode:\")\nprint(\" a. Initialize state\")\nprint(\" b. While not done:\")\nprint(\" - Choose action using epsilon-greedy\")\nprint(\" - Take action, observe reward and next state\")\nprint(\" - Update Q-table: Q(s,a) = Q(s,a) + \u03b1[r + \u03b3*max(Q(s',a')) - Q(s,a)]\")\nprint(\" - Set state = next_state\")\nprint(\" 3. Return Q-table\")\n\nprint(\"\\nKey Parameters:\")\nprint(\" - \u03b1 (alpha): Learning rate (0.0 to 1.0)\")\nprint(\" - \u03b3 (gamma): Discount factor (0.0 to 1.0)\")\nprint(\" - \u03b5 (epsilon): Exploration rate\")\nprint(\" - Q-table: State-action value function\")\n\nprint(\"\\n\u2705 Q-Learning algorithm understood!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    if random.random() < epsilon:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/exploration_strategies_programming_epsilon_greedy_strategy_and_visualizing_its_i.ipynb",
      "status": "passed",
      "execution_time": 1.6116409301757812,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/mini_projects_applying_rl_in_games_like_cartpole_and_frozenlake_implementing_q_l.ipynb",
      "status": "failed",
      "execution_time": 0.7431659698486328,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/setting_up_rl_environment_installing_openai_gym_and_using_python_based_framework.ipynb",
      "status": "failed",
      "execution_time": 0.5482029914855957,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/solving_rl_problems_defining_states_actions_and_rewards_running_rl_simulations.ipynb",
      "status": "passed",
      "execution_time": 1.4481220245361328,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/exercises/01_rl_fundamentals_and_mdps_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.6311321258544922,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/solutions/01_rl_fundamentals_and_mdps_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6290957927703857,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/01_q_learning.ipynb",
      "status": "passed",
      "execution_time": 1.010179042816162,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/02_sarsa_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.92205810546875,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/03_policy_gradient_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8089320659637451,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/04_monte_carlo_value_estimation.ipynb",
      "status": "failed",
      "execution_time": 0.822929859161377,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: First-Visit Monte Carlo Implementation\")\nprint(\"=\" * 60)\n\ndef generate_episode(policy, env, max_steps=100):\n \n    \n    \"\"\"Generate an episode following the policy.\"\"\"\n episode = []\n state = env.reset()[0] if hasattr(env.reset(), '__len__') else env.reset()\n \n for step in range(max_steps):\n # Choose action based on policy\n if isinstance(policy, dict):\n action = policy.get(state, random.choice(range(env.action_space.n)))\n else:\n action = policy(state)\n \n # Take action (simplified - assuming env.step returns tuple)\n if hasattr(env, 'step'):\n next_state, reward, done, truncated, info = env.step(action) if hasattr(env.step(action), '__len__') and len(env.step(action)) > 1 else (None, 0, True, False, {})\n if isinstance(env.step(action), tuple) and len(env.step(action)) >= 2:\n next_state, reward = env.step(action)[:2]\n done = env.step(action)[2] if len(env.step(action)) > 2 else Falseelse:\n next_state, reward, done = state, 0, Trueelse:\n next_state, reward, done = state, 0, True\n \n episode.append((state, action, reward))\n state = next_state\n \n if done:\n break\n \n return episode\n\ndef first_visit_mc(policy, env, n_episodes=1000, gamma=0.99):\n \n    \n    \"\"\"\n First-visit Monte Carlo for estimating state values.\n \"\"\"\n returns = defaultdict(list)\n V = defaultdict(float)\n \n for episode_num in range(n_episodes):\n episode = generate_episode(policy, env)\n \n # Calculate returns\n G = 0\n visited_states = set()\n \n # Process episode backwards\n for t in reversed(range(len(episode))):\n state, action, reward = episode[t]\n G = gamma * G + reward\n \n # First-visit: only update if state not visited yet in this episode\n if state not in visited_states:\n visited_states.add(state)\n returns[state].append(G)\n V[state] = np.mean(returns[state])\n \n return V, returns\n\n# Simple example: Random walk\nprint(\"\\nExample: Simple Random Walk\")\nprint(\" States: [0, 1, 2, 3, 4]\")\nprint(\" Actions: Move left (-1) or right (+1)\")\nprint(\" Goal: Estimate state values\")\n\n# Simplified environment simulation\nclass SimpleRandomWalk:\n \ndef __init__(self):\n self.state = 2\n self.n_states = 5\n \n def reset(self):\n self.state = 2\n return self.state\n \n def step(self, action):\n self.state = max(0, min(4, self.state + action))\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state in [0, 4]\n return self.state, reward, done\n \n @property\n def action_space(self):\n class Space:\n n = 2\n return Space()\n\n# Random policy\ndef random_policy(state):\n return random.choice([-1, 1])\n\nenv_simple = SimpleRandomWalk()\nV_mc, returns_mc = first_visit_mc(random_policy, env_simple, n_episodes=100, gamma=1.0)\n\nprint(f\"\\nEstimated State Values (First-Visit MC):\")\nfor state in sorted(V_mc.keys()):\n print(f\" V({state}) = {V_mc[state]:.4f} (from {len(returns_mc[state])} visits)\")\n\nprint(\"\\n\u2705 First-visit Monte Carlo implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    episode = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: First-Visit Monte Carlo Implementation\")\nprint(\"=\" * 60)\n\ndef generate_episode(policy, env, max_steps=100):\n \n    \n    \"\"\"Generate an episode following the policy.\"\"\"\n episode = []\n state = env.reset()[0] if hasattr(env.reset(), '__len__') else env.reset()\n \n for step in range(max_steps):\n # Choose action based on policy\n if isinstance(policy, dict):\n action = policy.get(state, random.choice(range(env.action_space.n)))\n else:\n action = policy(state)\n \n # Take action (simplified - assuming env.step returns tuple)\n if hasattr(env, 'step'):\n next_state, reward, done, truncated, info = env.step(action) if hasattr(env.step(action), '__len__') and len(env.step(action)) > 1 else (None, 0, True, False, {})\n if isinstance(env.step(action), tuple) and len(env.step(action)) >= 2:\n next_state, reward = env.step(action)[:2]\n done = env.step(action)[2] if len(env.step(action)) > 2 else Falseelse:\n next_state, reward, done = state, 0, Trueelse:\n next_state, reward, done = state, 0, True\n \n episode.append((state, action, reward))\n state = next_state\n \n if done:\n break\n \n return episode\n\ndef first_visit_mc(policy, env, n_episodes=1000, gamma=0.99):\n \n    \n    \"\"\"\n First-visit Monte Carlo for estimating state values.\n \"\"\"\n returns = defaultdict(list)\n V = defaultdict(float)\n \n for episode_num in range(n_episodes):\n episode = generate_episode(policy, env)\n \n # Calculate returns\n G = 0\n visited_states = set()\n \n # Process episode backwards\n for t in reversed(range(len(episode))):\n state, action, reward = episode[t]\n G = gamma * G + reward\n \n # First-visit: only update if state not visited yet in this episode\n if state not in visited_states:\n visited_states.add(state)\n returns[state].append(G)\n V[state] = np.mean(returns[state])\n \n return V, returns\n\n# Simple example: Random walk\nprint(\"\\nExample: Simple Random Walk\")\nprint(\" States: [0, 1, 2, 3, 4]\")\nprint(\" Actions: Move left (-1) or right (+1)\")\nprint(\" Goal: Estimate state values\")\n\n# Simplified environment simulation\nclass SimpleRandomWalk:\n \ndef __init__(self):\n self.state = 2\n self.n_states = 5\n \n def reset(self):\n self.state = 2\n return self.state\n \n def step(self, action):\n self.state = max(0, min(4, self.state + action))\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state in [0, 4]\n return self.state, reward, done\n \n @property\n def action_space(self):\n class Space:\n n = 2\n return Space()\n\n# Random policy\ndef random_policy(state):\n return random.choice([-1, 1])\n\nenv_simple = SimpleRandomWalk()\nV_mc, returns_mc = first_visit_mc(random_policy, env_simple, n_episodes=100, gamma=1.0)\n\nprint(f\"\\nEstimated State Values (First-Visit MC):\")\nfor state in sorted(V_mc.keys()):\n print(f\" V({state}) = {V_mc[state]:.4f} (from {len(returns_mc[state])} visits)\")\n\nprint(\"\\n\u2705 First-visit Monte Carlo implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    episode = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/05_td_algorithms_td0_nstep.ipynb",
      "status": "failed",
      "execution_time": 0.9001803398132324,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: TD(0) Implementation\")\nprint(\"=\" * 60)\n\ndef td0(policy, env_simulator, n_episodes=100, alpha=0.1, gamma=0.99):\n \n    \n    \"\"\"\n TD(0) for estimating state values.\n V(S_t) \u2190 V(S_t) + \u03b1[R_{t+1} + \u03b3V(S_{t+1}) - V(S_t)]\n \"\"\"\n V = defaultdict(float)\n \n for episode in range(n_episodes):\n state = env_simulator.reset()\n done = False\n \n while not done:\n # Choose action (simplified)\n action = policy(state) if callable(policy) else policy.get(state, 0)\n \n # Take step (simplified - assuming env interface)\n next_state, reward, done = env_simulator.step(action)\n \n # TD(0) update\n td_target = reward + gamma * V[next_state]\n td_error = td_target - V[state]\n V[state] = V[state] + alpha * td_error\n \n state = next_state\n \n return V\n\n# Simple example\nclass SimpleEnv:\n \ndef __init__(self):\n self.state = 1\n self.n_states = 5\n \n def reset(self):\n self.state = 1\n return self.state\n \n def step(self, action):\n # Simple transition: move towards goal (state 4)\n if self.state < 4:\n self.state += 1\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state == 4\n return self.state, reward, done\n\nenv = SimpleEnv()\ndef simple_policy(state):\n return 1 # Always move forward\n\nV_td0 = td0(simple_policy, env, n_episodes=100, alpha=0.1, gamma=1.0)\n\nprint(\"\\nTD(0) Estimated State Values:\")\nfor state in sorted(V_td0.keys()):\n print(f\" V({state}) = {V_td0[state]:.4f}\")\n\nprint(\"\\n\u2705 TD(0) implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    V = defaultdict(float)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: TD(0) Implementation\")\nprint(\"=\" * 60)\n\ndef td0(policy, env_simulator, n_episodes=100, alpha=0.1, gamma=0.99):\n \n    \n    \"\"\"\n TD(0) for estimating state values.\n V(S_t) \u2190 V(S_t) + \u03b1[R_{t+1} + \u03b3V(S_{t+1}) - V(S_t)]\n \"\"\"\n V = defaultdict(float)\n \n for episode in range(n_episodes):\n state = env_simulator.reset()\n done = False\n \n while not done:\n # Choose action (simplified)\n action = policy(state) if callable(policy) else policy.get(state, 0)\n \n # Take step (simplified - assuming env interface)\n next_state, reward, done = env_simulator.step(action)\n \n # TD(0) update\n td_target = reward + gamma * V[next_state]\n td_error = td_target - V[state]\n V[state] = V[state] + alpha * td_error\n \n state = next_state\n \n return V\n\n# Simple example\nclass SimpleEnv:\n \ndef __init__(self):\n self.state = 1\n self.n_states = 5\n \n def reset(self):\n self.state = 1\n return self.state\n \n def step(self, action):\n # Simple transition: move towards goal (state 4)\n if self.state < 4:\n self.state += 1\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state == 4\n return self.state, reward, done\n\nenv = SimpleEnv()\ndef simple_policy(state):\n return 1 # Always move forward\n\nV_td0 = td0(simple_policy, env, n_episodes=100, alpha=0.1, gamma=1.0)\n\nprint(\"\\nTD(0) Estimated State Values:\")\nfor state in sorted(V_td0.keys()):\n print(f\" V({state}) = {V_td0[state]:.4f}\")\n\nprint(\"\\n\u2705 TD(0) implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    V = defaultdict(float)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/06_policy_vs_value_iteration_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.710015058517456,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/applying_q_learning_and_sarsa_in_openai_gym_cartpole_frozenlake.ipynb",
      "status": "failed",
      "execution_time": 0.5512111186981201,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/comparing_policy_iteration_vs_value_iteration_through_code_based_experiments.ipynb",
      "status": "passed",
      "execution_time": 1.706489086151123,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/implementing_monte_carlo_methods_for_estimating_value_functions.ipynb",
      "status": "passed",
      "execution_time": 1.4760379791259766,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/running_td0_and_n_step_td_algorithms_in_simple_rl_environments.ipynb",
      "status": "failed",
      "execution_time": 0.5356810092926025,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/using_python_to_update_q_tables_and_display_agent_learning_progress.ipynb",
      "status": "passed",
      "execution_time": 1.704416036605835,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/exercises/01_q_learning_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.8266689777374268,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit2-policy-value/solutions/01_q_learning_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5888540744781494,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass GridWorld:\n    \n\ndef __init__(self, size=5):\n        self.size = size_self.start = (0, 0)\n        self.goal = (size-1, size-1)\n        self.agent_pos = self.start\n    \n    def reset(self):\n        self.agent_pos = self.start\n        return self.agent_pos\n    \n    def step(self, action):\n        moves = {0: (-1,0), 1: (1,0), 2: (0,-1), 3: (0,1)}\n        dx, dy = moves[action]_new_pos =  (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        new_pos = (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        \n        if 0 <= new_pos[0] < self.size and 0 <= new_pos[1] < self.size:\n            self.agent_pos = new_pos_reward = 10 if self.agent_pos == self.goal else -1_done = self.agent_pos == self.goal\n        return self.agent_pos, reward, done\n\nclass QLearningAgent:\n    \n\ndef __init__(self, n_states, n_actions, lr=0.1, gamma=0.95, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr_self.gamma = gamma_self.epsilon = epsilon\n    \n    def select_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(4)\n        return np.argmax(self.q_table[state])\n    \n    def update(self, state, action, reward, next_state, done):\n        if done:\n            target = reward\n        else:\n            target = reward + self.gamma * np.max(self.q_table[next_state])\n        self.q_table[state, action] += self.lr * (target - self.q_table[state, action])\n\nprint('\u2705 Q-learning solution implemented')\nprint('\\nTeaching Notes: Q-table updates, epsilon-greedy exploration')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def reset(self):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass GridWorld:\n    \n\ndef __init__(self, size=5):\n        self.size = size_self.start = (0, 0)\n        self.goal = (size-1, size-1)\n        self.agent_pos = self.start\n    \n    def reset(self):\n        self.agent_pos = self.start\n        return self.agent_pos\n    \n    def step(self, action):\n        moves = {0: (-1,0), 1: (1,0), 2: (0,-1), 3: (0,1)}\n        dx, dy = moves[action]_new_pos =  (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        new_pos = (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        \n        if 0 <= new_pos[0] < self.size and 0 <= new_pos[1] < self.size:\n            self.agent_pos = new_pos_reward = 10 if self.agent_pos == self.goal else -1_done = self.agent_pos == self.goal\n        return self.agent_pos, reward, done\n\nclass QLearningAgent:\n    \n\ndef __init__(self, n_states, n_actions, lr=0.1, gamma=0.95, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr_self.gamma = gamma_self.epsilon = epsilon\n    \n    def select_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(4)\n        return np.argmax(self.q_table[state])\n    \n    def update(self, state, action, reward, next_state, done):\n        if done:\n            target = reward\n        else:\n            target = reward + self.gamma * np.max(self.q_table[next_state])\n        self.q_table[state, action] += self.lr * (target - self.q_table[state, action])\n\nprint('\u2705 Q-learning solution implemented')\nprint('\\nTeaching Notes: Q-table updates, epsilon-greedy exploration')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def reset(self):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "other"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/01_dqn_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.5399112701416016,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/02_actor_critic.ipynb",
      "status": "passed",
      "execution_time": 2.4666240215301514,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/03_ppo_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.9152169227600098,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/04_training_evaluation_monitoring.ipynb",
      "status": "passed",
      "execution_time": 1.0632057189941406,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/05_optimization_experience_replay_reward_shaping.ipynb",
      "status": "passed",
      "execution_time": 0.5885970592498779,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/applications_applying_deep_rl_in_games_robotics_and_optimization_tasks_in_simula.ipynb",
      "status": "passed",
      "execution_time": 1.5081539154052734,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/handling_challenges_working_on_exploration_vs_exploitation_problems_stability_an.ipynb",
      "status": "passed",
      "execution_time": 1.601147174835205,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/implementing_deep_rl_starting_with_simple_algorithms_like_dqn_and_progressing_to.ipynb",
      "status": "passed",
      "execution_time": 4.051223993301392,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/optimization_experimenting_with_techniques_like_experience_replay_reward_shaping.ipynb",
      "status": "passed",
      "execution_time": 1.6540369987487793,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/training_and_evaluation_monitoring_learning_curves_rewards_and_stability_to_eval.ipynb",
      "status": "passed",
      "execution_time": 1.941627025604248,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/exercises/01_deep_reinforcement_learning_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7965250015258789,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit3-deep-rl/solutions/01_deep_reinforcement_learning_solution.ipynb",
      "status": "passed",
      "execution_time": 0.571868896484375,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "other"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/01_exploration_strategies.ipynb",
      "status": "passed",
      "execution_time": 0.7466480731964111,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/02_balancing_exploration.ipynb",
      "status": "passed",
      "execution_time": 2.3202900886535645,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/03_adaptive_exploration_ucb.ipynb",
      "status": "passed",
      "execution_time": 0.7573831081390381,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/04_comparing_exploration_methods.ipynb",
      "status": "passed",
      "execution_time": 0.8365492820739746,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/05_tuning_exploration_parameters.ipynb",
      "status": "passed",
      "execution_time": 0.9016220569610596,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/comparing_performance_of_different_exploration_methods.ipynb",
      "status": "passed",
      "execution_time": 1.472594976425171,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/tuning_exploration_parameters.ipynb",
      "status": "passed",
      "execution_time": 1.651399850845337,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/exercises/02_exploration_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.6453888416290283,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/solutions/02_exploration_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6147739887237549,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install numpy matplotlib -q\nimport numpy as np\nimport matplotlib.pyplot as plt_np.random.seed(42) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plt_np.random.seed(42) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install numpy matplotlib -q\nimport numpy as np\nimport matplotlib.pyplot as plt_np.random.seed(42) / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plt_np.random.seed(42) / print('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "other"
    },
    {
      "path": "Course 09/unit5-applications/examples/01_rl_applications.ipynb",
      "status": "passed",
      "execution_time": 0.7396628856658936,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/02_game_playing_agent.ipynb",
      "status": "passed",
      "execution_time": 1.268284797668457,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/03_resource_optimization.ipynb",
      "status": "passed",
      "execution_time": 1.5321128368377686,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/04_multi_agent_rl.ipynb",
      "status": "passed",
      "execution_time": 0.7703371047973633,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/05_hierarchical_rl_options.ipynb",
      "status": "passed",
      "execution_time": 0.7792880535125732,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/06_model_based_rl_world_models.ipynb",
      "status": "passed",
      "execution_time": 0.7853958606719971,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/07_model_based_vs_model_free_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.5610289573669434,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/08_goal_conditioned_rl.ipynb",
      "status": "passed",
      "execution_time": 0.776447057723999,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/building_model_based_rl_systems_with_learned_world_models.ipynb",
      "status": "passed",
      "execution_time": 1.7526390552520752,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/comparing_model_based_vs_model_free_approaches.ipynb",
      "status": "passed",
      "execution_time": 1.4577910900115967,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/experimenting_with_hierarchical_rl_using_options_framework.ipynb",
      "status": "passed",
      "execution_time": 1.5670700073242188,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/implementing_goal_conditioned_rl_for_complex_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.4212150573730469,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/implementing_multi_agent_rl_environments_and_training_cooperativecompetitive_age.ipynb",
      "status": "failed",
      "execution_time": 0.5366578102111816,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/exercises/01_rl_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.6382160186767578,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit5-applications/solutions/01_rl_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7847621440887451,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "other"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/01_generative_vs_discriminative.ipynb",
      "status": "failed",
      "execution_time": 0.7458770275115967,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values) / in enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8) / ax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12) / ax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12) / ax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20) / ax.set_xticks(x) / ax.set_xticklabels(categories) / ax.legend()\n ax.set_ylim(0, 11) / plt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\") / except ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Generative vs Discriminative Models\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\n\nThis example demonstrates:\n1. Difference between generative and discriminative models2. Simple examples of each\n3. When to use each type\n\"\"\"\n\nimport numpy as np\nfrom sklearn.naive_bayes \nimport GaussianNB # Generative\nfrom sklearn.linear_model \nimport LogisticRegression # Discriminative print(\"=\" * 60) / print(\"Example 1: Generative vs Discriminative Models\") / print(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\") / print(\"=\" * 60)\n\n# Sample data: Height and Weight to predict Gender\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629: \u0627\u0644\u0637\u0648\u0644 \u0648\u0627\u0644\u0648\u0632\u0646 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0627\u0644\u062c\u0646\u0633p\nrint(\"\\n1. Understanding the Difference\") / print(\"\u0641\u0647\u0645 \u0627\u0644\u0641\u0631\u0642\") / print(\"-\" * 60) / difference_explanation = \"\"\"\nGenerative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629):\n- Learn P(X, Y) - joint probability of features and labels\n- Can generate new data samples\n- Examples: Naive Bayes, GANs, VAEs\n\nDiscriminative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629):\n- Learn P(Y|X) - conditional probability of labels given features\n- Focus on decision boundary\n- Examples: Logistic Regression, SVM, Neural Networks\n\"\"\"\n\nprint(difference_explanation)\n\n# Example: Simple classification proble\nmp\nrint(\"\\n\" + \"=\" * 60) / print(\"2. Practical Example\") / print(\"\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u064a\") / print(\"=\" * 60)\n\n# Generate sample data\n# \u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629np.random.seed(42) / n_samples = 100\n\n# Male: taller and heavier on average\n# \u0627\u0644\u0630\u0643\u0648\u0631: \u0623\u0637\u0648\u0644 \u0648\u0623\u062b\u0642\u0644 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637m\nale_height = np.random.normal(175, 7, n_samples // 2) / male_weight = np.random.normal(80, 10, n_samples // 2) / male_data = np.column_stack([male_height, male_weight])\n\n# Female: shorter and lighter on average\n# \u0627\u0644\u0625\u0646\u0627\u062b: \u0623\u0642\u0635\u0631 \u0648\u0623\u062e\u0641 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637f\nemale_height = np.random.normal(165, 6, n_samples // 2) / female_weight = np.random.normal(65, 8, n_samples // 2) / female_data = np.column_stack([female_height, female_weight])\n\n# Combine data\nX = np.vstack([male_data, female_data]) / y = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\nprint(f\"\\nDataset created: {len(X)} samples\")\nprint(f\"Features: Height (cm), Weight (kg)\")\nprint(f\"Labels: 0 = Male, 1 = Female\")\n\n# Generative Model: Naive Baye\nsp\nrint(\"\\n\" + \"-\" * 60) / print(\"Generative Model: Naive Bayes\") / print(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a: Naive Bayes\") / print(\"-\" * 60) / generative_model = GaussianNB()\ngenerative_model.fit(X, y) / print(\"\u2713 Naive Bayes trained (learns P(X, Y))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 Naive Bayes (\u064a\u062a\u0639\u0644\u0645 P(X, Y))\")\n\n# Discriminative Model: Logistic Regression\nprint(\"\\n\" + \"-\" * 60) / print(\"Discriminative Model: Logistic Regression\") / print(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a: \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\") / print(\"-\" * 60) / discriminative_model = LogisticRegression()\ndiscriminative_model.fit(X, y) / print(\"\u2713 Logistic Regression trained (learns P(Y|X))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a (\u064a\u062a\u0639\u0644\u0645 P(Y|X))\")\n\n# Make prediction\nsp\nrint(\"\\n\" + \"=\" * 60) / print(\"3. Predictions\") / print(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\") / print(\"=\" * 60) / test_samples = np.array([\n [170, 75], # Average\n [180, 85], # Likely male\n [160, 60] # Likely female\n]) / gen_predictions = generative_model.predict(test_samples) / disc_predictions = discriminative_model.predict(test_samples) / print(\"\\nTest samples:\") / for i, sample in enumerate(test_samples):\n gen_pred = \"Male\" if gen_predictions[i] == 0 else \"Female\"\n disc_pred = \"Male\" if disc_predictions[i] == 0 else \"Female\"\n print(f\"\\nSample {i+1}: Height={sample[0]}\ncm, Weight={sample[1]}\nkg\") / print(f\" Generative (Naive Bayes): {gen_pred}\")\n print(f\" Discriminative (Logistic): {disc_pred}\")\n\nprint(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values) / in enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8) / ax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12) / ax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12) / ax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20) / ax.set_xticks(x) / ax.set_xticklabels(categories) / ax.legend()\n ax.set_ylim(0, 11) / plt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\") / except ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Generative vs Discriminative Models\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\n\nThis example demonstrates:\n1. Difference between generative and discriminative models2. Simple examples of each\n3. When to use each type\n\"\"\"\n\nimport numpy as np\nfrom sklearn.naive_bayes \nimport GaussianNB # Generative\nfrom sklearn.linear_model \nimport LogisticRegression # Discriminative print(\"=\" * 60) / print(\"Example 1: Generative vs Discriminative Models\") / print(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\") / print(\"=\" * 60)\n\n# Sample data: Height and Weight to predict Gender\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629: \u0627\u0644\u0637\u0648\u0644 \u0648\u0627\u0644\u0648\u0632\u0646 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0627\u0644\u062c\u0646\u0633p\nrint(\"\\n1. Understanding the Difference\") / print(\"\u0641\u0647\u0645 \u0627\u0644\u0641\u0631\u0642\") / print(\"-\" * 60) / difference_explanation = \"\"\"\nGenerative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629):\n- Learn P(X, Y) - joint probability of features and labels\n- Can generate new data samples\n- Examples: Naive Bayes, GANs, VAEs\n\nDiscriminative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629):\n- Learn P(Y|X) - conditional probability of labels given features\n- Focus on decision boundary\n- Examples: Logistic Regression, SVM, Neural Networks\n\"\"\"\n\nprint(difference_explanation)\n\n# Example: Simple classification proble\nmp\nrint(\"\\n\" + \"=\" * 60) / print(\"2. Practical Example\") / print(\"\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u064a\") / print(\"=\" * 60)\n\n# Generate sample data\n# \u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629np.random.seed(42) / n_samples = 100\n\n# Male: taller and heavier on average\n# \u0627\u0644\u0630\u0643\u0648\u0631: \u0623\u0637\u0648\u0644 \u0648\u0623\u062b\u0642\u0644 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637m\nale_height = np.random.normal(175, 7, n_samples // 2) / male_weight = np.random.normal(80, 10, n_samples // 2) / male_data = np.column_stack([male_height, male_weight])\n\n# Female: shorter and lighter on average\n# \u0627\u0644\u0625\u0646\u0627\u062b: \u0623\u0642\u0635\u0631 \u0648\u0623\u062e\u0641 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637f\nemale_height = np.random.normal(165, 6, n_samples // 2) / female_weight = np.random.normal(65, 8, n_samples // 2) / female_data = np.column_stack([female_height, female_weight])\n\n# Combine data\nX = np.vstack([male_data, female_data]) / y = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\nprint(f\"\\nDataset created: {len(X)} samples\")\nprint(f\"Features: Height (cm), Weight (kg)\")\nprint(f\"Labels: 0 = Male, 1 = Female\")\n\n# Generative Model: Naive Baye\nsp\nrint(\"\\n\" + \"-\" * 60) / print(\"Generative Model: Naive Bayes\") / print(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a: Naive Bayes\") / print(\"-\" * 60) / generative_model = GaussianNB()\ngenerative_model.fit(X, y) / print(\"\u2713 Naive Bayes trained (learns P(X, Y))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 Naive Bayes (\u064a\u062a\u0639\u0644\u0645 P(X, Y))\")\n\n# Discriminative Model: Logistic Regression\nprint(\"\\n\" + \"-\" * 60) / print(\"Discriminative Model: Logistic Regression\") / print(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a: \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\") / print(\"-\" * 60) / discriminative_model = LogisticRegression()\ndiscriminative_model.fit(X, y) / print(\"\u2713 Logistic Regression trained (learns P(Y|X))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a (\u064a\u062a\u0639\u0644\u0645 P(Y|X))\")\n\n# Make prediction\nsp\nrint(\"\\n\" + \"=\" * 60) / print(\"3. Predictions\") / print(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\") / print(\"=\" * 60) / test_samples = np.array([\n [170, 75], # Average\n [180, 85], # Likely male\n [160, 60] # Likely female\n]) / gen_predictions = generative_model.predict(test_samples) / disc_predictions = discriminative_model.predict(test_samples) / print(\"\\nTest samples:\") / for i, sample in enumerate(test_samples):\n gen_pred = \"Male\" if gen_predictions[i] == 0 else \"Female\"\n disc_pred = \"Male\" if disc_predictions[i] == 0 else \"Female\"\n print(f\"\\nSample {i+1}: Height={sample[0]}\ncm, Weight={sample[1]}\nkg\") / print(f\" Generative (Naive Bayes): {gen_pred}\")\n print(f\" Discriminative (Logistic): {disc_pred}\")\n\nprint(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/02_generative_model_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.9636359214782715,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/03_probabilistic_generative_models.ipynb",
      "status": "passed",
      "execution_time": 0.6754729747772217,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/04_building_training_simple_gan.ipynb",
      "status": "passed",
      "execution_time": 4.281652927398682,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/05_implementing_vae_image_generation.ipynb",
      "status": "passed",
      "execution_time": 3.4891841411590576,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/06_comparing_gan_vae_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.9399752616882324,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/06_comparing_generative_models_gans_vae.ipynb",
      "status": "passed",
      "execution_time": 0.9015531539916992,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/07_training_techniques_gradient_penalties.ipynb",
      "status": "passed",
      "execution_time": 3.221209764480591,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/08_evaluating_generative_models_fid_bleu.ipynb",
      "status": "passed",
      "execution_time": 1.589569091796875,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/09_generating_samples_trained_models.ipynb",
      "status": "passed",
      "execution_time": 0.7615249156951904,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/10_exploring_latent_spaces_interpolation.ipynb",
      "status": "passed",
      "execution_time": 0.801764726638794,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/building_and_training_a_simple_gan_using_tensorflowpytorch.ipynb",
      "status": "passed",
      "execution_time": 1.5282537937164307,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/experimenting_with_training_techniques_like_gradient_penalties_and_spectral_norm.ipynb",
      "status": "passed",
      "execution_time": 1.6557180881500244,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/exploring_latent_spaces_and_interpolation_in_vaes.ipynb",
      "status": "passed",
      "execution_time": 1.7547450065612793,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/exercises/01_generative_models_fundamentals_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.6277029514312744,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/solutions/01_generative_models_fundamentals_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5915820598602295,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 10/unit2-gans/examples/01_gan_architecture.ipynb",
      "status": "failed",
      "execution_time": 0.7381889820098877,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values) / in enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8) / ax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12) / ax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12) / ax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20) / ax.set_xticks(x) / ax.set_xticklabels(categories) / ax.legend()\n ax.set_ylim(0, 11) / plt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\") / except ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 2 - Example 1: GAN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\n\nThis example demonstrates:\n1. GAN architecture components2. Generator and Discriminator3. Adversarial training concept4. Loss functions\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60) / print(\"Example 1: GAN Architecture\") / print(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\") / print(\"=\" * 60)\n\n# 1. GAN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a GA\nNp\nrint(\"\\n1. GAN Architecture\") / print(\"\u0647\u064a\u0643\u0644 GAN\") / print(\"-\" * 60) / gan_explanation = \"\"\"\nGAN consists of two networks:\n\nGenerator (\u0627\u0644\u0645\u0648\u0644\u062f):\n- Takes random noise as input\n- Generates fake data\n- Tries to fool the discriminator\n- Goal: Generate realistic data\n\nDiscriminator (\u0627\u0644\u0645\u0645\u064a\u0632):\n- Takes real or fake data as input\n- Classifies as real or fake\n- Tries to distinguish real from fake\n- Goal: Correctly identify fake data\n\nTraining Process:\n- Generator and Discriminator compete\n- Generator improves to create better fakes\n- Discriminator improves to detect fakes\n- Equilibrium: Generator creates perfect fakes\n\"\"\"\n\nprint(gan_explanation)\n\n# 2. Simple Generator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0648\u0644\u062fp\nrint(\"\\n\" + \"=\" * 60) / print(\"2. Generator Network\") / print(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0648\u0644\u062f\") / print(\"=\" * 60) / def simple_generator(noise, weights):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple generator that transforms noise to data.\n \u0645\u0648\u0644\u062f \u0628\u0633\u064a\u0637 \u064a\u062d\u0648\u0644 \u0627\u0644\u0636\u0648\u0636\u0627\u0621 \u0625\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n \"\"\"\n # Simulate: noise -> hidden -> output hidden = noise * weights[0]\n output = hidden * weights[1]\n return output\n\n# Example: Generate fake data\nnoise = np.random.randn(10) # Random noisew\neights = [2.0, 1.5] # Generator weightsf\nake_data = simple_generator(noise, weights) / print(f\"\\nInput noise shape: {noise.shape}\") / print(f\"Generated fake data shape: {fake_data.shape}\") / print(f\"Sample fake data: {fake_data[:5]}\")\n\n# 3. Simple Discriminator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0645\u064a\u0632p\nrint(\"\\n\" + \"=\" * 60) / print(\"3. Discriminator Network\") / print(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0645\u064a\u0632\") / print(\"=\" * 60) / def simple_discriminator(data, threshold=0.5):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple discriminator that classifies real vs fake.\n \u0645\u0645\u064a\u0632 \u0628\u0633\u064a\u0637 \u064a\u0635\u0646\u0641 \u0627\u0644\u062d\u0642\u064a\u0642\u064a \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0645\u0632\u064a\u0641.\n \"\"\"\n # Simple rule: if data > threshold, likely real probability = 1 / (1 + np.exp(-np.mean(data)))\n prediction = \"real\" if probability > threshold else \"fake\"\n return prediction, probability\n\n# Test discriminato\nrr\neal_data = np.random.randn(10) + 2 # Real data (shifted) / fake_data = np.random.randn(10) - 2 # Fake data (shifted) / real_pred, real_prob = simple_discriminator(real_data) / fake_pred, fake_prob = simple_discriminator(fake_data) / print(f\"\\nReal data: {real_pred} (probability: {real_prob:.3 f})\")\nprint(f\"Fake data: {fake_pred} (probability: {fake_prob:.3 f})\")\n\n# 4. Adversarial Training Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064ap\nrint(\"\\n\" + \"=\" * 60) / print(\"4. Adversarial Training\") / print(\"\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064a\") / print(\"=\" * 60) / training_concept = \"\"\"\nAdversarial Training Process:\n\nStep 1: Train Discriminator\n- Show real data \u2192 Discriminator learns real patterns\n- Show fake data \u2192 Discriminator learns to detect fakes\n\nStep 2: Train Generator\n- Generate fake data\n- Try to fool discriminator\n- Update generator to create better fakes\n\nStep 3: Repeat\n- Discriminator gets better at detection\n- Generator gets better at generation\n- Both improve together\n\nThis creates a competitive learning environment!\n\"\"\"\n\nprint(training_concept)\n\n# 5. Loss Functions\n# \u062f\u0648\u0627\u0644 \u0627\u0644\u062e\u0633\u0627\u0631\u0629p\nrint(\"\\n\" + \"=\" * 60) / print(\"5. GAN Loss Functions\") / print(\"\u062f\u0648\u0627\u0644 \u062e\u0633\u0627\u0631\u0629 GAN\") / print(\"=\" * 60) / loss_explanation = \"\"\"\nGenerator Loss:\n- Wants to maximize discriminator's error on fake data\n- Loss = -log(D(fake_data))\nDiscriminator Loss:\n- Wants to correctly classify real and fake\n- Loss = -log(D(real_data)) - log(1 - D(fake_data))\nMinimax Game:\n- Generator minimizes its loss\n- Discriminator minimizes its loss\n- Nash equilibrium when both are optimal\n\"\"\"\n\nprint(loss_explanation) / print(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60) / print(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values) / in enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8) / ax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12) / ax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12) / ax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20) / ax.set_xticks(x) / ax.set_xticklabels(categories) / ax.legend()\n ax.set_ylim(0, 11) / plt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\") / except ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 2 - Example 1: GAN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\n\nThis example demonstrates:\n1. GAN architecture components2. Generator and Discriminator3. Adversarial training concept4. Loss functions\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60) / print(\"Example 1: GAN Architecture\") / print(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\") / print(\"=\" * 60)\n\n# 1. GAN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a GA\nNp\nrint(\"\\n1. GAN Architecture\") / print(\"\u0647\u064a\u0643\u0644 GAN\") / print(\"-\" * 60) / gan_explanation = \"\"\"\nGAN consists of two networks:\n\nGenerator (\u0627\u0644\u0645\u0648\u0644\u062f):\n- Takes random noise as input\n- Generates fake data\n- Tries to fool the discriminator\n- Goal: Generate realistic data\n\nDiscriminator (\u0627\u0644\u0645\u0645\u064a\u0632):\n- Takes real or fake data as input\n- Classifies as real or fake\n- Tries to distinguish real from fake\n- Goal: Correctly identify fake data\n\nTraining Process:\n- Generator and Discriminator compete\n- Generator improves to create better fakes\n- Discriminator improves to detect fakes\n- Equilibrium: Generator creates perfect fakes\n\"\"\"\n\nprint(gan_explanation)\n\n# 2. Simple Generator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0648\u0644\u062fp\nrint(\"\\n\" + \"=\" * 60) / print(\"2. Generator Network\") / print(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0648\u0644\u062f\") / print(\"=\" * 60) / def simple_generator(noise, weights):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple generator that transforms noise to data.\n \u0645\u0648\u0644\u062f \u0628\u0633\u064a\u0637 \u064a\u062d\u0648\u0644 \u0627\u0644\u0636\u0648\u0636\u0627\u0621 \u0625\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n \"\"\"\n # Simulate: noise -> hidden -> output hidden = noise * weights[0]\n output = hidden * weights[1]\n return output\n\n# Example: Generate fake data\nnoise = np.random.randn(10) # Random noisew\neights = [2.0, 1.5] # Generator weightsf\nake_data = simple_generator(noise, weights) / print(f\"\\nInput noise shape: {noise.shape}\") / print(f\"Generated fake data shape: {fake_data.shape}\") / print(f\"Sample fake data: {fake_data[:5]}\")\n\n# 3. Simple Discriminator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0645\u064a\u0632p\nrint(\"\\n\" + \"=\" * 60) / print(\"3. Discriminator Network\") / print(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0645\u064a\u0632\") / print(\"=\" * 60) / def simple_discriminator(data, threshold=0.5):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple discriminator that classifies real vs fake.\n \u0645\u0645\u064a\u0632 \u0628\u0633\u064a\u0637 \u064a\u0635\u0646\u0641 \u0627\u0644\u062d\u0642\u064a\u0642\u064a \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0645\u0632\u064a\u0641.\n \"\"\"\n # Simple rule: if data > threshold, likely real probability = 1 / (1 + np.exp(-np.mean(data)))\n prediction = \"real\" if probability > threshold else \"fake\"\n return prediction, probability\n\n# Test discriminato\nrr\neal_data = np.random.randn(10) + 2 # Real data (shifted) / fake_data = np.random.randn(10) - 2 # Fake data (shifted) / real_pred, real_prob = simple_discriminator(real_data) / fake_pred, fake_prob = simple_discriminator(fake_data) / print(f\"\\nReal data: {real_pred} (probability: {real_prob:.3 f})\")\nprint(f\"Fake data: {fake_pred} (probability: {fake_prob:.3 f})\")\n\n# 4. Adversarial Training Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064ap\nrint(\"\\n\" + \"=\" * 60) / print(\"4. Adversarial Training\") / print(\"\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064a\") / print(\"=\" * 60) / training_concept = \"\"\"\nAdversarial Training Process:\n\nStep 1: Train Discriminator\n- Show real data \u2192 Discriminator learns real patterns\n- Show fake data \u2192 Discriminator learns to detect fakes\n\nStep 2: Train Generator\n- Generate fake data\n- Try to fool discriminator\n- Update generator to create better fakes\n\nStep 3: Repeat\n- Discriminator gets better at detection\n- Generator gets better at generation\n- Both improve together\n\nThis creates a competitive learning environment!\n\"\"\"\n\nprint(training_concept)\n\n# 5. Loss Functions\n# \u062f\u0648\u0627\u0644 \u0627\u0644\u062e\u0633\u0627\u0631\u0629p\nrint(\"\\n\" + \"=\" * 60) / print(\"5. GAN Loss Functions\") / print(\"\u062f\u0648\u0627\u0644 \u062e\u0633\u0627\u0631\u0629 GAN\") / print(\"=\" * 60) / loss_explanation = \"\"\"\nGenerator Loss:\n- Wants to maximize discriminator's error on fake data\n- Loss = -log(D(fake_data))\nDiscriminator Loss:\n- Wants to correctly classify real and fake\n- Loss = -log(D(real_data)) - log(1 - D(fake_data))\nMinimax Game:\n- Generator minimizes its loss\n- Discriminator minimizes its loss\n- Nash equilibrium when both are optimal\n\"\"\"\n\nprint(loss_explanation) / print(\"\\n\" + \"=\" * 60) / print(\"Example completed successfully!\") / print(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\") / print(\"=\" * 60) / print(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\") / print(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/02_conditional_gans.ipynb",
      "status": "passed",
      "execution_time": 0.7327427864074707,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/03_stylegan_basics.ipynb",
      "status": "passed",
      "execution_time": 0.9073009490966797,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/04_text_generation_gpt_models.ipynb",
      "status": "passed",
      "execution_time": 6.771554946899414,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/04_training_techniques_gradient_penalties.ipynb",
      "status": "passed",
      "execution_time": 0.535614013671875,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/05_fine_tuning_language_models.ipynb",
      "status": "failed",
      "execution_time": 0.744196891784668,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Configure training\")\nprint(\" 4. Train on task data\")\nprint(\" 5. Evaluate performance\")\n\nprint(\"\\nFine-tuning Strategies:\")\nprint(\" - Full fine-tuning\")\nprint(\" - LoRA (Low-Rank Adaptation)\")\nprint(\" - Prompt tuning\")\nprint(\" - Adapter layers\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Task-specific performance\")\nprint(\" - Less data needed\")\nprint(\" - Faster training\")\nprint(\" - Better results\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Configure training\")\nprint(\" 4. Train on task data\")\nprint(\" 5. Evaluate performance\")\n\nprint(\"\\nFine-tuning Strategies:\")\nprint(\" - Full fine-tuning\")\nprint(\" - LoRA (Low-Rank Adaptation)\")\nprint(\" - Prompt tuning\")\nprint(\" - Adapter layers\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Task-specific performance\")\nprint(\" - Less data needed\")\nprint(\" - Faster training\")\nprint(\" - Better results\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/05_finetuning_language_models.ipynb",
      "status": "failed",
      "execution_time": 0.8468120098114014,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Update model parameters\")\nprint(\" 4. Evaluate on task\")\nprint(\" 5. Deploy fine-tuned model\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Better task performance\")\nprint(\" - Less data needed\")\nprint(\" - Domain adaptation\")\nprint(\" - Faster training\")\n\nprint(\"\\nTasks:\")\nprint(\" - Text classification\")\nprint(\" - Question answering\")\nprint(\" - Named entity recognition\")\nprint(\" - Summarization\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Update model parameters\")\nprint(\" 4. Evaluate on task\")\nprint(\" 5. Deploy fine-tuned model\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Better task performance\")\nprint(\" - Less data needed\")\nprint(\" - Domain adaptation\")\nprint(\" - Faster training\")\n\nprint(\"\\nTasks:\")\nprint(\" - Text classification\")\nprint(\" - Question answering\")\nprint(\" - Named entity recognition\")\nprint(\" - Summarization\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/06_prompt_engineering_openai_huggingface.ipynb",
      "status": "passed",
      "execution_time": 0.8389170169830322,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/07_building_text_to_text_generation.ipynb",
      "status": "passed",
      "execution_time": 5.535973787307739,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/07_text_to_text_generation_transformers.ipynb",
      "status": "passed",
      "execution_time": 0.8135619163513184,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/08_generating_creative_text_stories_poems.ipynb",
      "status": "passed",
      "execution_time": 5.522686004638672,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/09_evaluating_text_quality_bleu_perplexity.ipynb",
      "status": "passed",
      "execution_time": 1.7036278247833252,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/building_a_text_to_text_generation_system_using_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.3338429927825928,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/evaluating_text_generation_quality_using_metrics_like_bleu_and_perplexity.ipynb",
      "status": "passed",
      "execution_time": 1.656280755996704,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/fine_tuning_language_models_for_specific_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.6663317680358887,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/generating_creative_text_stories_poems_using_language_models.ipynb",
      "status": "passed",
      "execution_time": 1.4113037586212158,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/implementing_conversational_ai_or_chatbot_using_generative_models.ipynb",
      "status": "passed",
      "execution_time": 1.540111780166626,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/implementing_text_generation_using_gpt_models.ipynb",
      "status": "passed",
      "execution_time": 1.3353288173675537,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/practicing_prompt_engineering_with_openai_api_or_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.371016025543213,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/exercises/01_gan_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.1224639415740967,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit2-gans/solutions/01_gan_solution.ipynb",
      "status": "passed",
      "execution_time": 1.6519639492034912,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "other"
    },
    {
      "path": "Course 10/unit3-vaes/examples/01_vae_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.5813298225402832,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/02_vae_applications.ipynb",
      "status": "passed",
      "execution_time": 2.3348090648651123,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/03_vae_advanced_topics.ipynb",
      "status": "passed",
      "execution_time": 1.2762560844421387,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/applying_models_like_openai_codex_or_github_copilot_for_code_generation.ipynb",
      "status": "passed",
      "execution_time": 1.4509408473968506,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/audio_and_voice_synthesis_using_ai_tools_like_wavenet_or_jukebox.ipynb",
      "status": "passed",
      "execution_time": 1.800516128540039,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/automating_code_generation_and_software_development_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.5720291137695312,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/creating_ai_generated_music_and_human_voice_synthesis.ipynb",
      "status": "passed",
      "execution_time": 1.652209758758545,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/developing_comprehensive_projects_integrating_generative_ai_in_real_world_applic.ipynb",
      "status": "passed",
      "execution_time": 1.8464229106903076,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/experimenting_with_deepfake_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.629093885421753,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/generating_ai_created_images_using_stylegan_dall_e_or_stable_diffusion.ipynb",
      "status": "passed",
      "execution_time": 1.5862162113189697,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/exercises/01_vae_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.5468809604644775,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit3-vaes/solutions/01_vae_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5457170009613037,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision matplotlib -q\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np_device = torch.device('cuda' if torch.cuda.is_available() / else 'cpu')\nprint(f'Using device: {device}') / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_device = torch.device('cuda' if torch.cuda.is_available() / else 'cpu')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision matplotlib -q\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np_device = torch.device('cuda' if torch.cuda.is_available() / else 'cpu')\nprint(f'Using device: {device}') / print('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_device = torch.device('cuda' if torch.cuda.is_available() / else 'cpu')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "other"
    },
    {
      "path": "Course 10/unit4-applications/examples/01_generative_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 0.5300006866455078,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/02_image_generation_advanced.ipynb",
      "status": "passed",
      "execution_time": 8.235460042953491,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/03_music_generation.ipynb",
      "status": "passed",
      "execution_time": 1.7324230670928955,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/04_generating_ai_images_stylegan_dalle.ipynb",
      "status": "passed",
      "execution_time": 0.6484260559082031,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/05_audio_voice_synthesis_wavenet_jukebox.ipynb",
      "status": "passed",
      "execution_time": 0.6063628196716309,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/06_code_generation_openai_codex_copilot.ipynb",
      "status": "passed",
      "execution_time": 0.6091139316558838,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/applying_ai_regulatory_guidelines_like_gdpr_to_ensure_compliance_in_model_develo.ipynb",
      "status": "passed",
      "execution_time": 1.5939650535583496,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/building_ethical_ai_models_with_principles_like_fairness_and_transparency.ipynb",
      "status": "passed",
      "execution_time": 1.6152222156524658,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/exercises/01_generation_exercise.ipynb",
      "status": "passed",
      "execution_time": 6.629025936126709,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit4-applications/solutions/01_generation_solution.ipynb",
      "status": "failed",
      "execution_time": 0.738562822341919,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n# Load pre-trained model_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprint('\u2705 Text generation model loaded')\nprint('\\nTeaching Notes: Fine-tune GPT-2 on creative writing dataset')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n# Load pre-trained model_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprint('\u2705 Text generation model loaded')\nprint('\\nTeaching Notes: Fine-tune GPT-2 on creative writing dataset')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "other"
    },
    {
      "path": "Course 10/unit5-ethics/examples/01_generative_ai_ethics.ipynb",
      "status": "passed",
      "execution_time": 0.7608492374420166,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/02_deepfake_detection.ipynb",
      "status": "passed",
      "execution_time": 1.7833788394927979,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/03_future_trends_research.ipynb",
      "status": "passed",
      "execution_time": 0.9349329471588135,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/04_detecting_mitigating_bias_generative.ipynb",
      "status": "passed",
      "execution_time": 0.7668230533599854,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/05_experimenting_advanced_generative_models.ipynb",
      "status": "passed",
      "execution_time": 0.599118709564209,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/exercises/01_generative_ai_ethics_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7112019062042236,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit5-ethics/solutions/01_generative_ai_ethics_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7383449077606201,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "other"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/01_model_serving_api.ipynb",
      "status": "passed",
      "execution_time": 1.6969490051269531,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/02_model_packaging.ipynb",
      "status": "passed",
      "execution_time": 3.9919557571411133,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/03_local_deployment_testing.ipynb",
      "status": "failed",
      "execution_time": 3.336030960083008,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom flask import Flask, request, jsonify\nimport joblib\n\n# Load model\n# model = joblib.load('model.pkl')\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n # TODO: Implement prediction endpoint\n # Handle request, make prediction, return response\n pass\n\nif __name__ == '__main__':\n app.run(debug=True, host='0.0.0.0', port=5000)\n\nprint('Local deployment server defined')\n------------------\n\n----- stdout -----\n * Serving Flask app '__main__'\n----- stdout -----\n * Debug mode: on\n----- stderr -----\nAddress already in use\nPort 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\nOn macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> General -> AirDrop & Handoff.\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n------------------\n\nAn exception has occurred, use %tb to see the full traceback.\n\n\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom flask import Flask, request, jsonify\nimport joblib\n\n# Load model\n# model = joblib.load('model.pkl')\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n # TODO: Implement prediction endpoint\n # Handle request, make prediction, return response\n pass\n\nif __name__ == '__main__':\n app.run(debug=True, host='0.0.0.0', port=5000)\n\nprint('Local deployment server defined')\n------------------\n\n----- stdout -----\n * Serving Flask app '__main__'\n----- stdout -----\n * Debug mode: on\n----- stderr -----\nAddress already in use\nPort 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\nOn macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> General -> AirDrop & Handoff.\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n------------------\n\nAn exception has occurred, use %tb to see the full traceback.\n\n\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n\n\n",
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/04_model_preparation_saving.ipynb",
      "status": "passed",
      "execution_time": 0.7246661186218262,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/05_model_validation_testing.ipynb",
      "status": "passed",
      "execution_time": 0.6940691471099854,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/06_monitoring_updating_models.ipynb",
      "status": "passed",
      "execution_time": 0.662816047668457,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/building_api_interface_for_ai_models_implementing_a_simple_api_using_flask_or_fa.ipynb",
      "status": "passed",
      "execution_time": 1.521470069885254,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/containerizing_ai_model_using_docker_packaging_ai_model_into_a_container_and_dep.ipynb",
      "status": "passed",
      "execution_time": 1.4454081058502197,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/containerizing_ai_model_using_docker_to_package_a_trained_model_for_scalable_dep.ipynb",
      "status": "passed",
      "execution_time": 1.6890618801116943,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/creating_rest_api_for_ai_model_inference_using_flask_or_fastapi_to_serve_predict.ipynb",
      "status": "passed",
      "execution_time": 1.7171928882598877,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/deploying_model_on_cloud_hosting_a_model_on_aws_google_cloud_or_azure.ipynb",
      "status": "passed",
      "execution_time": 1.6546399593353271,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/implementing_security_measures_applying_authentication_encryption_and_access_con.ipynb",
      "status": "passed",
      "execution_time": 1.4202589988708496,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/managing_ai_model_deployment_using_kubernetes_running_and_scaling_a_deployed_mod.ipynb",
      "status": "passed",
      "execution_time": 1.4765992164611816,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/model_validation_and_testing_running_unit_tests_and_performance_evaluations_befo.ipynb",
      "status": "passed",
      "execution_time": 1.3678159713745117,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/monitoring_and_logging_deployed_models_on_cloud_setting_up_logging_tracking_api_.ipynb",
      "status": "passed",
      "execution_time": 1.4665000438690186,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/monitoring_and_updating_deployed_models_implementing_logs_feedback_loops_and_ret.ipynb",
      "status": "passed",
      "execution_time": 1.6047308444976807,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/preparing_ai_model_for_deployment_training_and_saving_a_model_using_tensorflow_o.ipynb",
      "status": "passed",
      "execution_time": 1.406567096710205,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/exercises/01_packaging_exercise.ipynb",
      "status": "passed",
      "execution_time": 3.2169530391693115,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit1-deployment-basics/solutions/01_packaging_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6759459972381592,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pickle5 onnx scikit-learn joblib -q\nimport pickle\nimport joblib\nimport onnx\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Create and train model_model = RandomForestClassifier(n_estimators=100)\nX = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100) / y = np.random.randint(0, 2, 100) / model.fit(X, y)\n\n# Package in different formats_pickle.dump(model, open('model.pkl', 'wb'))\njoblib.dump(model, 'model.joblib') / print('\u2705 Model packaged in multiple formats') / print('\\nTeaching Notes: Different formats for different use cases') / print('Grading: Task 1 (40pts), Task 2 (30pts), Task 3 (30pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100) / y = np.random.randint(0, 2, 100) / model.fit(X, y)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pickle5 onnx scikit-learn joblib -q\nimport pickle\nimport joblib\nimport onnx\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Create and train model_model = RandomForestClassifier(n_estimators=100)\nX = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100) / y = np.random.randint(0, 2, 100) / model.fit(X, y)\n\n# Package in different formats_pickle.dump(model, open('model.pkl', 'wb'))\njoblib.dump(model, 'model.joblib') / print('\u2705 Model packaged in multiple formats') / print('\\nTeaching Notes: Different formats for different use cases') / print('Grading: Task 1 (40pts), Task 2 (30pts), Task 3 (30pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100) / y = np.random.randint(0, 2, 100) / model.fit(X, y)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "other"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/01_flask_api_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7374629974365234,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/02_fastapi_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.5317068099975586,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/03_model_versioning.ipynb",
      "status": "failed",
      "execution_time": 0.6599030494689941,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install mlflow -q\nimport mlflow\nimport mlflow.sklearnprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mlflow.sklearnprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install mlflow -q\nimport mlflow\nimport mlflow.sklearnprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mlflow.sklearnprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/04_saving_loading_models_pickle_onnx.ipynb",
      "status": "passed",
      "execution_time": 0.7866621017456055,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/05_tensorflow_serving_torchserve.ipynb",
      "status": "passed",
      "execution_time": 0.7411439418792725,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/06_batch_vs_realtime_inference.ipynb",
      "status": "passed",
      "execution_time": 0.7756879329681396,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/07_kubernetes_scaling.ipynb",
      "status": "passed",
      "execution_time": 0.6183772087097168,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/containerizing_ai_model_using_docker_creating_docker_image_for_trained_ai_model_.ipynb",
      "status": "passed",
      "execution_time": 1.527393102645874,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/deploying_using_tensorflow_serving_or_torchserve_using_ready_made_frameworks_for.ipynb",
      "status": "passed",
      "execution_time": 1.8462870121002197,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/saving_and_loading_ai_model_using_pickle_onnx_or_savedmodel_for_tensorflow.ipynb",
      "status": "passed",
      "execution_time": 1.6707961559295654,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/scaling_model_deployment_using_kubernetes_deploying_container_based_ai_model_on_.ipynb",
      "status": "passed",
      "execution_time": 1.346384048461914,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/testing_batch_vs_real_time_inference_running_batch_processing_scripts_and_deploy.ipynb",
      "status": "passed",
      "execution_time": 1.662607192993164,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/exercises/03_api_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.6861441135406494,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit2-versioning-serving/solutions/03_api_deployment_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6827249526977539,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install fastapi uvicorn pydantic scikit-learn -q\nfrom fastapi \nimport FastAPI, HTTPException\nfrom pydantic \nimport BaseModel, validator\nimport pickle\nimport numpy as np\nfrom typing \nimport List_\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from fastapi\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install fastapi uvicorn pydantic scikit-learn -q\nfrom fastapi \nimport FastAPI, HTTPException\nfrom pydantic \nimport BaseModel, validator\nimport pickle\nimport numpy as np\nfrom typing \nimport List_\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from fastapi\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "other"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/01_cloud_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7440340518951416,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/02_aws_sagemaker.ipynb",
      "status": "passed",
      "execution_time": 2.0598771572113037,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/03_azure_ml_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7886230945587158,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/04_gcp_vertex_ai.ipynb",
      "status": "passed",
      "execution_time": 0.7024681568145752,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/05_security_measures.ipynb",
      "status": "passed",
      "execution_time": 0.8474929332733154,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/06_monitoring_logging_cloud.ipynb",
      "status": "passed",
      "execution_time": 0.7969439029693604,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/exercises/01_cloud_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.8144016265869141,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/solutions/01_cloud_deployment_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5440418720245361,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "other"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/01_docker_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.537621021270752,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/02_kubernetes_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7591090202331543,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/03_cloud_deployment_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.7712452411651611,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/04_cicd_pipelines.ipynb",
      "status": "passed",
      "execution_time": 0.7487821578979492,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/setting_up_cicd_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.6970748901367188,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/exercises/01_docker_and_containerization_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.5714409351348877,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/solutions/01_docker_and_containerization_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6725399494171143,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "other"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/01_model_monitoring.ipynb",
      "status": "passed",
      "execution_time": 0.7350990772247314,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/02_retraining_pipeline.ipynb",
      "status": "passed",
      "execution_time": 1.4486701488494873,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/03_alerting_incident_management.ipynb",
      "status": "passed",
      "execution_time": 1.3890070915222168,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/04_drift_detection.ipynb",
      "status": "passed",
      "execution_time": 1.207792043685913,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/05_experiment_tracking_mlflow_wandb.ipynb",
      "status": "passed",
      "execution_time": 0.7464389801025391,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/06_model_versioning_reproducibility.ipynb",
      "status": "passed",
      "execution_time": 0.6638278961181641,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/07_ab_testing_canary_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.689967155456543,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_canary_deployment_strategies.ipynb",
      "status": "passed",
      "execution_time": 1.5320510864257812,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_drift_detection_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.7088801860809326,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_model_versioning_and_reproducibility_practices.ipynb",
      "status": "passed",
      "execution_time": 1.3109192848205566,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/performing_ab_testing_for_model_comparison.ipynb",
      "status": "passed",
      "execution_time": 1.6765129566192627,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/setting_up_model_monitoring_and_performance_tracking_systems.ipynb",
      "status": "passed",
      "execution_time": 1.7735590934753418,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/setting_up_retraining_pipelines.ipynb",
      "status": "passed",
      "execution_time": 4.054050922393799,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/using_experiment_tracking_tools_mlflow_weights_biases.ipynb",
      "status": "passed",
      "execution_time": 1.5836479663848877,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/exercises/01_monitoring_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.8080880641937256,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/solutions/01_monitoring_solution.ipynb",
      "status": "passed",
      "execution_time": 1.808816909790039,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "other"
    },
    {
      "path": "Course 12/EXAMPLES/01_project_structure_template.ipynb",
      "status": "passed",
      "execution_time": 1.079420804977417,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/02_data_collection_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 1.028846025466919,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/03_model_development.ipynb",
      "status": "passed",
      "execution_time": 1.1762938499450684,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/04_model_evaluation.ipynb",
      "status": "passed",
      "execution_time": 1.1801247596740723,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/05_deployment_example.ipynb",
      "status": "passed",
      "execution_time": 1.2447509765625,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/06_project_documentation_template.ipynb",
      "status": "passed",
      "execution_time": 1.0486021041870117,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_01_project_proposal_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7477190494537354,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_02_system_design_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5328619480133057,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_03_implementation_planning_solution.ipynb",
      "status": "passed",
      "execution_time": 0.8201439380645752,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_01_project_proposal.ipynb",
      "status": "passed",
      "execution_time": 0.6288721561431885,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_02_system_design.ipynb",
      "status": "passed",
      "execution_time": 0.84529709815979,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_03_implementation_planning.ipynb",
      "status": "passed",
      "execution_time": 0.7426459789276123,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/01_project_proposal_literature_review.ipynb",
      "status": "passed",
      "execution_time": 0.7203528881072998,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/04_literature_review_research_papers.ipynb",
      "status": "passed",
      "execution_time": 0.8544011116027832,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/compiling_source_code_documents_and_final_submission_package.ipynb",
      "status": "passed",
      "execution_time": 1.8460369110107422,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/creating_project_timeline_and_resource_allocation_plan.ipynb",
      "status": "passed",
      "execution_time": 1.4875550270080566,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/defining_success_metrics_and_evaluation_criteria_for_the_project.ipynb",
      "status": "passed",
      "execution_time": 1.565161943435669,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/preparing_recorded_video_or_live_demonstration_of_project.ipynb",
      "status": "passed",
      "execution_time": 1.5660040378570557,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/selecting_and_defining_a_graduation_project_topic.ipynb",
      "status": "passed",
      "execution_time": 1.317917823791504,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/01_data_collection_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 1.7927980422973633,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/04_data_sourcing_strategies.ipynb",
      "status": "passed",
      "execution_time": 0.7610468864440918,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/collecting_and_acquiring_datasets_for_the_graduation_project.ipynb",
      "status": "passed",
      "execution_time": 1.5028071403503418,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/creating_data_exploration_notebooks_with_visualizations.ipynb",
      "status": "passed",
      "execution_time": 2.269487142562866,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/implementing_feature_engineering_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.7158150672912598,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/performing_data_cleaning_and_preprocessing_using_python_libraries_pandas_numpy.ipynb",
      "status": "passed",
      "execution_time": 1.6039769649505615,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/validating_data_quality_and_preparing_trainvalidationtest_splits.ipynb",
      "status": "passed",
      "execution_time": 1.667268991470337,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/01_model_training_hyperparameter_optimization.ipynb",
      "status": "passed",
      "execution_time": 15.806926012039185,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/04_model_selection_architecture_design.ipynb",
      "status": "passed",
      "execution_time": 3.3775291442871094,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/analyzing_model_outputs_and_identifying_areas_for_improvement.ipynb",
      "status": "passed",
      "execution_time": 1.4962880611419678,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/documenting_training_procedures_and_results.ipynb",
      "status": "passed",
      "execution_time": 1.6284801959991455,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/evaluating_model_performance_using_appropriate_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.5142121315002441,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/iteratively_refining_the_model_based_on_validation_results.ipynb",
      "status": "passed",
      "execution_time": 1.5034940242767334,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/performing_hyperparameter_optimization_using_grid_search_or_automated_tools.ipynb",
      "status": "passed",
      "execution_time": 1.3954098224639893,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/01_model_evaluation_optimization.ipynb",
      "status": "passed",
      "execution_time": 1.9412579536437988,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/04_experiments_performance_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.5764081478118896,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/05_comparing_baseline_models.ipynb",
      "status": "passed",
      "execution_time": 1.45530104637146,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/06_analyzing_failure_cases.ipynb",
      "status": "passed",
      "execution_time": 0.8176171779632568,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/07_visualizing_results_graphs_matrices.ipynb",
      "status": "passed",
      "execution_time": 1.6334168910980225,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/08_iterative_improvement_retraining.ipynb",
      "status": "passed",
      "execution_time": 1.364710807800293,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/analyzing_failure_cases_and_identifying_weaknesses_in_the_model.ipynb",
      "status": "passed",
      "execution_time": 1.2722811698913574,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/comparing_results_with_baseline_or_standard_models.ipynb",
      "status": "passed",
      "execution_time": 1.3211956024169922,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/conducting_experiments_and_collecting_performance_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.3902959823608398,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/iteratively_improving_model_parameters_or_retraining_with_improved_data.ipynb",
      "status": "passed",
      "execution_time": 1.4269530773162842,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/visualizing_results_using_graphs_confusion_matrices_or_heat_maps.ipynb",
      "status": "passed",
      "execution_time": 1.2614161968231201,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit5-documentation-presentation/examples/01_project_documentation_presentation.ipynb",
      "status": "passed",
      "execution_time": 0.7681539058685303,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit5-documentation-presentation",
      "type": "example"
    },
    {
      "path": "Course 12/unit5-documentation-presentation/examples/04_writing_final_project_report.ipynb",
      "status": "passed",
      "execution_time": 0.6065938472747803,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit5-documentation-presentation",
      "type": "example"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit1-data-processing/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 1.510587215423584,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"Unit 1 - Exercise 1: Solution\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644Complete solution for the data processing exercise\"\"\"\nprint(\"=\" * 60) / print(\"Exercise 1: Solution\") / print(\"\u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644\") / print(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nExercise 1: Solution\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Unit 1 - Exercise 1: Solution\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644Complete solution for the data processing exercise\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExercise 1: Solution\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"Unit 1 - Exercise 1: Solution\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644Complete solution for the data processing exercise\"\"\"\nprint(\"=\" * 60) / print(\"Exercise 1: Solution\") / print(\"\u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644\") / print(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nExercise 1: Solution\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Unit 1 - Exercise 1: Solution\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644Complete solution for the data processing exercise\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExercise 1: Solution\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u062a\u0645\u0631\u064a\u0646 1: \u0627\u0644\u062d\u0644\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\n\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit1-data-processing/solutions/exercise_02_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5997631549835205,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit2-regression/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7487607002258301,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit3-classification/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7344129085540771,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                            confusion_matrix) / from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    confusion_matrix) / from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                            confusion_matrix) / from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    confusion_matrix) / from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit4-clustering/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.003059864044189453,
      "error": "The notebook is invalid and is missing an expected key: metadata",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 82, in reads\n    raise ValidationError(msg) from None\njsonschema.exceptions.ValidationError: The notebook is invalid and is missing an expected key: metadata\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit5-model-selection/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.0003027915954589844,
      "error": "The notebook is invalid and is missing an expected key: metadata",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 82, in reads\n    raise ValidationError(msg) from None\njsonschema.exceptions.ValidationError: The notebook is invalid and is missing an expected key: metadata\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit1-ethics-foundations/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6152122020721436,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI EthicsExercise 1 Solution: Ethical Framework Application_This is the solution to Exercise 1.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\n# ============================================================================\n# SOLUTION: TASK 1 - Identify Ethical Issues\n# ============================================================================\ndef identify_ethical_issues():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify ethical issues in employee monitoring scenario\"\"\"_ethical_issues =  [\n ethical_issues = [\n {\n 'issue': 'Privacy Violation', 'issue_ar': '',\n 'severity': 9,\n 'description': 'Monitoring computer usage, emails, and keystrokes violates employee privacy',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Consent',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Employees may not be aware of or consent to this level of monitoring',\n 'description_ar': ''\n },\n {\n 'issue': 'Autonomy and Dignity',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Constant monitoring undermines employee autonomy and human dignity',\n 'description_ar': ''\n },\n {\n 'issue': 'Potential for Discrimination',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Productivity metrics may be biased against certain work styles or disabilities',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Transparency',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Employees may not know how their data is being used or evaluated',\n 'description_ar': ''\n }\n ]\n return ethical_issues\n# ============================================================================\n# SOLUTION: TASK 2 - Apply Ethical Frameworks\n# ============================================================================\ndef apply_utilitarianism():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nUtilitarian analysis\"\"\"_analysis =  {\n analysis = {\n 'benefits': [\n 'Increased productivity for company', 'Better performance management',\n 'Cost savings through efficiency',\n 'Data-driven decision making'\n ],\n 'harms': [\n 'Employee stress and anxiety',\n 'Loss of privacy',\n 'Reduced trust and morale',\n 'Potential for discrimination',\n 'Invasion of personal space'\n ],\n 'overall_utility': -2, # Harms outweigh benefits\n 'conclusion': 'Unethical - The harms to employees (stress, privacy loss, dignity) / outweigh the benefits to the company. The overall utility is negative.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_deontology():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nDeontological analysis\"\"\"_analysis =  {\n analysis = {\n 'moral_rules': [\n 'Respect for human dignity', 'Right to privacy',\n 'Informed consent',\n 'Treat people as ends, not means',\n 'Fair treatment and non-discrimination'\n ],\n 'violations': [\n 'Violates right to privacy without consent',\n 'Uses employees as means to company ends',\n 'Lacks informed consent',\n 'May violate fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates multiple moral duties including respect for privacy, dignity, and informed consent. The system treats employees as means rather than ends.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_rights_based():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nRights-based analysis\"\"\"_analysis =  {\n analysis = {\n 'rights_at_stake': [\n 'Right to privacy', 'Right to autonomy',\n 'Right to dignity',\n 'Right to informed consent',\n 'Right to fair treatment',\n 'Right to work-life balance'\n ],\n 'violations': [\n 'Severe violation of privacy rights',\n 'Violation of autonomy and dignity',\n 'Lack of informed consent',\n 'Potential violation of fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates fundamental human rights including privacy, autonomy, and dignity. The system cannot be justified from a rights-based perspective.',\n 'conclusion_ar': ''\n }\n return analysis\n# ============================================================================\n# SOLUTION: TASK 3 - Identify Stakeholders\n# ============================================================================\ndef identify_stakeholders():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify all stakeholders\"\"\"_stakeholders =  {\n stakeholders = {\n 'Employees': {\n 'interests': ['Privacy', 'Autonomy', 'Fair treatment', 'Job security'],\n 'interests_ar': ['', '', '', ''],\n 'impact': 9, # Highly affected\n 'influence': 5 # Moderate influence\n },\n 'Company Management': {\n 'interests': ['Productivity', 'Cost efficiency', 'Performance metrics'],\n 'interests_ar': ['', '', ''],\n 'impact': 6, # Moderately affected\n 'influence': 9 # High influence\n },\n 'HR Department': {\n 'interests': ['Performance management', 'Compliance', 'Employee relations'],\n 'interests_ar': ['', '', ''],\n 'impact': 7,\n 'influence': 7\n },\n 'AI Developers': {\n 'interests': ['Technical success', 'Innovation', 'Ethical development'],\n 'interests_ar': ['', '', ''],\n 'impact': 5,\n 'influence': 8\n },\n 'Unions': {\n 'interests': ['Worker rights', 'Privacy protection', 'Fair treatment'],\n 'interests_ar': ['', '', ''],\n 'impact': 8,\n 'influence': 6\n },\n 'Regulators': {\n 'interests': ['Compliance', 'Privacy laws', 'Labor rights'],\n 'interests_ar': ['', '', ''],\n 'impact': 4,\n 'influence': 9\n }\n }\n return stakeholders\n# ============================================================================\n# SOLUTION: TASK 4 - Recommendations\n# ============================================================================\ndef provide_recommendations():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nProvide ethical recommendations\"\"\"_recommendations =  [\n recommendations = [\n {\n 'recommendation': 'Obtain explicit, informed consent from all employees',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Limit monitoring to work-related activities only',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Ensure transparency about what is monitored and how data is used',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Implement privacy-preserving techniques (e.g., aggregate data only)',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Regular audits for bias and discrimination',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Provide opt-out mechanisms for employees',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Establish clear accountability and redress mechanisms',\n 'recommendation_ar': '',\n 'priority': 'High'\n }\n ]\n return recommendations\n# ============================================================================\n# SOLUTION: TASK 5 - Visualizations\n# ============================================================================\ndef create_stakeholder_matrix(stakeholders):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nCreate stakeholder impact\"\"\"_names =  list(stakeholders.keys())\n names = list(stakeholders.keys())_impacts =  [s['impact'] for s in stakeholders.values()]\n impacts = [s['impact'] for s in stakeholders.values()]_influences =  [s['influence'] for s in stakeholders.values()]\n influences = [s['influence'] for s in stakeholders.values()]\n fig, ax = plt.subplots(figsize=(12, 8))_scatter =  ax.scatter(influences, impacts, s=200, alpha=0.6,\n scatter = ax.scatter(influences, impacts, s=200, alpha=0.6, \n c=range(len(names)), cmap='viridis', edgecolors='black', linewidth=2)\n for i, name in enumerate(names):\n ax.annotate(name, (influences[i], impacts[i]), \n xytext=(5, 5), textcoords='offset points', fontsize=9)\n ax.set_xlabel('Influence Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_ylabel('Impact Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Stakeholder Impact-Influence Matrix\\n'\n '', fontsize=14, fontweight='bold', pad=20) / ax.set_xlim(0, 10) / ax.set_ylim(0, 10) / ax.grid(True, alpha=0.3, linestyle='--') / plt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight') / print(\"\u2705 Saved: stakeholder_matrix.png\") / plt.close()\ndef create_ethical_issues_chart(ethical_issues):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"Create ethical issues severity chart\"\"\"\n_issues =  [e['issue'] for e in ethical_issues]\n issues = [e['issue'] for e in ethical_issues]_severities =  [e['severity'] for e in ethical_issues]\n severities = [e['severity'] for e in ethical_issues]_colors =  ['# e74_c3_c' if s >= 9 else '#f39_colors = ['# e74_c3_c' if s >= 9 else '#f39\nc12' if s >= 7 else '#3498\ndb' \n for s in severities]\n fig, ax = plt.subplots(figsize=(12, 8))_bars =  ax.barh(issues, severities, color=colors, alpha=0.8,\n bars = ax.barh(issues, severities, color=colors, alpha=0.8, \n edgecolor='black', linewidth=1.5) / ax.set_xlabel('Severity Score (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Ethical Issues Severity Analysis\\n'\n '', fontsize=14, fontweight='bold', pad=20) / ax.set_xlim(0, 10) / ax.grid(axis='x', alpha=0.3, linestyle='--') / for i, (bar, severity) / in enumerate(zip(bars, severities)):\n ax.text(severity + 0.2, i, f'{severity}', \n va='center', fontweight='bold', fontsize=11)\n # Legend_high = mpatches.Patch(color='# e74_c3_c', label='High (9-10)' medium = mpatches.Patch(color='# f39\nc12', label='Medium (7-8)_low =  mpatches.Patch(color='# 3498_low = mpatches.Patch(color='# 3498\ndb', label='Low (<7) / ax.legend(handles=[high, medium, low], loc='lower right', fontsize=10) / plt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight') / print(\"\u2705 Saved: ethical_issues_severity.png\") / plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif __name__ == \"__main__\":\n print(\"=\"*80) / print(\"Unit 1 - Exercise 1 Solution\") / print(\"\") / print(\"=\"*80)\n # Task 1__\nprint(\"\\n\ud83d\udccb TASK 1: Ethical Issues\") / print(\"-\" * 60)_ethical_issues =  identify_ethical_issues()\n ethical_issues = identify_ethical_issues()\n for issue in ethical_issues:\n print(f\"\\n{issue[\"issue']}'issue_ar']}') / print(f\" Severity: {issue[\"severity']}') / print(f\" {issue[\"description']}')\n # Task 2__\nprint(\"\\n\\n\ud83d\udccb TASK 2: Framework Analysis\") / print(\"-\" * 60) / print(\"\\nUtilitarianism:\")_util =  apply_utilitarianism()\n util = apply_utilitarianism()\n print(f\" Overall Utility: {util[\"overall_utility']}') / print(f\" Conclusion: {util[\"conclusion']}') / print(\"\\nDeontology:\")_deon =  apply_deontology()\n deon = apply_deontology()\n print(f\" Conclusion: {deon[\"conclusion']}') / print(\"\\nRights-Based:\")_rights =  apply_rights_based()\n rights = apply_rights_based()\n print(f\" Conclusion: {rights[\"conclusion']}')\n # Task 3__\nprint(\"\\n\\n\ud83d\udccb TASK 3: Stakeholders\") / print(\"-\" * 60)_stakeholders =  identify_stakeholders()\n stakeholders = identify_stakeholders()\n for name, info in stakeholders.items():\n print(f\"\\n{name}:\") / print(f\" Impact: {info[\"impact']}'influence']}') / print(f\" Interests: {\", '.join(info['interests'])}')\n # Task 4__\nprint(\"\\n\\n\ud83d\udccb TASK 4: Recommendations\") / print(\"-\" * 60)_recommendations =  provide_recommendations()\n recommendations = provide_recommendations()\n for i, rec in enumerate(recommendations, 1):\n print(f\"\\n{i}. [{rec[\"priority']}] {rec['recommendation']}') / print(f\" {rec[\"recommendation_ar']}')\n # Task 5__\nprint(\"\\n\\n\ud83d\udccb TASK 5: Creating Visualizations\") / print(\"-\" * 60) / create_stakeholder_matrix(stakeholders) / create_ethical_issues_chart(ethical_issues) / print(\"\\n\" + \"=\"*80) / print(\"\u2705 Solution completed successfully!\") / print(\"\") / print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI EthicsExercise 1 Solution: Ethical Framework Application_This is the solution to Exercise 1.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\n# ============================================================================\n# SOLUTION: TASK 1 - Identify Ethical Issues\n# ============================================================================\ndef identify_ethical_issues():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify ethical issues in employee monitoring scenario\"\"\"_ethical_issues =  [\n ethical_issues = [\n {\n 'issue': 'Privacy Violation', 'issue_ar': '',\n 'severity': 9,\n 'description': 'Monitoring computer usage, emails, and keystrokes violates employee privacy',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Consent',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Employees may not be aware of or consent to this level of monitoring',\n 'description_ar': ''\n },\n {\n 'issue': 'Autonomy and Dignity',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Constant monitoring undermines employee autonomy and human dignity',\n 'description_ar': ''\n },\n {\n 'issue': 'Potential for Discrimination',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Productivity metrics may be biased against certain work styles or disabilities',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Transparency',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Employees may not know how their data is being used or evaluated',\n 'description_ar': ''\n }\n ]\n return ethical_issues\n# ============================================================================\n# SOLUTION: TASK 2 - Apply Ethical Frameworks\n# ============================================================================\ndef apply_utilitarianism():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nUtilitarian analysis\"\"\"_analysis =  {\n analysis = {\n 'benefits': [\n 'Increased productivity for company', 'Better performance management',\n 'Cost savings through efficiency',\n 'Data-driven decision making'\n ],\n 'harms': [\n 'Employee stress and anxiety',\n 'Loss of privacy',\n 'Reduced trust and morale',\n 'Potential for discrimination',\n 'Invasion of personal space'\n ],\n 'overall_utility': -2, # Harms outweigh benefits\n 'conclusion': 'Unethical - The harms to employees (stress, privacy loss, dignity) / outweigh the benefits to the company. The overall utility is negative.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_deontology():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nDeontological analysis\"\"\"_analysis =  {\n analysis = {\n 'moral_rules': [\n 'Respect for human dignity', 'Right to privacy',\n 'Informed consent',\n 'Treat people as ends, not means',\n 'Fair treatment and non-discrimination'\n ],\n 'violations': [\n 'Violates right to privacy without consent',\n 'Uses employees as means to company ends',\n 'Lacks informed consent',\n 'May violate fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates multiple moral duties including respect for privacy, dignity, and informed consent. The system treats employees as means rather than ends.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_rights_based():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nRights-based analysis\"\"\"_analysis =  {\n analysis = {\n 'rights_at_stake': [\n 'Right to privacy', 'Right to autonomy',\n 'Right to dignity',\n 'Right to informed consent',\n 'Right to fair treatment',\n 'Right to work-life balance'\n ],\n 'violations': [\n 'Severe violation of privacy rights',\n 'Violation of autonomy and dignity',\n 'Lack of informed consent',\n 'Potential violation of fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates fundamental human rights including privacy, autonomy, and dignity. The system cannot be justified from a rights-based perspective.',\n 'conclusion_ar': ''\n }\n return analysis\n# ============================================================================\n# SOLUTION: TASK 3 - Identify Stakeholders\n# ============================================================================\ndef identify_stakeholders():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify all stakeholders\"\"\"_stakeholders =  {\n stakeholders = {\n 'Employees': {\n 'interests': ['Privacy', 'Autonomy', 'Fair treatment', 'Job security'],\n 'interests_ar': ['', '', '', ''],\n 'impact': 9, # Highly affected\n 'influence': 5 # Moderate influence\n },\n 'Company Management': {\n 'interests': ['Productivity', 'Cost efficiency', 'Performance metrics'],\n 'interests_ar': ['', '', ''],\n 'impact': 6, # Moderately affected\n 'influence': 9 # High influence\n },\n 'HR Department': {\n 'interests': ['Performance management', 'Compliance', 'Employee relations'],\n 'interests_ar': ['', '', ''],\n 'impact': 7,\n 'influence': 7\n },\n 'AI Developers': {\n 'interests': ['Technical success', 'Innovation', 'Ethical development'],\n 'interests_ar': ['', '', ''],\n 'impact': 5,\n 'influence': 8\n },\n 'Unions': {\n 'interests': ['Worker rights', 'Privacy protection', 'Fair treatment'],\n 'interests_ar': ['', '', ''],\n 'impact': 8,\n 'influence': 6\n },\n 'Regulators': {\n 'interests': ['Compliance', 'Privacy laws', 'Labor rights'],\n 'interests_ar': ['', '', ''],\n 'impact': 4,\n 'influence': 9\n }\n }\n return stakeholders\n# ============================================================================\n# SOLUTION: TASK 4 - Recommendations\n# ============================================================================\ndef provide_recommendations():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nProvide ethical recommendations\"\"\"_recommendations =  [\n recommendations = [\n {\n 'recommendation': 'Obtain explicit, informed consent from all employees',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Limit monitoring to work-related activities only',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Ensure transparency about what is monitored and how data is used',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Implement privacy-preserving techniques (e.g., aggregate data only)',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Regular audits for bias and discrimination',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Provide opt-out mechanisms for employees',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Establish clear accountability and redress mechanisms',\n 'recommendation_ar': '',\n 'priority': 'High'\n }\n ]\n return recommendations\n# ============================================================================\n# SOLUTION: TASK 5 - Visualizations\n# ============================================================================\ndef create_stakeholder_matrix(stakeholders):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nCreate stakeholder impact\"\"\"_names =  list(stakeholders.keys())\n names = list(stakeholders.keys())_impacts =  [s['impact'] for s in stakeholders.values()]\n impacts = [s['impact'] for s in stakeholders.values()]_influences =  [s['influence'] for s in stakeholders.values()]\n influences = [s['influence'] for s in stakeholders.values()]\n fig, ax = plt.subplots(figsize=(12, 8))_scatter =  ax.scatter(influences, impacts, s=200, alpha=0.6,\n scatter = ax.scatter(influences, impacts, s=200, alpha=0.6, \n c=range(len(names)), cmap='viridis', edgecolors='black', linewidth=2)\n for i, name in enumerate(names):\n ax.annotate(name, (influences[i], impacts[i]), \n xytext=(5, 5), textcoords='offset points', fontsize=9)\n ax.set_xlabel('Influence Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_ylabel('Impact Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Stakeholder Impact-Influence Matrix\\n'\n '', fontsize=14, fontweight='bold', pad=20) / ax.set_xlim(0, 10) / ax.set_ylim(0, 10) / ax.grid(True, alpha=0.3, linestyle='--') / plt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight') / print(\"\u2705 Saved: stakeholder_matrix.png\") / plt.close()\ndef create_ethical_issues_chart(ethical_issues):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"Create ethical issues severity chart\"\"\"\n_issues =  [e['issue'] for e in ethical_issues]\n issues = [e['issue'] for e in ethical_issues]_severities =  [e['severity'] for e in ethical_issues]\n severities = [e['severity'] for e in ethical_issues]_colors =  ['# e74_c3_c' if s >= 9 else '#f39_colors = ['# e74_c3_c' if s >= 9 else '#f39\nc12' if s >= 7 else '#3498\ndb' \n for s in severities]\n fig, ax = plt.subplots(figsize=(12, 8))_bars =  ax.barh(issues, severities, color=colors, alpha=0.8,\n bars = ax.barh(issues, severities, color=colors, alpha=0.8, \n edgecolor='black', linewidth=1.5) / ax.set_xlabel('Severity Score (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Ethical Issues Severity Analysis\\n'\n '', fontsize=14, fontweight='bold', pad=20) / ax.set_xlim(0, 10) / ax.grid(axis='x', alpha=0.3, linestyle='--') / for i, (bar, severity) / in enumerate(zip(bars, severities)):\n ax.text(severity + 0.2, i, f'{severity}', \n va='center', fontweight='bold', fontsize=11)\n # Legend_high = mpatches.Patch(color='# e74_c3_c', label='High (9-10)' medium = mpatches.Patch(color='# f39\nc12', label='Medium (7-8)_low =  mpatches.Patch(color='# 3498_low = mpatches.Patch(color='# 3498\ndb', label='Low (<7) / ax.legend(handles=[high, medium, low], loc='lower right', fontsize=10) / plt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight') / print(\"\u2705 Saved: ethical_issues_severity.png\") / plt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif __name__ == \"__main__\":\n print(\"=\"*80) / print(\"Unit 1 - Exercise 1 Solution\") / print(\"\") / print(\"=\"*80)\n # Task 1__\nprint(\"\\n\ud83d\udccb TASK 1: Ethical Issues\") / print(\"-\" * 60)_ethical_issues =  identify_ethical_issues()\n ethical_issues = identify_ethical_issues()\n for issue in ethical_issues:\n print(f\"\\n{issue[\"issue']}'issue_ar']}') / print(f\" Severity: {issue[\"severity']}') / print(f\" {issue[\"description']}')\n # Task 2__\nprint(\"\\n\\n\ud83d\udccb TASK 2: Framework Analysis\") / print(\"-\" * 60) / print(\"\\nUtilitarianism:\")_util =  apply_utilitarianism()\n util = apply_utilitarianism()\n print(f\" Overall Utility: {util[\"overall_utility']}') / print(f\" Conclusion: {util[\"conclusion']}') / print(\"\\nDeontology:\")_deon =  apply_deontology()\n deon = apply_deontology()\n print(f\" Conclusion: {deon[\"conclusion']}') / print(\"\\nRights-Based:\")_rights =  apply_rights_based()\n rights = apply_rights_based()\n print(f\" Conclusion: {rights[\"conclusion']}')\n # Task 3__\nprint(\"\\n\\n\ud83d\udccb TASK 3: Stakeholders\") / print(\"-\" * 60)_stakeholders =  identify_stakeholders()\n stakeholders = identify_stakeholders()\n for name, info in stakeholders.items():\n print(f\"\\n{name}:\") / print(f\" Impact: {info[\"impact']}'influence']}') / print(f\" Interests: {\", '.join(info['interests'])}')\n # Task 4__\nprint(\"\\n\\n\ud83d\udccb TASK 4: Recommendations\") / print(\"-\" * 60)_recommendations =  provide_recommendations()\n recommendations = provide_recommendations()\n for i, rec in enumerate(recommendations, 1):\n print(f\"\\n{i}. [{rec[\"priority']}] {rec['recommendation']}') / print(f\" {rec[\"recommendation_ar']}')\n # Task 5__\nprint(\"\\n\\n\ud83d\udccb TASK 5: Creating Visualizations\") / print(\"-\" * 60) / create_stakeholder_matrix(stakeholders) / create_ethical_issues_chart(ethical_issues) / print(\"\\n\" + \"=\"*80) / print(\"\u2705 Solution completed successfully!\") / print(\"\") / print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit2-bias-justice/solutions/exercise_02_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7403452396392822,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI_Exercise 2 Solution: Bias Mitigation TechniquesComplete solution for the bias mitigation exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# SOLUTION 1: Generate Biased Dataset\n# ============================================================================\ndef generate_biased_dataset(n_samples = 2000):\n \n    \n    \n    \"\"\"\n Generate a synthetic dataset with bias.\n \"\"\"\n np.random.seed(42)\n # Sensitive attribute (e.g., gender: 0 = group A, 1 = group B)\n sensitive = np.random.binomial(1, 0.5, n_samples)\n # Features_X1 = np.random.normal(0, 1, n_samples)\n X2 = np.random.normal(0, 1, n_samples)\n # Introduce bias: group B has lower probability of positive outcome_true_prob = 0.3 + 0.4 * X1 + 0.3 * X2_bias_penalty = 0.3 * (1 - sensitive) # Group B (0) gets penalty_prob = true_prob - bias_penalty + np.random.normal(0, 0.1, n_samples)\n prob = np.clip(prob, 0, 1)\n # Target variable_y = (prob > 0.5).astype(int)\n # Create DataFrame_df = pd.DataFrame({\n 'feature1': X1, 'feature2': X2,\n 'sensitive': sensitive,\n 'target': y\n })\n return df\n# ============================================================================\n# SOLUTION 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Implement reweighing technique.\n \"\"\"\n # Calculate weights to balance groups_group_counts = pd.Series(sensitive_train).value_counts()\n total = len(sensitive_train)_weights =  np.ones(len(sensitive_train))\n weights = np.ones(len(sensitive_train))\n for group in group_counts.index:\n group_size = group_counts[group]\n # Weight inversely proportional to group size_weights[sensitive_train = = group] = total / (len(group_counts) * group_size)\n return weights\n# ============================================================================\n# SOLUTION 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \n    \"\"\"\n Train a baseline model without any bias mitigation.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)_model =  RandomForestClassifier(n_estimators = 100, random_state = 42)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train)\n return model, scaler\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Train a model using reweighing technique.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)\n # Get weights from reweighing_weights = preprocess_reweighing(X_train_scaled, y_train, sensitive_train)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train, sample_weight = weights)\n return model, scaler\n# ============================================================================\n# SOLUTION 4: Evaluate Fairness Metrics\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \n    \"\"\"\n Evaluate fairness metrics.\n \"\"\"\n_metrics =  {\n metrics = {\n 'demographic_parity_diff': demographic_parity_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'equalized_odds_diff': equalized_odds_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'accuracy': accuracy_score(y_true, y_pred)\n }\n return metrics\n# ============================================================================\n# SOLUTION 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \n    \"\"\"\n Compare baseline vs reweighing techniques.\n \"\"\"\n # Prepare data_X = df[['feature1', 'feature2']].valuesy = df['target'].values_sensitive = df['sensitive'].values\n # Split data_X_train, X_test, y_train, y_test, sensitive\ntrain, sensitive_test = train_test_split(\n X, y, sensitive, test_size = 0.3, random_state = 42, stratify=y\n )\n print(\"\\n\" + \"=\"*80)\n print(\"BASELINE MODEL (No Mitigation)\")\n print(\"=\"*80)\n # Train baseline model_baseline\nmodel, baseline_scaler = train_baseline_model(X_train, y_train)_X_test_scaled =  baseline_scaler.transform(X_test)\n X_test_scaled = baseline_scaler.transform(X_test)_y_pred_baseline =  baseline_model.predict(X_test_scaled)\n y_pred_baseline = baseline_model.predict(X_test_scaled)\n # Evaluate baseline_baseline_metrics = evaluate_fairness(y_test, y_pred_baseline, sensitive_test)\n print(f\"Accuracy: {baseline_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {baseline_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {baseline_metrics[\"equalized_odds_diff']:.4 f}')\n print(\"\\n\" + \"=\"*80)\n print(\"REWEIGHING MODEL\")\n print(\"=\"*80)\n # Train reweighed model_reweigh\nmodel, reweigh_scaler = train_reweighed_model(X_train, y_train, sensitive_train)_X_test_reweigh =  reweigh_scaler.transform(X_test)\n X_test_reweigh = reweigh_scaler.transform(X_test)_y_pred_reweigh =  reweigh_model.predict(X_test_reweigh)\n y_pred_reweigh = reweigh_model.predict(X_test_reweigh)\n # Evaluate reweighing_reweigh_metrics = evaluate_fairness(y_test, y_pred_reweigh, sensitive_test)\n print(f\"Accuracy: {reweigh_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {reweigh_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {reweigh_metrics[\"equalized_odds_diff']:.4 f}')\n # Comparison__\nprint(\"\\n\" + \"=\"*80)\n print(\"COMPARISON\")\n print(\"=\"*80)\n print(f\"Demographic Parity Improvement: \"\n f\"{abs(baseline_metrics[\"demographic_parity_diff']) - abs(reweigh_metrics['demographic_parity_diff']):.4 f}')\n print(f\"Equalized Odds Improvement: \"\n f\"{abs(baseline_metrics[\"equalized_odds_diff']) - abs(reweigh_metrics['equalized_odds_diff']):.4 f}')\n print(f\"Accuracy Change: {reweigh_metrics[\"accuracy'] - baseline_metrics['accuracy']:.4 f}')\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif __name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2 Solution: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate dataset__\nprint(\"\\nGenerating biased dataset...\")_df =  generate_biased_dataset()\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"\\nSensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n print(f\"\\nTarget distribution:\")\n print(df['target'].value_counts())\n # Compare techniques_compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Solution completed!\")\n print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI_Exercise 2 Solution: Bias Mitigation TechniquesComplete solution for the bias mitigation exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# SOLUTION 1: Generate Biased Dataset\n# ============================================================================\ndef generate_biased_dataset(n_samples = 2000):\n \n    \n    \n    \"\"\"\n Generate a synthetic dataset with bias.\n \"\"\"\n np.random.seed(42)\n # Sensitive attribute (e.g., gender: 0 = group A, 1 = group B)\n sensitive = np.random.binomial(1, 0.5, n_samples)\n # Features_X1 = np.random.normal(0, 1, n_samples)\n X2 = np.random.normal(0, 1, n_samples)\n # Introduce bias: group B has lower probability of positive outcome_true_prob = 0.3 + 0.4 * X1 + 0.3 * X2_bias_penalty = 0.3 * (1 - sensitive) # Group B (0) gets penalty_prob = true_prob - bias_penalty + np.random.normal(0, 0.1, n_samples)\n prob = np.clip(prob, 0, 1)\n # Target variable_y = (prob > 0.5).astype(int)\n # Create DataFrame_df = pd.DataFrame({\n 'feature1': X1, 'feature2': X2,\n 'sensitive': sensitive,\n 'target': y\n })\n return df\n# ============================================================================\n# SOLUTION 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Implement reweighing technique.\n \"\"\"\n # Calculate weights to balance groups_group_counts = pd.Series(sensitive_train).value_counts()\n total = len(sensitive_train)_weights =  np.ones(len(sensitive_train))\n weights = np.ones(len(sensitive_train))\n for group in group_counts.index:\n group_size = group_counts[group]\n # Weight inversely proportional to group size_weights[sensitive_train = = group] = total / (len(group_counts) * group_size)\n return weights\n# ============================================================================\n# SOLUTION 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \n    \"\"\"\n Train a baseline model without any bias mitigation.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)_model =  RandomForestClassifier(n_estimators = 100, random_state = 42)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train)\n return model, scaler\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Train a model using reweighing technique.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)\n # Get weights from reweighing_weights = preprocess_reweighing(X_train_scaled, y_train, sensitive_train)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train, sample_weight = weights)\n return model, scaler\n# ============================================================================\n# SOLUTION 4: Evaluate Fairness Metrics\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \n    \"\"\"\n Evaluate fairness metrics.\n \"\"\"\n_metrics =  {\n metrics = {\n 'demographic_parity_diff': demographic_parity_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'equalized_odds_diff': equalized_odds_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'accuracy': accuracy_score(y_true, y_pred)\n }\n return metrics\n# ============================================================================\n# SOLUTION 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \n    \"\"\"\n Compare baseline vs reweighing techniques.\n \"\"\"\n # Prepare data_X = df[['feature1', 'feature2']].valuesy = df['target'].values_sensitive = df['sensitive'].values\n # Split data_X_train, X_test, y_train, y_test, sensitive\ntrain, sensitive_test = train_test_split(\n X, y, sensitive, test_size = 0.3, random_state = 42, stratify=y\n )\n print(\"\\n\" + \"=\"*80)\n print(\"BASELINE MODEL (No Mitigation)\")\n print(\"=\"*80)\n # Train baseline model_baseline\nmodel, baseline_scaler = train_baseline_model(X_train, y_train)_X_test_scaled =  baseline_scaler.transform(X_test)\n X_test_scaled = baseline_scaler.transform(X_test)_y_pred_baseline =  baseline_model.predict(X_test_scaled)\n y_pred_baseline = baseline_model.predict(X_test_scaled)\n # Evaluate baseline_baseline_metrics = evaluate_fairness(y_test, y_pred_baseline, sensitive_test)\n print(f\"Accuracy: {baseline_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {baseline_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {baseline_metrics[\"equalized_odds_diff']:.4 f}')\n print(\"\\n\" + \"=\"*80)\n print(\"REWEIGHING MODEL\")\n print(\"=\"*80)\n # Train reweighed model_reweigh\nmodel, reweigh_scaler = train_reweighed_model(X_train, y_train, sensitive_train)_X_test_reweigh =  reweigh_scaler.transform(X_test)\n X_test_reweigh = reweigh_scaler.transform(X_test)_y_pred_reweigh =  reweigh_model.predict(X_test_reweigh)\n y_pred_reweigh = reweigh_model.predict(X_test_reweigh)\n # Evaluate reweighing_reweigh_metrics = evaluate_fairness(y_test, y_pred_reweigh, sensitive_test)\n print(f\"Accuracy: {reweigh_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {reweigh_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {reweigh_metrics[\"equalized_odds_diff']:.4 f}')\n # Comparison__\nprint(\"\\n\" + \"=\"*80)\n print(\"COMPARISON\")\n print(\"=\"*80)\n print(f\"Demographic Parity Improvement: \"\n f\"{abs(baseline_metrics[\"demographic_parity_diff']) - abs(reweigh_metrics['demographic_parity_diff']):.4 f}')\n print(f\"Equalized Odds Improvement: \"\n f\"{abs(baseline_metrics[\"equalized_odds_diff']) - abs(reweigh_metrics['equalized_odds_diff']):.4 f}')\n print(f\"Accuracy Change: {reweigh_metrics[\"accuracy'] - baseline_metrics['accuracy']:.4 f}')\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif __name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2 Solution: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate dataset__\nprint(\"\\nGenerating biased dataset...\")_df =  generate_biased_dataset()\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"\\nSensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n print(f\"\\nTarget distribution:\")\n print(df['target'].value_counts())\n # Compare techniques_compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Solution completed!\")\n print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit3-privacy-security/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6305427551269531,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1 Solution: Privacy Techniques\nComplete solution for the privacy techniques exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport hashlib\ndef anonymize_data(df, columns_to_anonymize):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data anonymization\"\"\"_df_anonymized =  df.copy()\n    df_anonymized = df.copy()\n    for col in columns_to_anonymize:\n        if col in df_anonymized.columns:\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]\n    return df_anonymized\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data pseudonymization using hashing\"\"\"_df_pseudonymized =  df.copy()\n    df_pseudonymized = df.copy()\n    for col in columns_to_pseudonymize:\n        if col in df_pseudonymized.columns:\n            df_pseudonymized[col] = df_pseudonymized[col].apply(\n                lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]\n            )\n    return df_pseudonymized\ndef add_differential_privacy_noise(value, epsilon=1.0, sensitivity=1.0):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nAdd Laplace noise for differential privacy\"\"\"_scale =  sensitivity / epsilon_noise = np.random.laplace(0, scale) / scale = sensitivity / epsilon_noise = np.random.laplace(0, scale) / return value + noise\nif __name__ == \"__main__\":\n    print(\"=\"*80) / print(\"Unit 3 - Exercise 1 Solution: Privacy Techniques\") / print(\"=\"*80)\n    # Test with sample data_np.random.seed(42) / df = pd.DataFrame({\n        'name': [f'Person_{i}' for i in range(10)], 'email': [f'user{i}@example.com' for i in range(10)], 'value': np.random.normal(100, 20, 10)\n    })\n    print(\"\\nOriginal Data:\") / print(df.head())\n    print(\"\\nAnonymized Data:\")_df_anon =  anonymize_data(df, ['name', 'email']) / df_anon = anonymize_data(df, ['name', 'email']) / print(df_anon.head())\n    print(\"\\nPseudonymized Data:\")_df_pseudo =  pseudonymize_data(df, ['name', 'email']) / df_pseudo = pseudonymize_data(df, ['name', 'email']) / print(df_pseudo.head())\n    print(\"\\nDifferential Privacy:\")_true_mean =  df['value'].mean()\n    true_mean = df['value'].mean()_noisy_mean =  add_differential_privacy_noise(true_mean, epsilon=1.0) / noisy_mean = add_differential_privacy_noise(true_mean, epsilon=1.0) / print(f\"True mean: {true_mean:.2f}\") / print(f\"Noisy mean: {noisy_mean:.2f}\") / print(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 67\u001b[0;36m\u001b[0m\n\u001b[0;31m    })\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1 Solution: Privacy Techniques\nComplete solution for the privacy techniques exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport hashlib\ndef anonymize_data(df, columns_to_anonymize):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data anonymization\"\"\"_df_anonymized =  df.copy()\n    df_anonymized = df.copy()\n    for col in columns_to_anonymize:\n        if col in df_anonymized.columns:\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]\n    return df_anonymized\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data pseudonymization using hashing\"\"\"_df_pseudonymized =  df.copy()\n    df_pseudonymized = df.copy()\n    for col in columns_to_pseudonymize:\n        if col in df_pseudonymized.columns:\n            df_pseudonymized[col] = df_pseudonymized[col].apply(\n                lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]\n            )\n    return df_pseudonymized\ndef add_differential_privacy_noise(value, epsilon=1.0, sensitivity=1.0):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nAdd Laplace noise for differential privacy\"\"\"_scale =  sensitivity / epsilon_noise = np.random.laplace(0, scale) / scale = sensitivity / epsilon_noise = np.random.laplace(0, scale) / return value + noise\nif __name__ == \"__main__\":\n    print(\"=\"*80) / print(\"Unit 3 - Exercise 1 Solution: Privacy Techniques\") / print(\"=\"*80)\n    # Test with sample data_np.random.seed(42) / df = pd.DataFrame({\n        'name': [f'Person_{i}' for i in range(10)], 'email': [f'user{i}@example.com' for i in range(10)], 'value': np.random.normal(100, 20, 10)\n    })\n    print(\"\\nOriginal Data:\") / print(df.head())\n    print(\"\\nAnonymized Data:\")_df_anon =  anonymize_data(df, ['name', 'email']) / df_anon = anonymize_data(df, ['name', 'email']) / print(df_anon.head())\n    print(\"\\nPseudonymized Data:\")_df_pseudo =  pseudonymize_data(df, ['name', 'email']) / df_pseudo = pseudonymize_data(df, ['name', 'email']) / print(df_pseudo.head())\n    print(\"\\nDifferential Privacy:\")_true_mean =  df['value'].mean()\n    true_mean = df['value'].mean()_noisy_mean =  add_differential_privacy_noise(true_mean, epsilon=1.0) / noisy_mean = add_differential_privacy_noise(true_mean, epsilon=1.0) / print(f\"True mean: {true_mean:.2f}\") / print(f\"Noisy mean: {noisy_mean:.2f}\") / print(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 67\u001b[0;36m\u001b[0m\n\u001b[0;31m    })\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit4-transparency-accountability/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6553089618682861,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1 Solution: SHAP and LIME Explanations\nComplete solution for the SHAP/LIME exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples) / age = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples) / income = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples) / credit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / approval = (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / return pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval}) / def calculate_shap_values(model, X_sample, X_train, feature_names):\n    baseline = model.predict_proba(X_train)[:, 1].mean()_sample_pred =  model.predict_proba(X_sample)[0, 1]\n    sample_pred = model.predict_proba(X_sample)[0, 1]_shap_values =  []\n    shap_values = []\n    for i in range(len(feature_names)):\n        X_perm = X_train.copy()\n        X_perm[:, i] = X_sample[0, i]_perm_pred =  model.predict_proba(X_perm)[:, 1].mean()\n        perm_pred = model.predict_proba(X_perm)[:, 1].mean()\n        shap_values.append(sample_pred - perm_pred) / return np.array(shap_values) / def calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    perturbations = np.random.normal(0, 0.1, (1000, X_sample.shape[1]))_X_pert =  X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]\n    X_pert = X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]_distances =  np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))\n    distances = np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))_linear_model =  Ridge(alpha=0.1) / linear_model = Ridge(alpha=0.1) / linear_model.fit(X_pert, y_pert, sample_weight=distances) / return linear_model.coef_\nif __name__ == \"__main__\":\n    print(\"=\"*80) / print(\"Unit 4 - Exercise 1 Solution: SHAP and LIME Explanations\") / print(\"=\"*80)_df =  generate_dataset()\n    df = generate_dataset()_X =  df[['age', 'income', 'credit_score']].values_y = df['approved'].values_X = df[['age', 'income', 'credit_score']].values_y = df['approved'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)_scaler =  StandardScaler()\n    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n    X_test_scaled = scaler.transform(X_test)_model =  RandomForestClassifier(n_estimators=100, random_state=42) / model = RandomForestClassifier(n_estimators=100, random_state=42) / model.fit(X_train_scaled, y_train)_sample =  X_test_scaled[0:1]\n    sample = X_test_scaled[0:1]_feature_names =  ['age', 'income', 'credit_score']\n    feature_names = ['age', 'income', 'credit_score']_shap_vals =  calculate_shap_values(model, sample, X_train_scaled, feature_names) / shap_vals = calculate_shap_values(model, sample, X_train_scaled, feature_names)_lime_vals =  calculate_lime_explanation(model, sample, X_train_scaled, feature_names) / lime_vals = calculate_lime_explanation(model, sample, X_train_scaled, feature_names) / print(\"\\nSHAP Values:\") / for name, val in zip(feature_names, shap_vals):\n        print(f\"  {name}: {val:.4f}\") / print(\"\\nLIME Values:\") / for name, val in zip(feature_names, lime_vals):\n        print(f\"  {name}: {val:.4f}\") / print(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples) / age = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples) / income = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples) / credit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / approval = (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / return pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval}) / def calculate_shap_values(model, X_sample, X_train, feature_names):\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1 Solution: SHAP and LIME Explanations\nComplete solution for the SHAP/LIME exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples) / age = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples) / income = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples) / credit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / approval = (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / return pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval}) / def calculate_shap_values(model, X_sample, X_train, feature_names):\n    baseline = model.predict_proba(X_train)[:, 1].mean()_sample_pred =  model.predict_proba(X_sample)[0, 1]\n    sample_pred = model.predict_proba(X_sample)[0, 1]_shap_values =  []\n    shap_values = []\n    for i in range(len(feature_names)):\n        X_perm = X_train.copy()\n        X_perm[:, i] = X_sample[0, i]_perm_pred =  model.predict_proba(X_perm)[:, 1].mean()\n        perm_pred = model.predict_proba(X_perm)[:, 1].mean()\n        shap_values.append(sample_pred - perm_pred) / return np.array(shap_values) / def calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    perturbations = np.random.normal(0, 0.1, (1000, X_sample.shape[1]))_X_pert =  X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]\n    X_pert = X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]_distances =  np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))\n    distances = np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))_linear_model =  Ridge(alpha=0.1) / linear_model = Ridge(alpha=0.1) / linear_model.fit(X_pert, y_pert, sample_weight=distances) / return linear_model.coef_\nif __name__ == \"__main__\":\n    print(\"=\"*80) / print(\"Unit 4 - Exercise 1 Solution: SHAP and LIME Explanations\") / print(\"=\"*80)_df =  generate_dataset()\n    df = generate_dataset()_X =  df[['age', 'income', 'credit_score']].values_y = df['approved'].values_X = df[['age', 'income', 'credit_score']].values_y = df['approved'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)_scaler =  StandardScaler()\n    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n    X_test_scaled = scaler.transform(X_test)_model =  RandomForestClassifier(n_estimators=100, random_state=42) / model = RandomForestClassifier(n_estimators=100, random_state=42) / model.fit(X_train_scaled, y_train)_sample =  X_test_scaled[0:1]\n    sample = X_test_scaled[0:1]_feature_names =  ['age', 'income', 'credit_score']\n    feature_names = ['age', 'income', 'credit_score']_shap_vals =  calculate_shap_values(model, sample, X_train_scaled, feature_names) / shap_vals = calculate_shap_values(model, sample, X_train_scaled, feature_names)_lime_vals =  calculate_lime_explanation(model, sample, X_train_scaled, feature_names) / lime_vals = calculate_lime_explanation(model, sample, X_train_scaled, feature_names) / print(\"\\nSHAP Values:\") / for name, val in zip(feature_names, shap_vals):\n        print(f\"  {name}: {val:.4f}\") / print(\"\\nLIME Values:\") / for name, val in zip(feature_names, lime_vals):\n        print(f\"  {name}: {val:.4f}\") / print(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples) / age = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples) / income = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples) / credit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / approval = (credit_score / 850 * 0.5 + income / 100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int) / return pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval}) / def calculate_shap_values(model, X_sample, X_train, feature_names):\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit5-governance-regulations/solutions/exercise_01_solution.ipynb",
      "status": "passed",
      "execution_time": 0.752310037612915,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_01/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7371931076049805,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef create_data_matrix(samples, features): return np.random.randn(samples, features) / def compute_dot_product(v1, v2): return np.dot(v1, v2) # Alternative: return v1 @ v2\ndef matrix_multiplication(A, B): return np.dot(A, B) # Alternative: return A @ B\ndef compute_transpose(matrix): return matrix.T # Alternative: return np.transpose(matrix)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def create_data_matrix(samples, features): return np.random.randn(samples, features) / def compute_dot_product(v1, v2): return np.dot(v1, v2) # Alternative: return v1 @ v2\u001b[0m\n\u001b[0m                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef create_data_matrix(samples, features): return np.random.randn(samples, features) / def compute_dot_product(v1, v2): return np.dot(v1, v2) # Alternative: return v1 @ v2\ndef matrix_multiplication(A, B): return np.dot(A, B) # Alternative: return A @ B\ndef compute_transpose(matrix): return matrix.T # Alternative: return np.transpose(matrix)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def create_data_matrix(samples, features): return np.random.randn(samples, features) / def compute_dot_product(v1, v2): return np.dot(v1, v2) # Alternative: return v1 @ v2\u001b[0m\n\u001b[0m                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_01/exercises/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5307669639587402,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_determinant(matrix): return np.linalg.det(matrix) / def compute_matrix_inverse(matrix): return np.linalg.inv(matrix) / def compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix) / return eigenvals, eigenvecs\ndef verify_inverse(matrix, inverse): identity = np.eye(matrix.shape[0]) / result = matrix @ inverse return np.allclose(result, identity)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_determinant(matrix): return np.linalg.det(matrix) / def compute_matrix_inverse(matrix): return np.linalg.inv(matrix) / def compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix) / return eigenvals, eigenvecs\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_determinant(matrix): return np.linalg.det(matrix) / def compute_matrix_inverse(matrix): return np.linalg.inv(matrix) / def compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix) / return eigenvals, eigenvecs\ndef verify_inverse(matrix, inverse): identity = np.eye(matrix.shape[0]) / result = matrix @ inverse return np.allclose(result, identity)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_determinant(matrix): return np.linalg.det(matrix) / def compute_matrix_inverse(matrix): return np.linalg.inv(matrix) / def compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix) / return eigenvals, eigenvecs\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_02/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5309178829193115,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead\ndef compute_derivative(func, x, h=1e-6): return (func(x + h) - func(x)) / h\ndef compute_gradient(func, point): h = 1e-6 grad = np.zeros_like(point) / for i in range(len(point)): # Create points for computing partial derivative point_plus = point.copy() point_plus[i] += h point_minus = point.copy() point_minus[i] -= h # Partial derivative: \u2202f/\u2202x\ni \u2248 (f(x+h) - f(x-h)) / (2\nh) / grad[i] = (func(point_plus) - func(point_minus)) / (2 * h) / return grad\ndef gradient_descent_step(func, x, learning_rate = 0.1): h = 1e-6 # Compute gradient numerically grad = (func(x + h) - func(x - h)) / (2 * h) # Move in opposite direction return x - learning\nrate * grad# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    i \u2248 (f(x+h) - f(x-h)) / (2\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '\u2248' (U+2248)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead\ndef compute_derivative(func, x, h=1e-6): return (func(x + h) - func(x)) / h\ndef compute_gradient(func, point): h = 1e-6 grad = np.zeros_like(point) / for i in range(len(point)): # Create points for computing partial derivative point_plus = point.copy() point_plus[i] += h point_minus = point.copy() point_minus[i] -= h # Partial derivative: \u2202f/\u2202x\ni \u2248 (f(x+h) - f(x-h)) / (2\nh) / grad[i] = (func(point_plus) - func(point_minus)) / (2 * h) / return grad\ndef gradient_descent_step(func, x, learning_rate = 0.1): h = 1e-6 # Compute gradient numerically grad = (func(x + h) - func(x - h)) / (2 * h) # Move in opposite direction return x - learning\nrate * grad# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    i \u2248 (f(x+h) - f(x-h)) / (2\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '\u2248' (U+2248)\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_02/exercises/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5955719947814941,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x) / return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50): results = {} for lr in learning_rates: final_x, _ = gradient_descent(func, gradient_func, initial_x, lr, iterations) / results[lr] = final\nx return results# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x) / return x, history\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x) / return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50): results = {} for lr in learning_rates: final_x, _ = gradient_descent(func, gradient_func, initial_x, lr, iterations) / results[lr] = final\nx return results# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x) / return x, history\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_03/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7444770336151123,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nclass SimpleGDOptimizer: \n\ndef __init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\nclass MomentumOptimizer: \n\ndef __init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.velocity = None def update(self, params, grads): if self.velocity is None: self.velocity = np.zeros_like(params) # Update velocity: v = momentum * v + lr * grads self.velocity = self.momentum * self.velocity + self.lr * grads # Update params: params = params - velocity return params - self.velocity\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100): results = {} for name, optimizer in optimizers.items(): params = initial_params.copy() if isinstance(initial_params, np.ndarray) else initial_params for i in range(iterations): grads = grad_func(params) params = optimizer.update(params, grads) results[name] = params return results\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 2\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nclass SimpleGDOptimizer: \n\ndef __init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\nclass MomentumOptimizer: \n\ndef __init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.velocity = None def update(self, params, grads): if self.velocity is None: self.velocity = np.zeros_like(params) # Update velocity: v = momentum * v + lr * grads self.velocity = self.momentum * self.velocity + self.lr * grads # Update params: params = params - velocity return params - self.velocity\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100): results = {} for name, optimizer in optimizers.items(): params = initial_params.copy() if isinstance(initial_params, np.ndarray) else initial_params for i in range(iterations): grads = grad_func(params) params = optimizer.update(params, grads) results[name] = params return results\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 2\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_04/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7382121086120605,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_covariance_matrix(data): # Center the data (subtract mean) centered = data - np.mean(data, axis=0) # Compute covariance: (1/n) * X^T @ X n = data.shape[0] return (centered.T @ centered) / (n - 1)\ndef pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\ncomponents top_eigenvectors = eigenvectors[:, :n_components] # 6. Project data reduced = centered @ top_eigenvectors # 7. Calculate explained variance ratio explained_variance_ratio = np.sum(eigenvalues[:n_components]) / np.sum(eigenvalues) return reduced, explained_variance_ratio\ndef calculate_variance_explained(eigenvalues, n_components): return np.sum(eigenvalues[:n_components]) / np.sum(eigenvalues)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_covariance_matrix(data): # Center the data (subtract mean) centered = data - np.mean(data, axis=0) # Compute covariance: (1/n) * X^T @ X n = data.shape[0] return (centered.T @ centered) / (n - 1)\ndef pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\ncomponents top_eigenvectors = eigenvectors[:, :n_components] # 6. Project data reduced = centered @ top_eigenvectors # 7. Calculate explained variance ratio explained_variance_ratio = np.sum(eigenvalues[:n_components]) / np.sum(eigenvalues) return reduced, explained_variance_ratio\ndef calculate_variance_explained(eigenvalues, n_components): return np.sum(eigenvalues[:n_components]) / np.sum(eigenvalues)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_05/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6578369140625,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95): n = len(data) / mean = np.mean(data) / std_err = stats.sem(data) # Standard error of the mean # Get t-critical value alpha = 1 - confidence t_critical = stats.t.ppf(1 - alpha/2, df=n-1) # Compute CI margin = t_critical * std\nerr lower = mean - margin upper = mean + margin return (lower, upper) / def t_test_two_samples(sample1, sample2): t_stat, p_value = stats.ttest_ind(sample1, sample2) / return t_stat, p_value\ndef interpret_p_value(p_value, alpha=0.05): if p_value < alpha: return f\"Significant difference (p={p_value:.4f} < {alpha})\" else: return f\"No significant difference (p={p_value:.4f} >= {alpha})\"def compare_models(model1_scores, model2_scores, alpha=0.05): # Compute means and CIs mean1 = np.mean(model1_scores) / mean2 = np.mean(model2_scores) / ci1 = compute_confidence_interval(model1_scores) / ci2 = compute_confidence_interval(model2_scores) # Perform t-test t\nstat, p_value = t_test_two_samples(model1_scores, model2_scores) # Interpret interpretation = interpret_p_value(p_value, alpha) / return { 'model1_mean': mean1, 'model2_mean': mean2, 'model1_ci': ci1, 'model2_ci': ci2, 't_statistic': t_stat, 'p_value': p_value, 'interpretation': interpretation, 'significant': p\nvalue < alpha }\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    value < alpha }\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95): n = len(data) / mean = np.mean(data) / std_err = stats.sem(data) # Standard error of the mean # Get t-critical value alpha = 1 - confidence t_critical = stats.t.ppf(1 - alpha/2, df=n-1) # Compute CI margin = t_critical * std\nerr lower = mean - margin upper = mean + margin return (lower, upper) / def t_test_two_samples(sample1, sample2): t_stat, p_value = stats.ttest_ind(sample1, sample2) / return t_stat, p_value\ndef interpret_p_value(p_value, alpha=0.05): if p_value < alpha: return f\"Significant difference (p={p_value:.4f} < {alpha})\" else: return f\"No significant difference (p={p_value:.4f} >= {alpha})\"def compare_models(model1_scores, model2_scores, alpha=0.05): # Compute means and CIs mean1 = np.mean(model1_scores) / mean2 = np.mean(model2_scores) / ci1 = compute_confidence_interval(model1_scores) / ci2 = compute_confidence_interval(model2_scores) # Perform t-test t\nstat, p_value = t_test_two_samples(model1_scores, model2_scores) # Interpret interpretation = interpret_p_value(p_value, alpha) / return { 'model1_mean': mean1, 'model2_mean': mean2, 'model1_ci': ci1, 'model2_ci': ci2, 't_statistic': t_stat, 'p_value': p_value, 'interpretation': interpretation, 'significant': p\nvalue < alpha }\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    value < alpha }\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    }
  ],
  "summary": {
    "passed": 633,
    "failed": 184,
    "pass_rate": 77.47858017135863
  }
}