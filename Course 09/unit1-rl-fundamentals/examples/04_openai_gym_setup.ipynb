{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up RL Environment: OpenAI Gym\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "- Install and set up OpenAI Gym\n",
    "- Understand Gym environments (spaces, observations, actions)\n",
    "- Interact with Gym environments (step, reset, render)\n",
    "- Explore different Gym environments (CartPole, FrozenLake, etc.)\n",
    "- Set up Python-based frameworks for RL\n",
    "\n",
    "## ðŸ”— Prerequisites\n",
    "\n",
    "- âœ… Python 3.8+ installed\n",
    "- âœ… pip package manager\n",
    "- âœ… Basic Python knowledge (functions, classes, loops)\n",
    "- âœ… Understanding of RL basics (agent, environment, rewards)\n",
    "\n",
    "---\n",
    "\n",
    "## Official Structure Reference\n",
    "\n",
    "This notebook covers practical activities from **Course 09, Unit 1**:\n",
    "- Setting up RL environment: installing OpenAI Gym and using Python-based frameworks for RL\n",
    "- **Source:** `DETAILED_UNIT_DESCRIPTIONS.md` - Unit 1 Practical Content\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**OpenAI Gym** is a toolkit for developing and comparing reinforcement learning algorithms. It provides a standardized interface for RL environments, making it easy to test algorithms across different problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI Gym (run this once)\n",
    "# !pip install gym matplotlib numpy\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(f\"OpenAI Gym version: {gym.__version__}\")\n",
    "print(\"\\nSetting up RL Environment: OpenAI Gym\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Installing and Setting Up OpenAI Gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Part 1: Installing and Setting Up OpenAI Gym\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. Installation:\")\n",
    "print(\" pip install gym\")\n",
    "print(\" (or: pip install gymnasium # newer version)\")\n",
    "\n",
    "print(\"\\n2. Import gym:\")\n",
    "print(\" import gym\")\n",
    "\n",
    "print(\"\\n3. List available environments:\")\n",
    "print(\" from gym import envs\")\n",
    "print(\" print(envs.registry.all())\")\n",
    "\n",
    "# List some popular environments\n",
    "print(\"\\n3. Popular Gym Environments:\")\n",
    "popular\n",
    "envs = [\n",
    " \"CartPole-v1\", \"FrozenLake-v1\",\n",
    " \"MountainCar-v0\",\n",
    " \"Acrobot-v1\",\n",
    " \"LunarLander-v2\"\n",
    "]\n",
    "for env_name in popular_envs:\n",
    " print(f\" - {env_name}\")\n",
    "\n",
    "print(\"\\nâœ… Gym setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Gym Environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 2: Understanding Gym Environments\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Interacting with Gym Environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 3: Interacting with Gym Environments\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Exploring Different Gym Environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 4: Exploring Different Gym Environments\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **OpenAI Gym**: Standard toolkit for RL environments\n",
    "2. **Environment Interface**: reset(), step(action), render()\n",
    "3. **Spaces**: Observation space and action space define valid inputs/outputs\n",
    "4. **Environments**: CartPole, FrozenLake, MountainCar, etc.\n",
    "\n",
    "### Setup Steps:\n",
    "1. Install: `pip install gym`\n",
    "2. Import: `import gym`\n",
    "3. Create: `env = gym.make('EnvironmentName-v1')`\n",
    "4. Interact: reset, step, render, close\n",
    "\n",
    "### Common Environments:\n",
    "- **CartPole-v1**: Balance a pole on a cart\n",
    "- **FrozenLake-v1**: Navigate a frozen lake grid\n",
    "- **MountainCar-v0**: Drive a car up a hill\n",
    "- **LunarLander-v2**: Land a spaceship\n",
    "\n",
    "### Next Steps:\n",
    "- Implement RL algorithms (Q-learning, DQN)\n",
    "- Train agents in these environments\n",
    "- Compare algorithm performance\n",
    "\n",
    "**Reference:** Course 09, Unit 1: \"Introduction to Reinforcement Learning\" - Setting up RL environment practical content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}