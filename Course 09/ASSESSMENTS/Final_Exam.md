# Final Exam: Reinforcement Learning
## AIAT 123

**Time Limit:** 2 hours  
**Total Points:** 100 points  
**Instructions:** Answer all questions. Show your work for partial credit.

---

## Part 1: Multiple Choice (30 points)

### Question 1 (5 points)
**CLO1:** What are the main components of an RL system?

A) Only agent  
B) Agent, environment, actions, rewards, states  
C) Only environment  
D) Only rewards

---

### Question 2 (5 points)
**CLO2:** What does Q-learning learn?

A) Policy directly  
B) Action-value function Q(s,a)  
C) Only value function  
D) Only rewards

---

### Question 3 (5 points)
**CLO3:** What is the main advantage of Deep Q-Networks (DQN)?

A) They are simpler  
B) They can handle high-dimensional state spaces  
C) They don't need experience replay  
D) They are always faster

---

### Question 4 (5 points)
**CLO4:** What is the exploration-exploitation dilemma?

A) Only exploration  
B) Balancing trying new actions vs using known good actions  
C) Only exploitation  
D) No dilemma exists

---

### Question 5 (5 points)
**CLO5:** Which is a real-world application of RL?

A) Only games  
B) Game AI, robotics, recommendation systems, autonomous vehicles  
C) Only robotics  
D) Only games and robotics

---

### Question 6 (5 points)
**CLO6:** What ethical concern is specific to RL?

A) Only bias  
B) Safety in exploration, reward hacking, unintended behaviors  
C) Only privacy  
D) No ethical concerns

---

## Part 2: Short Answer Questions (30 points)

### Question 7 (10 points)
**CLO1:** Explain the Markov Decision Process (MDP) framework. What are states, actions, rewards, and the transition function?

---

### Question 8 (10 points)
**CLO2:** Compare Q-learning and Policy Gradient methods. When would you use each?

---

### Question 9 (10 points)
**CLO3:** Explain how experience replay works in DQN and why it's important for stable training.

---

## Part 3: Practical/Coding Questions (25 points)

### Question 10 (15 points)
**CLO2:** Implement Q-learning algorithm for a simple grid world environment:
- 5x5 grid
- Start at (0,0), goal at (4,4)
- Actions: up, down, left, right
- Reward: +10 for goal, -1 for each step
- Implement Q-table updates and action selection

---

### Question 11 (10 points)
**CLO3:** Write code to create a simple DQN agent using PyTorch for the CartPole environment.

---

## Part 4: Case Study / Real-World Application (15 points)

### Question 12 (15 points)
**CLO5, CLO6:** Design an RL system for optimizing ad placement on a website:
1. Define the RL problem (states, actions, rewards)
2. Choose appropriate RL algorithm
3. Address exploration-exploitation balance
4. Consider ethical implications (user privacy, manipulation)
5. Evaluation strategy

---

**End of Exam**

**Good Luck!**
